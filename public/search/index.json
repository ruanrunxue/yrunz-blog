[{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：备忘录模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 适配器模式（Adapter）是最常用的结构型模式之一，在现实生活中，适配器模式也是处处可见，比如电源插头转换器，它可以让英式的插头工作在中式的插座上。\nGoF 对它的定义如下：\n Convert the interface of a class into another interface clients expect. Adapter lets classes work together that couldn’t otherwise because of incompatible interfaces.\n 简单来说，就是适配器模式让原本因为接口不匹配而无法一起工作的两个类/结构体能够一起工作。\n适配器模式所做的就是将一个接口 Adaptee，通过适配器 Adapter 转换成 Client 所期望的另一个接口 Target 来使用，实现原理也很简单，就是 Adapter 通过实现 Target 接口，并在对应的方法中调用 Adaptee 的接口实现。\nUML 结构 场景上下文 在 简单的分布式应用系统（示例代码工程）中，db 模块用来存储服务注册信息和系统监控数据，它是一个 key-value 数据库。在 访问者模式 中，我们为它实现了 Table 的按列查询功能；同时，我们也为它实现了简单的 SQL 查询功能（将会在 解释器模式 中介绍），查询的结果是 SqlResult 结构体，它提供一个 toMap 方法将结果转换成 map 。\n为了方便用户使用，我们将实现在终端控制台上提供人机交互的能力，如下所示，用户输入 SQL 语句，后台返回查询结果：\n终端控制台的具体实现为 Console，为了提供可扩展的查询结果显示样式，我们设计了 ConsoleRender 接口，但因 SqlResult 并未实现该接口，所以 Console 无法直接渲染 SqlResult 的查询结果。\n为此，我们需要实现一个适配器，让 Console 能够通过适配器将 SqlResult 的查询结果渲染出来。示例中，我们设计了适配器 TableRender，它实现了 ConsoleRender 接口，并以表格的形式渲染出查询结果，如前文所示。\n代码实现 // demo/db/sql.go package db // Adaptee SQL语句执行返回的结果，并未实现Target接口 type SqlResult struct { fields []string vals []interface{} } func (s *SqlResult) Add(field string, record interface{}) { s.fields = append(s.fields, field) s.vals = append(s.vals, record) } func (s *SqlResult) ToMap() map[string]interface{} { results := make(map[string]interface{}) for i, f := range s.fields { results[f] = s.vals[i] } return results } // demo/db/console.go package db // Client 终端控制台 type Console struct { db Db } // Output 调用ConsoleRender完成对查询结果的渲染输出 func (c *Console) Output(render ConsoleRender) { fmt.Println(render.Render()) } // Target接口，控制台db查询结果渲染接口 type ConsoleRender interface { Render() string } // TableRender表格形式的查询结果渲染Adapter // 关键点1: 定义Adapter结构体/类 type TableRender struct { // 关键点2: 在Adapter中聚合Adaptee，这里是把SqlResult作为TableRender的成员变量  result *SqlResult } // 关键点3: 实现Target接口，这里是实现了ConsoleRender接口 func (t *TableRender) Render() string { // 关键点4: 在Target接口实现中，调用Adaptee的原有方法实现具体的业务逻辑  vals := t.result.ToMap() var header []string var data []string for key, val := range vals { header = append(header, key) data = append(data, fmt.Sprintf(\u0026#34;%v\u0026#34;, val)) } builder := \u0026amp;strings.Builder{} table := tablewriter.NewWriter(builder) table.SetHeader(header) table.Append(data) table.Render() return builder.String() } // 这里是另一个Adapter，实现了将error渲染的功能 type ErrorRender struct { err error } func (e *ErrorRender) Render() string { return e.err.Error() } 客户端这么使用：\nfunc (c *Console) Start() { fmt.Println(\u0026#34;welcome to Demo DB, enter exit to end!\u0026#34;) fmt.Println(\u0026#34;\u0026gt; please enter a sql expression:\u0026#34;) fmt.Print(\u0026#34;\u0026gt; \u0026#34;) scanner := bufio.NewScanner(os.Stdin) for scanner.Scan() { sql := scanner.Text() if sql == \u0026#34;exit\u0026#34; { break } result, err := c.db.ExecSql(sql) if err == nil { // 关键点5：在需要Target接口的地方，传入适配器Adapter实例，其中创建Adapter实例时需要传入Adaptee实例  c.Output(NewTableRender(result)) } else { c.Output(NewErrorRender(err)) } fmt.Println(\u0026#34;\u0026gt; please enter a sql expression:\u0026#34;) fmt.Print(\u0026#34;\u0026gt; \u0026#34;) } } 在已经有了 Target 接口（ConsoleRender）和 Adaptee（SqlResult）的前提下，总结实现适配器模式的几个关键点：\n 定义 Adapter 结构体/类，这里是 TableRender 结构体。 在 Adapter 中聚合 Adaptee，这里是把 SqlResult 作为 TableRender 的成员变量。 Adapter 实现 Target 接口，这里是 TableRender 实现了 ConsoleRender 接口。 在 Target 接口实现中，调用 Adaptee 的原有方法实现具体的业务逻辑，这里是在 TableRender.Render() 调用 SqlResult.ToMap() 方法，得到查询结果，然后再对结果进行渲染。 在 Client 需要 Target 接口的地方，传入适配器 Adapter 实例，其中创建 Adapter 实例时传入 Adaptee 实例。这里是在 NewTableRender() 创建 TableRender 实例时，传入 SqlResult 作为入参，随后将 TableRender 实例传入 Console.Output() 方法。  扩展 适配器模式在 Gin 中的运用 Gin 是一个高性能的 Web 框架，它的常见用法如下：\n// 用户自定义的请求处理函数，类型为gin.HandlerFunc func myGinHandler(c *gin.Context) { ... // 具体处理请求的逻辑 } func main() { // 创建默认的route引擎,类型为gin.Engine  r := gin.Default() // route定义  r.GET(\u0026#34;/my-route\u0026#34;, myGinHandler) // route引擎启动  r.Run() } 在实际运用场景中，可能存在这种情况。用户起初的 Web 框架使用了 Go 原生的 net/http，使用场景如下：\n// 用户自定义的请求处理函数，类型为http.Handler func myHttpHandler(w http.ResponseWriter, r *http.Request) { ... // 具体处理请求的逻辑 } func main() { // route定义  http.HandleFunc(\u0026#34;/my-route\u0026#34;, myHttpHandler) // route启动  http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } 因性能问题，当前客户准备切换至 Gin 框架，显然，myHttpHandler 因接口不兼容，不能直接注册到 gin.Default() 上。为了方便用户，Gin 框架提供了一个适配器 gin.WrapH，可以将 http.Handler 类型转换成 gin.HandlerFunc 类型，它的定义如下：\n// WrapH is a helper function for wrapping http.Handler and returns a Gin middleware. func WrapH(h http.Handler) HandlerFunc { return func(c *Context) { h.ServeHTTP(c.Writer, c.Request) } } 使用方法如下：\n// 用户自定义的请求处理函数，类型为http.Handler func myHttpHandler(w http.ResponseWriter, r *http.Request) { ... // 具体处理请求的逻辑 } func main() { // 创建默认的route引擎  r := gin.Default() // route定义  r.GET(\u0026#34;/my-route\u0026#34;, gin.WrapH(myHttpHandler)) // route引擎启动  r.Run() } 在这个例子中，gin.Engine 就是 Client，gin.HandlerFunc 是 Target 接口，http.Handler 是 Adaptee，gin.WrapH 是 Adapter。这是一个 Go 风格的适配器模式实现，以更为简洁的 func 替代了 struct。\n典型应用场景  将一个接口 A 转换成用户希望的另外一个接口 B，这样就能使原来不兼容的接口 A 和接口 B 相互协作。 老系统的重构。在不改变原有接口的情况下，让老接口适配到新的接口。  优缺点 优点  能够使 Adaptee 和 Target 之间解耦。通过引入新的 Adapter 来适配 Target，Adaptee 无须修改，符合开闭原则。 灵活性好，能够很方便地通过不同的适配器来适配不同的接口。  缺点  增加代码复杂度。适配器模式需要新增适配器，如果滥用会导致系统的代码复杂度增大。  与其他模式的关联 适配器模式 和 装饰者模式、代理模式 在 UML 结构上具有一定的相似性。但适配器模式改变原有对象的接口，但不改变原有功能；而装饰者模式和代理模式则在不改变接口的情况下，增强原有对象的功能。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] Design Patterns, Chapter 4. Structural Patterns, GoF\n[3] 适配器模式, refactoringguru.cn\n[4] Gin Web Framework, Gin\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2023-12-10T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：适配器模式"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：命令模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 相对于代理模式、工厂模式等设计模式，备忘录模式（Memento）在我们日常开发中出镜率并不高，除了应用场景的限制之外，另一个原因，可能是备忘录模式 UML 结构的几个概念比较晦涩难懂，难以映射到代码实现中。比如 Originator（原发器）和 Caretaker（负责人），从字面上很难看出它们在模式中的职责。\n但从定义来看，备忘录模式又是简单易懂的，GoF 对备忘录模式的定义如下：\n Without violating encapsulation, capture and externalize an object’s internal state so that the object can be restored to this state later.\n 也即，在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外进行保存，以便在未来将对象恢复到原先保存的状态。\n从定义上看，备忘录模式有几个关键点：封装、保存、恢复。\n对状态的封装，主要是为了未来状态修改或扩展时，不会引发霰弹式修改；保存和恢复则是备忘录模式的主要特点，能够对当前对象的状态进行保存，并能够在未来某一时刻恢复出来。\n现在，在回过头来看备忘录模式的 3 个角色就比较好理解了：\n Memento（备忘录）：是对状态的封装，可以是 struct ，也可以是 interface。 Originator（原发器）：备忘录的创建者，备忘录里存储的就是 Originator 的状态。 Caretaker（负责人）：负责对备忘录的保存和恢复，无须知道备忘录中的实现细节。  UML 结构 场景上下文 在前文 【Go实现】实践GoF的23种设计模式：命令模式 我们提到，在 简单的分布式应用系统（示例代码工程）中，db 模块用来存储服务注册信息和系统监控数据。其中，服务注册信息拆成了 profiles 和 regions 两个表，在服务发现的业务逻辑中，通常需要同时操作两个表，为了避免两个表数据不一致的问题，db 模块需要提供事务功能:\n事务的核心功能之一是，当其中某个语句执行失败时，之前已执行成功的语句能够回滚，前文我们已经介绍如何基于 命令模式 搭建事务框架，下面我们将重点介绍，如何基于备忘录模式实现失败回滚的功能。\n代码实现 // demo/db/transaction.go package db // Command 执行数据库操作的命令接口，同时也是备忘录接口 // 关键点1：定义Memento接口，其中Exec方法相当于UML图中的SetState方法，调用后会将状态保存至Db中 type Command interface { Exec() error // Exec 执行insert、update、delete命令  Undo() // Undo 回滚命令  setDb(db Db) // SetDb 设置关联的数据库 } // 关键点2：定义Originator，在本例子中，状态都是存储在Db对象中 type Db interface {...} // Transaction Db事务实现，事务接口的调用顺序为begin -\u0026gt; exec -\u0026gt; exec \u0026gt; ... -\u0026gt; commit // 关键点3：定义Caretaker，Transaction里实现了对语句的执行（Do）和回滚（Undo）操作 type Transaction struct { name string // 关键点4：在Caretaker（Transaction）中引用Originator（Db）对象，用于后续对其状态的保存和恢复  db Db // 注意，这里的cmds并非备忘录列表，真正的history在Commit方法中  cmds []Command } // Begin 开启一个事务 func (t *Transaction) Begin() { t.cmds = make([]Command, 0) } // Exec 在事务中执行命令，先缓存到cmds队列中，等commit时再执行 func (t *Transaction) Exec(cmd Command) error { if t.cmds == nil { return ErrTransactionNotBegin } cmd.setDb(t.db) t.cmds = append(t.cmds, cmd) return nil } // Commit 提交事务，执行队列中的命令，如果有命令失败，则回滚后返回错误 func (t *Transaction) Commit() error { // 关键点5：定义备忘录列表，用于保存某一时刻的系统状态  history := \u0026amp;cmdHistory{history: make([]Command, 0, len(t.cmds))} for _, cmd := range t.cmds { // 关键点6：执行Do方法  if err := cmd.Exec(); err != nil { // 关键点8：当Do方法执行失败时，则进行Undo操作，根据备忘录history中的状态进行回滚  history.rollback() return err } // 关键点7：如果Do方法执行成功，则将状态（cmd）保存在备忘录history中  history.add(cmd) } return nil } // cmdHistory 命令执行历史 type cmdHistory struct { history []Command } func (c *cmdHistory) add(cmd Command) { c.history = append(c.history, cmd) } func (c *cmdHistory) rollback() { for i := len(c.history) - 1; i \u0026gt;= 0; i-- { c.history[i].Undo() } } // InsertCmd 插入命令 // 关键点9: 定义具体的备忘录类，实现Memento接口 type InsertCmd struct { db Db tableName string primaryKey interface{} newRecord interface{} } func (i *InsertCmd) Exec() error { return i.db.Insert(i.tableName, i.primaryKey, i.newRecord) } func (i *InsertCmd) Undo() { i.db.Delete(i.tableName, i.primaryKey) } func (i *InsertCmd) setDb(db Db) { i.db = db } // UpdateCmd 更新命令 type UpdateCmd struct {...} // DeleteCmd 删除命令 type DeleteCmd struct {...} 客户端可以这么使用：\nfunc client() { transaction := db.CreateTransaction(\u0026#34;register\u0026#34; + profile.Id) transaction.Begin() rcmd := db.NewUpdateCmd(regionTable).WithPrimaryKey(profile.Region.Id).WithRecord(profile.Region) transaction.Exec(rcmd) pcmd := db.NewUpdateCmd(profileTable).WithPrimaryKey(profile.Id).WithRecord(profile.ToTableRecord()) transaction.Exec(pcmd) if err := transaction.Commit(); err != nil { return ... } return ... } 这里并没有完全按照标准的备忘录模式 UML 进行实现，但本质是一样的，总结起来有以下几个关键点：\n 定义抽象备忘录 Memento 接口，这里为 Command 接口。Command 的实现是具体的数据库执行操作，并且存有对应的回滚操作，比如 InsertCmd 为“插入”操作，其对应的回滚操作为“删除”，我们保存的状态就是“删除”这一回滚操作。 定义 Originator 结构体/接口，这里为 Db 接口。备忘录 Command 记录的就是它的状态。 定义 Caretaker 结构体/接口，这里为 Transaction 结构体。Transaction 采用了延迟执行的设计，当调用 Exec 方法时只会将命令缓存到 cmds 队列中，等到调用 Commit 方法时才会执行。 在 Caretaker 中引用 Originator 对象，用于后续对其状态的保存和恢复。这里为 Transaction 聚合了 Db。 在 Caretaker 中定义备忘录列表，用于保存某一时刻的系统状态。这里为在 Transaction.Commit 方法中定义了 cmdHistory 对象，保存一直执行成功的 Command。 执行 Caretaker 具体的业务逻辑，这里为在 Transaction.Commit 中调用 Command.Exec 方法，执行具体的数据库操作命令。 业务逻辑执行成功后，保存当前的状态。这里为调用 cmdHistory.add 方法将 Command 保存起来。 如果业务逻辑执行失败，则恢复到原来的状态。这里为调用cmdHistory.rollback 方法，反向执行已执行成功的 Command 的 Undo 方法进行状态恢复。 根据具体的业务需要，定义具体的备忘录，这里定义了InsertCmd 、UpdateCmd 和 DeleteCmd 。  扩展 MySQL 的 undo log 机制 MySQL 的 undo log（回滚日志）机制本质上用的就是备忘录模式的思想，前文中 Transaction 回滚机制实现的方法参考的就是 undo log 机制。\nundo log 原理是，在提交事务之前，会把该事务对应的回滚操作（状态）先保存到 undo log 中，然后再提交事务，当出错的时候 MySQL 就可以利用 undo log 来回滚事务，即恢复原先的记录值。\n比如，执行一条插入语句：\ninsertintoregion(id,name)values(1,\u0026#34;beijing\u0026#34;);那么，写入到 undo log 中对应的回滚语句为：\ndeletefromregionwhereid=1;当执行一条语句失败，需要回滚时，MySQL 就会从读取对应的回滚语句来执行，从而将数据恢复至事务提交之前的状态。undo log 是 MySQL 实现事务回滚和多版本控制（MVCC）的根基。\n典型应用场景  事务回滚。事务回滚的一种常见实现方法是 undo log，其本质上用的就是备忘录模式。 系统快照（Snapshot）。多版本控制的用法，保存某一时刻的系统状态快照，以便在将来能够恢复。 撤销功能。比如 Microsoft Offices 这类的文档编辑软件的撤销功能。  优缺点 优点  提供了一种状态恢复的机制，让系统能够方便地回到某个特定状态下。 实现了对状态的封装，能够在不破坏封装的前提下实现状态的保存和恢复。  缺点  资源消耗大。系统状态的保存意味着存储空间的消耗，本质上是空间换时间的策略。undo log 是一种折中方案，保存的状态并非某一时刻数据库的所有数据，而是一条反操作的 SQL 语句，存储空间大大减少。 并发安全。在多线程场景，实现备忘录模式时，要注意在保证状态的不变性，否则可能会有并发安全问题。  与其他模式的关联 在实现 Undo/Redo 操作时，你通常需要同时使用 备忘录模式 与 命令模式。\n另外，当你需要遍历备忘录对象中的成员时，通常会使用 迭代器模式，以防破坏对象的封装。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：命令模式, 元闰子\n[3] Design Patterns, Chapter 5. Behavioral Patterns, GoF\n[4] 备忘录模式, refactoringguru.cn\n[5] MySQL 8.0 Reference Manual :: 15.6.6 Undo Logs, MySQL\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2023-11-25T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：备忘录模式"},{"content":" 上一篇：《纳瓦尔宝典》：如何积累财富？\n 你幸福吗？ “你幸福吗？”，看到这个问题，你的第一反应是什么？\n在孩童时候，我们常常会这样说，“我的梦想是\u0026hellip;，然后过上幸福的生活。”，但是，实现了梦想，就真的能获得幸福吗？有人的梦想是开公司做老板，但成为公司老板之后，可能会面临工作压力大、应酬多、陪伴家人时间少等问题，幸福感依然不强。\n所以，幸福到底是什么？我们要做些什么才能真正获得幸福？世俗意义上的成功与幸福是什么样的关系？\n对于这些问题，纳瓦尔有他的理解。\n什么是幸福？ 幸福很难有一个标准的定义，有人认为幸福是欲望得到满足、财富自由；也有人认为幸福是知足常乐、身体健康。\n在纳瓦尔看来，幸福是一种没有缺憾感、无欲无求、活在当下的状态。\n幸福并不是一种客观存在，而是一种主观感受。大自然并没有“幸福”和“不幸福”的概念，它只存在于我们大脑之中，因为我们有了欲望，才会给事物打上“好”和“不好”的标签。\n也因为有了欲望，人们才会深陷于过去的“错误”之中，总想着“要是\u0026hellip;，就好了”；才会对未来的“失败”深深恐惧，总想着“如果\u0026hellip;，那该怎么办”。这让我们长期处于焦虑的状态，从而无法真正感受当下，怎会幸福。\n而当你无欲无求时，自然也就不会悔不当初、不会谋求未来，此时此刻，你的内心会是一片宁静，是满足的，是快乐的，是幸福的。\n如何获得幸福 幸福，不是天生的，与基因无关，而是一种技能，能够通过后天习得的技能。\n就像可以通过锻炼来提高身体素质一样，我们也能通过刻意的练习来提高幸福感，可以尝试这么做：\n 降低自己的身份感。我们都只是浩瀚宇宙中的一粒尘埃，没那么重要，关注自己就好。 屏蔽脑海中的噪音和杂念、不在乎那些无关紧要的事。人的精力是有限的，想得越多，做得就越少，就越焦虑。 冥想。冥想是锻炼屏蔽杂念能力的一个好方法。 远离郁郁寡欢的人、和快乐知足的人相处。情绪是会传染的，想要获得幸福，就要经常跟幸福的人相处。 珍惜时间。  幸福，需要心境平和、活在当下。\n在任何时候，我们的大脑都只有很小一部分是关注当下的，大部分精力都在规划未来或悔恨过去。比如，在下班的路上，我们可能会想今天的工作怎么又没做好，也可能会想明天的汇报该怎么办，但很少会关注此时此刻走路时身体的状态，或感受周围的环境。\n这样的状态，我们很难获得绝妙的生活体验，无法欣赏身边的一切美好；如果每天都沉浸于过去或未来，那无疑是亲手扼杀自己的幸福。\n要想活在当下，必须要做到心境平和。但是，事情总是一件压着一件，永远有做不完的事，所以焦虑感才会普遍存在。那么，要怎样才能做到心境平和呢？\n纳瓦尔的方法是，不与焦虑对抗，接受这一现实，并不断问自己，“我是想一直执着于这些想法，还是想重获内心的平静？”，答案显而易见。于接受中寻找幸福，是我们必备的技能。\n幸福，源于好习惯。\n孩童时候的我们，幸福感都差不多。然而随着年龄的增长，有些人的幸福感越来越强，而有些人变得越来越不快乐，一个重要的原因就是，两类人群习惯不同。\n好的习惯可能会导致短暂的痛苦，但会带来长期的幸福。比如，少喝酒少吃糖、远离社交媒体，都能提高情绪稳定性；不好的习惯能带来短暂的快感，却会摧毁长期的幸福，比如沉迷电子游戏、抽烟酗酒。\n而幸福生活的本质，就是不断用精心培养的好习惯，去替换那些在不经意间养成的坏习惯。\n成功与幸福 很多人把成功和幸福划上等号，而纳瓦尔则认为两者存在一定的冲突。幸福就是满足现状；而成功源于对现状的不满，是对现在的改造。\n这里纳瓦尔所说的成功，指的是物质上的成功，对此，他是这样的解释的：再好的东西，很快就会习惯，它们无法持续带来刺激或愉快的感觉。人类的本性是贪婪的，普通人追求物质成功的脚步很难停下来，而追逐过程本就是对现状不满的过程。\n所以，不要过度执着于成功，欲望是主动选择的不开心，减少欲望，反而能使幸福感增加。\n最后 每个人对幸福的理解都各有不同；同一个人在不同年龄段，对幸福的理解也会有所差异。\n我们可以参考纳瓦尔的幸福观，并得到一些启发，但更重要的是，探索出此时此刻自己对幸福的定义。\n 参考 [1] 纳瓦尔宝典，埃里克·乔根森\n[2] 《纳瓦尔宝典》：如何积累财富？，元闰子\n[3] 《认知觉醒》的读后感，元闰子\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2023-11-19T00:00:00Z","permalink":"https://www.yrunz.com/p/%E7%BA%B3%E7%93%A6%E5%B0%94%E5%AE%9D%E5%85%B8%E5%A6%82%E4%BD%95%E8%8E%B7%E5%BE%97%E5%B9%B8%E7%A6%8F/","title":"《纳瓦尔宝典》：如何获得幸福？"},{"content":"关于《纳瓦尔宝典》 《纳瓦尔宝典》的主角，纳瓦尔·拉维康特，是一名成功的创业者和天使投资人，典型的硅谷大佬。本书收集整理了他的一些智慧箴言，它与记录查理·芒格智慧箴言的《穷查理宝典》有着相似的出发点，给大众传授大师的人生建议。\n从书的副标题“财富与幸福指南”能看出，它的主题是关于如何积累财富和获得幸福人生。《纳瓦尔宝典》并非教你如何投资，而更偏向个人成长。与它类似的，除了前面提到的《穷查理宝典》，还有《认知觉醒》、《财富自由之路》等，都是好书，都值得一读。\n本文主要总结《纳瓦尔宝典》中关于“积累财富”的一些人生建议。\n财富是什么？ 很多人会把“金钱”和“财富”划上等号，但这两者有着本质的区别。纳瓦尔对财富给出了通俗易懂的定义：\n 财富就是在你睡觉时也可以帮你赚钱的资产\n 比如可出租的房子、投入生产的工厂、持续工作的计算机程序等，都是常见的财富。\n而金钱只是转移财富的方式，是社会的信用符号，具有调用别人时间的能力。\n大多数人终其一生都在追求财富，我们努力工作、省吃俭用，却仍然没能做到财富自由。\n所以，获得财富跟努力程度没有必然的联系，与埋头苦干相比，更重要的是选择正确的方向。想要获得财富，你必须要知道做什么、怎么做、什么时候做。\n我要做什么？ 这世上，有很多获得财富的成功案例，但并非所有案例都适合你。盲目追求热点，并不会带来财富，关键是找到你的专长。\n 专长指的是无法通过培训获得的知识。如果社会可以培训你，那么社会也可以培训他人来取代你。\n 每个人的 DNA 里或多或少都会有一些比大多数人都擅长的东西，我们把它称为，专长和天赋。这是与生俱来的，其他人很难通过社会培训习得，或者需要付出巨大的代价。\n在“成为你自己”这件事上，没人能做得比你好，\n专长能带来差异化的竞争力，而你要做的，就是要持续地扩大你的优势，彻底一骑绝尘。\n识别自己的专长并不容易，这需要对自身有一个全面的了解，可以尝试这样：\n 从儿童时代开始回顾，找到那些别人要很努力，而你却毫无费劲就能完成的事。 从自己的兴趣中寻找，不是三分钟热度，而是你愿意为之付出一辈子的事。  我要怎么做？ 杠杆效应  给我一个支点，我可以翘起整个地球。 —— 阿基米德\n 当你找到自己的专长后，下一步就是，利用杠杆效应把专长规模化。一般来说，杠杆有 3 种：\n  劳动力杠杆，也即让别人给你打工。这是最古老的一种杠杆，但在现代社会中最低效。人员管理是一件极其复杂、极具挑战的工作，需要高超的领导技巧。\n  资本杠杆，也即利用今钱来扩大影响力。这是一种更现代的杠杆，虽然也需要一定的技巧，但管理资本要比管理人简单得多。但前提是，有钱。\n  复制边际成本为零的产品（下文统称新型杠杆），这是最新出现的一种杠杆，也是普通人最能触及的，并且借助互联网能够产生爆发式的增长，比如，书籍、媒体、代码。\n  使用劳动力杠杆需要有人追随你；使用资本杠杆需要资金；使用新型杠杆只需一台电脑或手机，而且无须经过他人的许可。\n其中，代码是最强大的一种杠杆，只需运行一台计算机就够了。并且，随着 SaaS 愈发成熟，普通人利用代码来规模化产品也变得愈发简单。\n复利效应  复利是世界第八大奇迹。知之者赚、不知之者被赚。—— 爱因斯坦\n 复利不仅仅适用于金融领域，在知识、经验、专长等方面，只要能积累的东西，都能产生复利效应。\n明确了杠杆后，下一步就是相信复利效应，坚持、坚持、再坚持。没有一夜暴富，成功需要时间，需要你对自己热爱的事物孜孜不倦，需要你的专长不断精进，需要你相信时间的力量。\n我要什么时候做？ 答案只有一个，现在！\n财富是人生的终极目标吗？ 财富不是人生的终极目标，幸福才是。财富只是通往幸福的一种工具，两者不能划等号，富豪的幸福感不见得一定比普通人的强。相比学习如何获得财富，其实，我们更应该学习如何获得幸福。\n下一篇，我们将总结纳瓦尔关于如何获得幸福的建议。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 纳瓦尔宝典，埃里克·乔根森\n[2] 如何超过大多数人, 酷壳 左耳朵耗子\n[3] 《认知觉醒》的读后感，元闰子\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2023-11-05T00:00:00Z","permalink":"https://www.yrunz.com/p/%E7%BA%B3%E7%93%A6%E5%B0%94%E5%AE%9D%E5%85%B8%E5%A6%82%E4%BD%95%E7%A7%AF%E7%B4%AF%E8%B4%A2%E5%AF%8C/","title":"《纳瓦尔宝典》：如何积累财富？"},{"content":"我想，2022 年的关键字，是“变”，工作、生活、心态都在变。人，总是趋于稳定；然而，变，才是生命中的主旋律。变化来临时，我们通常会经历阻力、挫折、迷茫，如何面对这些，将人分成了不同的样子。有人迷失自我、随波逐流；有人保持初心、逆风前行。\n薛定谔说，“人活着就是在对抗熵增定律，生命以负熵为生。”\n但是，在变化中保持不变的初心，很难。自问在过去的一年里·做到了吗？有点，但不多。2022 年也曾迷茫过，所幸每次都能调整回来，阅读、写作、生活，一直都在。\n阅读 2022 年读过的书不多，读完的，也才一半。\n最近一直在反思，人的精力是有限的，但书是无尽的；不同的书、同一本书的不同章节，质量也参差不齐。这种情况下，选择读什么、怎么读变得尤为重要。最直接地，读经典。但经典也很多、很厚，全部读完，也很难。\n所以，还是要回到根本问题，你为什么要读书？\n个人以为，如果想学习一门技术、弄清楚一个问题，那么可以选读相关章节；如果是想提升人文素养、获得人生感悟，那么还是通读为好。所以，我的阅读策略慢慢调整为，选读技术类书籍，通读人文类书籍。不管那种方式，读书过程中，思考是必不可少的。\n Computer Systems A Programmers Perspective (3rd edition)，中文名 深入理解计算机系统。CSAPP 不必多说，被誉为计算机必读经典，缺点是，难啃。今年因工作需要，专门把第二章精读了一遍，对数值类型有了更深刻的理解，还写了总结 深入理解计算机系统的数值类型。 Database System Concepts (7th edithion)，中文名 数据库系统概念。数据库领域的经典，值得通读，结合 CMU 的公开课更佳，目前只读到了第四章。 Clean Agile: Back to Basics，中文名 敏捷整洁之道。Martin 大叔继 代码整洁之道、架构整洁之道 之后的又一力作，介绍软件敏捷开发的流程。印象最深的一点是，项目管理是一个在 Good、Fast、Cheap、Done 之间 trade-off 的过程，四者只能满足其三，比如，想要在人力投入有限的情况下，快速完成需求交付，就必须牺牲软件的质量。 API Design Patterns，可以看成是 Google APIs 设计规范的详细版，对从事平台框架、微服务开发的同学很有帮助。 大数据处理框架 Apache Spark 设计与实现，对 Spark 的设计和实现原理都介绍得很清楚，做到了深入浅出，看完会对 Spark 有一个系统的认识。要是能够结合源码就更好了。 Spark SQL 内核剖析，读了前几章，算是 Spark 源码剖析类书籍里面讲的比较好的了，但对新手不友好，也可能是 Spark 太过博大精深了。 Trino: The Definitive Guide，可作为 Trino 的入门书籍，比较全，但很浅。Trino 是一个开源分布式 SQL 查询引擎，主打低时延和跨源查询，由 Facebook 开源的 Presto 演进而来。 Scala 编程（第三版），因工作需要在 Spark 上做开发，专门找来补 Scala 的知识，粗粗扫一遍。感受是，Scala 的语法糖真多。   棋王，阿城作品，包含了《棋王》、《树王》、《孩子王》三篇中篇小说，总结成一句话： 故事好、文字好。《棋王》最出名，关于“棋痴”王一生的故事，最后的九人车轮战，很有武侠风；《树王》最写实，两个“树王”，殊途同归；《孩子王》最童真，也是我最喜欢的一篇，探讨了教育问题，读完忍不住买了一本新华字典，想着每天学习几个字，最终没能坚持下来。 威尼斯日记、阿城文集之二，读完棋王，又专门找了两本阿城的作品来读。阿城的文字很有画面感，简洁、有力，而且读的过程中会不断惊叹于作者那渊博的知识。 芯片战争，因工作涉及，专门挑了一本关于芯片行业的通识书籍。读的时候会想起吴军的《浪潮之巅》，一本是互联网行业，一本是半导体行业，共同点是，可读性都很强。 极简欧洲史，把欧洲文明的基本要素总结为： 古希腊罗马文化、基督教教义以及日耳曼战士文化，以一个新颖的思路介绍了欧洲历史。印象最深的是，第一次发现，基督教里面的上帝和耶稣竟不是一个人。 人类群星闪耀时，描写了 14 个影响人类文明的历史瞬间，带有较多作者的主观感受。最喜欢的《决定世界的一分钟》，讲述拿破仑在滑铁卢战役上的惨败，记得还出现在初中课本上。 打开：周濂的 100 堂西方哲学课，介绍了从古希腊到近现代的西方哲学发展史，作为哲学入门读物很不错。今年看了不少哲学相关的知识，深感哲学对思维的重要性，它会让你养成思考的习惯。 刘擎西方现代思想讲义，2 年前买的书，没读完；阳的期间重新拿了起来，在发烧的深夜，读了 2 章，竟然神奇的退烧了。  写作 2022 年还算高产，写过的文章，比前两年加起来还多，类别也丰富起来了，技术类、思考类、记事类，都有。但也有很多计划写的，因为太懒、太拖，没完成。表达上，也有所转变，以前会想着，能不能再加点描述，再多点字；现在则是，能不能简洁点，再少点字。\n对我来说，写作是一件非常费时的事情，写一篇，往往需要一天时间，甚至更多。也一直在反思个中原因，结论是，不够专注。所以，想要高效地写好文章，还得费神，容不得半点分心。写作虽然费时、费神，但着实能提升表达和抽象能力。当你能够将一个复杂知识，用通俗易懂的方式表达出来时，才算是真正学会了。\n 实践GoF的23种设计模式：Go 实现，本来计划 2022 年就完成的系列写作，最终也只完成了一半（12 篇），希望能在 2023 年能完结。 假如让你来设计 SSL/TLS 协议，仿照《Operating Systems: Three Easy Pieces》的写作思路，从对称加密讲起，一步步推导出 SSL/TLS 的基本原理，个人认为是 2022 年最通俗易懂的一篇技术文章。 从分层架构到微服务架构（五）之服务化架构，时隔一年后，再次下笔写下了本系列的第 5 篇。从分层架构到微服务架构 系列是对《Fundamentals of Software Architecture》中提到的 8 中架构模式的总结，也希望能在 2023 年能完结。 用 Keynote 画出手绘风格的配图，一直很多小伙伴问我文章的配图是怎么画的，于是写了这篇。配图，是技术文章的重要组成部分，好的配图，能够极大提升文章的易读性，减轻读者负担。 深入理解 SQL 中的 Grouping Sets 语句，新项目组的第一个需求，跟 GROUPING SETS 语句相关。借此机会，以 Spark SQL 作为切入点，把其中技术原理弄清楚了。 深入理解计算机系统的数值类型，新项目组的第二个需求，与数值类型相关。为此，专门翻看了 CSAPP 和 IEEE 标准，把整型、浮点型的表示、转换规则都弄清楚了。 从哲学的角度看中医，年初时在喜马拉雅上听王德峰的 中西思想必修课，听到有关中医的哲学思辨时，深有感触，于是结合网上的一些资料和自身的经历，写了一篇胡说八道的文章。 懒惰，偶然看到一句话 “生活中往往没有标准答案，当你要求别人给你一个标准答案时，就是思想上的懒惰了”，于是开始反思自己在思想上的懒惰，具体表现就是，读的多，想的少。 让人生多些可能，2022 年做了一个重要的决定，换了部门。从应用服务开发，到大数据性能优化；从技术，到管理。新的技术栈、新的挑战，为的是，让人生多些可能。 属于篮球的快乐又回来了，换了部门，没那么忙了，打球的次数变多了。遇到了新的伙伴们，篮球的快乐好像又找回来了，有感而发，回顾了自己的篮球生涯。 送行，9 月份回老家参加朋友婚礼，此时正好在读阿城的作品，写作热情高昂，所以首次尝试用文字记录生活。生活中有很多感人的细节，希望以后能够好好观察生活，用文字记录感动。 二阶思维，偶然看到一篇文章《Second-Order Thinking: What Smart People Use to Outperform》，恰好自己也在有意练习思考，深感二阶思维带来的好处。  生活 2022 年，疫情改变了很多东西，还好，随着政策的放开，很多东西也慢慢回归正常。\n篮球 2022 年很幸运能遇到了一群一起打篮球的伙伴。\n读书时就爱打球，工作之后，太忙、也找不到伙伴，打得少。下半年换了部门，遇到了新伙伴，没那么忙了，每周能打几次；打得多，认识的伙伴也多起来；打完球、吃宵夜、聊会天，生活气息就有了。\n吃                                               家里就厨房装备最齐全，厨艺不行，热情来凑。周末闲在家中，尝试了不少菜和汤，甚至还烧起烤来。\n奇怪的是，很多小时候讨厌的佐料，如今变得喜爱。比如，沙姜，它有股很特别的甜香味，以前无法入口，现在倒是喜欢用来爆炒和作蘸料。生活中，事情很难一成不变，讨厌的会变成喜欢的、喜欢的也会变成讨厌的，唯有变化本身是不变的。\n吉他                         大一的时候，就开始学吉他，过去十年，弹得少且浅，复杂一点曲子都没毅力练下去。\n机缘巧合，9 月份买了新吉他，告别陪伴了十年的老吉他，弹琴的兴致又起来了。可能是工作多年带来的心态变化，对复杂的曲子不再感到恐惧，多练就行。\n除了指弹之外，最意想不到的是，还在视频号中录起了弹唱；对于只唱 K 过一次、在大学宿舍只弹琴不开口的自己，可以说是破天荒了。一切都在变化之中。\n最后，愿自己能在 2023 年的变化洪流中，依旧初心不变。\n","date":"2023-01-23T00:00:00Z","permalink":"https://www.yrunz.com/p/2022-%E5%B9%B4%E5%B0%8F%E7%BB%93/","title":"2022 年小结"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：代理模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 现在的软件系统往往是分层设计。在业务层执行一次请求时，我们很清楚请求的上下文，包括，请求是做什么的、参数有哪些、请求的接收者是谁、返回值是怎样的。相反，基础设施层并不需要完全清楚业务上下文，它只需知道请求的接收者是谁即可，否则就耦合过深了。\n因此，我们需要对请求进行抽象，将上下文信息封装到请求对象里，这其实就是命令模式，而该请求对象就是 Command。\nGoF 对命令模式（Command Pattern）的定义如下：\n Encapsulate a request as an object, thereby letting you parameterize clients with different requests, queue or log requests, and support undoable operations.\n 也即，命令模式可将请求转换为一个包含与请求相关的所有信息的对象， 它能将请求参数化、延迟执行、实现 Undo / Redo 操作等。\n上述的请求是广义上的概念，可以是网络请求，也可以是函数调用，更通用地，指一个动作。\n命令模式主要包含 3 种角色：\n Command，命令，是对请求的抽象。具体的命令实现时，通常会引用 Receiver。 Invoker，请求的发起发起方，它并不清楚 Command 和 Receiver 的实现细节，只管调用命令的接口。 Receiver，请求的接收方。  命令模式，一方面，能够使得 Invoker 与 Receiver 消除彼此之间的耦合，让对象之间的调用关系更加灵活；另一方面，能够很方便地实现延迟执行、Undo、Redo 等操作，因此被广泛应用在软件设计中。\nUML 结构 场景上下文 在 简单的分布式应用系统（示例代码工程）中，db 模块用来存储服务注册信息和系统监控数据。其中，服务注册信息拆成了 profiles 和 regions 两个表，在服务发现的业务逻辑中，通常需要同时操作两个表，为了避免两个表数据不一致的问题，db 模块需要提供事务功能:\n事务的核心功能之一是，当其中某个语句执行失败时，之前已执行成功的语句能够回滚，而使用命令模式能够很方便地实现该功能。\n代码实现 // demo/db/transaction.go package db // Command 执行数据库操作的命令接口 // 关键点1: 定义命令抽象接口 type Command interface { // 关键点2: 命令抽象接口中声明执行命令的方法  Exec() error // Exec 执行insert、update、delete命令  // 关键点3: 如果有撤销功能，则需要定义Undo方法  Undo() // Undo 回滚命令  setDb(db Db) // SetDb 设置关联的数据库 } // Transaction Db事务实现，事务接口的调用顺序为begin -\u0026gt; exec -\u0026gt; exec \u0026gt; ... -\u0026gt; commit // 关键点4: 定义Invoker对象 type Transaction struct { name string db Db // 关键点5: Invoker对象持有Command的引用  cmds []Command } // Begin 开启一个事务 func (t *Transaction) Begin() { t.cmds = make([]Command, 0) } // Exec 在事务中执行命令，先缓存到cmds队列中，等commit时再执行 func (t *Transaction) Exec(cmd Command) error { if t.cmds == nil { return ErrTransactionNotBegin } cmd.setDb(t.db) t.cmds = append(t.cmds, cmd) return nil } // Commit 提交事务，执行队列中的命令，如果有命令失败，则回滚后返回错误 // 关键点6: 为Invoker对象定义Call方法，在方法内调用Command的执行方法Exec func (t *Transaction) Commit() error { history := \u0026amp;cmdHistory{history: make([]Command, 0, len(t.cmds))} for _, cmd := range t.cmds { if err := cmd.Exec(); err != nil { history.rollback() return err } history.add(cmd) } return nil } // cmdHistory 命令执行历史 type cmdHistory struct { history []Command } func (c *cmdHistory) add(cmd Command) { c.history = append(c.history, cmd) } // 关键点7: 在回滚方法中，调用已执行命令的Undo方法 func (c *cmdHistory) rollback() { for i := len(c.history) - 1; i \u0026gt;= 0; i-- { c.history[i].Undo() } } // InsertCmd 插入命令 // 关键点8: 定义具体的命令类，实现Command接口 type InsertCmd struct { // 关键点9: 命令通常持有接收者的引用，以便在执行方法中与接收者交互  db Db tableName string primaryKey interface{} newRecord interface{} } // 关键点10: 命令对象执行方法中，调用Receiver的Action方法，这里的Receiver为db对象，Action方法为Insert方法 func (i *InsertCmd) Exec() error { return i.db.Insert(i.tableName, i.primaryKey, i.newRecord) } func (i *InsertCmd) Undo() { i.db.Delete(i.tableName, i.primaryKey) } func (i *InsertCmd) setDb(db Db) { i.db = db } // UpdateCmd 更新命令 type UpdateCmd struct {...} // DeleteCmd 删除命令 type DeleteCmd struct {...} 客户端可以这么使用：\nfunc client() { transaction := db.CreateTransaction(\u0026#34;register\u0026#34; + profile.Id) transaction.Begin() rcmd := db.NewUpdateCmd(regionTable).WithPrimaryKey(profile.Region.Id).WithRecord(profile.Region) transaction.Exec(rcmd) pcmd := db.NewUpdateCmd(profileTable).WithPrimaryKey(profile.Id).WithRecord(profile.ToTableRecord()) transaction.Exec(pcmd) if err := transaction.Commit(); err != nil { return ... } return ... } 总结实现命令模式的几个关键点：\n 定义命令抽象接口，本例子中为 Command 接口。 在命令抽象接口中声明执行命令的方法，本例子中为 Exec 方法。 如果要实现撤销功能，还需要为命令对象定义 Undo 方法，在操作回滚时调用。 定义 Invoker 对象，本例子中为 Transaction 对象。 在 Invoker 对象持有 Command 的引用，本例子为 Command 的切片 cmds。 为 Invoker 对象定义 Call 方法，用于执行具体的命令，在方法内调用 Command 的执行方法 ，本例子中为 Transaction.Commit 方法。 如果要实现撤销功能，还要在回滚方法中，调用已执行命令的 Undo 方法，本例子中为 cmdHistory.rollback 方法。 定义具体的命令类，实现 Command 接口，本例子中为 InsertCmd、UpdateCmd、DeleteCmd。 命令通常持有接收者的引用，以便在执行方法中与接收者交互。本例子中，Receiver 为 Db 对象。 最后，在命令对象执行方法中，调用 Receiver 的 Action 方法，本例子中， Receiver 的 Action 方法为 db.Insert 方法。  值得注意的是，本例子中 Transaction 对象在 Transaction.Exec 方法中只是将 Command 保存在队列中，只有当调用 Transaction.Commit 方法时才延迟执行相应的命令。\n扩展 os/exec 中的命令模式 Go 标准库的 os/exec 包也用到了命令模式。\npackage main import ( \u0026#34;os/exec\u0026#34; ) // 对应命令模式中的Invoker func main() { cmd := exec.Command(\u0026#34;sleep\u0026#34;, \u0026#34;1\u0026#34;) err := cmd.Run() } 在上述例子中，我们通过 exec.Command 方法将一个 shell 命令转换成一个命令对象 exec.Cmd，其中的 Cmd.Run() 方法即是命令执行方法；而 main() 函数，对应到命令模式中的 Invoker；Receiver 则是操作系统执行 shell 命令的具体进程，从 exec.Cmd 的源码中可以看到：\n// src/os/exec/exec.go package exec // 对应命令模式中的Command type Cmd struct { ... // 对应命令模式中的Receiver  Process *os.Process ... } // 对应命令模式中Command的执行方法 func (c *Cmd) Run() error { if err := c.Start(); err != nil { return err } return c.Wait() } func (c *Cmd) Start() error { ... // Command与Receiver的交互  c.Process, err = os.StartProcess(c.Path, c.argv(), \u0026amp;os.ProcAttr{...}) ... } CQRS 架构 CQRS 架构，全称为 Command Query Responsibility Segregation，命令查询职责隔离架构。CQRS 架构是微服务架构模式中的一种，它利用事件（命令）来维护从多个服务复制数据的只读视图，通过读写分离思想，提升微服务架构下查询的性能。\nCQRS 架构可分为 命令端 和 查询端，其中命令端负责数据的更新；查询端负责数据的查询。命令端的写数据库在数据更新时，会向查询端的只读数据库发送一个同步数据的事件，保证数据的最终一致性。\n其中的命令端，就使用到了命令模式的思想，将数据更新请求封装成命令，异步更新到写数据库中。\n典型应用场景  事务模式。事务模式下往往需要 Undo 操作，使用命令模式实现起来很方便。 远程执行。Go 标准库下的 exec.Cmd、http.Client 都属于该类型，将请求封装成命令来执行。 CQRS 架构。微服务架构模式中的一种，通过命令模式来实现数据的异步更新。 延迟执行。当你希望一个操作能够延迟执行时，通常会将它封装成命令，然后放到一个队列中。  优缺点 优点  符合单一职责原则。在命令模式下，每个命令都是职责单一、松耦合的；当然也可以通过组合的方式，将多个简单的命令组合成一个负责的命令。 可以很方便地实现操作的延迟执行、回滚、重做等。 在分布式架构下，命令模式能够方便地实现异步的数据更新、方法调用等，提升性能。  缺点  命令模式下，调用往往是异步的，而异步会导致系统变得复杂，问题出现时不好定位解决。 随着业务越来越复杂，命令对象也会增多，代码会变得更难维护。  与其他模式的关联 在实现 Undo/Redo 操作时，你通常需要同时使用 命令模式 和 备忘录模式。\n另外，命令模式 也常常和 观察者模式 一起出现，比如在 CQRS 架构中，当命令端更新数据库后，写数据库就会通过事件将数据同步到读数据库上，这里就用到了 观察者模式。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：观察者模式, 元闰子\n[3] Design Patterns, Chapter 5. Behavioral Patterns, GoF\n[4] 命令模式, refactoringguru.cn\n[5] The command pattern in Go, rolandjitsu\n[6] CQRS 模式, microsoft azure\n[7] CQRS Design Pattern in Microservices Architectures, Mehmet Ozkaya\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-12-22T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：命令模式"},{"content":"事情往往不是你想象的那样，有时候，看似解决了问题，却在不经意间，引发了更严重的后果。帮助我们思考、决策、解决问题的最有效方法是，运用二阶思维。\n什么是二阶思维？  一阶思维是单纯而肤浅的，几乎人人都能做到；二阶思维则是深邃、复杂而迂回的，能做到的人少之又少。\n—— 霍华德·马克斯\n 我们的每一个行动都会导致一个后果，而每个后果，都会有进一步导致其他的后果。由行动直接导致的后果，我们称为一阶后果（First-Order Consequences）；由一阶后果导致的，二阶、三阶\u0026hellip; 后果，这里，我们统称为二阶后果（Second-Order Consequences）。\n好的一阶后果，不见得会有好的二阶后果，很多时候，它们是反的。\n二阶思维（Second-Order Thinking），简单来说，就是做事情不能只看一阶后果，还要考虑二阶后果。相对于一阶思维，它更强调对问题的深入思考，从逻辑、系统、因果、时间等多种维度来综合考虑。\n霍华德·马克斯在《投资最重要的事》中有举到一个股票投资的例子：\n 一阶思维的人，会这么想：“公司的前景是光明的，这表示股票会上涨”。\n二阶思维的人，则会考虑到：\n 未来可能出现的结果会在什么范围之内？ 我认为会出现什么样的结果？ 我正确的概率有多大？ 人们的共识是什么？ 我的预期与人们的共识有多大差异？ 资产的当前价格与大众所认为的未来价格以及我所认为的未来价格相符的程度如何？ 价格中所反映的共识心理是过于乐观，还是过于悲观？ 如果大众的看法是正确的，那么资产价格将会发生怎样的改变？如果我是正确的，那么资产价格又会怎样？   显然，二阶思维与一阶思维之间有着巨大的工作量差异，二阶思维对人的要求更高，实践起来也更复杂。\n二阶思维有什么用？  没有考虑二阶或者三阶后果，是造成众多痛苦而糟糕的决策的重要原因之一。\n—— 雷伊·达里奥\n 善用二阶思维，能帮助我们更好地决策、更好地找到问题根本从而解决问题。\n更好地决策 以软件开发中需求管理为例。我们总说以客户为中心，那么，一阶思维者的做法，很有可能是，将客户/产品经理所提的每个需求都纳入到版本中。这种不假思索的做法，看似满足了客户的所有诉求，实际危害更大。它忽略了最重要的一点，开发的人力是有限的，从而很容易导致版本无法按时交付。\n更好的方法是，运用二阶思维来进行需求的管理。\n我们可以从多个维度来决策一个需求是否应该被纳入版本，比如，该需求能给客户带来多大的收益？在哪些场景下才有收益？没有它系统能不能正常运行？需求的工作量有多大？当前开发人力能不能满足？\n这样，我们就能大致估算出每个需求的价值，然后对需求做价值的优先排序，最后根据当前的开发人力做需求裁剪。确保在交付时间点到时，我们能够为客户提供一个可用的、价值最大的软件系统。\n更好地找到问题根源 在决策中，我们用的是正向的二阶思维，也即，从眼前一步步往后推演出未来的各种可能性。\n而在找问题根源时，我们用的是逆向的二阶思维，也即，从眼前要解决的问题开始，分析产生这个问题的原因，然后不断扩展、推演，一直找到问题根源。\n比如，在《深入理解计算机系统的数值类型》中，有一个 double 转型为 float 的例子：\n// Java public static void main(String[] args) { double d1 = 3.267393471324506; System.out.print(\u0026#34;double d1: \u0026#34;); System.out.println(d1); System.out.print(\u0026#34;float d1: \u0026#34;); System.out.println((float) d1); } // 输出结果 double d1: 3.267393471324506 float d1: 3.2673936 从结果来看，转型的规则并不是简单的四舍五入。如果是一阶思维者，很容易会这样想，浮点数的转换应该存在精度丢失，然后就结束了。\n如果是二阶思维者，你一定会有这样的疑问，为什么会得到这样的转换结果？\n那么，接下来，你很可能就会这样干：\n 查阅 《Java 语言规范》，发现 double 到 float 的近似规则是 Round-to-even，但 3.267393471324506 到 3.2673936 也不符合这个规则。然后想，有没可能近似规则是用在二进制的表示上？ 继续查阅 《Java 语言规范》，发现计算机的浮点数实现都遵循着《IEEE Standard 754 Floating-Point Representation》 规范。 接着，从 《IEEE Standard 754 Floating-Point Representation》找到了 double 和 float 在二进制表示上差异，并发现 double 转型 float 时会出现截断。 对比 3.267393471324506 到 3.2673936 的二进制表示，发现截断后，再通过 Round-to-even 来近似，就能得出正确的结果。  看，经过这样的层层追溯，我们最终找到了问题的答案！\n怎样锻炼二阶思维？  经济领域中，最关键的是不管别人对你说什么，你总要问：“然后呢？”。 这个方法可以应用于几乎其他所有领域。所以，你必须经常问：“然后呢？”\n—— 沃伦.巴菲特\n 二阶思维并不是与生俱来的，它更像是一种习惯，需要我们不断地实践、总结、养成。\n总要问：然后呢？ 当你决定做一件事情前，总要问自己：“然后呢”？\n这时，可以拿出你的笔，在纸上列出一阶后果、二阶后果、三阶后果、\u0026hellip;，把所能想到的可能性都显现地列举出来，以帮助我们更好地决策。\n比如，作为架构师的你，想在业务服务和数据库之间加上一层缓存，来优化数据读性能。那么，在系统设计时，你不能仅仅看到这一点，而应该运用二阶思维，尽可能地，把增加缓存之后可能出现的现象/结果，都列出来，分析一遍：\n凡事从时间维度多加考虑 在做决策前，在时间维度上多加考虑，如果做了这件事，10 小时之后会怎样？10 天之后会怎样？10 周之后会怎样？10 个月之后会怎样？10 年之后会怎样？\n比如，在《一步步降低软件复杂性》提到的 战术编程 与 战略编程 的例子，我们总是偏向战术编程，因为它能够节省大量开发时间，更快地完成需求交付。但是，当你从时间的维度来考虑时，结果就会有所不同：\n另一个典型的例子是，背单词。我们总认为每天背 10 个单词好像没有多大用处，要是真能坚持下来，1 年就能认识 3650 个单词，2 年就是 7300 个单词，10 年后是 3 万多个。所以，不要低估时间的力量。\n多问几个：为什么？ 接触一个知识，碰到一个问题，多问几个：“为什么”？\n要养成问 “为什么” 的习惯，通过质疑，不断找到现象或问题的根本所在。\n对于一个知识，如果没有经过深度思考，只能算暂时记住，并不能纳入到你的知识体系中。\n比如，对于 SSL/TLS 协议建立连接的过程，如果只是流于表面地把它背下来，可能你会因此通过面试，却无法深入理解其背后所涉及的密码学、数字证书、网络通信等原理知识（详见《假如让你来设计SSL/TLS协议》）。\n对于一个问题，如果没有定位到根因，临时的规避做法，往往会导致更严重的后果。\n比如，在一个分布式系统中，当出现服务请求超时现象时，一阶思维者的做法，很有可能是，通过增加请求超时时长来规避问题。然而，出现请求超时的原因有很多，如果是下游服务处理不过来导致的，增加超时时长只会让问题愈发恶劣，更好的做法是增加流控机制。\n所以，多问几个“为什么”，找到根源，才能更好地解决问题。\n最后 相比一阶思维，二阶思维能够让我们更好地做出决策、找到问题的根源。但这需要更深入的思考，耗费的时间和精力也会更多。\n这与人类的天然惰性是相违背的，就像在《懒惰》里提到的，“读书很容易，但思考很难”。\n好消息是，二阶思维是一种习惯，能够通过不断地练习来养成。本文列出了 3 个比较容易实践的锻炼方法：\n 做一件事前，总是问：“然后呢？”； 凡事从时间维度多加考虑； 遇到知识/问题，多问几个：“为什么？”。  养成二阶思维的习惯是一个漫长、痛苦的过程，但坚持下来，总会收获很大。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] Second-Order Thinking: What Smart People Use to Outperform, Mental Models\n[2] 二阶思维Second-Order Thinking——让你脱颖而出的思维方式, 芒格学院\n[3] 投资最重要的事情, 霍华德·马克斯\n[4] 深入理解计算机系统的数值类型, 元闰子\n[5] 懒惰, 元闰子\n[6] 假如让你来设计SSL/TLS协议, 元闰子\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-11-20T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BA%8C%E9%98%B6%E6%80%9D%E7%BB%B4/","title":"二阶思维"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：访问者模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 GoF 对代理模式（Proxy Pattern）的定义如下：\n Provide a surrogate or placeholder for another object to control access to it.\n 也即，代理模式为一个对象提供一种代理以控制对该对象的访问。\n它是一个使用率非常高的设计模式，在现实生活中，也是很常见。比如，演唱会门票黄牛。假设你需要看一场演唱会，但官网上门票已经售罄，于是就当天到现场通过黄牛高价买了一张。在这个例子中，黄牛就相当于演唱会门票的代理，在正式渠道无法购买门票的情况下，你通过代理完成了该目标。\n从演唱会门票的例子我们也能看出，使用代理模式的关键在于，当 Client 不方便直接访问一个对象时，提供一个代理对象控制该对象的访问。Client 实际上访问的是代理对象，代理对象会将 Client 的请求转给本体对象去处理。\nUML 结构 场景上下文 在 简单的分布式应用系统（示例代码工程）中，db 模块用来存储服务注册和监控信息，它是一个 key-value 数据库。为了提升访问数据库的性能，我们决定为它新增一层缓存：\n另外，我们希望客户端在使用数据库时，并不感知缓存的存在，这些，代理模式可以做到。\n代码实现 // demo/db/cache.go package db // 关键点1: 定义代理对象，实现被代理对象的接口 type CacheProxy struct { // 关键点2: 组合被代理对象，这里应该是抽象接口，提升可扩展性  db Db cache sync.Map // key为tableName，value为sync.Map[key: primaryId, value: interface{}]  hit int miss int } // 关键点3: 在具体接口实现上，嵌入代理本身的逻辑 func (c *CacheProxy) Query(tableName string, primaryKey interface{}, result interface{}) error { cache, ok := c.cache.Load(tableName) if ok { if record, ok := cache.(*sync.Map).Load(primaryKey); ok { c.hit++ result = record return nil } } c.miss++ if err := c.db.Query(tableName, primaryKey, result); err != nil { return err } cache.(*sync.Map).Store(primaryKey, result) return nil } func (c *CacheProxy) Insert(tableName string, primaryKey interface{}, record interface{}) error { if err := c.db.Insert(tableName, primaryKey, record); err != nil { return err } cache, ok := c.cache.Load(tableName) if !ok { return nil } cache.(*sync.Map).Store(primaryKey, record) return nil } ... // 关键点4: 代理也可以有自己特有方法，提供一些辅助的功能 func (c *CacheProxy) Hit() int { return c.hit } func (c *CacheProxy) Miss() int { return c.miss } ... 客户端这样使用：\n// 客户端只看到抽象的Db接口 func client(db Db) { table := NewTable(\u0026#34;region\u0026#34;). WithType(reflect.TypeOf(new(testRegion))). WithTableIteratorFactory(NewRandomTableIteratorFactory()) db.CreateTable(table) table.Insert(1, \u0026amp;testRegion{Id: 1, Name: \u0026#34;region\u0026#34;}) result := new(testRegion) db.Query(\u0026#34;region\u0026#34;, 1, result) } func main() { // 关键点5: 在初始化阶段，完成缓存的实例化，并依赖注入到客户端  cache := NewCacheProxy(\u0026amp;memoryDb{tables: sync.Map{}}) client(cache) } 本例子中，Subject 是 Db 接口，Proxy 是 CacheProxy 对象，SubjectImpl 是 memoryDb 对象：\n总结实现代理模式的几个关键点：\n 定义代理对象，实现被代理对象的接口。本例子中，前者是 CacheProxy 对象，后者是 Db 接口。 代理对象组合被代理对象，这里组合的应该是抽象接口，让代理的可扩展性更高些。本例子中，CacheProxy 对象组合了 Db 接口。 代理对象在具体接口实现上，嵌入代理本身的逻辑。本例子中，CacheProxy 在 Query、Insert 等方法中，加入了缓存 sync.Map 的读写逻辑。 代理对象也可以有自己特有方法，提供一些辅助的功能。本例子中，CacheProxy 新增了Hit、Miss 等方法用于统计缓存的命中率。 最后，在初始化阶段，完成代理的实例化，并依赖注入到客户端。这要求，客户端依赖抽象接口，而不是具体实现，否则代理就不透明了。  扩展 Go 标准库中的反向代理 代理模式最典型的应用场景是远程代理，其中，反向代理又是最常用的一种。\n以 Web 应用为例，反向代理位于 Web 服务器前面，将客户端（例如 Web 浏览器）请求转发后端的 Web 服务器。反向代理通常用于帮助提高安全性、性能和可靠性，比如负载均衡、SSL 安全链接。\nGo 标准库的 net 包也提供了反向代理，ReverseProxy，位于 net/http/httputil/reverseproxy.go 下，实现 http.Handler 接口。http.Handler 提供了处理 Http 请求的能力，也即相当于 Http 服务器。那么，对应到 UML 结构图中，http.Handler 就是 Subject，ReverseProxy 就是 Proxy：\n下面列出 ReverseProxy 的一些核心代码：\n// net/http/httputil/reverseproxy.go package httputil type ReverseProxy struct { // 修改前端请求，然后通过Transport将修改后的请求转发给后端  Director func(*http.Request) // 可理解为Subject，通过Transport来调用被代理对象的ServeHTTP方法处理请求  Transport http.RoundTripper // 修改后端响应，并将修改后的响应返回给前端  ModifyResponse func(*http.Response) error // 错误处理  ErrorHandler func(http.ResponseWriter, *http.Request, error) ... } func (p *ReverseProxy) ServeHTTP(rw http.ResponseWriter, req *http.Request) { // 初始化transport  transport := p.Transport if transport == nil { transport = http.DefaultTransport } ... // 修改前端请求  p.Director(outreq) ... // 将请求转发给后端  res, err := transport.RoundTrip(outreq) ... // 修改后端响应  if !p.modifyResponse(rw, res, outreq) { return } ... // 给前端返回响应  err = p.copyResponse(rw, res.Body, p.flushInterval(res)) ... } ReverseProxy 就是典型的代理模式实现，其中，远程代理无法直接引用后端的对象引用，因此这里通过引入 Transport 来远程访问后端服务，可以将 Transport 理解为 Subject。\n可以这么使用 ReverseProxy：\nfunc proxy(c *gin.Context) { remote, err := url.Parse(\u0026#34;https://yrunz.com\u0026#34;) if err != nil { panic(err) } proxy := httputil.NewSingleHostReverseProxy(remote) proxy.Director = func(req *http.Request) { req.Header = c.Request.Header req.Host = remote.Host req.URL.Scheme = remote.Scheme req.URL.Host = remote.Host req.URL.Path = c.Param(\u0026#34;proxyPath\u0026#34;) } proxy.ServeHTTP(c.Writer, c.Request) } func main() { r := gin.Default() r.Any(\u0026#34;/*proxyPath\u0026#34;, proxy) r.Run(\u0026#34;:8080\u0026#34;) } 典型应用场景  远程代理（remote proxy），远程代理适用于提供服务的对象处在远程的机器上，通过普通的函数调用无法使用服务，需要经过远程代理来完成。因为并不能直接访问本体对象，所有远程代理对象通常不会直接持有本体对象的引用，而是持有远端机器的地址，通过网络协议去访问本体对象。 虚拟代理（virtual proxy），在程序设计中常常会有一些重量级的服务对象，如果一直持有该对象实例会非常消耗系统资源，这时可以通过虚拟代理来对该对象进行延迟初始化。 保护代理（protection proxy），保护代理用于控制对本体对象的访问，常用于需要给 Client 的访问加上权限验证的场景。 缓存代理（cache proxy），缓存代理主要在 Client 与本体对象之间加上一层缓存，用于加速本体对象的访问，常见于连接数据库的场景。 智能引用（smart reference），智能引用为本体对象的访问提供了额外的动作，常见的实现为 C++ 中的智能指针，为对象的访问提供了计数功能，当访问对象的计数为 0 时销毁该对象。  优缺点 优点  可以在客户端不感知的情况下，控制访问对象，比如远程访问、增加缓存、安全等。 符合 开闭原则，可以在不修改客户端和被代理对象的前提下，增加新的代理；也可以在不修改客户端和代理的前提下，更换被代理对象。  缺点  作为远程代理时，因为多了一次转发，会影响请求的时延。  与其他模式的关联 从结构上看，装饰模式 和 代理模式 具有很高的相似性，但是两种所强调的点不一样。前者强调的是为本体对象添加新的功能，后者强调的是对本体对象的访问控制。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：装饰模式, 元闰子\n[3] Design Patterns, Chapter 4. Structural Patterns, GoF\n[4] 代理模式, refactoringguru.cn\n[5] 什么是反向代理？, cloudflare\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-10-16T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：代理模式"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：迭代器模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 GoF 对访问者模式（Visitor Pattern）的定义如下：\n Represent an operation to be performed on the elements of an object structure. Visitor lets you define a new operation without changing the classes of the elements on which it operates.\n 访问者模式的目的是，解耦数据结构和算法，使得系统能够在不改变现有代码结构的基础上，为对象新增一种新的操作。\n上一篇介绍的 迭代器模式 也做到了数据结构和算法的解耦，不过它专注于遍历算法。访问者模式，则在遍历的同时，将操作作用到数据结构上，一个常见的应用场景是语法树的解析。\nUML 结构 场景上下文 在 简单的分布式应用系统（示例代码工程）中，db 模块用来存储服务注册和监控信息，它是一个 key-value 数据库。另外，我们给 db 模块抽象出 Table 对象：\n// demo/db/table.go package db // Table 数据表定义 type Table struct { name string metadata map[string]int // key为属性名，value属性值的索引, 对应到record上存储  records map[interface{}]record iteratorFactory TableIteratorFactory // 默认使用随机迭代器 } 目的是提供类似于关系型数据库的按列查询能力，比如：\n上述的按列查询只是等值比较，未来还可能会实现正则表达式匹配等方式，因此我们需要设计出可供未来扩展的接口。这种场景，使用访问者模式正合适。\n代码实现 // demo/db/table_visitor.go package db // 关键点1: 定义表查询的访问者抽象接口，允许后续扩展查询方式 type TableVisitor interface { // 关键点2: Visit方法以Element作为入参，这里的Element为Table对象  Visit(table *Table) ([]interface{}, error) } // 关键点3: 定义Visitor抽象接口的实现对象，这里FieldEqVisitor实现按列等值查询逻辑 type FieldEqVisitor struct { field string value interface{} } // 关键点4: 为FieldEqVisitor定义Visit方法，实现具体的等值查询逻辑 func (f *FieldEqVisitor) Visit(table *Table) ([]interface{}, error) { result := make([]interface{}, 0) idx, ok := table.metadata[f.field] if !ok { return nil, ErrRecordNotFound } for _, r := range table.records { if reflect.DeepEqual(r.values[idx], f.value) { result = append(result, r) } } if len(result) == 0 { return nil, ErrRecordNotFound } return result, nil } func NewFieldEqVisitor(field string, value interface{}) *FieldEqVisitor { return \u0026amp;FieldEqVisitor{ field: field, value: value, } } // demo/db/table.go package db type Table struct {...} // 关键点5: 为Element定义Accept方法，入参为Visitor接口 func (t *Table) Accept(visitor TableVisitor) ([]interface{}, error) { return visitor.Visit(t) } 客户端可以这么使用：\nfunc client() { table := NewTable(\u0026#34;testRegion\u0026#34;).WithType(reflect.TypeOf(new(testRegion))) table.Insert(1, \u0026amp;testRegion{Id: 1, Name: \u0026#34;beijing\u0026#34;}) table.Insert(2, \u0026amp;testRegion{Id: 2, Name: \u0026#34;beijing\u0026#34;}) table.Insert(3, \u0026amp;testRegion{Id: 3, Name: \u0026#34;guangdong\u0026#34;}) visitor := NewFieldEqVisitor(\u0026#34;name\u0026#34;, \u0026#34;beijing\u0026#34;) result, err := table.Accept(visitor) if err != nil { t.Error(err) } if len(result) != 2 { t.Errorf(\u0026#34;visit failed, want 2, got %d\u0026#34;, len(result)) } } 总结实现访问者模式的几个关键点：\n 定义访问者抽象接口，上述例子为 TableVisitor， 目的是允许后续扩展表查询方式。 访问者抽象接口中，Visit 方法以 Element 作为入参，上述例子中， Element 为 Table 对象。 为 Visitor 抽象接口定义具体的实现对象，上述例子为 FieldEqVisitor。 在访问者的 Visit 方法中实现具体的业务逻辑，上述例子中 FieldEqVisitor.Visit(...) 实现了按列等值查询逻辑。 在被访问者 Element 中定义 Accept 方法，以访问者 Visitor 作为入参。上述例子中为 Table.Accept(...) 方法。  扩展 Go 风格实现 上述实现是典型的面向对象风格，下面以 Go 风格重新实现访问者模式：\n// demo/db/table_visitor_func.go package db // 关键点1: 定义一个访问者函数类型 type TableVisitorFunc func(table *Table) ([]interface{}, error) // 关键点2: 定义工厂方法，工厂方法返回的是一个访问者函数，实现了具体的访问逻辑 func NewFieldEqVisitorFunc(field string, value interface{}) TableVisitorFunc { return func(table *Table) ([]interface{}, error) { result := make([]interface{}, 0) idx, ok := table.metadata[field] if !ok { return nil, ErrRecordNotFound } for _, r := range table.records { if reflect.DeepEqual(r.values[idx], value) { result = append(result, r) } } if len(result) == 0 { return nil, ErrRecordNotFound } return result, nil } } // 关键点3: 为Element定义Accept方法，入参为Visitor函数类型 func (t *Table) AcceptFunc(visitorFunc TableVisitorFunc) ([]interface{}, error) { return visitorFunc(t) } 客户端可以这么使用：\nfunc client() { table := NewTable(\u0026#34;testRegion\u0026#34;).WithType(reflect.TypeOf(new(testRegion))) table.Insert(1, \u0026amp;testRegion{Id: 1, Name: \u0026#34;beijing\u0026#34;}) table.Insert(2, \u0026amp;testRegion{Id: 2, Name: \u0026#34;beijing\u0026#34;}) table.Insert(3, \u0026amp;testRegion{Id: 3, Name: \u0026#34;guangdong\u0026#34;}) result, err := table.AcceptFunc(NewFieldEqVisitorFunc(\u0026#34;name\u0026#34;, \u0026#34;beijing\u0026#34;)) if err != nil { t.Error(err) } if len(result) != 2 { t.Errorf(\u0026#34;visit failed, want 2, got %d\u0026#34;, len(result)) } } Go 风格的实现，利用了函数闭包的特点，更加简洁了。\n总结几个实现关键点：\n 定义一个访问者函数类型，函数签名以 Element 作为入参，上述例子为 TableVisitorFunc 类型。 定义一个工厂方法，工厂方法返回的是具体的访问访问者函数，上述例子为 NewFieldEqVisitorFunc 方法。这里利用了函数闭包的特性，在访问者函数中直接引用工厂方法的入参，与 FieldEqVisitor 中持有两个成员属性的效果一样。 为 Element 定义 Accept 方法，入参为 Visitor 函数类型 ，上述例子是 Table.AcceptFunc(...) 方法。  与迭代器模式结合 访问者模式经常与迭代器模式一起使用。比如上述例子中，如果你定义的 Visitor 实现不在 db 包内，那么就无法直接访问 Table 的数据，这时就需要通过 Table 提供的迭代器来实现。\n在 简单的分布式应用系统（示例代码工程）中，db 模块存储的服务注册信息如下：\n// demo/service/registry/model/service_profile.go package model // ServiceProfileRecord 存储在数据库里的类型 type ServiceProfileRecord struct { Id string // 服务ID  Type ServiceType // 服务类型  Status ServiceStatus // 服务状态  Ip string // 服务IP  Port int // 服务端口  RegionId string // 服务所属regionId  Priority int // 服务优先级，范围0～100，值越低，优先级越高  Load int // 服务负载，负载越高表示服务处理的业务压力越大 } 现在，我们要查询符合指定 ServiceId 和 ServiceType 的服务记录，可以这么实现一个 Visitor：\n// demo/service/registry/model/service_profile.go package model type ServiceProfileVisitor struct { svcId string svcType ServiceType } func (s *ServiceProfileVisitor) Visit(table *db.Table) ([]interface{}, error) { var result []interface{} // 通过迭代器来遍历Table的所有数据  iter := table.Iterator() for iter.HasNext() { profile := new(ServiceProfileRecord) if err := iter.Next(profile); err != nil { return nil, err } // 先匹配ServiceId，如果一致则无须匹配ServiceType  if profile.Id != \u0026#34;\u0026#34; \u0026amp;\u0026amp; profile.Id == s.svcId { result = append(result, profile) continue } // ServiceId匹配不上，再匹配ServiceType  if profile.Type != \u0026#34;\u0026#34; \u0026amp;\u0026amp; profile.Type == s.svcType { result = append(result, profile) } } return result, nil } 典型应用场景   k8s 中，kubectl 通过访问者模式来处理用户定义的各类资源。\n  编译器中，通常使用访问者模式来实现对语法树解析，比如 LLVM。\n  希望对一个复杂的数据结构执行某些操作，并支持后续扩展。\n  优缺点 优点  数据结构和操作算法解耦，符合 单一职责原则。 支持对数据结构扩展多种操作，具备较强的可扩展性，符合 开闭原则。  缺点  访问者模式某种程度上，要求数据结构必须对外暴露其内在实现，否则访问者就无法遍历其中数据（可以结合迭代器模式来解决该问题）。 如果被访问对象内的数据结构变更，可能要更新所有的访问者实现。  与其他模式的关联  访问者模式 经常和 迭代器模式 一起使用，使得被访问对象无须向外暴露内在数据结构。 也经常和 组合模式 一起使用，比如在语法树解析中，递归访问和解析树的每个节点（节点组合成树）。  文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：迭代器模式, 元闰子\n[3] Design Patterns, Chapter 5. Behavioral Patterns, GoF\n[4] GO 编程模式：K8S VISITOR 模式, 酷壳\n[5] 访问者模式, refactoringguru.cn\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-10-06T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：访问者模式"},{"content":"前些天回老家参加朋友婚礼，明天还要上班，下午也该回去了。\n午饭时候，侄女在旁边手玩着手，低头嘟囔，\n“学叔，你得听日先回无啦？”，\n“好快就翻黎啦”。\n粗粗吃完，回房间眯了一会，把行李拎下楼，准备启程了。\n老妈看见，急忙放下手中忙活，开始乒乒乓乓地收拾，虾、墨鱼滑、蜂蜜、苹果、橘子、一捆生菜，一个都没落下；随后匆忙换好鞋子，提着几袋就出门，连着行李一起放上车。\n等东西都放好，坐上车，启动，打开地图导航，出发了。\n老爸在前头，边摆弄好街上散落的摩托车，给车子腾出位置；边双手举过头顶，不停向后招手，指挥着车子向前。老妈则是默默在车后头跟着。\n经过旧屋时，奶奶也出来了，等车窗放下，两只手搭到车门，把头微微伸入，\n“家阵上嗲哈？”\n“系啊。”\n“回去健健康康喔，一路顺风哈，回到记得打个电话俾婆婆哈。”\n“好啊。”\n挤挤开过了这条街，来到街口，老爸突然说，“你妈妈讲要送你出路口哇。”\n于是，把车门解锁，爸妈先后打开车门，坐了上来。\n去路口的路的两边边停满了车，双行道容不下两辆车并排开，地面还偶尔冒出些小石包，不敢开快。\n车上三人一句句闲聊，没多久，就到路口；停下来，等前后车都过了，回头问，“系度放你地落哈？”\n老妈急忙回了句，“呃，系度落。”\n老爸先下车，微微站出路口，背扣双手；刺眼的阳光下，紧皱着眉头，来回观察路况。\n老妈下车后，不断叮嘱把车窗摇上来，别让空调漏了出去。\n看老爸没有明示，我也轻踩油门，出路口左转离去了。\n等车身回直，瞄了眼后视镜，发现他们还站在路口，背扣双手，看着这边；\n过了一会，再看，还在，远远地看着；\n又过了一会，老妈先转身回去了；没一会，老爸也回头走进了路口。\n（完 \u0026ndash; 2022.09.04）\n","date":"2022-09-04T00:00:00Z","permalink":"https://www.yrunz.com/p/%E9%80%81%E8%A1%8C/","title":"送行"},{"content":"前言 在日常编程中，数值类型（numeric types）是我们打交道最多的类型，可能没有之一。除了最熟悉的 int，还有 long、float、double 等。正因太熟悉，我们往往不会深究它们的底层原理。因为平时的工作中，知道个大概，也够用了。\n但，在某些业务场景下，比如金融业务，数值运算不准确会带来灾难性的后果。这时，你就必须清楚数值类型的二进制表示、截断、转型等原理，否则很难保证运算结果的正确性。\n另外，数值类型也是一个容易被黑客攻击的点，考虑如下一段代码：\n// C++ /* Declaration of library function memcpy */ void *memcpy(void *dest, void *src, size_t n); /* Kernel memory region holding user-accessible data */ #define KSIZE 1024 char kbuf[KSIZE]; /* Copy at most maxlen bytes from kernel region to user buffer */ int copy_from_kernel(void *user_dest, int maxlen) { /* Byte count len is minimum of buffer size and maxlen */ int len = KSIZE \u0026lt; maxlen ? KSIZE : maxlen; memcpy(user_dest, kbuf, len); return len; } 如果你熟悉数值类型的原理，一定会敏锐察觉出第 10 行存在 int 到 size_t 的类型转换。在 64 位系统中，size_t 通常被定义为 unsigned long 类型，如果攻击者在调用 copy_from_kernel 时，特意传入一个负数的 maxlen，转型到 memcpy 中的 n 将会是一个很大的正数，从而导致了内存拷贝的越界！\n数值类型是计算机编程的基础，用的很多，也很重要，理解它的底层原理，有助于写出正确的代码，避免一些意料之外的错误。\n 每个计算机系统都有固定的 word size，也即常说的 xx 位，它也是指针的大小，跟 虚拟内存 相关，比如一个 w 位系统上的应用程序，最多能够访问 $2^{w}$ byte 大小的虚拟内存。\n最常用的是 32 位 和 64 位 系统，某些数值类型在它们之上会有些差异，比如 long 类型 在 32 位系统上是 32 bit 大小，在 64 位系统上是 64 bit 大小。考虑如今 64 位系统逐渐成为主流，本文会以它作为基础，进行数值类型的介绍。\n 整数 在计算机系统中，整数可以分成 无符号（unsigned）整数 和 有符号（signed）整数 两大类，这之下，按照类型表示的 bit 位大小，又可细分成 8 位的 char/byte/int8 、16 位的 short/innt16、32 位的 int/int32 和 64 位的 long/int64，它们的取值范围如下：\n   类型 最小值 最大值     [signed] char -128 127   unsigned char 0 255   short -32,768 32,767   unsigned short 0 65,535   int −2,147,483,648 2,147,483,647   unsigned int 0 4,294,967,295   long −9,223,372,036,854,775,808 −9,223,372,036,854,775,807   unsigned long 0 18,446,744,073,709,551,615    死记这个表不容易，下面我们将试图从二进制编码层面去理解它。\n二进制编码 整数在计算机系统上都是以二进制存储的，对于一个 w 位的整数 $x$，它的二进制表示写成这样： $$ [x_{w-1}, x_{w-2}, \u0026hellip;, x_0]_b $$ 其中，$x_i$ 取值 $0$ 或 $1$。\n无符号编码（Unsigned Encodings） 在二进制表示的基础上，无符号编码 是这样： $$ x = \\sum_{i=0}^{w-1}x_i \\cdot 2^i $$ 比如，w = 4 场景下的一些例子： $$ [0001]_b=0\\cdot2^3+0\\cdot2^2+0\\cdot2^1+1\\cdot2^0=0+0+0+1=1 $$ $$ [0101]_b=0\\cdot2^3+1\\cdot2^2+0\\cdot2^1+1\\cdot2^0=0+4+0+1=5 $$\n$$ [1011]_b=1\\cdot2^3+0\\cdot2^2+1\\cdot2^1+1\\cdot2^0=8+0+2+1=11 $$\n$$ [1111]_b=1\\cdot2^3+1\\cdot2^2+1\\cdot2^1+1\\cdot2^0=8+4+2+1=15 $$\n由上述可知，无符号编码无法表示负数，因此只能表示无符号整数。为了表示有符号整数，还要探寻另一种编码方式。\n原码编码（True Form Encodings） 为了区分正数和负数，很容易想到使用一个 bit 位作为符号位，$0$ 表示正数，$1$ 表示负数。在无符号编码的基础上，使用最高位作为符号位，其他位含义不变，得出 原码编码 形式： $$ x = (-1)^{x_{w-1}} \\cdot \\sum_{i=0}^{w-2}x_i2^i $$ 比如，w = 4 场景下的一些例子： $$ [0001]_b=(-1)^0\\cdot(0\\cdot2^2+0\\cdot2^1+1\\cdot2^0)=1\\cdot(0+0+1)=1 $$ $$ [0101]_b=(-1)^0\\cdot(1\\cdot2^2+0\\cdot2^1+1\\cdot2^0)=1\\cdot(4+0+1)=5 $$\n$$ [1011]_b=(-1)^1\\cdot(0\\cdot2^2+1\\cdot2^1+1\\cdot2^0)=-1\\cdot(0+2+1)=-3 $$\n$$ [1111]_b=(-1)^1\\cdot(1\\cdot2^2+1\\cdot2^1+1\\cdot2^0)=-1\\cdot(4+2+1)=-7 $$\n虽然原码编码方式简单直观，但它还存在两个问题：\n（1）$0$ 存在两种编码形式\n原码编码方式下，$0$ 存在两种编码形式，$[0,0,\u0026hellip;,0]_b$ 和 $[1,0,\u0026hellip;,0]_b$。同一个整数值，却有两种编码，这对计算机系统来说没什么意义，反而是一种浪费。\n（2）带负数的加法运算不正确\n原码编码方式下，两个正数的加法没问题，一旦带上负数，结果就出错了：\n所以，原码编码方式，注定不会被使用。\n补码编码（Two\u0026rsquo;s-complement Encodings） 于是，补码编码 被发明，它也是建立在无符号编码的基础上，仍然取最高位为符号位，编码方式是这样： $$ x = -x_{w-1} \\cdot 2^{w-1} + \\sum_{i=0}^{w-2}x_i2^i $$ **它与无符号编码的唯一区别是，最高位的取值从** $x_{w-1} \\cdot 2^{w-1}$ **变成了** $-x_{w-1} \\cdot 2^{w-1}$。\n比如，w = 4 场景下的一些例子： $$ [0001]_b=-0\\cdot2^3 +0\\cdot2^2+0\\cdot2^1+1\\cdot2^0)=0+0+0+1=1 $$ $$ [0101]_b=-0\\cdot2^3+1\\cdot2^2+0\\cdot2^1+1\\cdot2^0=0+4+0+1)=5 $$\n$$ [1011]_b=-1\\cdot2^3+0\\cdot2^2+1\\cdot2^1+1\\cdot2^0=-8+0+2+1=-5 $$\n$$ [1111]_b=-1\\cdot2^3+1\\cdot2^2+1\\cdot2^1+1\\cdot2^0=-8+4+2+1=-1 $$\n补码编码很巧妙地解决了原码编码的两个问题：\n首先，0 在补码编码下只有一种编码形式，$[0,0,\u0026hellip;,0]_b$ 。\n此外，带负数的加法运算，也正确了。\n因为补码编码的简单和正确性，目前，几乎所有的计算机系统，都采用补码编码来表示有符号整数。\n位运算 位运算主要包含 取反、与、或、异或、移位 等几种，我们在业务开发时用得比较少，但如果你有阅读开源代码的习惯，就会经常发现它们的踪迹。如果碰巧对位运算不熟悉，那么阅读这些代码，就同读天书一般。\n取反（~）、与（\u0026amp;）、或（|）、异或（^）的规则比较简单：\n移位运算，可以分成 左移 和 右移 两种，其中，右移又可分为 逻辑右移 和 算术右移。\n左移（\u0026laquo;）运算，是对二进制整数，向左移若干位，高位丢弃，低位补零。也即，对 $[x_{w-1}, x_{w-2}, \u0026hellip;, x_0]_b$ 左移 $k$ 位，得到 $[x_{w-k-1}, x_{w-k-2}, \u0026hellip;, x_0, 0, \u0026hellip;, 0]_b$。\n比如，对 int i = -1 左移 10 位，会得到 i = -1024 的结果：\n// Java语言 public static void main(String[] args) { int i = -1; System.out.println(\u0026#34;Before \u0026lt;\u0026lt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); i \u0026lt;\u0026lt;= 10; System.out.println(\u0026#34;After \u0026lt;\u0026lt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); } // 输出结果： Before \u0026lt;\u0026lt; , i\u0026#39;s value is -1 i\u0026#39;s binary string is 11111111111111111111111111111111 After \u0026lt;\u0026lt; , i\u0026#39;s value is -1024 i\u0026#39;s binary string is 11111111111111111111110000000000  在 C/C++ 中，两种右移操作符都是 \u0026raquo;，对无符号整数用的是逻辑右移，对有符号整数用的是算术右移；在 Java 中，逻辑右移的操作符是 \u0026raquo;\u0026gt;，算术右移的操作符是 \u0026raquo;。为了方便区分，下文统一用 Java 的表示方法。\n 逻辑右移（\u0026raquo;\u0026gt;）运算，是对二进制整数，向右移若干位，高位补零，低位丢弃。也即，对 $[x_{w-1}, x_{w-2}, \u0026hellip;, x_0]_b$ 逻辑左移 k 位，得到 $[0, \u0026hellip;, 0,x_{w-1}, x_{w-2}, \u0026hellip;, x_k]_b$。\n比如，对 int i = -1 逻辑右移 10 位，会得到 i = 4194303 的结果：\n// Java语言 public static void main(String[] args) { int i = -1; System.out.println(\u0026#34;Before \u0026gt;\u0026gt;\u0026gt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); i \u0026gt;\u0026gt;\u0026gt;= 10; System.out.println(\u0026#34;After \u0026gt;\u0026gt;\u0026gt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); } // 输出结果： Before \u0026gt;\u0026gt;\u0026gt; , i\u0026#39;s value is -1 i\u0026#39;s binary string is 11111111111111111111111111111111 After \u0026gt;\u0026gt;\u0026gt; , i\u0026#39;s value is 4194303 i\u0026#39;s binary string is 1111111111111111111111 算术右移（\u0026raquo;）运算，是对二进制整数，向右移若干位，高位补符号位，低位丢弃。也即，对 $[x_{w-1}, x_{w-2}, \u0026hellip;, x_0]_b$ 逻辑左移 k 位，得到 $[x_{w-1}, \u0026hellip;, x_{w-1},x_{w-1}, x_{w-2}, \u0026hellip;, x_k]_b$。\n比如，对 int i = -1 算术右移 10 位，仍会得到 i = -1 的结果：\n// Java语言 public static void main(String[] args) { int i = -1; System.out.println(\u0026#34;Before \u0026gt;\u0026gt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); i \u0026gt;\u0026gt;= 10; System.out.println(\u0026#34;After \u0026gt;\u0026gt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); } // 输出结果： Before \u0026gt;\u0026gt; , i\u0026#39;s value is -1 i\u0026#39;s binary string is 11111111111111111111111111111111 After \u0026gt;\u0026gt; , i\u0026#39;s value is -1 i\u0026#39;s binary string is 11111111111111111111111111111111 目前为止，介绍移位运算的原理时，我们都默认 k \u0026lt; w，如果 k \u0026gt;= w 会怎样？\n比如， $[x_{w-1}, x_{w-2}, \u0026hellip;, x_0]_b$ 左移 w 位，结果会是 $[0, 0, \u0026hellip;, 0]_b$ 吗：\n// Java语言 public static void main(String[] args) { int i1 = -1; System.out.println(\u0026#34;Before \u0026lt;\u0026lt; 31, i1\u0026#39;s value is \u0026#34; + i1); System.out.println(\u0026#34;i1\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i1)); i1 \u0026lt;\u0026lt;= 31; System.out.println(\u0026#34;After \u0026lt;\u0026lt; 31, i1\u0026#39;s value is \u0026#34; + i1); System.out.println(\u0026#34;i1\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i1)); int i2 = -1; System.out.println(\u0026#34;Before \u0026lt;\u0026lt; 32, i2\u0026#39;s value is \u0026#34; + i2); System.out.println(\u0026#34;i2\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i2)); i2 \u0026lt;\u0026lt;= 32; System.out.println(\u0026#34;After \u0026lt;\u0026lt; 32, i2\u0026#39;s value is \u0026#34; + i2); System.out.println(\u0026#34;i2\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i2)); } // 输出结果： Before \u0026lt;\u0026lt; 31, i1\u0026#39;s value is -1 i1\u0026#39;s binary string is 11111111111111111111111111111111 After \u0026lt;\u0026lt; 31, i1\u0026#39;s value is -2147483648 i1\u0026#39;s binary string is 10000000000000000000000000000000 Before \u0026lt;\u0026lt; 32, i2\u0026#39;s value is -1 i2\u0026#39;s binary string is 11111111111111111111111111111111 After \u0026lt;\u0026lt; 32, i2\u0026#39;s value is -1 i2\u0026#39;s binary string is 11111111111111111111111111111111 上述例子中， w = 32，我们发现 k = 31 时，结果还符合预期；当 k = 32 时，结果不是 0，而是 -1，也即相当于 k = 0 时的结果。\n原因是这样，对 w 位整数 x，当执行 x \u0026lt;\u0026lt; k 时，实际执行的是 x \u0026lt;\u0026lt; (k % w)。所以，当 i2 \u0026lt;\u0026lt; 32 时，实际是 i2 \u0026lt;\u0026lt; 32 % 32 = i2 \u0026lt;\u0026lt; 0。\n右移操作也遵循同样的规则，也即 x \u0026gt;\u0026gt; k = x \u0026gt;\u0026gt; (k % w)， x \u0026gt;\u0026gt;\u0026gt; k = x \u0026gt;\u0026gt;\u0026gt; (k % w)。\n算术运算 整数的算术运算也不总符合我们的常识，比如下面这个例子：\n// Java语言 public static void main(String[] args) { int i1 = 2147483647; int i2 = 1; System.out.printf(\u0026#34;2147483647+1=%d\\n\u0026#34;, i1+i2); } // 输出结果： 2147483647+1=-2147483648 两个正数 2147483647 和 1 相加，实际运行结果却是一个负数 -2147483648。原因是，运算结果超出了 int 类型的表示范围，我们把这种现象称作 溢出。\n接下来，我们将介绍整数类型常见的几种算术运算，包括当运算出现溢出时，计算机系统的处理方式。\n加法 （1）无符号整数加法运算\n对两个 w 位的无符号整数 $x, y \\in[0, 2^w-1]$，有 $x+y\\in[0, 2^{w+1}-2]$；如果仍用一个 w 位的整数表示相加结果，那么当结果在 $[2^w, 2^{w+1}-2]$ 范围时，也即结果需要 w + 1 位表示时，运算就产生溢出了。\n如果出现溢出，系统会对结果进行截断，只保留低 w 位。\n比如，w = 4 场景下的一些例子：\n因此，如果用 $+_w^{u}$ 表示 w 位无符号整数的加法运算，那么它有如下规则： $$ x+_w^{u}y= \\begin{cases} x+y, \u0026amp;x+y\u0026lt;2^w\\ \u0026amp;正常\\\nx+y-2^w, \u0026amp;2^w\\le x+y\u0026lt;2^{w+1}\\ \u0026amp;溢出 \\end{cases} $$ 其中，溢出场景因为对结果的进行截断，舍去了 $w+1$ 位，所以结果需要减去 $2^w$。\n（2）有符号整数加法运算\n对两个 w 位的有符号整数 $x, y \\in[-2^{w-1}, 2^{w-1}-1]$，有 $x+y \\in[-2^{w}, 2^{w}-2]$；如果仍用一个 w 位的整数表示相加结果，那么当结果在 $[-2^{w}, -2^{w-1}-1]$ 和 $[2^{w-1}, 2^{w}-2]$ 范围时，运算就产生溢出了。\n比如，w = 4 场景下的一些例子：\n由上述例子可知，两个 w 位的负数相加，即使结果需要 w + 1 位表示，也可能是正常场景。这取决于截断位 w 位后的最高位，为 1 则还属于正常场景，为 0 则属于溢出场景。\n因此，如果用 $+_w^{t}$ 表示 w 位有符号整数的加法运算，那么它有如下规则： $$ x+_w^{t}y= \\begin{cases} x+y-2^w, \u0026amp;2^{w-1}\\le x+y\\ \u0026amp;正溢出\\\nx+y, \u0026amp;-2^{w-1}\\le x+y \u0026lt;2^{w-1}\\ \u0026amp;正常\\\nx+y+2^w, \u0026amp;x+y\u0026lt;-2^{w-1}\\ \u0026amp;负溢出 \\end{cases} $$\n 正溢出场景下，原本 $x+y=2^{w-1}+\\sum_{i=0}^{w-2}x_i\\cdot2^i$，但按照补码编码方式，实际变成了 $x+_w^{t}y=-2^{w-1}+\\sum_{i=0}^{w-2}x_i\\cdot2^i$，所以就有 $x+_w^{t}y=x+y-2^w$。 负溢出场景下，w 位一定是 0，原本 $x+y=-2^{w}+\\sum_{i=0}^{w-2}x_i\\cdot2^i$，结果截断之后，实际变成了 $x+_w^{t}y=\\sum_{i=0}^{w-2}x_i\\cdot2^i$，所以就有 $x+_w^{t}y=x+y+2^w$。   为什么负溢出场景下，w 位一定是 0？\n负溢出场景出现的条件是 $x+y\u0026lt;-2^{w-1}$，也即 : $$ x+y=-2^w+\\sum_{i=0}^{w-1}x_i\\cdot 2^i \u0026lt; -2^{w-1}\\\n=\u0026gt;\\sum_{i=0}^{w-1}x_i\\cdot 2^i \u0026lt; 2^w-2^{w-1}=2^{w-1}\\\n=\u0026gt;x_{w-1}\\cdot 2^{w-1} + \\sum_{i=0}^{w-2}x_i\\cdot 2^i \u0026lt; 2^{w-1}\\\n$$ 如果要使上述不等式成立，$x_{w-1}$ 必然为 0.\n 前面很多公式，但记住这个就行，无符号整数和有符号整数的加法运算规则，本质都是一样的，可以拆解成 4 步：\n 先计算出真实加法运算的结果值。 对结果值用 w + 1 位二进制表示。 再将 w + 1 位的二进制结果截断，保留低 w 位。 将截断后的 w 位二进制值转换回十进制整数，得到最终结果。无符号整数用无符号编码，有符号整数用补码编码。  取反 取反，也即求相反数，给定一个整数 $x$，那么它的相反数 $y = -x$，也即满足 $x + y = 0$。\n（1）无符号整数的取反\n对一个 w 位的无符号整数 $x \\in [0, 2^w-1]$，对它取反，也即找到一个整数 $y \\in [0, 2^w-1]$，使得 $x + y = 0$：\n 当 $x = 0$，那么很容易得出 $y = 0$； 当 x \u0026gt; 0，只有在溢出场景才会存在 $x+y=0$ 的可能。由前文可知，无符号整数加法溢出场景下，$x+_w^uy=x+y-2^w=0$ 时，有，$y=2^w-x$。  因此，如果用 $-_w^{u}$ 表示 w 位无符号整数的取反运算，那么它有如下规则： $$ -_w^{u}x= \\begin{cases} x, \u0026amp;x=0\\\n2^w-x, \u0026amp;x\u0026gt;0 \\end{cases} $$ 比如，w = 8 场景下的例子：\n// C++ int main() { uint8_t i1 = 0; uint8_t i2 = -i1; printf(\u0026#34;i1=%u\\n\u0026#34;, i1); printf(\u0026#34;-i1=%u\\n\u0026#34;, i2); uint8_t i3 = 100; uint8_t i4 = -i3; printf(\u0026#34;i3=%u\\n\u0026#34;, i3); printf(\u0026#34;-i3=%u\\n\u0026#34;, i4); printf(\u0026#34;2^8-i3=256-%u=%u\\n\u0026#34;, i3, 256-i3); return 0; } // 输出结果 i1=0 -i1=0 i3=100 -i3=156 2^8-i3=256-100=156 （2）有符号整数的取反\n对一个 w 位的有符号整数 $x \\in [-2^{w-1}, 2^{w-1}-1]$，对它取反，也即找到一个整数 $y \\in [-2^{w-1}, 2^{w-1}-1]$，使得 $x + y = 0$：\n 当 $x \u0026gt; -2^{w-1}$，很容易得出 $y = -x$，因为此时 $-x\\in [-2^{w-1}+1, 2^{w-1}-1]$ ，仍是有效的范围。 当 $x = -2^{w-1}$，因为 $2^{w-1}$ 已经不再有效范围内，所以只能是溢出场景。而 $-2^{w-1}-2^{w-1}=-2^w$，截断为 w 之后，刚好为 0。所以，此时 $-x = -2^{w-1}$。  因此，如果用 $-_w^{t}$ 表示 w 位有符号整数的取反运算，那么它有如下规则： $$ -_w^{t}x= \\begin{cases} -2^{w-1}, \u0026amp;x=-2^{w-1}\\\n-x, \u0026amp;x\u0026gt;-2^{w-1} \\end{cases} $$ 比如，w = 8 场景下的例子：\n// C++ int main() { int8_t i1 = -128; int8_t i2 = -i1; printf(\u0026#34;i1=%d\\n\u0026#34;, i1); printf(\u0026#34;-i1=%d\\n\u0026#34;, i2); int8_t i3 = 100; int8_t i4 = -i3; printf(\u0026#34;i3=%d\\n\u0026#34;, i3); printf(\u0026#34;-i3=%d\\n\u0026#34;, i4); return 0; } // 输出结果 i1=-128 -i1=-128 i3=100 -i3=-100 乘法 前面介绍加法时说过，无符号整数和有符号整数的加法运算都可以拆成 4 步，这对乘法运算也适用。\n对于无符号整数 $x,y \\in [0, 2^w-1]$，那么 $x\\cdot y \\in [0, (2^w-1)^2]=[0,2^{2w}-2^w+1]$，即无符号整数的乘法运算结果最多需要 2w 位来表示。\n比如，w = 8 时，无符号整数的例子：\n// C++ int main() { uint8_t i1 = 100; uint8_t i2 = 2; uint8_t i3 = i1 * i2; printf(\u0026#34;normal: i1 * i2 = %d * %d = %d\\n\u0026#34;, i1, i2, i3); uint8_t i4 = 100; uint8_t i5 = 3; uint8_t i6 = i4 * i5; printf(\u0026#34;overflow: i4 * i5 = %d * %d = %d\\n\u0026#34;, i4, i5, i6); return 0; } // 输出结果 normal: i1 * i2 = 100 * 2 = 200 overflow: i4 * i5 = 100 * 3 = 44 对于有符号整数 $x,y \\in [-2^{w-1}, 2^{w-1}-1]$，那么 $x\\cdot y \\in [-2^{w-1}\\cdot(2^{w-1}-1), (-2^{w-1})^2]=[-2^{2w-2}+2^{w-1},2^{2w-2}]$，即有符号整数的乘法运算结果最多也需要 2w 位来表示。\n比如，w = 8 时，有符号整数的例子：\n// C++ int main() { int8_t i1 = -50; int8_t i2 = 2; int8_t i3 = i1 * i2; printf(\u0026#34;normal: i1 * i2 = %d * %d = %d\\n\u0026#34;, i1, i2, i3); int8_t i4 = -128; int8_t i5 = 127; int8_t i6 = i4 * i5; printf(\u0026#34;overflow: i4 * i5 = %d * %d = %d\\n\u0026#34;, i4, i5, i6); return 0; } // 输出结果 normal: i1 * i2 = -50 * 2 = -100 overflow: i4 * i5 = -128 * 127 = -128 大部分机器上，乘法运算消耗 3 ~ 10 个 CPU 时钟周期，而加法运算和位运算只消耗 1 个时钟周期，所以，追求极致性能的程序都会想办法通过加法运算和位运算来替代乘法运算。\n如果不考虑截断，对 $x=[x_{w-1}, x_{w-2}, \u0026hellip;, x_0]_b$ 左移 k 位，会得到: $$ [x_{w-1}, x_{w-2}, \u0026hellip;, x_0,0,\u0026hellip;,0]_b=\\sum_{i=0}^{w-1}x_i\\cdot 2^{i+k}=[\\sum_{i=0}^{w-1}x_i\\cdot 2^i]\\cdot 2^k=x\\cdot 2^k $$ **也即，对** $x$ **左移 k 位 相当于乘以** $2^k$ 。\n如果考虑截断，就会存在溢出场景，对于 w 位的整数，左移 k 位效果也等同于 $x*_w^u2^k$ 或 $x*_w^t2^k$。\n比如，w = 8 时，无符号整数的例子：\n// C++ int main() { uint8_t i1 = 100; uint8_t i2 = 4; uint8_t i3 = i1 * i2; printf(\u0026#34;i1 * i2 = %d * %d = %d\\n\u0026#34;, i1, i2, i3); uint8_t k = 2; uint8_t i4 = i1 \u0026lt;\u0026lt; k; printf(\u0026#34;i1 \u0026lt;\u0026lt; k = %d \u0026lt;\u0026lt; %d = %d\\n\u0026#34;, i1, k, i4); return 0; } // 输出结果 i1 * i2 = 100 * 4 = 144 i1 \u0026lt;\u0026lt; k = 100 \u0026lt;\u0026lt; 2 = 144 有符号整数的例子：\n// C++ int main() { int8_t i1 = -50; int8_t i2 = 4; int8_t i3 = i1 * i2; printf(\u0026#34;i1 * i2 = %d * %d = %d\\n\u0026#34;, i1, i2, i3); int8_t k = 2; int8_t i4 = i1 \u0026lt;\u0026lt; k; printf(\u0026#34;i1 \u0026lt;\u0026lt; k = %d \u0026lt;\u0026lt; %d = %d\\n\u0026#34;, i1, k, i4); return 0; } // 输出结果 i1 * i2 = -50 * 4 = 56 i1 \u0026lt;\u0026lt; k = -50 \u0026lt;\u0026lt; 2 = 56 那么，对于与任意常数 K 的相乘，有没可能转换为移位操作？\n任意常数 K，可以表示成 $[(0\u0026hellip;0)(1\u0026hellip;1)(0\u0026hellip;0)\\cdot\\cdot\\cdot(1\u0026hellip;1)]_b$ 的形式，也即，由一系列连续的 0 和 连续的 1 组成，比如 14 可以表示成 $[(0\u0026hellip;0)(111)(0)]_b$。\n假设只存在一个连续的 1 序列，从高到低， 位于 n 到 m 位，比如 14 中，n = 3，m = 1，那么： $$ x\\cdot K=(x\u0026laquo; n)+(x\u0026laquo; n-1)+\u0026hellip;+(x\u0026laquo; m) $$ $$ x\\cdot K=(x\u0026laquo; (n+1))-(x\u0026laquo; m) $$\n比如，$x\\cdot14$ 就可以表示成 $(x\u0026laquo; 3)+(x\u0026laquo; 2)+(x\u0026laquo; 1)$ 或者 $(x\u0026laquo; 4)-(x\u0026laquo; 1)$：\n// C++ int main() { int8_t x = 5; int8_t K = 14; printf(\u0026#34;x * 14 = %d\\n\u0026#34;, x*K); printf(\u0026#34;(x\u0026lt;\u0026lt;3) + (x\u0026lt;\u0026lt;2) + (x\u0026lt;\u0026lt;1) = %d\\n\u0026#34;, (x\u0026lt;\u0026lt;3)+(x\u0026lt;\u0026lt;2)+(x\u0026lt;\u0026lt;1)); printf(\u0026#34;(x\u0026lt;\u0026lt;4) - (x\u0026lt;\u0026lt;1) = %d\\n\u0026#34;, (x\u0026lt;\u0026lt;4)-(x\u0026lt;\u0026lt;1)); return 0; } // 输出结果 x * 14 = 70 (x\u0026lt;\u0026lt;3) + (x\u0026lt;\u0026lt;2) + (x\u0026lt;\u0026lt;1) = 70 (x\u0026lt;\u0026lt;4) - (x\u0026lt;\u0026lt;1) = 70 同理，当 K 的二进制表示，存在多个连续的 1 序列时，也成立。\n除法 除法运算比乘法运算更慢，通常需要 30 个 CPU 时钟以上。同理， $x/2^k$ 也可以转换成右移运算，注意结果的取整： $$ \\lfloor x/2^k\\rfloor = x \u0026raquo; k\\ or\\ x \u0026raquo;\u0026gt; k $$\n$$ \\lceil x/2^k \\rceil = (x+(1\u0026laquo; k)-1)\u0026raquo; k\\ or\\ (x+(1\u0026laquo; k)-1)\u0026raquo;\u0026gt; k $$\n// C++ int main() { int8_t x = -50; int8_t K = 4; printf(\u0026#34;x / 4 = %d\\n\u0026#34;, x/K); printf(\u0026#34;x \u0026gt;\u0026gt; 2 = %d\\n\u0026#34;, x\u0026gt;\u0026gt;2); printf(\u0026#34;(x+(1\u0026lt;\u0026lt;2))\u0026gt;\u0026gt;2 = %d\\n\u0026#34;, (x+(1\u0026lt;\u0026lt;2))\u0026gt;\u0026gt;2); uint8_t y = 50; uint8_t Z = 4; printf(\u0026#34;y / 4 = %d\\n\u0026#34;, y/Z); printf(\u0026#34;y \u0026gt;\u0026gt;\u0026gt; 2 = %d\\n\u0026#34;, y\u0026gt;\u0026gt;2); printf(\u0026#34;(y+(1\u0026lt;\u0026lt;2))\u0026gt;\u0026gt;\u0026gt;2 = %d\\n\u0026#34;, (y+(1\u0026lt;\u0026lt;2))\u0026gt;\u0026gt;2); return 0; } // 输出结果 x / 4 = -12 x \u0026gt;\u0026gt; 2 = -13 (x+(1\u0026lt;\u0026lt;2))\u0026gt;\u0026gt;2 = -12 y / 4 = 12 y \u0026gt;\u0026gt;\u0026gt; 2 = 12 (y+(1\u0026lt;\u0026lt;2))\u0026gt;\u0026gt;\u0026gt;2 = 13 浮点数 考虑如下一段代码：\n// Java public class Example { public static void main(String[] args) { int i = 12345; float f = 12345.0F; System.out.printf(\u0026#34;binary str of i: %s\\n\u0026#34;, int2BinaryStr(i)); System.out.printf(\u0026#34;binary str of f: %s\\n\u0026#34;, float2BinaryStr(f)); } // 将int转为32位的二进制表示  private static String int2BinaryStr(int i) { String str = Integer.toBinaryString(i); for (int len = str.length(); len \u0026lt; 32; len++) { str = \u0026#34;0\u0026#34; + str; } return str; } // 将float转为32位的二进制表示  private static String float2BinaryStr(float f) { return int2BinaryStr(Float.floatToRawIntBits(f)); } } 我们将整数 i = 12345 和 浮点数 f = 12345.0 转成二进制表示，结果如下：\nbinary str of i: 00000000000000000011000000111001 binary str of f: 01000110010000001110010000000000 虽然从十进制上看，值都是 12345，但是两种类型的二进制表示却差别很大，说明，计算机系统对整数和浮点数的处理是两套不同的机制。\n大部分编程语言支持的整数最大是 64 位，但很多场景下，我们需要更大的取值范围，或者是小数运算，这些都是 64 位整数无法满足的场景。为了解决这些，计算机系统引入了 浮点数（Floating Point）类型。\n浮点数类型可以分为 32 位单精度 float/float32 类型和 64 位双精度 double/float64 类型，取值范围如下：\n   类型 最小值 最大值     float -3.40282347E+38 3.40282347E+38   double -1.79769313486231570E+308 1.79769313486231570E+308    虽然浮点数的取值范围很广，但它只能精确表示其中一小部分，其他都是近似表示。\n下面，我们将深入介绍浮点数的二进制表示和近似规则。\n简单浮点数编码 对于十进制数 $d$，可以表示成 $[d_md_{m-1}\\cdot\\cdot\\cdot d_1d_0.d_{-1}d_{-2}\\cdot\\cdot\\cdot d_{-n+1}d_{-n}]_d$，其中，以小数点 $.$ 为界，左边为整数部分，右边为小数部分，那么： $$ d=\\sum_{i=-n}^m10^i\\cdot d_i $$ 比如，$123.45_d=10^2\\cdot1+10^1\\cdot2+10^0\\cdot3+10^{-1}\\cdot4+10^{-2}\\cdot5$ 。\n同理，对于二进制数 $b$，也可以表示成 $[b_mb_{m-1}\\cdot\\cdot\\cdot b_1b_0.b_{-1}b_{-2}\\cdot\\cdot\\cdot b_{-n+1}b_{-n}]_b$，同样以小数点 $.$ 分割整数和小数部分，那么： $$ b=\\sum_{i=-n}^m2^i\\cdot b_i $$ 比如，$101.11_b=2^2\\cdot1+2^1\\cdot0+2^0\\cdot1+2^{-1}\\cdot1+2^{-2}\\cdot1=5.75_d$。\n计算机系统的这种编码方式，注定只能表示 $M*2^E$ 形式的数，其他的，只能近似表示。\n比如，无法精确表示 0.2：\n   二进制表示 分数 十进制表示     0.0 0/2 0.0   0.01 1/4 0.25   0.010 2/8 0.25   0.0011 3/16 0.1875   0.00110 6/32 0.1875   0.001101 13/64 0.203125   0.0011010 26/128 0.203125   0.00110011 51/256 0.19921875    浮点数除了表示小数之外，还须表示大数，按照这种二进制编码思路，如果要表示 $5\\cdot2^{100}$ ，需要 102 位，受限于计算机系统的编码长度，这显然不能接受。\n其实，对 $M\\cdot2^E$ 形式的数，我们只须存储 M 和 E 即可，再来一个符号位 s，即可表示这种形式的数： $V=(-1)^s\\cdot M\\cdot2^E$。\n对 w 位浮点数，可以用 1 位表示 s，用 k 位表示 E，用 n 位表示 M，那么就有 w = 1 + k + n：\n（1）s 的编码\n用 0 表示正数，1 表示负数。\n（2）E 的编码\n二进制表示为 $[e_{k-1}e_{k-2}\u0026hellip;e_1e_0]$，因为 E 可以是正，也可以是负，因此，可以直接用 **补码** 进行编码。\n比如，k = 4 时，E 的取值是这样的：\n   e E     0000 0   0001 1   \u0026hellip;    0111 7   1000 -8   1001 -7   \u0026hellip;    1111 -1    但是，这样从 $[0000]_b$ 到 $[1111]_b$ 并不是递增的趋势。另一种方法是，对 e 用无符号编码，令 $E = e - Bias$，其中，$Bias=2^{k-1}-1$。比如，k = 4 时，$Bias=7$，那么 E 的取值是这样的：\n   e Bias E     0000 7 -7   0001 7 -6   \u0026hellip;     0111 7 0   1000 7 1   1001 7 2   \u0026hellip;     1111 7 8    （3）M 的编码\n二进制表示为 $[m_{n-1}m_{m-2}\u0026hellip;m_1m_0]$，M 不涉及负数，因此可以只用最高位表示整数，其他表示小数，即 $[m_{n-1}.m_{m-2}\u0026hellip;m_1m_0]$。比如，当 n = 3 时，M 的取值如下：\n   m M 十进制     000 0.00 0.00 (0/4)   001 0.01 0.25 (1/4)   010 0.10 0.5 (2/4)   011 0.11 0.75 (3/4)   100 1.00 1.00 (4/4)   101 1.01 1.25 (5/4)   110 1.10 1.5 (6/4)   111 1.11 1.75 (7/4)    但是，这种编码方式会导致 0 有很多种表示。比如 w = 8，k = 4，n = 3 时，因为 $V=(-1)^s\\cdot M\\cdot2^E$，所以 $[00000000]_b$、$[00001000]_b$、$[00010000]_b$ 等的浮点数值都是 0。\n可以这么改动，令 $m=[0.m_{n-1}m_{m-2}\u0026hellip;m_1m_0]$，当 $e = 0$ 时，$M = m$；当 $e\\neq0$ 时，$M=1+m$：\n   e m M 十进制     0000 000 0.000 0.000 (0/8)   0000 001 0.001 0.125 (1/8)   \u0026hellip;      0000 111 0.111 0.875 (7/8)   0001 000 1.000 1.000 (8/8)   0001  1.001 1.125 (9/8)   \u0026hellip;       这样，既解决了 0 的表示问题，又让 M 的精度更大了。\nIEEE 浮点数编码 上述这些编码方法，就是 IEEE 754 Floating-Point Representation 标准中定义的浮点数编码方式的基本思路，标准会在此基础上做了一些调整，比如新增了 Infinity 和 NaN 的表示。\nIEEE 标准将浮点数分成 单精度 和 双精度 两种，分别用 32 位和 64 位表示，它们的 k 值和 n 值都不同：\n在此基础上，根据 e 的取值不同，又分为 3 种场景，Denormalized Values、Normalized Values、Special Values：\n（1）Denormalized Values\n此场景下，e 取值为全 0，用来表示 0 值，以及接近 0 的小数。\n在 $V=(-1)^s\\cdot M\\cdot2^E$ 的表示下，$M = m$，$E = 1 - Bias = 1 - (2^{k-1}-1)$。\n 为什么 ，而不是 E = -Bias？\n根据前文分析，应该有 E = e - Bias，但 Denormalized Values 中，确是 E = 1 - Bias，而不是 E = 0 - Bias。\n这主要考虑到，从 Denormalized Values 到 Normalized Values 的平滑过度，让 Largest Denormalized Value 和 Smallest Normalized Value 更接近。后面的举例可以看到。\n 这里，0 分为了 -0.0 和 +0.0，在一些科学计算场景下，它们会表示不同的含义。比如 $1/(+0.0) =+\\infty$，$1/(-0.0) =-\\infty$。\n（2） Normalized Values\n此场景下，e 取值不是全 0，也不是全 1，是最常见的场景。\n在 $V=(-1)^s\\cdot M\\cdot2^E$ 的表示下，$M = 1 + m = 1.m_{n-1}m_{n-2}\u0026hellip;m_0$，$E = e - Bias = e - (2^{k-1}-1)$。\n（3）Special Values\n此场景下，e 取值为全 1，用来表示 Infinity 和 NaN。\n m 取值全 0，表示 Infinity：1）s = 0 时，为 $+\\infty$；2）s = 1 时，为 $-\\infty$。 m 取值不是全 0，表示 NaN（Not a Number），比如 $\\sqrt{-1}$ 或者 $\\infty-\\infty$。  比如，w = 8，k = 4（此时，$Bias=2^{k-1}-1=7$），n = 3 时，IEEE 标准浮点数的编码例子如下：\n   场景 二进制 e E $2^E$ m M $2^E\\cdot M$ 十进制     Denormalized 0 0000 000 0 -6 1/64 0/8 0/8 0/512 0.0    0 0000 001 0 -6 1/64 1/8 1/8 1/512 0.001953    \u0026hellip;           0 0000 111 0 -6 1/64 7/8 7/8 7/512 0.013672   Normalized 0 0001 000 1 -6 1/64 0/8 8/8 8/512 0.015625    0 0001 001 1 -6 1/64 1/8 9/8 9/512 0.017578    \u0026hellip;           0 1110 111 14 7 128 7/8 15/8 1920/8 240.0   Infinity 0 1111 000 - - - - - - $+\\infty$   NaN 0 1111 001 - - - - - - NaN    \u0026hellip;       NaN     从上表可以看出，因为 Denormalized 场景下令 E = 1 - Bias，从 Denormalized 到 Normalized 的过度，也即 7/512 到 8/512，更平滑了。如果令 E = - Bias，则是从 7/1024 到 8/512，跨度太大。\n 到这里，我们已经深入介绍了 IEEE 浮点数编码格式，回到本节最开始的例子，如何从 int i = 12345 的二进制表示，推断出 float f = 12345.0 的二进制表示？\n 首先，12345 整数的二进制表示为 $11000000111001_b$ ，也可以表示成 $1.1000000111001_b \\cdot 2^{13}$ ，对应到 $V=(-1)^s\\cdot M\\cdot2^E$ 的形式，可以确认 s = 0，E = 13，M = 1.1000000111001。 另外，12345 属于 Normalized 场景，而 float 类型中 k = 8，有，$E = e - (2^{8-1}-1) = 13$，得出 e = 140，按 k 位无符号编码表示为 $[10001100]_b$。 同理，由 $M = 1 + 0.m_{n-1}m_{n-2}\u0026hellip;m_0=1.1000000111001$，float 类型中，n = 23，所以，得出 m 的二进制表示为 $[10000001110010000000000]_b$，注意，**低位补零**。 最后将 s、e、m 按照 float 单精度的编码格式组合起来，就是 $[0\\ 10001100\\ 10000001110010000000000]_b$，也即 12345.0 的二进制编码。  近似规则（Rounding） 前面说过，浮点数只能表示 $M*2^E$ 形式的数，其他的，只能近似表示。\n近似规则，我们最熟悉的是 “四舍五入”，比如，要保留 2 位小数，那么 1.234、1.235、1.236 近似之后分别是 1.23、1.24、1.24。\nIEEE 浮点数标准中，并没采用 “四舍五入” 法，定义了如下 4 种近似规则：\n Round-to-even，往更近的方向靠，如果向上和向下的距离一样，则往偶数的方向靠。 Round-toward-zero，往 0 的方向靠。 Round-down，往更小的方向靠。 Round-up，往更大的方向靠。  比如，下面的例子，需要近似为整数：\n   规则 1.40 1.60 1.50 2.50 -1.50     Round-to-even 1 2 2 2 -2   Round-toward-zero 1 1 1 2 -1   Round-down 1  1  -2   Round-up 2 2  3 -1    这些规则对二进制也生效，比如，Round-to-even 规则，在二进制中，0 代表偶数，1 表示奇数。下面例子中，需要按照 Round-to-even 近似保留 2 位小数：\n   二进制（十进制） 向下 中点 向上 Round-to-even     10.00011 (67/32) 10.00 (64/32) 68/32 10.01 (72/32) 10.00 (64/32)   10.00110 (70/32) 10.00 (64/32) 68/32 10.01 (72/32) 10.01 (72/32)   10.11100 (23/8) 10.11 (22/8) 23/8 11.00 (24/8) 11.00 (24/8)   10.10100 (21/8) 10.10 (20/8) 21/8 10.11 (22/8) 10.10 (20/8)    上述例子中，前 2 个按照就近原则近似；后 2 个处于中点位置，往偶数方向靠。\n注意，IEEE 标准规定 Round-to-even 为默认的近似规则。\n浮点数运算 浮点数的运算规则比较简单，令 $\\oplus$ 指代后一类的运算符，x 和 y 为浮点数类型，那么 $x \\oplus y$ 的运算结果为 $Round(x \\oplus y)$，也即对真实计算结果进行近似。\n注意，算术运算的结合律、分配率在浮点数运算下是不生效的，比如：\n// Java public static void main(String[] args) { // 结合律不满足示例  float f1 = 3.14F; float f2 = 1e10F; float f3 = (f1 + f2) - f2; float f4 = f1 + (f2 - f2); System.out.printf(\u0026#34;(3.14 + 1e10) - 1e10 = %f\\n\u0026#34;, f3); System.out.printf(\u0026#34;3.14 + (1e10 - 1e10) = %f\\n\u0026#34;, f4); // 分配律不满足示例  float f5 = 1e20F; float f6 = f5 * (f5 - f5); float f7 = f5 * f5 - f5 * f5; System.out.printf(\u0026#34;1e20 * (1e20 - 1e20) = %f\\n\u0026#34;, f6); System.out.printf(\u0026#34;1e20 * 1e20 - 1e20 * 1e20 = %f\\n\u0026#34;, f7); } // 输出结果 (3.14 + 1e10) - 1e10 = 0.000000 3.14 + (1e10 - 1e10) = 3.140000 1e20 * (1e20 - 1e20) = 0.000000 1e20 * 1e20 - 1e20 * 1e20 = NaN 结合律例子中，(3.14+1e10)-1e10 结果是 0，因为 3.14 在近似时，精度丢失了，也即 3.14+1e10=1e10；类似，分配律例子中，1e20*1e20 的结果超出了 float 类型的表示范围，得到 Infinity，而 Infinity - Infinity 的结果是 NaN。\n注意，浮点数运算结果，如果超出了浮点数表示范围，会得到 Infinity/-Infinity。这与整数运算的溢出机制有所区别。\n数值类型转换 数值类型间的转换，可以分成 2 类：宽转换（Widening Conversion）和 窄转换（Narrowing Conversion）。\n宽转换指往表示范围更广的类型转换，比如从 int 到 long、从 long 到 float；窄转换则相反。\n整型间转换 （1）宽转换\n整型间的宽转换不会产生溢出，无符号整数场景，高位补零；有符号整数场景，高位补符号位。\n// C++ int main() { int8_t i1 = 100; cout \u0026lt;\u0026lt; \u0026#34;int8_t i1: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;(i1) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;int16_t i1: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;16\u0026gt;((int16_t) i1) \u0026lt;\u0026lt; endl; int8_t i2 = -100; cout \u0026lt;\u0026lt; \u0026#34;int8_t i2: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;(i2) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;int16_t i2: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;16\u0026gt;((int16_t) i2) \u0026lt;\u0026lt; endl; uint8_t i3 = 200; cout \u0026lt;\u0026lt; \u0026#34;uint8_t i3: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;(i3) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;uint16_t i3: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;16\u0026gt;((uint16_t) i3) \u0026lt;\u0026lt; endl; return 0; } // 输出结果 int8_t i1: 01100100 int16_t i1: 0000000001100100 int8_t i2: 10011100 int16_t i2: 1111111110011100 uint8_t i3: 11001000 uint16_t i3: 0000000011001000 （2）窄转换\n整型间的窄转换直接进行高位截断，只保留低 n 位。比如 16 位的 int16 转换为 8 位的 int8，直接保留 int16 类型值的低 8 位作为转换结果。\n// C++ int main() { int16_t i1 = 200; cout \u0026lt;\u0026lt; \u0026#34;int16_t i1: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;16\u0026gt;(i1) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;int8_t i1: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;((int8_t) i1) \u0026lt;\u0026lt; endl; int16_t i2 = -200; cout \u0026lt;\u0026lt; \u0026#34;int16_t i2: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;16\u0026gt;(i2) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;int8_t i2: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;((int8_t) i2) \u0026lt;\u0026lt; endl; uint16_t i3 = 300; cout \u0026lt;\u0026lt; \u0026#34;uint16_t i3: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;16\u0026gt;(i3) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;uint8_t i3: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;((uint8_t) i3) \u0026lt;\u0026lt; endl; return 0; } // 输出结果 int16_t i1: 0000000011001000 int8_t i1: 11001000 int16_t i2: 1111111100111000 int8_t i2: 00111000 uint16_t i3: 0000000100101100 uint8_t i3: 00101100 （3）无符号整数与有符号整数间的转换\n无符号整数与有符号整数间的转换规则是：\n 如果两者二进制位数一致，比如 int8 到 uint8 的转换，则二进制数值不变，只是改变编码方式； 如果位数不一致，比如 int16 到 uint8 的转换，则二进制数值，先按照宽转换或窄转换规则转换，再改变编码方式。  // C++ int main() { uint8_t i1 = 200; cout \u0026lt;\u0026lt; \u0026#34;uint8_t i1, decimal: \u0026#34; \u0026lt;\u0026lt; +i1 \u0026lt;\u0026lt; \u0026#34;, binary: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;(i1) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;int8_t i1, decimal: \u0026#34; \u0026lt;\u0026lt; +(int8_t) i1 \u0026lt;\u0026lt; \u0026#34;, binary: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;((int8_t) i1) \u0026lt;\u0026lt; endl; int16_t i2 = -300; cout \u0026lt;\u0026lt; \u0026#34;int16_t i2, decimal: \u0026#34; \u0026lt;\u0026lt; +i2 \u0026lt;\u0026lt; \u0026#34;, binary: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;16\u0026gt;(i2) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;uint8_t i2, decimal: \u0026#34; \u0026lt;\u0026lt; +(uint8_t) i2 \u0026lt;\u0026lt; \u0026#34;, binary: \u0026#34; \u0026lt;\u0026lt; bitset\u0026lt;8\u0026gt;((uint8_t) i2) \u0026lt;\u0026lt; endl; return 0; } // 输出结果 uint8_t i1, decimal: 200, binary: 11001000 int8_t i1, decimal: -56, binary: 11001000 int16_t i2, decimal: -300, binary: 1111111011010100 uint8_t i2, decimal: 212, binary: 11010100 整数与浮点数间转型 （1）宽转换\n整型到浮点数类型的转换这一方向，为宽转换：\n 如果浮点数的精度，能够表示整数，则正常转换。 如果浮点数精度，无法表示整数，则需要近似，会导致精度丢失。  // Java public static void main(String[] args) { int i1 = 1234567; System.out.printf(\u0026#34;int i1: %d, float i1: \u0026#34;, i1); System.out.println((float) i1); int i2 = 123456789; System.out.printf(\u0026#34;int i2: %d, float i2: \u0026#34;, i2); System.out.println((float) i2); } // 输出结果 int i1: 1234567, float i1: 1234567.0 int i2: 123456789, float i2: 1.23456792E8 上述例子中，i2=123456789 超过 float 类型能够表示的精度，所以为近似后的结果 1.23456792E8。\n那么，为什么 123456789 会近似为 1.23456792E8？\n要解释该问题，首先要把它们转换成二进制表示：\npublic static void main(String[] args) { ... System.out.println(\u0026#34;int i2: \u0026#34; + int2BinaryStr(i2)); System.out.println(\u0026#34;float i2: \u0026#34; + float2BinaryStr((float) i2)); } // 输出结果 int i2: 00000111010110111100110100010101 float i2: 01001100111010110111100110100011 接下来，我们根据 IEEE 浮点数的编码规则，尝试将 int i2 转换成 float i2：\n int i2 的二进制 $00000111010110111100110100010101_b$，可以写成 $1.11010110111100110100010101\\cdot2^{26}$，对应到 $V=(-1)^s\\cdot M\\cdot2^E$ 的形式，可以确认 s = 0，E = 26，M = 1.11010110111100110100010101。 float 类型中 k = 8，有，$E = e - (2^{8-1}-1) = 26$，得出 e = 153，按 k 位无符号编码表示为 $[10011001]_b$。 同理，由 $M = 1 + 0.m_{n-1}m_{n-2}\u0026hellip;m_0=1.11010110111100110100010101$，但由于 float 类型的 n = 23，而 m 一共有 26 位，因此需要按照 round-to-even 规则，对 0.11010110111100110100010101进行近似，保留 23 位小数，得到 0.11010110111100110100011，所以 m 为 $[11010110111100110100011]_b$ 最后，将 s、e、m 按照 float 单精度的编码格式组合起来，就是 $[0\\ 10011001\\ 11010110111100110100011]_b$，转换成十进制，就是 1.23456792E8。  （2）窄转换\n浮点数类型到整型的转换这一方向，为窄转换：\n 如果浮点数的整数部分，能够用整型表示，则直接舍去小数，保留整数部分。 如果超出了整型范围，则结果为该整型的最大/最小值。  // Java public static void main(String[] args) { float f1 = 12345.123F; System.out.print(\u0026#34;float f1: \u0026#34;); System.out.print(f1); System.out.printf(\u0026#34;, int f1: %d\\n\u0026#34;, (int) f1); float f2 = 1.2345E20F; System.out.print(\u0026#34;float f2: \u0026#34;); System.out.print(f2); System.out.printf(\u0026#34;, int f2: %d\\n\u0026#34;, (int) f2); float f3 = -1.2345E20F; System.out.print(\u0026#34;float f3: \u0026#34;); System.out.print(f3); System.out.printf(\u0026#34;, int f3: %d\\n\u0026#34;, (int) f3); } // 输出结果 float f1: 12345.123, int f1: 12345 float f2: 1.2345E20, int f2: 2147483647 float f3: -1.2345E20, int f3: -2147483648 浮点数间转型 （1）宽转换\n单精度 float 到 双精度 double 为宽转换，不会出现精度丢失的问题。\n对于 $V=(-1)^s\\cdot M\\cdot2^E$ ，规则如下：\n s 保持不变。 在 E 保持不变的前提下，因为 float 的 k = 8，而 double 的 k = 11，所以两者的 e 会有所不同。 在 M 保持不变的前提下，float 的 n = 23，而 double 的 n =52，所以 m 需要低位补 52 - 23 = 29 个 0。  // Java public static void main(String[] args) { float f1 = 1.2345E20F; System.out.print(\u0026#34;float f1: \u0026#34;); System.out.print(f1); System.out.print(\u0026#34;, double f1: \u0026#34;); System.out.println((double) f1); System.out.println(\u0026#34;float f1: \u0026#34; + float2BinaryStr(f1)); System.out.println(\u0026#34;double f1: \u0026#34; + double2BinaryStr((double) f1)); } // 输出结果 float f1: 1.2345E20, double f1: 1.2344999897320129E20 float f1: 01100000110101100010011011010000 double f1: 0100010000011010110001001101101000000000000000000000000000000000 （2）窄转换\ndouble 到 float 为窄转换，会存在精度丢失问题。\n如果 double 值超出了 float 的表示范围，则转换结果为 Infinity：\n// Java public static void main(String[] args) { double d1 = 1E200; System.out.print(\u0026#34;double d1: \u0026#34;); System.out.println(d1); System.out.print(\u0026#34;float d1: \u0026#34;); System.out.println((float) d1); double d2 = -1E200; System.out.print(\u0026#34;double d2: \u0026#34;); System.out.println(d2); System.out.print(\u0026#34;float d2: \u0026#34;); System.out.println((float) d2); } // 输出结果 double d1: 1.0E200 float d1: Infinity double d2: -1.0E200 float d2: -Infinity 如果 double 值还在 float 的表示范围内，则按照如下转换规则：\n s 保持不变。 在 E 保持不变的前提下，因为 float 的 k = 8，而 double 的 k = 11，所以两者的 e 会有所不同。 对于 M，因为 float 的 n = 23，而 double 的 n = 52，所以转换到 float 之后，需要进行截断，只保留高 23 位。  // Java public static void main(String[] args) { double d1 = 3.267393471324506; System.out.print(\u0026#34;double d1: \u0026#34;); System.out.println(d1); System.out.print(\u0026#34;float d1: \u0026#34;); System.out.println((float) d1); System.out.println(\u0026#34;double d1: \u0026#34; + double2BinaryStr(d1)); System.out.println(\u0026#34;float d1: \u0026#34; + float2BinaryStr((float) d1)); } // 输出结果 double d1: 3.267393471324506 float d1: 3.2673936 double d1: 0100000000001010001000111001111100110000001101000000010101110110 float d1: 01000000010100010001110011111010 最后 本文花了很长的篇幅，深入介绍了计算机系统对数值类型的编码、运算、转换的底层原理。\n数值类型间的转换是最容易出现隐藏 bug 的地方，特别是无符号整数与有符号整数之间的转换。所以，很多现代的编程语言，如 Java、Go 等都不再支持无符号整数，根除了该隐患。\n另外，浮点数的编码方式，注定它只能精确表示一小部分的数值范围，大部分都是近似，所以才有了不能用等号来比较两个浮点数的说法。\n数值类型虽然很基础，但使用时一定要多加小心。希望本文能够加深你对数值类型的理解，让你写出更健壮的程序。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] Computer Systems: A Programmer\u0026rsquo;s Perspective (3rd edition), Randal E. Bryant .etc\n[2] The Java® Language Specification (Java SE 18 Edition), James Gosling .etc\n[3] IEEE Standard 754 Floating-Point Representation, IEEE\n[4] 漫话：为什么计算机用补码存储数据？, 漫话编程\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-08-18T00:00:00Z","permalink":"https://www.yrunz.com/p/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B/","title":"深入理解计算机系统的数值类型"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：观察者模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 有时会遇到这样的需求，开发一个模块，用于保存对象；不能用简单的数组、列表，得是红黑树、跳表等较为复杂的数据结构；有时为了提升存储效率或持久化，还得将对象序列化；但必须给客户端提供一个易用的 API，允许方便地、多种方式地遍历对象，丝毫不察觉背后的数据结构有多复杂。\n对这样的 API，很适合使用 迭代器模式（Iterator Pattern）实现。\nGoF 对 迭代器模式 的定义如下：\n Provide a way to access the elements of an aggregate object sequentially without exposing its underlying representation.\n 从描述可知，迭代器模式主要用在访问对象集合的场景，能够向客户端隐藏集合的实现细节。\nJava 的 Collection 家族、C++ 的 STL 标准库，都是使用迭代器模式的典范，它们为客户端提供了简单易用的 API，并且能够根据业务需要实现自己的迭代器，具备很好的可扩展性。\nUML 结构 场景上下文 在 简单的分布式应用系统（示例代码工程）中，db 模块用来存储服务注册和监控信息，它的主要接口如下：\n// demo/db/db.go package db // Db 数据库抽象接口 type Db interface { CreateTable(t *Table) error CreateTableIfNotExist(t *Table) error DeleteTable(tableName string) error Query(tableName string, primaryKey interface{}, result interface{}) error Insert(tableName string, primaryKey interface{}, record interface{}) error Update(tableName string, primaryKey interface{}, record interface{}) error Delete(tableName string, primaryKey interface{}) error ... } 从增删查改接口可以看出，它是一个 key-value 数据库，另外，为了提供类似关系型数据库的按列查询能力，我们又抽象出 Table 对象：\n// demo/db/table.go package db // Table 数据表定义 type Table struct { name string recordType reflect.Type records map[interface{}]record } 其中，Table 底层用 map 存储对象数据，但并没有存储对象本身，而是从对象转换而成的 record 。record 的实现原理是利用反射机制，将对象的属性名 field 和属性值 value 分开存储，以此支持按列查询能力（一类对象可以类比为一张表）：\n// demo/db/record.go package db type record struct { primaryKey interface{} fields map[string]int // key为属性名，value属性值的索引  values []interface{} // 存储属性值 } // 从对象转换成record func recordFrom(key interface{}, value interface{}) (r record, e error) { ... // 异常处理  vType := reflect.TypeOf(value) vVal := reflect.ValueOf(value) if vVal.Type().Kind() == reflect.Pointer { vType = vType.Elem() vVal = vVal.Elem() } record := record{ primaryKey: key, fields: make(map[string]int, vVal.NumField()), values: make([]interface{}, vVal.NumField()), } for i := 0; i \u0026lt; vVal.NumField(); i++ { fieldType := vType.Field(i) fieldVal := vVal.Field(i) name := strings.ToLower(fieldType.Name) record.fields[name] = i record.values[i] = fieldVal.Interface() } return record, nil } 当然，客户端并不会察觉 db 模块背后的复杂机制，它们直接使用的仍是对象：\ntype testRegion struct { Id int Name string } func client() { mdb := db.MemoryDbInstance() tableName := \u0026#34;testRegion\u0026#34; table := NewTable(tableName).WithType(reflect.TypeOf(new(testRegion))) mdb.CreateTable(table) mdb.Insert(tableName, \u0026#34;region1\u0026#34;, \u0026amp;testRegion{Id: 0, Name: \u0026#34;region-1\u0026#34;}) result := new(testRegion) mdb.Query(tableName, \u0026#34;region1\u0026#34;, result) } 另外，除了上述按 Key 查询接口，我们还想提供全表查询接口，有随机和有序 2 种表记录遍历方式，并且支持客户端自己扩展遍历方式。下面使用迭代器模式来实现该需求。\n代码实现 这里并没有按照标准的 UML 结构去实现，而是结合 工厂方法模式 来解决公共代码的复用问题：\n// demo/db/table_iterator.go package db // 关键点1: 定义迭代器抽象接口，允许后续客户端扩展遍历方式 // TableIterator 表迭代器接口 type TableIterator interface { HasNext() bool Next(next interface{}) error } // 关键点2: 定义迭代器接口的实现 // tableIteratorImpl 迭代器接口公共实现类 type tableIteratorImpl struct { // 关键点3: 定义一个集合存储待遍历的记录，这里的记录已经排序好或者随机打散  records []record // 关键点4: 定义一个cursor游标记录当前遍历的位置  cursor int } // 关键点5: 在HasNext函数中的判断是否已经遍历完所有记录 func (r *tableIteratorImpl) HasNext() bool { return r.cursor \u0026lt; len(r.records) } // 关键点6: 在Next函数中取出下一个记录，并转换成客户端期望的对象类型，记得增加cursor func (r *tableIteratorImpl) Next(next interface{}) error { record := r.records[r.cursor] r.cursor++ if err := record.convertByValue(next); err != nil { return err } return nil } // 关键点7: 通过工厂方法模式，完成不同类型的迭代器对象创建 // TableIteratorFactory 表迭代器工厂 type TableIteratorFactory interface { Create(table *Table) TableIterator } // 随机迭代器 type randomTableIteratorFactory struct{} func (r *randomTableIteratorFactory) Create(table *Table) TableIterator { var records []record for _, r := range table.records { records = append(records, r) } rand.Seed(time.Now().UnixNano()) rand.Shuffle(len(records), func(i, j int) { records[i], records[j] = records[j], records[i] }) return \u0026amp;tableIteratorImpl{ records: records, cursor: 0, } } // 有序迭代器 // Comparator 如果i\u0026lt;j返回true，否则返回false type Comparator func(i, j interface{}) bool // sortedTableIteratorFactory 根据主键进行排序，排序逻辑由Comparator定义 type sortedTableIteratorFactory struct { comparator Comparator } func (s *sortedTableIteratorFactory) Create(table *Table) TableIterator { var records []record for _, r := range table.records { records = append(records, r) } sort.Sort(newRecords(records, s.comparator)) return \u0026amp;tableIteratorImpl{ records: records, cursor: 0, } } 最后，为 Table 对象引入 TableIterator：\n// demo/db/table.go  // Table 数据表定义 type Table struct { name string recordType reflect.Type records map[interface{}]record // 关键点8: 持有迭代器工厂方法接口  iteratorFactory TableIteratorFactory // 默认使用随机迭代器 } // 关键点9: 定义Setter方法，提供迭代器工厂的依赖注入 func (t *Table) WithTableIteratorFactory(iteratorFactory TableIteratorFactory) *Table { t.iteratorFactory = iteratorFactory return t } // 关键点10: 定义创建迭代器的接口，其中调用迭代器工厂完成实例化 func (t *Table) Iterator() TableIterator { return t.iteratorFactory.Create(t) } 客户端这样使用：\nfunc client() { table := NewTable(\u0026#34;testRegion\u0026#34;).WithType(reflect.TypeOf(new(testRegion))). WithTableIteratorFactory(NewSortedTableIteratorFactory(regionIdComparator)) iter := table.Iterator() for iter.HashNext() { next := new(testRegion) err := iter.Next(next) ... } } 总结实现迭代器模式的几个关键点：\n 定义迭代器抽象接口，目的是提供客户端自扩展能力，通常包含 HashNext() 和 Next() 两个方法，上述例子为 TableIterator。 定义迭代器接口的实现类，上述例子为 tableIteratorImpl，这里主要起到了 Java/C++ 等带继承特性语言中，基类的作用，目的是复用代码。 在实现类中持有待遍历的记录集合，通常是已经排序好或随机打散后的，上述例子为 tableIteratorImpl.records。 在实现类中持有游标值，记录当前遍历的位置，上述例子为 tableIteratorImpl.cursor。 在 HashNext() 方法中判断是否已经遍历完所有记录。 在 Next() 方法中取出下一个记录，并转换成客户端期望的对象类型，取完后增加游标值。 通过工厂方法模式，完成不同类型的迭代器对象创建，上述例子为 TableIteratorFactory 接口，以及它的实现，randomTableIteratorFactory 和 sortedTableIteratorFactory。 在待遍历的对象中，持有迭代器工厂方法接口，上述例子为 Table.iteratorFactory。 为对象定义 Setter 方法，提供迭代器工厂的依赖注入，上述例子为 Table.WithTableIteratorFactory() 方法。 为对象定义创建迭代器的接口，上述例子为 Table.Iterator() 方法。  其中，7～9 步是结合 工厂方法模式 实现时的特有步骤，如果你的迭代器实现中没有用到工厂方法模式，可以省略这几步。\n扩展 Go 风格的实现 前面的实现，是典型的面向对象风格，下面以随机迭代器为例，给出一个 Go 风格的实现：\n// demo/db/table_iterator_closure.go package db // 关键点1: 定义HasNext和Next函数类型 type HasNext func() bool type Next func(interface{}) error // 关键点2: 定义创建迭代器的方法，返回HashNext和Next函数 func (t *Table) ClosureIterator() (HasNext, Next) { var records []record for _, r := range t.records { records = append(records, r) } rand.Seed(time.Now().UnixNano()) rand.Shuffle(len(records), func(i, j int) { records[i], records[j] = records[j], records[i] }) size := len(records) cursor := 0 // 关键点3: 在迭代器创建方法定义HasNext和Next的实现逻辑  hasNext := func() bool { return cursor \u0026lt; size } next := func(next interface{}) error { record := records[cursor] cursor++ if err := record.convertByValue(next); err != nil { return err } return nil } return hasNext, next } 客户端这样用：\nfunc client() { table := NewTable(\u0026#34;testRegion\u0026#34;).WithType(reflect.TypeOf(new(testRegion))). WithTableIteratorFactory(NewSortedTableIteratorFactory(regionIdComparator)) hasNext, next := table.ClosureIterator() for hasNext() { result := new(testRegion) err := next(result) ... } } Go 风格的实现，利用了函数闭包的特点，把原本在迭代器实现的逻辑，放到了迭代器创建方法上。相比面向对象风格，省掉了迭代器抽象接口和实现对象的定义，看起来更加的简洁。\n总结几个实现关键点：\n 声明 HashNext 和 Next 的函数类型，等同于迭代器抽象接口的作用。 定义迭代器创建方法，返回类型为 HashNext 和 Next，上述例子为 ClosureIterator() 方法。 在迭代器创建方法内，定义 HasNext 和 Next 的具体实现，利用函数闭包来传递状态（records 和 cursor）。  基于 channel 的实现 我们还能基于 Go 语言中的 channel 来实现迭代器模式，因为前文的 db 模块应用场景并不适用，所以另举一个简单的例子：\ntype Record int func (r *Record) doSomething() { // ... } type ComplexCollection struct { records []Record } // 关键点1: 定义迭代器创建方法，返回只能接收的channel类型 func (c *ComplexCollection) Iterator() \u0026lt;-chan Record { // 关键点2: 创建一个无缓冲的channel  ch := make(chan Record) // 关键点3: 另起一个goroutine往channel写入记录，如果接收端还没开始接收，会阻塞住  go func() { for _, record := range c.records { ch \u0026lt;- record } // 关键点4: 写完后，关闭channel  close(ch) }() return ch } 客户端这样使用：\nfunc client() { collection := NewComplexCollection() // 关键点5: 使用时，直接通过for-range来遍历channel读取记录  for record := range collection.Iterator() { record.doSomething() } } 总结实现基于 channel 的迭代器模式的几个关键点：\n 定义迭代器创建方法，返回一个只能接收的 channel。 在迭代器创建方法中，定义一个无缓冲的 channel。 另起一个 goroutine 往 channel 中写入记录。如果接收端没有接收，会阻塞住。 写完后，关闭 channel。 客户端使用时，直接通过 for-range 遍历 channel 读取记录即可。  带有 callback 函数的实现 还可以在创建迭代器时，传入一个 callback 函数，在迭代器返回记录前，先调用 callback 函数对记录进行一些操作。\n比如，在基于 channel 的实现例子中，可以增加一个 callback 函数，将每个记录打印出来：\n// 关键点1: 声明callback函数类型，以Record作为入参 type Callback func(record *Record) //关键点2: 定义具体的callback函数 func PrintRecord(record *Record) { fmt.Printf(\u0026#34;%+v\\n\u0026#34;, record) } // 关键点3: 定义以callback函数作为入参的迭代器创建方法 func (c *ComplexCollection) Iterator(callback Callback) \u0026lt;-chan Record { ch := make(chan Record) go func() { for _, record := range c.records { // 关键点4: 遍历记录时，调用callback函数作用在每条记录上  callback(\u0026amp;record) ch \u0026lt;- record } close(ch) }() return ch } func client() { collection := NewComplexCollection() // 关键点5: 创建迭代器时，传入具体的callback函数  for record := range collection.Iterator(PrintRecord) { record.doSomething() } } 总结实现带有 callback 的迭代器模式的几个关键点：\n 声明 callback 函数类型，以 Record 作为入参。 定义具体的 callback 函数，比如上述例子中打印记录的 PrintRecord 函数。 定义迭代器创建方法，以 callback 函数作为入参。 迭代器内，遍历记录时，调用 callback 函数作用在每条记录上。 客户端创建迭代器时，传入具体的 callback 函数。  典型应用场景   对象集合/存储类模块，并希望向客户端隐藏模块背后的复杂数据结构。\n  希望支持客户端自扩展多种遍历方式。\n  优缺点 优点   隐藏模块背后复杂的实现机制，为客户端提供一个简单易用的接口。\n  支持扩展多种遍历方式，具备较强的可扩展性，符合 开闭原则。\n  遍历算法和数据存储分离，符合 单一职责原则。\n  缺点  容易滥用，比如给简单的集合类型实现迭代器接口，反而使代码更复杂。 相比于直接遍历集合，迭代器效率要更低一些，因为涉及到更多对象的创建，以及可能的对象拷贝。 需要时刻注意在迭代器遍历过程中，由原始集合发生变更引发的并发问题。一种解决方法是，在创建迭代器时，拷贝一份原始数据（TableIterator 就这么实现），但存在效率低、内存占用大的问题。  与其他模式的关联 迭代器模式通常会与 工厂方法模式 一起使用，如前文实现。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：工厂方法模式, 元闰子\n[3] Design Patterns, Chapter 5. Behavioral Patterns, GoF\n[4] Iterators in Go, Ewen Cheslack-Postava\n[5] 迭代器模式, refactoringguru.cn\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-07-30T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：迭代器模式"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：装饰者模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 现在有 2 个服务，Service A 和 Service B，通过 REST 接口通信；Service A 在某个业务场景下调用 Service B 的接口完成一个计算密集型任务，假设接口为 http://service_b/api/v1/domain；该任务运行时间很长，但 Service A 不想一直阻塞在接口调用上。为了满足 Service A 的要求，通常有 2 种方案：\n  Service A 隔一段时间调用一次 Service B 的接口，如果任务还没完成，就返回 HTTP Status 102 Processing；如果已完成，则返回 HTTP Status 200 Ok。\n  Service A 在请求 Service B 接口时带上 callback uri，比如 http://service_b/api/v1/domain?callbackuri=http://service_a/api/v1/domain，Service B 收到请求后立即返回 HTTP Status 200 Ok，等任务完成后再调用 Service A callback uri 进行通知。\n  方案 1 须要轮询接口，轮询太频繁会导致资源浪费，间隔太长又会导致任务完成后 Service A 无法及时感知。显然，方案 2 更加高效，因此也被广泛应用。\n方案 2 用到的思想就是本文要介绍的观察者模式（Observer Pattern），GoF 对它的定义如下：\n Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.\n 我们将观察者称为 Observer，被观察者（或主体）称为 Subject，那么 Subject 和 Observer 是一对多的关系，当 Subject 状态变更时，所有的 Observer 都会被通知到。\nUML 结构 场景上下文 在 简单的分布式应用系统（示例代码工程）中，应用之间通过 network 模块来通信，其中通信模型采用观察者模式：\n从上图可知，App 直接依赖 http 模块，而 http 模块底层则依赖 socket 模块：\n 在 App2 初始化时，先向 http 模块注册一个 request handler，处理 App1 发送的 http 请求。 http 模块会将 request handler 转换为 packet handler 注册到 socket 模块上。 App 1 发送 http 请求，http 模块将请求转换为 socket packet 发往 App 2 的 socket 模块。 App 2 的 socket 模块收到 packet 后，调用 packet handler 处理该报文；packet handler 又会调用 App 2 注册的 request handler 处理该请求。  在上述 socket - http - app 三层模型 中，对 socket 和 http，socket 是 Subject，http 是 Observer；对 http 和 app，http 是 Subject，app 是 Observer。\n代码实现 因为在观察者模式的实现上，socket 模块和 http 模块类似，所以，下面只给出 socket 模块的实现：\n// demo/network/socket.go package network // 关键点1: 定义Observer接口 // SocketListener Socket报文监听者 type SocketListener interface { // 关键2: 为Observer定义更新处理方法，入参为相关的上下文对象 \tHandle(packet *Packet) error } // Subject接口 // Socket 网络通信Socket接口 type Socket interface { // Listen 在endpoint指向地址上起监听 \tListen(endpoint Endpoint) error // Close 关闭监听 \tClose(endpoint Endpoint) // Send 发送网络报文 \tSend(packet *Packet) error // Receive 接收网络报文 \tReceive(packet *Packet) // AddListener 增加网络报文监听者 \tAddListener(listener SocketListener) } // 关键点3: 定义Subject对象 // socketImpl Socket的默认实现 type socketImpl struct { // 关键点4: 在Subject中持有Observer的集合 \tlisteners []SocketListener } // 关键点5: 为Subject定义注册Observer的方法 func (s *socketImpl) AddListener(listener SocketListener) { s.listeners = append(s.listeners, listener) } // 关键点6: 当Subject状态变更时，遍历Observers集合，调用它们的更新处理方法 func (s *socketImpl) Receive(packet *Packet) { for _, listener := range s.listeners { listener.Handle(packet) } } ... 总结实现观察者模式的几个关键点：\n 定义 Observer 接口，上述例子中为 SocketListener 接口。 为 Observer 接口定义状态更新的处理方法，其中方法入参为相关的上下文对象。上述例子为 Handle 方法，上下文对象为 Packet。 定义 Subject 对象，上述例子为 socketImpl 对象。当然，也可以先将 Subject 抽象为接口，比如上述例子中的 Socket 接口，但大多数情况下都不是必须的。 在 Subject 对象中，持有 Observer 接口的集合，上述例子为 listeners 属性。让 Subject 依赖 Observer 接口，能够使 Subject 与具体的 Observer 实现解耦，提升代码的可扩展性。 为 Subject 对象定义注册 Observer 的方法，上述例子为 AddListener 方法。 当 Subject 状态变更时，遍历 Observer 集合，并调用它们的状态更变处理方法，上述例子为 Receive 方法。  扩展 发布-订阅模式 与观察者模式相近的，是发布-订阅模式（Pub-Sub Pattern），很多人会把两者等同，但它们之间还是有些差异。\n从前文的观察者模式实现中，我们发现 Subject 持有 Observer 的引用，当状态变更时，Subject 直接调用 Observer 的更新处理方法完成通知。也就是，Subject 知道有哪些 Observer，也知道 Observer 的数量：\n在发布-订阅模式中，我们将发布方称为 Publisher，订阅方称为 Subscriber，不同于观察者模式，Publisher 并不直接持有 Subscriber 引用，它们之间通常通过 Broker 来完成解耦。也即，Publisher 不知道有哪些 Subscriber，也不知道 Subscriber 的数量：\n发布-订阅模式被广泛应用在消息中间件的实现上，比如 Apache Kafka 基于 Topic 实现了发布-订阅模式，发布方称为 Producer，订阅方称为 Consumer。\n下面，我们通过 简单的分布式应用系统（示例代码工程）中的 mq 模块，展示一个简单的发布-订阅模式实现，在该实现中，我们将 Publisher 的 produce 方法和 Subscriber 的 consume 方法都合并到 Broker 中：\n// demo/mq/memory_mq.go  // 关键点1: 定义通信双方交互的消息，携带topic信息 // Message 消息队列中消息定义 type Message struct { topic Topic payload string } // 关键点2: 定义Broker对象 // memoryMq 内存消息队列，通过channel实现 type memoryMq struct { // 关键点3: Broker中维持一个队列的map，其中key为topic，value为queue，go语言通常用chan实现。 \tqueues sync.Map // key为Topic，value为chan *Message，每个topic单独一个队列 } // 关键点4: 为Broker定义Produce方法，根据消息中的topic选择对应的queue发布消息 func (m *memoryMq) Produce(message *Message) error { record, ok := m.queues.Load(message.Topic()) if !ok { q := make(chan *Message, 10000) m.queues.Store(message.Topic(), q) record = q } queue, ok := record.(chan *Message) if !ok { return errors.New(\u0026#34;model\u0026#39;s type is not chan *Message\u0026#34;) } queue \u0026lt;- message return nil } // 关键点5: 为Broker定义Consume方法，根据topic选择对应的queue消费消息 func (m *memoryMq) Consume(topic Topic) (*Message, error) { record, ok := m.queues.Load(topic) if !ok { q := make(chan *Message, 10000) m.queues.Store(topic, q) record = q } queue, ok := record.(chan *Message) if !ok { return nil, errors.New(\u0026#34;model\u0026#39;s type is not chan *Message\u0026#34;) } return \u0026lt;-queue, nil } 客户端使用时，直接调用 memoryMq 的 Produce 方法和 Consume 方法完成消息的生产和消费：\n// 发布方 func publisher() { msg := NewMessage(\u0026#34;test\u0026#34;, \u0026#34;hello world\u0026#34;) err := MemoryMqInstance().Produce(msg) assert.Nil(t, err) } // 订阅方 func subscriber() { result, err := MemoryMqInstance().Consume(\u0026#34;test\u0026#34;) assert.Nil(err) assert.Equal(t, \u0026#34;hello world\u0026#34;, result.payload) } 总结实现发布-订阅模式的几个关键点：\n 定义通信双方交互的消息，携带 topic 信息，上述例子为 Message 对象。 定义 Broker 对象，Broker 是缓存消息的地方，上述例子为 memoryMq 对象。 在 Broker 中维持一个队列的 map，其中 key 为 topic，value 为 queue，go 语言通常用 chan 来实现 queue，上述例子为 queues 属性。 为 Broker 定义 produce 方法，根据消息中的 topic 选择对应的 queue 发布消息，上述例子为 Produce 方法。 为 Broker 定义 consume 方法，根据 topic 选择对应的 queue 消费消息，上述例子为 Consume 方法。  Push 模式 VS Pull 模式 实现观察者模式和发布-订阅模式时，都会涉及到 Push 模式或 Pull 模式的选取。所谓 Push 模式，指的是 Subject/Publisher 直接将消息推送给 Observer/Subscriber；所谓 Pull 模式，指的是 Observer/Subscriber 主动向 Subject/Publisher 拉取消息：\nPush 模式和 Pull 模式的选择，取决于通信双方处理消息的速率大小。\n如果 Subject/Publisher 方生产消息的速率要比 Observer/Subscriber 方处理消息的速率小，可以选择 Push 模式，以求得更高效、及时的消息传递；相反，如果 Subject/Publisher 方产生消息的速率要大，就要选择 Pull 模式，由 Observer/Subscriber 方决定消息的消费速率，否则可能导致 Observer/Subscriber 崩溃。\nPull 模式有个缺点，如果当前无消息可处理，将导致 Observer/Subscriber 空轮询，可以采用类似 Kafka 的解决方案：让 Observer/Subscriber 阻塞一定时长，让出 CPU，避免长期无效的 CPU 空转。\n典型应用场景  需要监听某个状态的变更，且在状态变更时，通知到监听者。 web 框架。很多 web 框架都用了观察者模式，用户注册请求 handler 到框架，框架收到相应请求后，调用 handler 完成处理逻辑。 消息中间件。如 Kafka、RocketMQ 等。  优缺点 优点   消息通信双方解耦。观察者模式通过依赖接口达到松耦合；发布-订阅模式则通过 Broker 达到解耦目的。\n  支持广播通信。\n  可基于 topic 来达到指定消费某一类型消息的目的。\n  缺点  通知 Observer/Subscriber 的顺序是不确定的，应用程序不应该依赖通知顺序来保证业务逻辑的正确性。 广播通信场景，需要 Observer/Subscriber 自己去判断是否需要处理该消息，否则容易导致 unexpected update。  与其他模式的关联 观察者模式和发布-订阅模式中的 Subject 和 Broker，通常都会使用 单例模式 来确保它们全局唯一。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：单例模式, 元闰子\n[3] Design Patterns, Chapter 5. Behavioral Patterns, GoF\n[4] 观察者模式, refactoringguru.cn\n[5] 观察者模式 vs 发布订阅模式, 柳树\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-07-23T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：观察者模式"},{"content":"第一次接触篮球，大概是五年级的时候。那段时间跟大哥唯一的一次打架后，冷战了好久。不知老爸是不是察觉到什么，也许是临时兴起，给我们买了个篮球。球摸到了，兄弟也和好了。\n小学时候打篮球，热情是有的，常常早上 5 点多起床就去，但对篮球这项运动没什么概念。记得第一次比赛，替补上场，愣是在中场当了 2 个回合的立棍，不参与进攻，也不参与防守，就被教练急忙换下了。\n初中时候，身边都是些“要身体有身体，要技术有技术”的怪兽们，适合在场下静静地看，看他们飞天遁地的表演。偶尔还能偷学到一两招，转头就能在第二天用上。那时候的快乐很简单，跟同学们一起下课、打球，还常常叫嚣着要跟“南门头火箭队”决一胜负，只是一直没等来那场决战。\n高中时候，除了学习，还是学习，也就偶尔能在体育课上玩玩，次数也屈指可数。\n终于等到大学，逃不过男大学生的三点一线：上课、打球、游戏。一年级的学院新生杯比赛，我们一路打到决赛，面对的是不久前刚赢过我们的 S 班，但靠着 MVP 的稳定发挥，我们艰难拿下冠军。那是第一次冠军，也是最后一次。后来，我们的 MVP 专心搞学术了，而我们班，也再没达到原来的高度。\n后面来到北校区，遇到了一群很会打球的师兄们，第一次看他们用无球挡制造得分机会时，心里感叹，“篮球原来还能这么打！”。慢慢地，我们几个也有样学样，无球挡、跑位、内切、传球\u0026hellip;；你尽管跑，人到球到；接到传球，先大喊一声，“好球！”；投不进，懊恼的不是没得分，而是浪费了队友那一手好传球。\n偶尔也会遇到一些人，埋怨道，“怎么这么多挡，练过的吧”。\n窃喜，心想，“哪有，一起打久了，默契而已”。\n有些人以得分、打进高难度球为乐；我们，以分享球、打出流畅配合为乐。我想，这就是所谓的兄弟篮球吧。\n如果挑一个篮球生涯的巅峰期，得是研一时候。本科的好多伙伴都还在，兄弟篮球愈发成熟，正好遇上学校研究生篮球比赛。\n第一场，就遇上了实力很强的 J 学院，记得他们队中还有个校队大魔王。那场，我们打得很强硬，也很有韧性，就憋着一股气要赢；连讨厌抢篮板的我都去拼篮板了；赢球，也顺理成章了。\n过了第一场，后面几场轻松很多，下次再遇到强劲的对手，是半决赛的 C 学院。\n比赛打到最后几秒，落后 1 分，我方球权；\n底线发球，Z 爷接球，转身，摆脱，抛投；\n学生时代总有些遗憾，那一球，就是我们的遗憾之一。\n再后来，大家各自工作，也很难再遇上这样的一群家伙了。加上工作繁忙，几个月没打一次，偶尔几个聚起来玩玩，也没了以前那般体力。于是，打球的次数越来越少，想着再找不回以前打球的快乐了吧。\n前段时间工作换了新环境，没那么忙了，打球的次数变多了。遇到了新的伙伴们，无球挡、内切、传球竟也慢慢都有了，篮球的快乐好像又找回来了。\n大学时候，经常会在球场上遇到这样的几个人：他们满头白发；总是站在罚球线附近指挥；偶尔中投几个；更多的是各种使坏的小动作。\n以前很讨厌他们。\n现在想想，等老了，要是能成为他们这样，好像也挺不错的。\n（完）\n","date":"2022-07-08T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%B1%9E%E4%BA%8E%E7%AF%AE%E7%90%83%E7%9A%84%E5%BF%AB%E4%B9%90%E5%8F%88%E5%9B%9E%E6%9D%A5%E4%BA%86/","title":"属于篮球的快乐又回来了"},{"content":"前言 SQL 中 Group By 语句大家都很熟悉，根据指定的规则对数据进行分组，常常和聚合函数一起使用。\n比如，考虑有表 dealer，表中数据如下：\n   id (Int) city (String) car_model (String) quantity (Int)     100 Fremont Honda Civic 10   100 Fremont Honda Accord 15   100 Fremont Honda CRV 7   200 Dublin Honda Civic 20   200 Dublin Honda Accord 10   200 Dublin Honda CRV 3   300 San Jose Honda Civic 5   300 San Jose Honda Accord 8    如果执行 SQL 语句 SELECT id, sum(quantity) FROM dealer GROUP BY id ORDER BY id，会得到如下结果：\n+---+-------------+ |id|sum(quantity)|+---+-------------+ |100|32||200|33||300|13|+---+-------------+ 上述 SQL 语句的意思就是对数据按 id 列进行分组，然后在每个分组内对 quantity 列进行求和。\nGroup By 语句除了上面的简单用法之外，还有更高级的用法，常见的是 Grouping Sets、RollUp 和 Cube，它们在 OLAP 时比较常用。其中，RollUp 和 Cube 都是以 Grouping Sets 为基础实现的，因此，弄懂了 Grouping Sets，也就理解了 RollUp 和 Cube 。\n本文首先简单介绍 Grouping Sets 的用法，然后以 Spark SQL 作为切入点，深入解析 Grouping Sets 的实现机制。\n Spark SQL 是 Apache Spark 大数据处理框架的一个子模块，用来处理结构化信息。它可以将 SQL 语句翻译多个任务在 Spark 集群上执行，允许用户直接通过 SQL 来处理数据，大大提升了易用性。\n Grouping Sets 简介 Spark SQL 官方文档中 SQL Syntax 一节对 Grouping Sets 语句的描述如下：\n Groups the rows for each grouping set specified after GROUPING SETS. （\u0026hellip; 一些举例） This clause is a shorthand for a UNION ALL where each leg of the UNION ALL operator performs aggregation of each grouping set specified in the GROUPING SETS clause. （\u0026hellip; 一些举例）\n 也即，Grouping Sets 语句的作用是指定几个 grouping set 作为 Group By 的分组规则，然后再将结果联合在一起。它的效果和，先分别对这些 grouping set 进行 Group By  分组之后，再通过 Union All 将结果联合起来，是一样的。\n比如，对于 dealer 表，Group By Grouping Sets ((city, car_model), (city), (car_model), ()) 和 Union All((Group By city, car_model), (Group By city), (Group By car_model), 全局聚合) 的效果是相同的：\n先看 Grouping Sets 版的执行结果：\nspark-sql\u0026gt;SELECTcity,car_model,sum(quantity)ASsumFROMdealer\u0026gt;GROUPBYGROUPINGSETS((city,car_model),(city),(car_model),())\u0026gt;ORDERBYcity,car_model;+--------+------------+---+ |city|car_model|sum|+--------+------------+---+ |null|null|78||null|HondaAccord|33||null|HondaCRV|10||null|HondaCivic|35||Dublin|null|33||Dublin|HondaAccord|10||Dublin|HondaCRV|3||Dublin|HondaCivic|20||Fremont|null|32||Fremont|HondaAccord|15||Fremont|HondaCRV|7||Fremont|HondaCivic|10||SanJose|null|13||SanJose|HondaAccord|8||SanJose|HondaCivic|5|+--------+------------+---+ 再看 Union All 版的执行结果：\nspark-sql\u0026gt;(SELECTcity,car_model,sum(quantity)ASsumFROMdealerGROUPBYcity,car_model)UNIONALL\u0026gt;(SELECTcity,NULLascar_model,sum(quantity)ASsumFROMdealerGROUPBYcity)UNIONALL\u0026gt;(SELECTNULLascity,car_model,sum(quantity)ASsumFROMdealerGROUPBYcar_model)UNIONALL\u0026gt;(SELECTNULLascity,NULLascar_model,sum(quantity)ASsumFROMdealer)\u0026gt;ORDERBYcity,car_model;+--------+------------+---+ |city|car_model|sum|+--------+------------+---+ |null|null|78||null|HondaAccord|33||null|HondaCRV|10||null|HondaCivic|35||Dublin|null|33||Dublin|HondaAccord|10||Dublin|HondaCRV|3||Dublin|HondaCivic|20||Fremont|null|32||Fremont|HondaAccord|15||Fremont|HondaCRV|7||Fremont|HondaCivic|10||SanJose|null|13||SanJose|HondaAccord|8||SanJose|HondaCivic|5|+--------+------------+---+ 两版的查询结果完全一样。\nGrouping Sets 的执行计划 从执行结果上看，Grouping Sets 版本和 Union All 版本的 SQL 是等价的，但 Grouping Sets 版本更加简洁。\n那么，Grouping Sets 仅仅只是 Union All 的一个缩写，或者语法糖吗？\n为了进一步探究 Grouping Sets 的底层实现是否和 Union All 是一致的，我们可以来看下两者的执行计划。\n首先，我们通过 explain extended 来查看 Union All 版本的 Optimized Logical Plan:\nspark-sql\u0026gt; explain extended (SELECT city, car_model, sum(quantity) AS sum FROM dealer GROUP BY city, car_model) UNION ALL (SELECT city, NULL as car_model, sum(quantity) AS sum FROM dealer GROUP BY city) UNION ALL (SELECT NULL as city, car_model, sum(quantity) AS sum FROM dealer GROUP BY car_model) UNION ALL (SELECT NULL as city, NULL as car_model, sum(quantity) AS sum FROM dealer) ORDER BY city, car_model; == Parsed Logical Plan == ... == Analyzed Logical Plan == ... == Optimized Logical Plan == Sort [city#93 ASC NULLS FIRST, car_model#94 ASC NULLS FIRST], true +- Union false, false :- Aggregate [city#93, car_model#94], [city#93, car_model#94, sum(quantity#95) AS sum#79L] : +- Project [city#93, car_model#94, quantity#95] : +- HiveTableRelation [`default`.`dealer`, ..., Data Cols: [id#92, city#93, car_model#94, quantity#95], Partition Cols: []] :- Aggregate [city#97], [city#97, null AS car_model#112, sum(quantity#99) AS sum#81L] : +- Project [city#97, quantity#99] : +- HiveTableRelation [`default`.`dealer`, ..., Data Cols: [id#96, city#97, car_model#98, quantity#99], Partition Cols: []] :- Aggregate [car_model#102], [null AS city#113, car_model#102, sum(quantity#103) AS sum#83L] : +- Project [car_model#102, quantity#103] : +- HiveTableRelation [`default`.`dealer`, ..., Data Cols: [id#100, city#101, car_model#102, quantity#103], Partition Cols: []] +- Aggregate [null AS city#114, null AS car_model#115, sum(quantity#107) AS sum#86L] +- Project [quantity#107] +- HiveTableRelation [`default`.`dealer`, ..., Data Cols: [id#104, city#105, car_model#106, quantity#107], Partition Cols: []] == Physical Plan == ... 从上述的 Optimized Logical Plan 可以清晰地看出 Union All 版本的执行逻辑：\n 执行每个子查询语句，计算得出查询结果。其中，每个查询语句的逻辑是这样的：  在 HiveTableRelation 节点对 dealer 表进行全表扫描。 在 Project 节点选出与查询语句结果相关的列，比如对于子查询语句 SELECT NULL as city, NULL as car_model, sum(quantity) AS sum FROM dealer，只需保留 quantity 列即可。 在 Aggregate 节点完成 quantity 列对聚合运算。在上述的 Plan 中，Aggregate 后面紧跟的就是用来分组的列，比如 Aggregate [city#902] 就表示根据 city 列来进行分组。   在 Union 节点完成对每个子查询结果的联合。 最后，在 Sort 节点完成对数据的排序，上述 Plan 中 Sort [city#93 ASC NULLS FIRST, car_model#94 ASC NULLS FIRST] 就表示根据 city 和 car_model 列进行升序排序。  接下来，我们通过 explain extended 来查看 Grouping Sets 版本的 Optimized Logical Plan：\nspark-sql\u0026gt; explain extended SELECT city, car_model, sum(quantity) AS sum FROM dealer GROUP BY GROUPING SETS ((city, car_model), (city), (car_model), ()) ORDER BY city, car_model; == Parsed Logical Plan == ... == Analyzed Logical Plan == ... == Optimized Logical Plan == Sort [city#138 ASC NULLS FIRST, car_model#139 ASC NULLS FIRST], true +- Aggregate [city#138, car_model#139, spark_grouping_id#137L], [city#138, car_model#139, sum(quantity#133) AS sum#124L] +- Expand [[quantity#133, city#131, car_model#132, 0], [quantity#133, city#131, null, 1], [quantity#133, null, car_model#132, 2], [quantity#133, null, null, 3]], [quantity#133, city#138, car_model#139, spark_grouping_id#137L] +- Project [quantity#133, city#131, car_model#132] +- HiveTableRelation [`default`.`dealer`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, Data Cols: [id#130, city#131, car_model#132, quantity#133], Partition Cols: []] == Physical Plan == ... 从 Optimized Logical Plan 来看，Grouping Sets 版本要简洁很多！具体的执行逻辑是这样的：\n 在 HiveTableRelation 节点对 dealer 表进行全表扫描。 在 Project 节点选出与查询语句结果相关的列。 接下来的 Expand 节点是关键，数据经过该节点后，多出了 spark_grouping_id 列。从 Plan 中可以看出来，Expand 节点包含了 Grouping Sets 里的各个 grouping set 信息，比如 [quantity#133, city#131, null, 1] 对应的就是 (city) 这一 grouping set。而且，每个 grouping set 对应的 spark_grouping_id 列的值都是固定的，比如 (city) 对应的 spark_grouping_id 为 1。 在 Aggregate 节点完成 quantity 列对聚合运算，其中分组的规则为 city, car_model, spark_grouping_id。注意，数据经过 Aggregate 节点后，spark_grouping_id 列被删除了！ 最后，在 Sort 节点完成对数据的排序。  从 Optimized Logical Plan 来看，虽然 Union All 版本和 Grouping Sets 版本的效果一致，但它们的底层实现有着巨大的差别。\n其中，Grouping Sets 版本的 Plan 中最关键的是 Expand 节点，目前，我们只知道数据经过它之后，多出了 spark_grouping_id 列。而且从最终结果来看，spark_grouping_id 只是 Spark SQL 的内部实现细节，对用户并不体现。\n spark_grouping_id 其实可通过 GROUPING_ID() 函数查询得到，但一般用户不必关注。\n 那么：\n Expand 的实现逻辑是怎样的，为什么能达到 Union All 的效果？ Expand 节点的输出数据是怎样的？ spark_grouping_id 列的作用是什么？  通过 Physical Plan，我们发现 Expand 节点对应的算子名称也是 Expand:\n== Physical Plan == AdaptiveSparkPlan isFinalPlan=false +- Sort [city#138 ASC NULLS FIRST, car_model#139 ASC NULLS FIRST], true, 0 +- Exchange rangepartitioning(city#138 ASC NULLS FIRST, car_model#139 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=422] +- HashAggregate(keys=[city#138, car_model#139, spark_grouping_id#137L], functions=[sum(quantity#133)], output=[city#138, car_model#139, sum#124L]) +- Exchange hashpartitioning(city#138, car_model#139, spark_grouping_id#137L, 200), ENSURE_REQUIREMENTS, [plan_id=419] +- HashAggregate(keys=[city#138, car_model#139, spark_grouping_id#137L], functions=[partial_sum(quantity#133)], output=[city#138, car_model#139, spark_grouping_id#137L, sum#141L]) +- Expand [[quantity#133, city#131, car_model#132, 0], [quantity#133, city#131, null, 1], [quantity#133, null, car_model#132, 2], [quantity#133, null, null, 3]], [quantity#133, city#138, car_model#139, spark_grouping_id#137L] +- Scan hive default.dealer [quantity#133, city#131, car_model#132], HiveTableRelation [`default`.`dealer`, ..., Data Cols: [id#130, city#131, car_model#132, quantity#133], Partition Cols: []] 带着前面的几个问题，接下来我们深入 Spark SQL 的 Expand 算子源码寻找答案。\nExpand 算子的实现 Expand 算子在 Spark SQL 源码中的实现为 ExpandExec 类（Spark SQL 中的算子实现类的命名都是 XxxExec 的格式，其中 Xxx 为具体的算子名，比如 Project 算子的实现类为 ProjectExec），核心代码如下：\n/** * Apply all of the GroupExpressions to every input row, hence we will get * multiple output rows for an input row. * @param projections The group of expressions, all of the group expressions should * output the same schema specified bye the parameter `output` * @param output The output Schema * @param child Child operator */ case class ExpandExec( projections: Seq[Seq[Expression]], output: Seq[Attribute], child: SparkPlan) extends UnaryExecNode with CodegenSupport { ... // 关键点1，将child.output，也即上游算子输出数据的schema，  // 绑定到表达式数组exprs，以此来计算输出数据  private[this] val projection = (exprs: Seq[Expression]) =\u0026gt; UnsafeProjection.create(exprs, child.output) // doExecute()方法为Expand算子执行逻辑所在  protected override def doExecute(): RDD[InternalRow] = { val numOutputRows = longMetric(\u0026#34;numOutputRows\u0026#34;) // 处理上游算子的输出数据，Expand算子的输入数据就从iter迭代器获取  child.execute().mapPartitions { iter =\u0026gt; // 关键点2，projections对应了Grouping Sets里面每个grouping set的表达式，  // 表达式输出数据的schema为this.output, 比如 (quantity, city, car_model, spark_grouping_id)  // 这里的逻辑是为它们各自生成一个UnsafeProjection对象，通过该对象的apply方法就能得出Expand算子的输出数据  val groups = projections.map(projection).toArray new Iterator[InternalRow] { private[this] var result: InternalRow = _ private[this] var idx = -1 // -1 means the initial state  private[this] var input: InternalRow = _ override final def hasNext: Boolean = (-1 \u0026lt; idx \u0026amp;\u0026amp; idx \u0026lt; groups.length) || iter.hasNext override final def next(): InternalRow = { // 关键点3，对于输入数据的每一条记录，都重复使用N次，其中N的大小对应了projections数组的大小，  // 也即Grouping Sets里指定的grouping set的数量  if (idx \u0026lt;= 0) { // in the initial (-1) or beginning(0) of a new input row, fetch the next input tuple  input = iter.next() idx = 0 } // 关键点4，对输入数据的每一条记录，通过UnsafeProjection计算得出输出数据，  // 每个grouping set对应的UnsafeProjection都会对同一个input计算一遍  result = groups(idx)(input) idx += 1 if (idx == groups.length \u0026amp;\u0026amp; iter.hasNext) { idx = 0 } numOutputRows += 1 result } } } } ... } ExpandExec 的实现并不复杂，想要理解它的运作原理，关键是看懂上述源码中提到的 4 个关键点。\n关键点 1 和 关键点 2 是基础，关键点 2 中的 groups 是一个 UnsafeProjection[N] 数组类型，其中每个 UnsafeProjection 代表了 Grouping Sets 语句里指定的 grouping set，它的定义是这样的：\n// A projection that returns UnsafeRow. abstract class UnsafeProjection extends Projection { override def apply(row: InternalRow): UnsafeRow } // The factory object for `UnsafeProjection`. object UnsafeProjection extends CodeGeneratorWithInterpretedFallback[Seq[Expression], UnsafeProjection] { // Returns an UnsafeProjection for given sequence of Expressions, which will be bound to  // `inputSchema`.  def create(exprs: Seq[Expression], inputSchema: Seq[Attribute]): UnsafeProjection = { create(bindReferences(exprs, inputSchema)) } ... } UnsafeProjection 起来了类似列投影的作用，其中， apply 方法根据创建时的传参 exprs 和 inputSchema，对输入记录进行列投影，得出输出记录。\n比如，前面的 GROUPING SETS ((city, car_model), (city), (car_model), ()) 例子，它对应的 groups 是这样的：\n其中，AttributeReference 类型的表达式，在计算时，会直接引用输入数据对应列的值；Iteral 类型的表达式，在计算时，值是固定的。\n关键点 3 和 关键点 4 是 Expand 算子的精华所在，ExpandExec 通过这两段逻辑，将每一个输入记录，扩展（Expand）成 N 条输出记录。\n 关键点 4 中 groups(idx)(input) 等同于 groups(idx).apply(input) 。\n 还是以前面 GROUPING SETS ((city, car_model), (city), (car_model), ()) 为例子，效果是这样的：\n到这里，我们已经弄清楚 Expand 算子的工作原理，再回头看前面提到的 3 个问题，也不难回答了：\n  Expand 的实现逻辑是怎样的，为什么能达到 Union All 的效果？\n如果说 Union All 是先聚合再联合，那么 Expand 就是先联合再聚合。Expand 利用 groups 里的 N 个表达式对每条输入记录进行计算，扩展成 N 条输出记录。后面再聚合时，就能达到与 Union All 一样的效果了。\n  Expand 节点的输出数据是怎样的？\n在 schema 上，Expand 输出数据会比输入数据多出 spark_grouping_id 列；在记录数上，是输入数据记录数的 N 倍。\n  spark_grouping_id 列的作用是什么？\nspark_grouping_id 给每个 grouping set 进行编号，这样，即使在 Expand 阶段把数据先联合起来，在 Aggregate 阶段（把 spark_grouping_id 加入到分组规则）也能保证数据能够按照每个 grouping set 分别聚合，确保了结果的正确性。\n我们可以通过在 SELECT 语句后加上 GROUPING_ID() 函数来查询 spark_grouping_id：\nspark-sql\u0026gt; SELECT city, car_model, sum(quantity) AS sum, GROUPING_ID() as spark_grouping_id FROM dealer \u0026gt; GROUP BY GROUPING SETS ((city, car_model), (city), (car_model), ()) \u0026gt; ORDER BY city, car_model; +--------+------------+---+-----------------+ | city| car_model|sum|spark_grouping_id| +--------+------------+---+-----------------+ | null| null| 78| 3| | null|Honda Accord| 33| 2| | null| Honda CRV| 10| 2| | null| Honda Civic| 35| 2| | Dublin| null| 33| 1| | Dublin|Honda Accord| 10| 0| | Dublin| Honda CRV| 3| 0| | Dublin| Honda Civic| 20| 0| | Fremont| null| 32| 1| | Fremont|Honda Accord| 15| 0| | Fremont| Honda CRV| 7| 0| | Fremont| Honda Civic| 10| 0| |San Jose| null| 13| 1| |San Jose|Honda Accord| 8| 0| |San Jose| Honda Civic| 5| 0| +--------+------------+---+-----------------+ 这样，我们就能清晰看出每一条记录对应的 grouping set 是哪个了。\n  查询性能对比 从前文可知，Grouping Sets 和 Union All 两个版本的 SQL 语句有着一样的效果，但是它们的执行计划却有着巨大的差别。下面，我们将比对两个版本之间的执行性能差异。\nspark-sql 执行完 SQL 语句之后会打印耗时信息，我们对两个版本的 SQL 分别执行 10 次，得到如下信息：\n// Grouping Sets 版本执行10次的耗时信息 // SELECT city, car_model, sum(quantity) AS sum FROM dealer GROUP BY GROUPING SETS ((city, car_model), (city), (car_model), ()) ORDER BY city, car_model; Time taken: 0.289 seconds, Fetched 15 row(s) Time taken: 0.251 seconds, Fetched 15 row(s) Time taken: 0.259 seconds, Fetched 15 row(s) Time taken: 0.258 seconds, Fetched 15 row(s) Time taken: 0.296 seconds, Fetched 15 row(s) Time taken: 0.247 seconds, Fetched 15 row(s) Time taken: 0.298 seconds, Fetched 15 row(s) Time taken: 0.286 seconds, Fetched 15 row(s) Time taken: 0.292 seconds, Fetched 15 row(s) Time taken: 0.282 seconds, Fetched 15 row(s) // Union All 版本执行10次的耗时信息 // (SELECT city, car_model, sum(quantity) AS sum FROM dealer GROUP BY city, car_model) UNION ALL (SELECT city, NULL as car_model, sum(quantity) AS sum FROM dealer GROUP BY city) UNION ALL (SELECT NULL as city, car_model, sum(quantity) AS sum FROM dealer GROUP BY car_model) UNION ALL (SELECT NULL as city, NULL as car_model, sum(quantity) AS sum FROM dealer) ORDER BY city, car_model; Time taken: 0.628 seconds, Fetched 15 row(s) Time taken: 0.594 seconds, Fetched 15 row(s) Time taken: 0.591 seconds, Fetched 15 row(s) Time taken: 0.607 seconds, Fetched 15 row(s) Time taken: 0.616 seconds, Fetched 15 row(s) Time taken: 0.64 seconds, Fetched 15 row(s) Time taken: 0.623 seconds, Fetched 15 row(s) Time taken: 0.625 seconds, Fetched 15 row(s) Time taken: 0.62 seconds, Fetched 15 row(s) Time taken: 0.62 seconds, Fetched 15 row(s) 可以算出，Grouping Sets 版本的 SQL 平均耗时为 0.276s；Union All 版本的 SQL 平均耗时为 0.616s，是前者的 2.2 倍！\n所以，Grouping Sets 版本的 SQL 不仅在表达上更加简洁，在性能上也更加高效。\nRollUp 和 Cube Group By 的高级用法中，还有 RollUp 和 Cube 两个比较常用。\n首先，我们看下 RollUp 语句。\nSpark SQL 官方文档中 SQL Syntax 一节对 RollUp 语句的描述如下：\n Specifies multiple levels of aggregations in a single statement. This clause is used to compute aggregations based on multiple grouping sets. ROLLUP is a shorthand for GROUPING SETS. （\u0026hellip; 一些例子）\n 官方文档中，把 RollUp 描述为 Grouping Sets 的简写，等价规则为：RollUp(A, B, C) == Grouping Sets((A, B, C), (A, B), (A), ())。\n比如，Group By RollUp(city, car_model) 就等同于 Group By Grouping Sets((city, car_model), (city), ())。\n下面，我们通过 expand extended 看下 RollUp 版本 SQL 的 Optimized Logical Plan：\nspark-sql\u0026gt; explain extended SELECT city, car_model, sum(quantity) AS sum FROM dealer GROUP BY ROLLUP(city, car_model) ORDER BY city, car_model; == Parsed Logical Plan == ... == Analyzed Logical Plan == ... == Optimized Logical Plan == Sort [city#2164 ASC NULLS FIRST, car_model#2165 ASC NULLS FIRST], true +- Aggregate [city#2164, car_model#2165, spark_grouping_id#2163L], [city#2164, car_model#2165, sum(quantity#2159) AS sum#2150L] +- Expand [[quantity#2159, city#2157, car_model#2158, 0], [quantity#2159, city#2157, null, 1], [quantity#2159, null, null, 3]], [quantity#2159, city#2164, car_model#2165, spark_grouping_id#2163L] +- Project [quantity#2159, city#2157, car_model#2158] +- HiveTableRelation [`default`.`dealer`, ..., Data Cols: [id#2156, city#2157, car_model#2158, quantity#2159], Partition Cols: []] == Physical Plan == ... 从上述 Plan 可以看出，RollUp 底层实现用的也是 Expand 算子，说明 RollUp 确实是基于 Grouping Sets 实现的。 而且 Expand [[quantity#2159, city#2157, car_model#2158, 0], [quantity#2159, city#2157, null, 1], [quantity#2159, null, null, 3]] 也表明 RollUp 符合等价规则。\n下面，我们按照同样的思路，看下 Cube 语句。\nSpark SQL 官方文档中 SQL Syntax 一节对 Cube 语句的描述如下：\n CUBE clause is used to perform aggregations based on combination of grouping columns specified in the GROUP BYclause. CUBE is a shorthand for GROUPING SETS. (\u0026hellip; 一些例子)\n 同样，官方文档把 Cube 描述为 Grouping Sets 的简写，等价规则为：Cube(A, B, C) == Grouping Sets((A, B, C), (A, B), (A, C), (B, C), (A), (B), (C), ())。\n比如，Group By Cube(city, car_model) 就等同于 Group By Grouping Sets((city, car_model), (city), (car_model), ())。\n下面，我们通过 expand extended 看下 Cube 版本 SQL 的 Optimized Logical Plan：\nspark-sql\u0026gt; explain extended SELECT city, car_model, sum(quantity) AS sum FROM dealer GROUP BY CUBE(city, car_model) ORDER BY city, car_model; == Parsed Logical Plan == ... == Analyzed Logical Plan == ... == Optimized Logical Plan == Sort [city#2202 ASC NULLS FIRST, car_model#2203 ASC NULLS FIRST], true +- Aggregate [city#2202, car_model#2203, spark_grouping_id#2201L], [city#2202, car_model#2203, sum(quantity#2197) AS sum#2188L] +- Expand [[quantity#2197, city#2195, car_model#2196, 0], [quantity#2197, city#2195, null, 1], [quantity#2197, null, car_model#2196, 2], [quantity#2197, null, null, 3]], [quantity#2197, city#2202, car_model#2203, spark_grouping_id#2201L] +- Project [quantity#2197, city#2195, car_model#2196] +- HiveTableRelation [`default`.`dealer`, ..., Data Cols: [id#2194, city#2195, car_model#2196, quantity#2197], Partition Cols: []] == Physical Plan == ... 从上述 Plan 可以看出，Cube 底层用的也是 Expand 算子，说明 Cube 确实基于 Grouping Sets 实现，而且也符合等价规则。\n所以，RollUp 和 Cube 可以看成是 Grouping Sets 的语法糖，在底层实现和性能上是一样的。\n最后 本文重点讨论了 Group By 高级用法 Groupings Sets 语句的功能和底层实现。\n虽然 Groupings Sets 的功能，通过 Union All 也能实现，但前者并非后者的语法糖，它们的底层实现完全不一样。Grouping Sets 采用的是先联合再聚合的思路，通过 spark_grouping_id 列来保证数据的正确性；Union All 则采用先聚合再联合的思路。Grouping Sets 在 SQL 语句表达和性能上都有更大的优势。\nGroup By 的另外两个高级用法 RollUp 和 Cube 则可以看成是 Grouping Sets 的语法糖，它们的底层都是基于 Expand 算子实现，在性能上与直接使用 Grouping Sets 是一样的，但在 SQL 表达上更加简洁。\n文章配图 可以在 用Keynote画出手绘风格的配图 中找到文章的绘图方法。\n 参考 [1] Spark SQL Guide, Apache Spark\n[2] apache spark 3.3 版本源码, Apache Spark, GitHub\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-07-03T00:00:00Z","permalink":"https://www.yrunz.com/p/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-sql-%E4%B8%AD%E7%9A%84-grouping-sets-%E8%AF%AD%E5%8F%A5/","title":"深入理解 SQL 中的 Grouping Sets 语句"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：原型模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 我们经常会遇到“给现有对象/模块新增功能”的场景，比如 http router 的开发场景下，除了最基础的路由功能之外，我们常常还会加上如日志、鉴权、流控等 middleware。如果你查看框架的源码，就会发现 middleware 功能的实现用的就是装饰者模式（Decorator Pattern）。\nGoF 给装饰者模式的定义如下：\n Decorators provide a flexible alternative to subclassing for extending functionality. Attach additional responsibilities to an object dynamically.\n 简单来说，装饰者模式通过组合的方式，提供了能够动态地给对象/模块扩展新功能的能力。理论上，只要没有限制，它可以一直把功能叠加下去，具有很高的灵活性。\n 如果写过 Java，那么一定对 I/O Stream 体系不陌生，它是装饰者模式的经典用法，客户端程序可以动态地为原始的输入输出流添加功能，比如按字符串输入输出，加入缓冲等，使得整个 I/O Stream 体系具有很高的可扩展性和灵活性。\n UML 结构 场景上下文 在简单的分布式应用系统（示例代码工程）中，我们设计了 Sidecar 边车模块，它的用处主要是为了 1）方便扩展 network.Socket 的功能，如增加日志、流控等非业务功能；2）让这些附加功能对业务程序隐藏起来，也即业务程序只须关心看到 network.Socket 接口即可。\n代码实现 Sidecar 的这个功能场景，很适合使用装饰者模式来实现，代码如下：\n// demo/network/socket.go package network // 关键点1: 定义被装饰的抽象接口 // Socket 网络通信Socket接口 type Socket interface { // Listen 在endpoint指向地址上起监听  Listen(endpoint Endpoint) error // Close 关闭监听  Close(endpoint Endpoint) // Send 发送网络报文  Send(packet *Packet) error // Receive 接收网络报文  Receive(packet *Packet) // AddListener 增加网络报文监听者  AddListener(listener SocketListener) } // 关键点2: 提供一个默认的基础实现 type socketImpl struct { listener SocketListener } func DefaultSocket() *socketImpl { return \u0026amp;socketImpl{} } func (s *socketImpl) Listen(endpoint Endpoint) error { return Instance().Listen(endpoint, s) } ... // socketImpl的其他Socket实现方法  // demo/sidecar/flowctrl_sidecar.go package sidecar // 关键点3: 定义装饰器，实现被装饰的接口 // FlowCtrlSidecar HTTP接收端流控功能装饰器，自动拦截Socket接收报文，实现流控功能 type FlowCtrlSidecar struct { // 关键点4: 装饰器持有被装饰的抽象接口作为成员属性  socket network.Socket ctx *flowctrl.Context } // 关键点5: 对于需要扩展功能的方法，新增扩展功能 func (f *FlowCtrlSidecar) Receive(packet *network.Packet) { httpReq, ok := packet.Payload().(*http.Request) // 如果不是HTTP请求，则不做流控处理  if !ok { f.socket.Receive(packet) return } // 流控后返回429 Too Many Request响应  if !f.ctx.TryAccept() { httpResp := http.ResponseOfId(httpReq.ReqId()). AddStatusCode(http.StatusTooManyRequest). AddProblemDetails(\u0026#34;enter flow ctrl state\u0026#34;) f.socket.Send(network.NewPacket(packet.Dest(), packet.Src(), httpResp)) return } f.socket.Receive(packet) } // 关键点6: 不需要扩展功能的方法，直接调用被装饰接口的原生方法即可 func (f *FlowCtrlSidecar) Close(endpoint network.Endpoint) { f.socket.Close(endpoint) } ... // FlowCtrlSidecar的其他方法  // 关键点7: 定义装饰器的工厂方法，入参为被装饰接口 func NewFlowCtrlSidecar(socket network.Socket) *FlowCtrlSidecar { return \u0026amp;FlowCtrlSidecar{ socket: socket, ctx: flowctrl.NewContext(), } } // demo/sidecar/all_in_one_sidecar_factory.go // 关键点8: 使用时，通过装饰器的工厂方法，把所有装饰器和被装饰者串联起来 func (a AllInOneFactory) Create() network.Socket { return NewAccessLogSidecar(NewFlowCtrlSidecar(network.DefaultSocket()), a.producer) } 总结实现装饰者模式的几个关键点：\n 定义需要被装饰的抽象接口，后续的装饰器都是基于该接口进行扩展。 为抽象接口提供一个基础实现。 定义装饰器，并实现被装饰的抽象接口。 装饰器持有被装饰的抽象接口作为成员属性。“装饰”的意思是在原有功能的基础上扩展新功能，因此必须持有原有功能的抽象接口。 在装饰器中，对于需要扩展功能的方法，新增扩展功能。 不需要扩展功能的方法，直接调用被装饰接口的原生方法即可。 为装饰器定义一个工厂方法，入参为被装饰接口。 使用时，通过装饰器的工厂方法，把所有装饰器和被装饰者串联起来。  扩展 Go 风格的实现 在 Sidecar 的场景上下文中，被装饰的 Socket 是一个相对复杂的接口，装饰器通过实现 Socket 接口来进行功能扩展，是典型的面向对象风格。\n如果被装饰者是一个简单的接口/方法/函数，我们可以用更具 Go 风格的实现方式，考虑前文提到的 http router 场景。如果你使用原生的 net/http 进行 http router 开发，通常会这么实现：\nfunc main() { // 注册/hello的router  http.HandleFunc(\u0026#34;/hello\u0026#34;, hello) // 启动http服务器  http.ListenAndServe(\u0026#34;localhost:8080\u0026#34;, nil) } // 具体的请求处理逻辑，类型是 http.HandlerFunc func hello(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026#34;hello, world\u0026#34;)) } 其中，我们通过 http.HandleFunc 来注册具体的 router， hello 是具体的请求处理方法。现在，我们想为该 http 服务器增加日志、鉴权等通用功能，那么可以把 func(w http.ResponseWriter, r *http.Request) 作为被装饰的抽象接口，通过新增日志、鉴权等装饰器完成功能扩展。\n// demo/network/http/http_handle_func_decorator.go  // 关键点1: 确定被装饰接口，这里为原生的http.HandlerFunc type HandlerFunc func(ResponseWriter, *Request) // 关键点2: 定义装饰器类型，是一个函数类型，入参和返回值都是 http.HandlerFunc 函数 type HttpHandlerFuncDecorator func(http.HandlerFunc) http.HandlerFunc // 关键点3: 定义装饰函数，入参为被装饰的接口和装饰器可变列表 func Decorate(h http.HandlerFunc, decorators ...HttpHandlerFuncDecorator) http.HandlerFunc { // 关键点4: 通过for循环遍历装饰器，完成对被装饰接口的装饰  for _, decorator := range decorators { h = decorator(h) } return h } // 关键点5: 实现具体的装饰器 func WithBasicAuth(h http.HandlerFunc) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { cookie, err := r.Cookie(\u0026#34;Auth\u0026#34;) if err != nil || cookie.Value != \u0026#34;Pass\u0026#34; { w.WriteHeader(http.StatusForbidden) return } // 关键点6: 完成功能扩展之后，调用被装饰的方法，才能将所有装饰器和被装饰者串起来  h(w, r) } } func WithLogger(h http.HandlerFunc) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { log.Println(r.Form) log.Printf(\u0026#34;path %s\u0026#34;, r.URL.Path) h(w, r) } } func hello(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026#34;hello, world\u0026#34;)) } func main() { // 关键点7: 通过Decorate函数完成对hello的装饰  http.HandleFunc(\u0026#34;/hello\u0026#34;, Decorate(hello, WithLogger, WithBasicAuth)) // 启动http服务器  http.ListenAndServe(\u0026#34;localhost:8080\u0026#34;, nil) } 上述的装饰者模式的实现，用到了类似于 Functional Options 的技巧，也是巧妙利用了 Go 的函数式编程的特点，总结下来有如下几个关键点：\n 确定被装饰的接口，上述例子为 http.HandlerFunc。 定义装饰器类型，是一个函数类型，入参和返回值都是被装饰接口，上述例子为 func(http.HandlerFunc) http.HandlerFunc。 定义装饰函数，入参为被装饰的接口和装饰器可变列表，上述例子为 Decorate 方法。 在装饰方法中，通过for循环遍历装饰器，完成对被装饰接口的装饰。这里是用来类似 Functional Options 的技巧，一定要注意装饰器的顺序！ 实现具体的装饰器，上述例子为 WithBasicAuth 和 WithLogger 函数。 在装饰器中，完成功能扩展之后，记得调用被装饰者的接口，这样才能将所有装饰器和被装饰者串起来。 在使用时，通过装饰函数完成对被装饰者的装饰，上述例子为 Decorate(hello, WithLogger, WithBasicAuth)。  Go 标准库中的装饰者模式 在 Go 标准库中，也有一个运用了装饰者模式的模块，就是 context，其中关键的接口如下：\npackage context // 被装饰接口 type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key any) any } // cancel装饰器 type cancelCtx struct { Context // 被装饰接口  mu sync.Mutex done atomic.Value children map[canceler]struct{}= err error } // cancel装饰器的工厂方法 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { // ...  c := newCancelCtx(parent) propagateCancel(parent, \u0026amp;c) return \u0026amp;c, func() { c.cancel(true, Canceled) } } // timer装饰器 type timerCtx struct { cancelCtx // 被装饰接口  timer *time.Timer deadline time.Time } // timer装饰器的工厂方法 func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { // ...  c := \u0026amp;timerCtx{ cancelCtx: newCancelCtx(parent), deadline: d, } // ...  return c, func() { c.cancel(true, Canceled) } } // timer装饰器的工厂方法 func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } // value装饰器 type valueCtx struct { Context // 被装饰接口  key, val any } // value装饰器的工厂方法 func WithValue(parent Context, key, val any) Context { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } // ...  return \u0026amp;valueCtx{parent, key, val} } 使用时，可以这样：\n// 使用时，可以这样 func main() { ctx := context.Background() ctx = context.WithValue(ctx, \u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;) ctx, _ = context.WithTimeout(ctx, time.Duration(1)) ctx = context.WithValue(ctx, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;) } 不管是 UML 结构，还是使用方法，context 模块都与传统的装饰者模式有一定出入，但也不妨碍 context 是装饰者模式的典型运用。还是那句话，学习设计模式，不能只记住它的结构，而是学习其中的动机和原理。\n典型使用场景  I/O 流，比如为原始的 I/O 流增加缓冲、压缩等功能。 Http Router，比如为基础的 Http Router 能力增加日志、鉴权、Cookie等功能。 \u0026hellip;\u0026hellip;  优缺点 优点  遵循开闭原则，能够在不修改老代码的情况下扩展新功能。 可以用多个装饰器把多个功能组合起来，理论上可以无限组合。  缺点  一定要注意装饰器装饰的顺序，否则容易出现不在预期内的行为。 当装饰器越来越多之后，系统也会变得复杂。  与其他模式的关联 装饰者模式和代理模式具有很高的相似性，但是两种所强调的点不一样。前者强调的是为本体对象添加新的功能；后者强调的是对本体对象的访问控制。\n装饰者模式和适配器模式的区别是，前者只会扩展功能而不会修改接口；后者则会修改接口。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：建造者模式, 元闰子\n[3] Design Patterns, Chapter 4. Structural Patterns, GoF\n[4] 装饰模式, refactoringguru.cn\n[5] Golang Decorator Pattern, Henry Du\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-06-28T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：装饰者模式"},{"content":" 一个月前作出换个领域的决定，今天清退完旧物，也算为过去 5 年的工作打了个结。新的征程即将开始。\n 想的太多了，做的也就少了 很喜欢黄华老师在《云端遐思》里的一句话：这个世界很大，但我们很容易把自己锁死，锁在一座大城里，锁在一块业务里。而诗和远方却永远停留在自己的梦里。\n我想这是当代人的一个困境吧。我们常说“为生活所迫”，本应美好的生活，变成了一块巨石重重地压在我们身上。而且，随着年龄增长，巨石变得越来越重，我们前进的步伐也逐渐缓慢，直到最后停留在原地，走不动了。\n导致这块巨石加重的因素有很多，可能是一套房子、一次投资、一份工作；但导致我们走不动的原因，不是巨石，是我们选择了背负这块巨石。\n求稳，是刻在我们中华民族的骨子里的观念。《菜根谭》修身篇的第一条就说，“思立掀天揭地的事功，须向薄冰上履过”，劝告我们要如履薄冰地做人、做事。\n所以，我们在面临选择时，往往会考虑很多，“会不会是一个深坑，还是保险起见”，“感觉跟现在也差不太多，还是算了”。想得越多，就越倾向于维持在稳定的现状，反正石头还背得动；越到后面，就越没有勇气做出改变。\n假如洞穴之外仍是洞穴 柏拉图的《理想国》里有个著名的洞穴比喻，大概的意思是这样的：有一群被困在洞穴里的囚徒，他们认为洞穴就是世界的本身；有一天，其中一人被解除桎梏，来到了洞穴之外的阳光之下；刚开始，他的眼睛会很难受，后面渐渐开始适应阳光，认识到洞外的世界有多真实和美好。那个看到了阳光的囚徒，就是看到了“善的理念”的哲人。\n那么，假如洞穴之外还是洞穴，走出洞穴与留在洞穴又有什么区别呢？换作是你，又会怎么选择？\n洞穴之外的洞穴是生活中的常态。我们常常付出很多努力，然后鼓起勇气做出一个选择，但生活并没有因此得到改善，甚至变得更糟糕了。一来二去，也就失去了穿越洞穴的勇气，即使下一条路通向的是阳光。\n就算你是一个旁观者，在看到他的“不幸”遭遇之后，相信你也会更倾向于留下，以求得更稳定的生活。\n从一个洞穴，到另一个洞穴，真的完全没有收获吗？我想未必。比起永远困在同一个洞穴，在各个洞穴之间来回穿越，体验不同洞穴的风土人情，不断开阔眼界，也不失为一种好的生活。而且，这种生活也更符合苏格拉底的那个著名观点：未经审视的人生是不值得过的。\n人生有无限的可能 人生有无限的可能，《瞬息全宇宙》，前段时间很火的电影，很生动地把这句话呈现了出来。生活中我们所做的每一个细微的选择，都会导致一个平行宇宙的出现，不同宇宙里的你可能过着完全不同的人生。\n当前宇宙的你，可能就同电影里的主角 Evelyn 一样，过着最不好的人生，每天都充斥着各种琐碎的、不好的事情；但只要你下定决心做出选择，就有可能体验到另类人生。\n当然，选择的代价是巨大的，就像电影里想要在不同的宇宙间跳转就必须做出违反常理的行为一样，而且选择之后的人生也是不可知的。\n尽管如此，它还是值得去体验，最坏的结果也不过是在体验完之后，仍然觉得当前的人生最合适，再回来就是了。相信经历过这些之后，你也会更加珍惜当下的生活。\n认识你自己 德尔菲神庙上最著名的一条箴言：认识你自己。\n每个人都有“非你不能做，非你做不好”的自然天赋，我们要做的就是不断调整方向，校准目标，去发现和实现它们。这过程必然会经历失败，但是没关系，失败本来就是人生的一部分，我们应该敢于试错。\n人生就是不断地认识自己、发现自己，唯有这样，才能成为更好的自己。\n最后送上狄金森的一首短诗：\n假如我没见过太阳， 或许我还可以忍受黑暗， 可如今，太阳把我的寂寞照耀得更加荒凉  说回这次换领域的选择，如果你在一年前告诉我有这么一个机会，是我非常喜欢、感兴趣的领域，我会选择它吗？我想未必。\n就像你从小告诉我很多大道理，但直到我经历了很多、对这些道理有切身体会的那一刻之前，我都不会理解它们。\n可能这就是人生吧。\n ","date":"2022-06-10T00:00:00Z","permalink":"https://www.yrunz.com/p/%E8%AE%A9%E4%BA%BA%E7%94%9F%E5%A4%9A%E4%BA%9B%E5%8F%AF%E8%83%BD/","title":"让人生多些可能"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：抽象工厂模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简介 原型模式（Prototype Pattern）主要解决对象复制的问题，它的核心就是 Clone() 方法，返回原型对象的复制品。\n最简单直接的对象复制方式是这样的：重新实例化一个该对象的实例，然后遍历原始对象的所有成员变量， 并将成员变量值复制到新实例中。但这种方式的缺点也很明显：\n 客户端程序必须清楚对象的实现细节。暴露细节往往不是件好事，它会导致代码耦合过深。 对象可能存在一些私有属性，客户端程序无法访问它们，也就无法复制。 很难保证所有的客户端程序都能完整不漏地把所有成员属性复制完。  更好的方法是使用原型模式，将复制逻辑委托给对象本身，这样，上述两个问题也都解决了。\nUML 结构 场景上下文 在简单的分布式应用系统（示例代码工程）中，我们设计了一个服务消息中介（Service Mediator）服务，可以把它看成是一个消息路由器，负责服务发现和消息转发：\n消息转发也就意味着它必须将上游服务的请求原封不动地转发给下游服务，这是一个典型的对象复制场景。不过，在我们的实现里，服务消息中介会先修改上行请求的 URI，之后再转发给下游服务。因为上行请求 URI 中携带了下游服务的类型信息，用来做服务发现，在转发给下游服务时必须剔除。\n比如，订单服务（order service）要发请求给库存服务（stock service），那么：\n 订单服务先往服务消息中介发出 HTTP 请求，其中 URI 为 /stock-service/api/v1/stock。 服务消息中介收到上行请求后，会从 URI 中提取出下游服务类型 stock-service ，通过服务注册中心发现库存服务的 Endpoint。 随后，服务消息中介将修改后的请求转发给库存服务，其中 URI 为 /api/v1/stock。  代码实现 如果按照简单直接的对象复制方式，实现是这样的：\n// 服务消息中介 type ServiceMediator struct { registryEndpoint network.Endpoint localIp string server *http.Server sidecarFactory sidecar.Factory } // Forward 转发请求，请求URL为 /{serviceType}+ServiceUri 的形式，如/serviceA/api/v1/task func (s *ServiceMediator) Forward(req *http.Request) *http.Response { // 提取上行请求URI中的服务类型  svcType := s.svcTypeOf(req.Uri()) // 剔除服务类型之后的请求URI  svcUri := s.svcUriOf(req.Uri()) // 根据服务类型做服务发现  dest, err := s.discovery(svcType) if err != nil { ... // 异常处理  } // 复制上行请求，将URI更改为剔除服务类型之后的URI  forwardReq := http.EmptyRequest(). AddUri(svcUri). AddMethod(req.Method()). AddHeaders(req.Headers()). AddQueryParams(req.QueryParams()). AddBody(req.Body()) // 转发请求给下游服务  client, err := http.NewClient(s.sidecarFactory.Create(), s.localIp) if err != nil { ... // 异常处理  } defer client.Close() resp, err := client.Send(dest, forwardReq) if err != nil { ... // 异常处理  } // 复制下行响应，将ReqId更改为上行请求的ReqId，其他保持不变  return http.NewResponse(req.ReqId()). AddHeaders(resp.Headers()). AddStatusCode(resp.StatusCode()). AddProblemDetails(resp.ProblemDetails()). AddBody(resp.Body()) } ... 上述实现中有 2 处进行了对象的复制：上行请求的复制和下行响应的复制。且不说直接进行对象复制具有前文提到的 3 种缺点，就代码可读性上来看也是稍显冗余。下面，我们使用原型模式进行优化。\n首先，为 http.Request 和 http.Response 定义 Clone 方法：\n// demo/network/http/http_request.go package http type Request struct { reqId ReqId method Method uri Uri queryParams map[string]string headers map[string]string body interface{} } // 关键点1: 定义原型复制方法Clone func (r *Request) Clone() *Request { // reqId重新生成，其他都拷贝原来的值  reqId := rand.Uint32() % 10000 return \u0026amp;Request{ reqId: ReqId(reqId), method: r.method, uri: r.uri, queryParams: r.queryParams, headers: r.headers, body: r.body, } } ... // demo/network/http/http_response.go  type Response struct { reqId ReqId statusCode StatusCode headers map[string]string body interface{} problemDetails string } func (r *Response) Clone() *Response { return \u0026amp;Response{ reqId: r.reqId, statusCode: r.statusCode, headers: r.headers, body: r.body, problemDetails: r.problemDetails, } } ... 最后，在客户端程序处通过 Clone 方法来完成对象的复制：\n// demo/service/mediator/service_mediator.go  type ServiceMediator struct {...} func (s *ServiceMediator) Forward(req *http.Request) *http.Response { ... dest, err := s.discovery(svcType) if err != nil { ... } // 关键点2: 通过Clone方法完成对象的复制，然后在此基础上进行进一步的修改  forwardReq := req.Clone().AddUri(svcUri) ... resp, err := client.Send(dest, forwardReq) if err != nil { ... } return resp.Clone().AddReqId(req.ReqId()) } 原型模式的实现相对简单，可总结为 2 个关键点：\n 为原型对象定义 Clone 方法，在此方法上完成成员属性的拷贝。 在客户端程序中通过 Clone 来完成对象的复制。  需要注意的是，我们不一定非得遵循标准的原型模式 UML 结构定义一个原型接口，然后让原型对象实现它，比如：\n// Cloneable 原型复制接口 type Cloneable interface { Clone() Cloneable } type Response struct {...} // 实现原型复制接口 func (r *Response) Clone() Cloneable { return \u0026amp;Response{ reqId: r.reqId, statusCode: r.statusCode, headers: r.headers, body: r.body, problemDetails: r.problemDetails, } } 在当前场景下，这样并不会给程序带来任何好处，反而新增一次类型强转，让程序变得更复杂了：\nfunc (s *ServiceMediator) Forward(req *http.Request) *http.Response { ... resp, err := client.Send(dest, forwardReq) if err != nil { ... } // 因为Clone方法返回的是Cloneable接口，因此需要转型为*http.Response  return resp.Clone().(*http.Response).AddReqId(req.ReqId()) } 所以，运用设计模式，最重要的是学得其中精髓，而不是仿照其形式，否则很容易适得其反。\n扩展 原型模式和与建造者模式的结合 原型模式和建造者模式相结合，也是常见的场景。还是以 http.Request 为例：\n首先，我们先为它新增一个 requestBuilder 对象来完成对象的构造：\n// demo/network/http/http_request_builder.go type requestBuilder struct { req *Request } // 普通Builder工厂方法，新创建一个Request对象 func NewRequestBuilder() *requestBuilder { return \u0026amp;requestBuilder{req: EmptyRequest()} } func (r *requestBuilder) AddMethod(method Method) *requestBuilder { r.req.method = method return r } func (r *requestBuilder) AddUri(uri Uri) *requestBuilder { r.req.uri = uri return r } ... // 一系列 Addxxx 方法  func (r *requestBuilder) Builder() *Request { return r.req } 下面，我们为 requestBuilder 新增一个 NewRequestBuilderCopyFrom 工厂方法来达到原型复制的效果：\n// demo/network/http/http_request_builder.go  // 实现原型模式的Builder工厂方法，复制已有的Request对象 func NewRequestBuilderCopyFrom(req *Request) *requestBuilder { reqId := rand.Uint32() % 10000 replica := \u0026amp;Request{ reqId: ReqId(reqId), method: req.method, uri: req.uri, queryParams: req.queryParams, headers: req.headers, body: req.body, } // 将复制后的对象赋值给requestBuilder  return \u0026amp;requestBuilder{req: replica} } 用法如下：\nfunc (s *ServiceMediator) Forward(req *http.Request) *http.Response { ... dest, err := s.discovery(svcType) if err != nil { ... } // 原型模式和建造者模式相结合的实现  forwardReq := http.NewRequestBuilderCopyFrom(req).Builder().AddUri(svcUri) ... resp, err := client.Send(dest, forwardReq) if err != nil { ... } // 普通原型模式的实现  return resp.Clone().AddReqId(req.ReqId()) } 浅拷贝和深拷贝 如果原型对象的成员属性包含了指针类型，那么就会存在浅拷贝和深拷贝两种复制方式，比如对于原型对象 ServiceProfile，其中的 Region 属性为指针类型：\n// demo/service/registry/model/service_profile.go package model // ServiceProfile 服务档案，其中服务ID唯一标识一个服务实例，一种服务类型可以有多个服务实例 type ServiceProfile struct { Id string // 服务ID  Type ServiceType // 服务类型  Status ServiceStatus // 服务状态  Endpoint network.Endpoint // 服务Endpoint  Region *Region // 服务所属region  Priority int // 服务优先级，范围0～100，值越低，优先级越高  Load int // 服务负载，负载越高表示服务处理的业务压力越大 } 浅拷贝的做法是直接复制指针：\n// 浅拷贝实现 func (s *ServiceProfile) Clone() Cloneable { return \u0026amp;ServiceProfile{ Id: s.Id, Type: s.Type, Status: s.Status, Endpoint: s.Endpoint, Region: s.Region, // 指针复制，浅拷贝  Priority: s.Priority, Load: s.Load, } } 深拷贝的做法则是创建新的 Region 对象：\n// 深拷贝实现 func (s *ServiceProfile) Clone() Cloneable { return \u0026amp;ServiceProfile{ Id: s.Id, Type: s.Type, Status: s.Status, Endpoint: s.Endpoint, Region: \u0026amp;Region{ // 新创建一个Region对象，深拷贝  Id: s.Region.Id, Name: s.Region.Name, Country: s.Region.Country, }, Priority: s.Priority, Load: s.Load, } } 具体使用哪种方式，因不同业务场景而异。浅拷贝直接复制指针，在性能上会好点；但某些场景下，引用同一个对象实例可能会导致业务异常，这时候就必须使用深拷贝了。\n典型使用场景  不管是复杂还是简单的对象，只要存在对象复制的场景，都适合使用原型模式。  优缺点 优点  对客户端隐藏实现细节，有利于避免代码耦合。 让客户端代码更简洁，有利于提升可读性。 可方便地复制复杂对象，有利于杜绝客户端复制对象时的低级错误，比如漏复制属性。  缺点  某些业务场景需要警惕浅拷贝问题。  与其他模式的关联 如前文提到的，原型模式和建造者模式相结合也是一种常见的应用场景。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：建造者模式, 元闰子\n[3] Design Patterns, Chapter 3. Creational Patterns, GoF\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-06-02T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：原型模式"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：工厂方法模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简述 上一篇我们介绍了工厂方法模式，本文，我们继续介绍它的兄弟，抽象工厂模式（Abstract Factory Pattern）。\n在工厂方法模式中，我们通过一个工厂方法接口来创建产品，而创建哪类产品，由具体的工厂对象来决定。抽象工厂模式和工厂方法模式的功能很类似，只是把“产品”，变成了“产品族”。产品族就意味着这是一系列有关联的、一起使用的对象。我们当然也可以为产品族中的每个产品定义一个工厂方法接口，但这显得有些冗余，因为一起使用通常也意味着同时创建，所以把它们放到同一个抽象工厂来创建会更合适。\nUML 结构 场景上下文 在简单的分布式应用系统（示例代码工程）中，我们有一个 Monitor 监控系统模块，该模块可以看成是一个简单的 ETL 系统，负责对监控数据的采集、处理、输出。整个模块被设计为插件化风格的架构，Pipeline是数据处理的流水线，其中包含了 Input、Filter 和 Output 三类插件，Input 负责从各类数据源中获取监控数据，Filter 负责数据处理，Output 负责将处理后的数据输出。更详细的设计思想我们在桥接模式一篇再做介绍，本文主要聚焦如何使用抽象工厂模式来解决各类插件的配置加载问题。\n作为 ETL 系统，Monitor 模块应该具备灵活的扩展能力来应对不同的监控数据类型，因此，我们希望能够通过配置文件来定义 Pipeline 的行为。比如，下面就是一个 yaml 格式的配置内容：\nname:pipeline_0# pipeline名称type:simple# pipeline类型input:# input插件定义name:input_0# input插件名称type:memory_mq# input插件类型，这里使用的是MemoryMQ作为输入context:# input插件的配置上下文topic:access_log.topic# 这里配置的是订阅的MemoryMQ主题filters:# filter插件链定义，多个filter插件组成一个filters插件链- name:filter_0# filter插件名称type:extract_log# filter插件类型- name:filter_1type:add_timestampoutput:# output插件定义name:output_0# output插件名称type:memory_db# output插件类型，这里使用的是MemoryDB作为输出context:# output插件上下文tableName:monitor_record_0# 这里配置的是MemoryDB表名另外，我们也希望 Monitor 模块支持多种类型的配置文件格式，比如，json 配置内容应该也支持：\n{ \u0026#34;name\u0026#34;: \u0026#34;pipeline_0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;simple\u0026#34;, \u0026#34;input\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;input_0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;memory_mq\u0026#34;, \u0026#34;context\u0026#34;: { \u0026#34;topic\u0026#34;: \u0026#34;access_log.topic\u0026#34; } }, \u0026#34;filters\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;filter_0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;extract_log\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;filter_1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;add_timestamp\u0026#34; } ], \u0026#34;output\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;output_0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;memory_db\u0026#34;, \u0026#34;context\u0026#34;: { \u0026#34;tableName\u0026#34;: \u0026#34;monitor_record_0\u0026#34; } } } 所以，整体的效果是这样的：\n可以看出，配置管理子模块中对象之间的关系，很符合抽象工厂模式的 UML 的结构，其中产品族就是 4 个插件配置对象，conf.Input、conf.Filter、conf.Output、conf.Pipeline，因此，我们下面使用抽象工厂模式来实现该子模块。\n代码实现 首先，我们先把各个配置对象（产品）定义好：\n// demo/monitor/config/config.go package config // 配置基础结构 type item struct { Name string `json:\u0026#34;name\u0026#34; yaml:\u0026#34;name\u0026#34;` PluginType string `json:\u0026#34;type\u0026#34; yaml:\u0026#34;type\u0026#34;` Ctx plugin.Context `json:\u0026#34;context\u0026#34; yaml:\u0026#34;context\u0026#34;` loadConf func(conf string, item interface{}) error // 封装不同配置文件的加载逻辑，实现多态的关键 } // Input配置对象 type Input item func (i *Input) Load(conf string) error { return i.loadConf(conf, i) } // Filter配置对象 type Filter item func (f *Filter) Load(conf string) error { return f.loadConf(conf, f) } // Output配置对象 type Output item func (o *Output) Load(conf string) error { return o.loadConf(conf, o) } // Pipeline配置对象 type Pipeline struct { item `yaml:\u0026#34;,inline\u0026#34;` // yaml嵌套时需要加上,inline  Input Input `json:\u0026#34;input\u0026#34; yaml:\u0026#34;input\u0026#34;` Filters []Filter `json:\u0026#34;filters\u0026#34; yaml:\u0026#34;filters,flow\u0026#34;` Output Output `json:\u0026#34;output\u0026#34; yaml:\u0026#34;output\u0026#34;` } func (p *Pipeline) Load(conf string) error { return p.loadConf(conf, p) } 在 Java/C++ 等面向对象的编程语言中，我们定义一个产品的不同实现的时，通常采用继承的方式，也即先定义一个基类封装好公共逻辑，再定义不同的继承自该基类的不同子类来实现具体的逻辑。比如，对于 Input 配置对象，在 Java 中可能是这样定义的：\n// 基类 public abstract class InputConfig implements Config { protected String name; protected InputType type; protected Context ctx; // 子类实现具体加载逻辑  @Override public abstract void load(String conf); ... } // Json子类 public class JsonInputConfig extends InputConfig { @Override public void load(String conf) { ... // Json配置文件加载逻辑  } } // yaml子类 public class YamlInputConfig extends InputConfig { @Override public void load(String conf) { ... // Yaml配置文件加载逻辑  } } 但是在 Go 语言中并没有继承的概念，也无法定义抽象基类，因此，我们通过定义一个函数对象 loadConf 来实现多态，它的类型是 func(conf string, item interface{}) error，具体做的事情就是解析 conf 字符串（配置文件内容），然后完成 item 的赋值。\n Go 语言中通过函数对象来实现多态的技巧，我们在介绍模板方法模式时也会用到。\n 接下来，我们定义抽象工厂接口：\n// demo/monitor/config/config_factory.go  // 关键点1: 定义抽象工厂接口，里面定义了产品族中各个产品的工厂方法 type Factory interface { CreateInputConfig() Input CreateFilterConfig() Filter CreateOutputConfig() Output CreatePipelineConfig() Pipeline } 然后是不同的实现：\n// demo/monitor/config/json_config_factory.go  // loadJson 加载json配置 func loadJson(conf string, item interface{}) error { return json.Unmarshal([]byte(conf), item) } // 关键点2: 实现抽象工厂接口 type JsonFactory struct {} func NewJsonFactory() *JsonFactory { return \u0026amp;JsonFactory{} } // CreateInputConfig 例子 {\u0026#34;name\u0026#34;:\u0026#34;input1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;memory_mq\u0026#34;, \u0026#34;context\u0026#34;:{\u0026#34;topic\u0026#34;:\u0026#34;monitor\u0026#34;,...}} func (j JsonFactory) CreateInputConfig() Input { return Input{loadConf: loadJson} } // CreateFilterConfig 例子 [{\u0026#34;name\u0026#34;:\u0026#34;filter1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;to_json\u0026#34;},{\u0026#34;name\u0026#34;:\u0026#34;filter2\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;add_timestamp\u0026#34;},...] func (j JsonFactory) CreateFilterConfig() Filter { return Filter{loadConf: loadJson} } // CreateOutputConfig 例子 {\u0026#34;name\u0026#34;:\u0026#34;output1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;memory_db\u0026#34;, \u0026#34;context\u0026#34;:{\u0026#34;tableName\u0026#34;:\u0026#34;test\u0026#34;,...}} func (j JsonFactory) CreateOutputConfig() Output { return Output{loadConf: loadJson} } // CreatePipelineConfig 例子 {\u0026#34;name\u0026#34;:\u0026#34;pipline1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;simple\u0026#34;, \u0026#34;input\u0026#34;:{...}, \u0026#34;filter\u0026#34;:{...}, \u0026#34;output\u0026#34;:{...}} func (j JsonFactory) CreatePipelineConfig() Pipeline { pipeline := Pipeline{} pipeline.loadConf = loadJson return pipeline } // demo/monitor/config/yaml_config_factory.go // loadYaml 加载yaml配置 func loadYaml(conf string, item interface{}) error { return yaml.Unmarshal([]byte(conf), item) } // YamlFactory Yaml配置工厂 type YamlFactory struct { } func NewYamlFactory() *YamlFactory { return \u0026amp;YamlFactory{} } func (y YamlFactory) CreateInputConfig() Input { return Input{loadConf: loadYaml} } func (y YamlFactory) CreateFilterConfig() Filter { return Filter{loadConf: loadYaml} } func (y YamlFactory) CreateOutputConfig() Output { return Output{loadConf: loadYaml} } func (y YamlFactory) CreatePipelineConfig() Pipeline { pipeline := Pipeline{} pipeline.loadConf = loadYaml return pipeline } 使用方法如下；\n// demo/monitor/monitor_system.go type System struct { plugins map[string]plugin.Plugin // 关键点3: 在使用时依赖抽象工厂接口  configFactory config.Factory } func NewSystem(configFactory config.Factory) *System { return \u0026amp;System{ plugins: make(map[string]plugin.Plugin), configFactory: configFactory, } } func (s *System) LoadConf(conf string) error { pipelineConf := s.configFactory.CreatePipelineConfig() if err := pipelineConf.Load(conf); err != nil { return err } ... } // demo/example.go func main() { // 关键点4: 在初始化是依赖注入具体的工厂实现  monitorSys := monitor.NewSystem(config.NewYamlFactory()) conf, _ := ioutil.ReadFile(\u0026#34;monitor_pipeline.yaml\u0026#34;) monitorSys.LoadConf(string(conf)) ... } 总结实现抽象工厂模式的几个关键点：\n 定义抽象工厂接口，里面包含创建各个产品的工厂方法定义。 定义抽象工厂接口的实现类。 在客户端程序中依赖抽象工厂接口，通过接口来完成产品的创建。 在客户端程序初始化时，将抽象工厂接口的具体实现依赖注入进去。  典型应用场景  系统中有产品族，产品有不同的实现，且需要支持扩展。 希望产品的创建逻辑和业务逻辑分离。  优缺点 优点  产品创建逻辑和业务逻辑分离，符合单一职责原理。 具有较高的可扩展性，新增一种产品族实现，只需新增一个抽象工厂实现即可。  缺点  新增一些对象/接口的定义，滥用会导致代码更加复杂。  与其他模式的关联 很多同学容易将工厂方法模式和抽象工厂模式混淆，工厂方法模式主要应用在单个产品的实例化场景；抽象工厂模式则应用在“产品族”的实例化场景，可以看成是工厂方法模式的一种演进。\n另外，抽象工厂接口的实现类，有时也会通过单例模式来实现。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] 【Go实现】实践GoF的23种设计模式：工厂方法模式, 元闰子\n[3] Design Patterns, Chapter 3. Creational Patterns, GoF\n更多文章请关注微信公众号：元闰子的邀请\n  ","date":"2022-05-29T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：抽象工厂模式"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：建造者模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简述 工厂方法模式（Factory Method Pattern）跟上一篇讨论的建造者模式类似，都是将对象创建的逻辑封装起来，为使用者提供一个简单易用的对象创建接口。两者在应用场景上稍有区别，建造者模式常用于需要传递多个参数来进行实例化的场景；工厂方法模式常用于不指定对象具体类型的情况下创建对象的场景。\nUML 结构 代码实现 示例 在简单的分布式应用系统（示例代码工程）中，我们设计了 Sidecar 边车模块， Sidecar 的作用是为了给原生的 Socket 增加额外的功能，比如流控、日志等。\nSidecar 模块的设计运用了装饰者模式，修饰的是 Socket 。所以客户端其实是把 Sidecar 当成是 Socket 来使用了，比如：\n// demo/network/http/http_client.go package http // 创建一个新的HTTP客户端，以Socket接口作为入参 func NewClient(socket network.Socket, ip string) (*Client, error) { ... // 一些初始化逻辑 \treturn client, nil } // 使用NewClient时，我们可以传入Sidecar来给Http客户端附加额外的流控功能 client, err := http.NewClient(sidecar.NewFlowCtrlSidecar(network.DefaultSocket()), \u0026#34;192.168.0.1\u0026#34;) 在服务消息中介中，每次收到上游服务的 HTTP 请求，都会调用 http.NewClient 来创建一个 HTTP 客户端，并通过它将请求转发给下游服务：\ntype ServiceMediator struct { ... server *http.Server } // Forward 转发请求，请求URL为 /{serviceType}+ServiceUri 的形式，如/serviceA/api/v1/task func (s *ServiceMediator) Forward(req *http.Request) *http.Response { ... // 发现下游服务的目的IP地址  dest, err := s.discovery(svcType) // 创建HTTP客户端，硬编码sidecar.NewFlowCtrlSidecar(network.DefaultSocket())  client, err := http.NewClient(sidecar.NewFlowCtrlSidecar(network.DefaultSocket()), s.localIp) // 通过HTTP客户端转发请求  resp, err := client.Send(dest, forwardReq) ... } 在上述实现中，我们在调用 http.NewClient 时把 sidecar.NewFlowCtrlSidecar(network.DefaultSocket()) 硬编码进去了，那么如果以后要扩展 Sidecar ，就得修改这段代码逻辑，这违反了开闭原则 OCP。\n有经验的同学可能会想到，可以通过让 ServiceMediator 依赖 Socket 接口，在 Forward 方法调用 http.NewClient 时把 Socket 接口作为入参；然后在 ServiceMediator 初始化时，将具体类型的 Sidecar 注入到 ServiceMediator 中：\ntype ServiceMediator struct { ... server *http.Server // 依赖Socket抽象接口  socket network.Socket } // Forward 转发请求，请求URL为 /{serviceType}+ServiceUri 的形式，如/serviceA/api/v1/task func (s *ServiceMediator) Forward(req *http.Request) *http.Response { ... // 发现下游服务的目的IP地址  dest, err := s.discovery(svcType) // 创建HTTP客户端，将s.socket抽象接口作为入参  client, err := http.NewClient(s.socket, s.localIp) // 通过HTTP客户端转发请求  resp, err := client.Send(dest, forwardReq) ... } // 在ServiceMediator初始化时，将具体类型的Sidecar注入到ServiceMediator中 mediator := \u0026amp;ServiceMediator{ socket: sidecar.NewFlowCtrlSidecar(network.DefaultSocket()) } 上述的修改，从原来依赖具体，改成了依赖抽象，符合了开闭原则。\n但是， Forward 方法存在并发调用的场景，因此它希望每次被调用时都创建一个新的 Socket/Sidecar 来完成网络通信，否则就需要加锁来保证并发安全。而上述的修改会导致在 ServiceMediator 的生命周期内都使用同一个 Socket/Sidecar，显然不符合要求。\n因此，我们需要一个方法，既能够满足开闭原则，而且在每次调用Forward 方法时也能够创建新的 Socket/Sidecar 实例。工厂方法模式恰好就能满足这两点要求，下面我们通过它来完成代码的优化。\n实现 // demo/sidecar/sidecar_factory.go  // 关键点1: 定义一个Sidecar工厂抽象接口 type Factory interface { // 关键点2: 工厂方法返回Socket抽象接口 \tCreate() network.Socket } // 关键点3: 按照需要实现具体的工厂  // demo/sidecar/raw_socket_sidecar_factory.go // RawSocketFactory 只具备原生socket功能的sidecar，实现了Factory接口 type RawSocketFactory struct { } func (r RawSocketFactory) Create() network.Socket { return network.DefaultSocket() } // demo/sidecar/all_in_one_sidecar_factory.go // AllInOneFactory 具备所有功能的sidecar工厂，实现了Factory接口 type AllInOneFactory struct { producer mq.Producible } func (a AllInOneFactory) Create() network.Socket { return NewAccessLogSidecar(NewFlowCtrlSidecar(network.DefaultSocket()), a.producer) } 上述代码中，我们定义了一个工厂抽象接口 Factory ，并有了 2 个具体的实现 RawSocketFactory 和 AllInOneFactory。最后， ServiceMediator 依赖 Factory ，并在 Forward 方法中通过 Factory 来创建新的 Socket/Sidecar ：\n// demo/service/mediator/service_mediator.go  type ServiceMediator struct { ... server *http.Server // 关键点4: 客户端依赖Factory抽象接口  sidecarFactory sidecar.Factory } // Forward 转发请求，请求URL为 /{serviceType}+ServiceUri 的形式，如/serviceA/api/v1/task func (s *ServiceMediator) Forward(req *http.Request) *http.Response { ... // 发现下游服务的目的IP地址  dest, err := s.discovery(svcType) // 创建HTTP客户端，调用sidecarFactory.Create()生成Socket作为入参  client, err := http.NewClient(s.sidecarFactory.Create(), s.localIp) // 通过HTTP客户端转发请求  resp, err := client.Send(dest, forwardReq) ... } // 关键点5: 在ServiceMediator初始化时，将具体类型的sidecar.Factory注入到ServiceMediator中 mediator := \u0026amp;ServiceMediator{ sidecarFactory: \u0026amp;AllInOneFactory{} // sidecarFactory: \u0026amp;RawSocketFactory{} } 下面总结实现工厂方法模式的几个关键点：\n 定义一个工厂方法抽象接口，比如前文中的 sidecar.Factory。 工厂方法中，返回需要创建的对象/接口，比如 network.Socket。其中，工厂方法通常命名为 Create。 按照具体需要，定义工厂方法抽象接口的具体实现对象，比如 RawSocketFactory 和 AllInOneFactory。 客户端使用时，依赖工厂方法抽象接口。 在客户端初始化阶段，完成具体工厂对象的依赖注入。  扩展 Go 风格的实现 前文的工厂方法模式实现，是非常典型的面向对象风格，下面我们给出一个更具 Go 风格的实现。\n// demo/sidecar/sidecar_factory_func.go  // 关键点1: 定义Sidecar工厂方法类型 type FactoryFunc func() network.Socket // 关键点2: 按需定义具体的工厂方法实现，注意这里定义的是工厂方法的工厂方法，返回的是FactoryFunc工厂方法类型 func RawSocketFactoryFunc() FactoryFunc { return func() network.Socket { return network.DefaultSocket() } } func AllInOneFactoryFunc(producer mq.Producible) FactoryFunc { return func() network.Socket { return NewAccessLogSidecar(NewFlowCtrlSidecar(network.DefaultSocket()), producer) } } type ServiceMediator struct { ... server *http.Server // 关键点3: 客户端依赖FactoryFunc工厂方法类型  sidecarFactoryFunc FactoryFunc } func (s *ServiceMediator) Forward(req *http.Request) *http.Response { ... dest, err := s.discovery(svcType) // 关键点4: 创建HTTP客户端，调用sidecarFactoryFunc()生成Socket作为入参  client, err := http.NewClient(s.sidecarFactoryFunc(), s.localIp) resp, err := client.Send(dest, forwardReq) ... } // 关键点5: 在ServiceMediator初始化时，将具体类型的FactoryFunc注入到ServiceMediator中 mediator := \u0026amp;ServiceMediator{ sidecarFactoryFunc: RawSocketFactoryFunc() // sidecarFactory: AllInOneFactoryFunc(producer) } 上述的实现，利用了 Go 语言中函数作为一等公民的特点，少定义了几个 interface 和 struct，代码更加的简洁。\n几个实现的关键点与面向对象风格的实现类似。值得注意的是 关键点2 ，我们相当于定义了一个工厂方法的工厂方法，这么做是为了利用函数闭包的特点来传递参数。如果直接定义工厂方法，那么 AllInOneFactoryFunc 的实现是下面这样的，无法实现多态：\n// 并非FactoryFunc类型，无法实现多态 func AllInOneFactoryFunc(producer mq.Producible) network.Socket { return NewAccessLogSidecar(NewFlowCtrlSidecar(network.DefaultSocket()), producer) } 简单工厂 工厂方法模式的另一个变种是简单工厂，它并不通过多态，而是通过简单的 switch-case/if-else 条件判断来决定创建哪种产品：\n// demo/sidecar/sidecar_simple_factory.go  // 关键点1: 定义sidecar类型 type Type uint8 // 关键点2: 按照需要定义sidecar具体类型 const ( Raw Type = iota AllInOne ) // 关键点3: 定义简单工厂对象 type SimpleFactory struct { producer mq.Producible } // 关键点4: 定义工厂方法，入参为sidecar类型，根据switch-case或者if-else来创建产品 func (s SimpleFactory) Create(sidecarType Type) network.Socket { switch sidecarType { case Raw: return network.DefaultSocket() case AllInOne: return NewAccessLogSidecar(NewFlowCtrlSidecar(network.DefaultSocket()), s.producer) default: return nil } } // 关键点5: 创建产品时传入具体的sidecar类型，比如sidecar.AllInOne simpleFactory := \u0026amp;sidecar.SimpleFactory{producer: producer} sidecar := simpleFactory.Create(sidecar.AllInOne) 静态工厂方法 静态工厂方法是 Java/C++ 的说法，主要用于替代构造函数来完成对象的实例化，能够让代码的可读性更好，而且起到了与客户端解耦的作用。比如 Java 的静态工厂方法实现如下：\npublic class Packet { private final Endpoint src; private final Endpoint dest; private final Object payload; private Packet(Endpoint src, Endpoint dest, Object payload) { this.src = src; this.dest = dest; this.payload = payload; } // 静态工厂方法  public static Packet of(Endpoint src, Endpoint dest, Object payload) { return new Packet(src, dest, payload); } ... } // 用法 packet = Packet.of(src, dest, payload) Go 中并没有静态一说，直接通过普通函数来完成对象的构造即可，比如：\n// demo/network/packet.go type Packet struct { src Endpoint dest Endpoint payload interface{} } // 工厂方法 func NewPacket(src, dest Endpoint, payload interface{}) *Packet { return \u0026amp;Packet{ src: src, dest: dest, payload: payload, } } // 用法 packet := NewPacket(src, dest, payload) 典型应用场景  对象实例化逻辑较为复杂时，可选择使用工厂方法模式/简单工厂/静态工厂方法来进行封装，为客户端提供一个易用的接口。 如果实例化的对象/接口涉及多种实现，可以使用工厂方法模式实现多态。 普通对象的创建，推荐使用静态工厂方法，比直接的实例化（比如 \u0026amp;Packet{src: src, dest: dest, payload: payload}）具备更好的可读性和低耦合。  优缺点 优点  代码的可读性更好。 与客户端程序解耦，当实例化逻辑变更时，只需改动工厂方法即可，避免了霰弹式修改。  缺点  引入工厂方法模式会新增一些对象/接口的定义，滥用会导致代码更加复杂。  与其他模式的关联 很多同学容易将工厂方法模式和抽象工厂模式混淆，抽象工厂模式主要运用在实例化“产品族”的场景，可以看成是工厂方法模式的一种演进。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] Design Patterns, Chapter 3. Creational Patterns, GoF\n[3] Factory patterns in Go (Golang), Soham Kamani\n[4] 工厂方法, 维基百科\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-05-21T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：工厂方法模式"},{"content":"开始 前几天，看到这样的一句话：\n 生活中往往没有标准答案，当你要求别人给你一个标准答案时，就是思想上的懒惰了。\n 当我们说一个人“懒惰”时，通常都指他贪玩、不爱学习、好吃懒做。如果按照这个标准，自问我也不是一个懒惰的人。读书时就一直被当成是热爱学习的“好学生”；工作后也一直在践行曾国藩的“少睡多做，一人之生气”。\n但是，当我读到 思想上的懒惰 时，心里一惊，感觉自我设立的“勤奋”人设，在心中崩塌了。\n读书是很容易的事，可是思考却很难 富兰克林说，“读书是很容易的事，可是思考却很难”。\n在当代，读书更不是件难事。智能手机上的读书软件、听书 APP 层出不穷，只要利用好碎片时间，我们就能读书。工作之余，自己也读了不少书，特别是看完《穷查理宝典》后，开始践行查理芒格的“多学科交叉”理论，书籍涉猎也更广了。然后在年终时，把一年里读过的书列出来，给自己设立一个”勤奋“的人设，幻想着有一天能够融汇贯通，走上人生巅峰。\n人们总说读书是润物细无声，但几年过去了，读书好像并没有给自己的工作和生活带来多大的改变，难道努力和勤奋都配不上回报吗？\n最近算是想明白了，是自己缺少思考，陷入了思想上的懒惰。\n回顾过去的读书经历，也只是读而已。美其名曰追求知识广度，想着留个印象，以后总会有用处；实则在偷懒，逃避思考，毕竟吃透一个知识或问题，真的太烧脑、太耗时了。\n我想，很多人也会有类似的这些经历：复习时遇到一道题目，一时弄不太懂，“算了，时间来不及了，先记住，万一考试遇上了还能背出来”；工作时碰到一个程序 Bug，一时定位不出来，重启一下竟然好了，“算了，反正也不复现了，有问题也肯定是环境问题”。\n这些经历里，时间也许是个问题，但根本问题还是出在人类的懒惰天性。犹太人有句谚语，“人类一思考，上帝就发笑”，而我确实也做到了不给上帝发笑的机会。\n未经审视的人生是不值得过的 苏格拉底说，“未经审视的人生是不值得过的”。\n如果只在读书上缺乏思考，最多也就缺少点思想深度。但如果在人生规划上也缺乏思考，可能就会浑浑噩噩地过完一辈子。\n在当代的中国社会里，人们常常因为一套房子，就被锁在了一座城市里；因为一摞金钱，就忘掉了梦想；因为一份工作，就一直忍气吞声。在世俗意义上的成功的驱动之下，我们很容易疲于奔命，却很少停下来思考和规划自己的人生，问问自己到底真正想要的是什么。\n也许，只有等到年过花甲了，回过头来一看，才发现人生少了一点精彩。\n回顾过去二十几年的人生，自己也是一直在朝着世俗意义的成功稳步前进。努力读书，勤奋工作，工作之余还会读书写作，在很多家人朋友的眼里，也算是过得很好的了。但是，这段未经审视的人生，也许还可以更精彩一些。\n最后 这段时间也慢慢开始尝试着去思考了，在读书的时候，在独处的时候。也许跟最近接触了很多哲学方面的知识有关。以前觉得哲学家们都是些闲人，老是想一些不切实际的问题，最近才感受到，他们才是人类的明灯。平时多接触些西方哲学，学习他们刨根问底的特质，辩证思考问题的方法，慢慢的，自己也会去多问几个为什么了。\n至于如何才能在读书时培养深入思考的习惯，我想，做笔记会是一个很好的方法。做笔记能够让读书速度慢下来，有更多思考的间隙；而且把当时的想法记录下来，后面再回看，会有一种自豪感。\n至于如何才能过上精彩的人生，我想，需要勇气。\n","date":"2022-05-08T00:00:00Z","permalink":"https://www.yrunz.com/p/%E6%87%92%E6%83%B0/","title":"懒惰"},{"content":"开篇词 一直以来，时不时都会收到一些小伙伴的私信或留言，问“文章中的配图是用什么工具画的？”，比如：\n              我的回答也一直都很简练，“Keynote 画的”。细想一下，其实有种听君一席话，如听一席话的感觉。所以，今天专门花点时间总结一下自己文章配图的一些风格选择。\n用 MacOS 的小伙伴应该都对 Keynote 很熟悉，可以把它看成是 MacOS 上的 PowerPoint。\n想到用 Keynote 来画图的源头，是从看到《A successful Git branching model》这篇文章上很好看的手绘风格配图开始：\n        几轮 Google 之后才找到原来是通过 Keynote 画出来的，从此迷上了用 Keynote 来画这种手绘风格的配图。\n中途也有尝试过其他手绘风格的画图软件，比如 Excalidraw。Excalidraw 是一款开源免费的手绘风格画图软件，相比 Keynote，它显得更加的手绘风。不过对中文字体的支持太弱了，与英文字体放在一起显得极其不协调，最后也就放弃了。\n        几番对比之后，还是觉得 Keynote 在易用性、效率、配色、样式等方面更好用。下面，开始简单介绍下在使用 Keynote 画图时，主题、样式、形状、配色、字体等方面的一些选择和搭配。\n主题 Keynote 上有很多内置的主题，主题们都非常的好看（个人觉得 MacOS 在审美方面还是比 Windows 强不少）：\n主题的选取其实就是配图中背景的选取，既然给自己的配图定的是手绘风格，自然就要选一个跟手绘风搭配的主题。看来看去，还是觉得 草图 这个主题最顺眼。羊皮纸颜色的背景，跟手绘风很搭配。\n草图 主题中的空白背景和网格背景都很好看，根据个人喜好选择即可，个人比较喜欢空白背景的简约风。\n        样式 手绘风格的配图主要由 Keynote 上内置的 线条描边 和 图案边框 样式定格。在 Keynote 右侧的 样式 栏就能够选择，上面有好几种手绘风格的样式，个人比较喜欢下面的这种：\n        形状 Keynote 上内置的形状和图案已经够用了，再配合上内置的手绘风格线条/边框样式就很好看了：\n配色 关于图案配色，网上有很多颜色搭配网站，比如 Color Hunt， Nippon Colors， Color Drop，Coolors。可以按照自己的喜好来选择，实在有选择困难症的，选一个点赞数量较多的配色也基本不会错。\n              不过个人还是比较喜欢 草图 主题上的颜色搭配。一方面，它看起来很顺眼；另一方面，因为是主题内置，所以用起来很方便，不用重新取色搭配。个人用得最多的是最上层的浅色搭配，看起来明亮轻快些，不至于太压抑。\n另外，在线条和字体颜色的选择上，个人更喜欢使用内置的浅黑色，感觉它和手绘风格更加搭一些。\n字体 既然是手绘风格，就不能选择太过正式的字体。Keynote 内置的字体中，个人觉得跟手绘风格较搭的有 娃娃体、手札体、翩翩体、凌惠体 四种字体。最开始选择的是 娃娃体，后面觉得有点太 Q 了，就选择了各方面较为平衡的 手札体。\n最后 好的配图对文章是一个巨大的加分项，能够让人有看下去的欲望。而画好配图是一件很费时费力的事情，特别是工具使用不熟练的时候。\n画图软件有很多，比如 Keynote、PowerPoint、Visio、亿图、Excalidraw、Sketch、OmniGraffle、ProcessOn 等。有免费的，也有付费的。有功能齐全，但用法复杂的；也有基本够用，但用法简单的。找到一个合适自己的就行，关键是要提升画图效率，避免在配图上花费太多时间。\n最后，提升使用 Keynote 画图效率的一个好方法，就是将常用的图案预先画好，并保存到一个 Keynote 文稿上，等用到时再复制-粘贴使用即可。\n 相关链接 [1] Excalidraw: https://excalidraw.com\n[2] Color Hunt: https://www.colorhunt.co\n[3] Nippon Colors: https://nipponcolors.com\n[4] Color Drop: https://colordrop.io\n[5] Coolors: https://coolors.co\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-05-07T00:00:00Z","permalink":"https://www.yrunz.com/p/%E7%94%A8keynote%E7%94%BB%E5%87%BA%E6%89%8B%E7%BB%98%E9%A3%8E%E6%A0%BC%E7%9A%84%E9%85%8D%E5%9B%BE/","title":"用Keynote画出手绘风格的配图"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：单例模式\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简述 在程序设计中，我们会经常遇到一些复杂的对象，其中有很多成员属性，甚至嵌套着多个复杂的对象。这种情况下，创建这个复杂对象就会变得很繁琐。对于 C++/Java 而言，最常见的表现就是构造函数有着长长的参数列表：\nMyObject obj = new MyObject(param1, param2, param3, param4, param5, param6, ...) 对于 Go 语言来说，最常见的表现就是多层的嵌套实例化：\nobj := \u0026amp;MyObject{ Field1: \u0026amp;Field1 { Param1: \u0026amp;Param1 { Val: 0, }, Param2: \u0026amp;Param2 { Val: 1, }, ... }, Field2: \u0026amp;Field2 { Param3: \u0026amp;Param3 { Val: 2, }, ... }, ... } 上述的对象创建方法有两个明显的缺点：（1）对使用者不友好，使用者在创建对象时需要知道的细节太多；（2）代码可读性很差。\n针对这种对象成员较多，创建对象逻辑较为繁琐的场景，非常适合使用建造者模式来进行优化。\n建造者模式的作用有如下几个：\n1、封装复杂对象的创建过程，使对象使用者不感知复杂的创建逻辑。2、可以一步步按照顺序对成员进行赋值，或者创建嵌套对象，并最终完成目标对象的创建。3、对多个对象复用同样的对象创建逻辑。其中，第1和第2点比较常用，下面对建造者模式的实现也主要是针对这两点进行示例。\nUML 结构 代码实现 示例 在简单的分布式应用系统（示例代码工程）中，我们定义了服务注册中心，提供服务注册、去注册、更新、 发现等功能。要实现这些功能，服务注册中心就必须保存服务的信息，我们把这些信息放在了 ServiceProfile 这个数据结构上，定义如下：\n// demo/service/registry/model/service_profile.go // ServiceProfile 服务档案，其中服务ID唯一标识一个服务实例，一种服务类型可以有多个服务实例 type ServiceProfile struct { Id string // 服务ID  Type ServiceType // 服务类型  Status ServiceStatus // 服务状态  Endpoint network.Endpoint // 服务Endpoint  Region *Region // 服务所属region  Priority int // 服务优先级，范围0～100，值越低，优先级越高  Load int // 服务负载，负载越高表示服务处理的业务压力越大 } // demo/service/registry/model/region.go // Region 值对象，每个服务都唯一属于一个Region type Region struct { Id string Name string Country string } // demo/network/endpoint.go // Endpoint 值对象，其中ip和port属性为不可变，如果需要变更，需要整对象替换 type Endpoint struct { ip string port int } 实现 如果按照直接实例化方式应该是这样的：\n// 多层的嵌套实例化 profile := \u0026amp;ServiceProfile{ Id: \u0026#34;service1\u0026#34;, Type: \u0026#34;order\u0026#34;, Status: Normal, Endpoint: network.EndpointOf(\u0026#34;192.168.0.1\u0026#34;, 8080), Region: \u0026amp;Region{ // 需要知道对象的实现细节 \tId: \u0026#34;region1\u0026#34;, Name: \u0026#34;beijing\u0026#34;, Country: \u0026#34;China\u0026#34;, }, Priority: 1, Load: 100, } 虽然 ServiceProfile 结构体嵌套的层次不多，但是从上述直接实例化的代码来看，确实存在对使用者不友好和代码可读性较差的缺点。比如，使用者必须先对 Endpoint 和 Region 进行实例化，这实际上是将 ServiceProfile 的实现细节暴露给使用者了。下面我们引入建造者模式对代码进行优化重构：\n// demo/service/registry/model/service_profile.go // 关键点1: 为ServiceProfile定义一个Builder对象 type serviceProfileBuild struct { // 关键点2: 将ServiceProfile作为Builder的成员属性 \tprofile *ServiceProfile } // 关键点3: 定义构建ServiceProfile的方法 func (s *serviceProfileBuild) WithId(id string) *serviceProfileBuild { s.profile.Id = id // 关键点4: 返回Builder接收者指针，支持链式调用 \treturn s } func (s *serviceProfileBuild) WithType(serviceType ServiceType) *serviceProfileBuild { s.profile.Type = serviceType return s } func (s *serviceProfileBuild) WithStatus(status ServiceStatus) *serviceProfileBuild { s.profile.Status = status return s } func (s *serviceProfileBuild) WithEndpoint(ip string, port int) *serviceProfileBuild { s.profile.Endpoint = network.EndpointOf(ip, port) return s } func (s *serviceProfileBuild) WithRegion(regionId, regionName, regionCountry) *serviceProfileBuild { s.profile.Region = \u0026amp;Region{Id: regionId, Name: regionName, Country: regionCountry} return s } func (s *serviceProfileBuild) WithPriority(priority int) *serviceProfileBuild { s.profile.Priority = priority return s } func (s *serviceProfileBuild) WithLoad(load int) *serviceProfileBuild { s.profile.Load = load return s } // 关键点5: 定义Build方法，在链式调用的最后调用，返回构建好的ServiceProfile func (s *serviceProfileBuild) Build() *ServiceProfile { return s.profile } // 关键点6: 定义一个实例化Builder对象的工厂方法 func NewServiceProfileBuilder() *serviceProfileBuild { return \u0026amp;serviceProfileBuild{profile: \u0026amp;ServiceProfile{}} } 实现建造者模式有 6 个关键点：\n 为 ServiceProfile 定义一个 Builder 对象 serviceProfileBuild，通常我们将它设计为包内可见，来限制客户端的滥用。 把需要构建的 ServiceProfile 作为 Builder 对象 serviceProfileBuild 的成员属性，用来存储构建过程中的状态。 为 Builder 对象 serviceProfileBuild 定义用来构建 ServiceProfile 的一系列方法，上述代码中我们使用了 WithXXX 的风格。 在构建方法中返回 Builder 对象指针本身，也即接收者指针，用来支持链式调用，提升客户端代码的简洁性。 为 Builder 对象定义 Build() 方法，返回构建好的 ServiceProfile 实例，在链式调用的最后调用。 定义一个实例化 Builder 对象的工厂方法 NewServiceProfileBuilder()。  那么，使用建造者模式实例化逻辑是这样的：\n// 建造者模式的实例化方法 profile := NewServiceProfileBuilder(). WithId(\u0026#34;service1\u0026#34;). WithType(\u0026#34;order\u0026#34;). WithStatus(Normal). WithEndpoint(\u0026#34;192.168.0.1\u0026#34;, 8080). WithRegion(\u0026#34;region1\u0026#34;, \u0026#34;beijing\u0026#34;, \u0026#34;China\u0026#34;). WithPriority(1). WithLoad(100). Build() 当使用建造者模式来进行对象创建时，使用者不再需要知道对象具体的实现细节（这里体现为无须预先实例化 Endpoint 和 Region 对象），代码可读性、简洁性也更好了。\n扩展 Functional Options 模式 进一步思考，其实前文提到的建造者实现方式，还有 2 个待改进点：\n 我们额外新增了一个 Builder 对象，如果能够把 Builder 对象省略掉，同时又能避免长长的入参列表就更好了。 熟悉 Java 的同学应该能够感觉出来，这种实现具有很强的“Java 风格”。并非说这种风格不好，而是在 Go 中理应有更具“Go 风格”的建造者模式实现。  针对这两点，我们可以通过 Functional Options 模式 来优化。Functional Options 模式也是用来构建对象的，这里我们也把它看成是建造者模式的一种扩展。它利用了 Go 语言中函数作为一等公民的特点，结合函数的可变参数，达到了优化上述 2 个改进点的目的。使用 Functional Options 模式的实现是这样的：\n// demo/service/registry/model/service_profile_functional_options.go // 关键点1: 定义构建ServiceProfile的functional option，以*ServiceProfile作为入参的函数 type ServiceProfileOption func(profile *ServiceProfile) // 关键点2: 定义实例化ServiceProfile的工厂方法，使用ServiceProfileOption作为可变入参 func NewServiceProfile(svcId string, svcType ServiceType, options ...ServiceProfileOption) *ServiceProfile { // 关键点3: 可为特定的字段提供默认值 \tprofile := \u0026amp;ServiceProfile{ Id: svcId, Type: svcType, Status: Normal, Endpoint: network.EndpointOf(\u0026#34;192.168.0.1\u0026#34;, 80), Region: \u0026amp;Region{Id: \u0026#34;region1\u0026#34;, Name: \u0026#34;beijing\u0026#34;, Country: \u0026#34;China\u0026#34;}, Priority: 1, Load: 100, } // 关键点4: 通过ServiceProfileOption来修改字段 \tfor _, option := range options { option(profile) } return profile } // 关键点5: 定义一系列构建ServiceProfile的方法，在ServiceProfileOption实现构建逻辑，并返回ServiceProfileOption func Status(status ServiceStatus) ServiceProfileOption { return func(profile *ServiceProfile) { profile.Status = status } } func Endpoint(ip string, port int) ServiceProfileOption { return func(profile *ServiceProfile) { profile.Endpoint = network.EndpointOf(ip, port) } } func SvcRegion(svcId, svcName, svcCountry string) ServiceProfileOption { return func(profile *ServiceProfile) { profile.Region = \u0026amp;Region{ Id: svcId, Name: svcName, Country: svcCountry, } } } func Priority(priority int) ServiceProfileOption { return func(profile *ServiceProfile) { profile.Priority = priority } } func Load(load int) ServiceProfileOption { return func(profile *ServiceProfile) { profile.Load = load } } 实现 Functional Options 模式有 5 个关键点：\n 定义 Functional Option 类型 ServiceProfileOption，本质上是一个入参为构建对象 ServiceProfile 的指针类型。（注意必须是指针类型，值类型无法达到修改目的） 定义构建 ServiceProfile 的工厂方法，以 ServiceProfileOption 的可变参数作为入参。函数的可变参数就意味着可以不传参，因此一些必须赋值的属性建议还是定义对应的函数入参。 可为特定的属性提供默认值，这种做法在 为配置对象赋值的场景 比较常见。 在工厂方法中，通过 for 循环利用 ServiceProfileOption 完成构建对象的赋值。 定义一系列的构建方法，以需要构建的属性作为入参，返回 ServiceProfileOption 对象，并在ServiceProfileOption 中实现属性赋值。  Functional Options 模式 的实例化逻辑是这样的：\n// Functional Options 模式的实例化逻辑 profile := NewServiceProfile(\u0026#34;service1\u0026#34;, \u0026#34;order\u0026#34;, Status(Normal), Endpoint(\u0026#34;192.168.0.1\u0026#34;, 8080), SvcRegion(\u0026#34;region1\u0026#34;, \u0026#34;beijing\u0026#34;, \u0026#34;China\u0026#34;), Priority(1), Load(100)) 相比于传统的建造者模式，Functional Options 模式的使用方式明显更加的简洁，也更具“Go 风格”了。\nFluent API 模式 前文中，不管是传统的建造者模式，还是 Functional Options 模式，我们都没有限定属性的构建顺序，比如：\n// 传统建造者模式不限定属性的构建顺序 profile := NewServiceProfileBuilder(). WithPriority(1). // 先构建Priority也完全没问题  WithId(\u0026#34;service1\u0026#34;). ... // Functional Options 模式也不限定属性的构建顺序 profile := NewServiceProfile(\u0026#34;service1\u0026#34;, \u0026#34;order\u0026#34;, Priority(1), // 先构建Priority也完全没问题 \tStatus(Normal), ... 但是在一些特定的场景，对象的属性是要求有一定的构建顺序的，如果违反了顺序，可能会导致一些隐藏的错误。当然，我们可以与使用者的约定好属性构建的顺序，但这种约定是不可靠的，你很难保证使用者会一直遵守该约定。所以，更好的方法应该是通过接口的设计来解决问题， Fluent API 模式 诞生了。下面，我们使用 Fluent API 模式进行实现：\n// demo/service/registry/model/service_profile_fluent_api.go type ( // 关键点1: 为ServiceProfile定义一个Builder对象 \tfluentServiceProfileBuilder struct { // 关键点2: 将ServiceProfile作为Builder的成员属性 \tprofile *ServiceProfile } // 关键点3: 定义一系列构建属性的fluent接口，通过方法的返回值控制属性的构建顺序 \tidBuilder interface { WithId(id string) typeBuilder } typeBuilder interface { WithType(svcType ServiceType) statusBuilder } statusBuilder interface { WithStatus(status ServiceStatus) endpointBuilder } endpointBuilder interface { WithEndpoint(ip string, port int) regionBuilder } regionBuilder interface { WithRegion(regionId, regionName, regionCountry string) priorityBuilder } priorityBuilder interface { WithPriority(priority int) loadBuilder } loadBuilder interface { WithLoad(load int) endBuilder } // 关键点4: 定义一个fluent接口返回完成构建的ServiceProfile，在最后调用链的最后调用 \tendBuilder interface { Build() *ServiceProfile } ) // 关键点5: 为Builder定义一系列构建方法，也即实现关键点3中定义的Fluent接口 func (f *fluentServiceProfileBuilder) WithId(id string) typeBuilder { f.profile.Id = id return f } func (f *fluentServiceProfileBuilder) WithType(svcType ServiceType) statusBuilder { f.profile.Type = svcType return f } func (f *fluentServiceProfileBuilder) WithStatus(status ServiceStatus) endpointBuilder { f.profile.Status = status return f } func (f *fluentServiceProfileBuilder) WithEndpoint(ip string, port int) regionBuilder { f.profile.Endpoint = network.EndpointOf(ip, port) return f } func (f *fluentServiceProfileBuilder) WithRegion(regionId, regionName, regionCountry string) priorityBuilder { f.profile.Region = \u0026amp;Region{ Id: regionId, Name: regionName, Country: regionCountry, } return f } func (f *fluentServiceProfileBuilder) WithPriority(priority int) loadBuilder { f.profile.Priority = priority return f } func (f *fluentServiceProfileBuilder) WithLoad(load int) endBuilder { f.profile.Load = load return f } func (f *fluentServiceProfileBuilder) Build() *ServiceProfile { return f.profile } // 关键点6: 定义一个实例化Builder对象的工厂方法 func NewFluentServiceProfileBuilder() idBuilder { return \u0026amp;fluentServiceProfileBuilder{profile: \u0026amp;ServiceProfile{}} } 实现 Fluent API 模式有 6 个关键点，大部分与传统的建造者模式类似：\n 为 ServiceProfile 定义一个 Builder 对象 fluentServiceProfileBuilder。 把需要构建的 ServiceProfile 设计为 Builder 对象 fluentServiceProfileBuilder 的成员属性。 定义一系列构建属性的 Fluent 接口，通过方法的返回值控制属性的构建顺序，这是实现 Fluent API 的关键。比如 WithId 方法的返回值是 typeBuilder 类型，表示紧随其后的就是 WithType 方法。 定义一个 Fluent 接口（这里是 endBuilder）返回完成构建的 ServiceProfile，在最后调用链的最后调用。 为 Builder 定义一系列构建方法，也即实现关键点 3 中定义的 Fluent 接口，并在构建方法中返回 Builder 对象指针本身。 定义一个实例化 Builder 对象的工厂方法 NewFluentServiceProfileBuilder()，返回第一个 Fluent 接口，这里是 idBuilder，表示首先构建的是 Id 属性。  Fluent API 的使用与传统的建造者实现使用类似，但是它限定了方法调用的顺序。如果顺序不对，在编译期就报错了，这样就能提前把问题暴露在编译器，减少了不必要的错误使用。\n// Fluent API的使用方法 profile := NewFluentServiceProfileBuilder(). WithId(\u0026#34;service1\u0026#34;). WithType(\u0026#34;order\u0026#34;). WithStatus(Normal). WithEndpoint(\u0026#34;192.168.0.1\u0026#34;, 8080). WithRegion(\u0026#34;region1\u0026#34;, \u0026#34;beijing\u0026#34;, \u0026#34;China\u0026#34;). WithPriority(1). WithLoad(100). Build() // 如果方法调用不按照预定的顺序，编译器就会报错 profile := NewFluentServiceProfileBuilder(). WithType(\u0026#34;order\u0026#34;). WithId(\u0026#34;service1\u0026#34;). WithStatus(Normal). WithEndpoint(\u0026#34;192.168.0.1\u0026#34;, 8080). WithRegion(\u0026#34;region1\u0026#34;, \u0026#34;beijing\u0026#34;, \u0026#34;China\u0026#34;). WithPriority(1). WithLoad(100). Build() // 上述代码片段把WithType和WithId的调用顺序调换了，编译器会报如下错误 // NewFluentServiceProfileBuilder().WithType undefined (type idBuilder has no field or method WithType) 典型应用场景 建造者模式主要应用在实例化复杂对象的场景，常见的有：\n 配置对象。比如创建 HTTP Server 时需要多个配置项，这种场景通过 Functional Options 模式就能够很优雅地实现配置功能。 SQL 语句对象。一些 ORM 框架在构造 SQL 语句时也经常会用到 Builder 模式。比如 xorm 框架中构建一个 SQL 对象是这样的：builder.Insert().Into(\u0026quot;table1\u0026quot;).Select().From(\u0026quot;table2\u0026quot;).ToBoundSQL() 复杂的 DTO 对象。 \u0026hellip;\u0026hellip;  优缺点 优点 1、将复杂的构建逻辑从业务逻辑中分离出来，遵循了单一职责原则。2、可以将复杂对象的构建过程拆分成多个步骤，提升了代码的可读性，并且可以控制属性构建的顺序。3、对于有多种构建方式的场景，可以将 Builder 设计为一个接口来提升可扩展性。4、Go 语言中，利用 Functional Options 模式可以更为简洁优雅地完成复杂对象的构建。\n缺点 1、传统的建造者模式需要新增一个 Builder 对象来完成对象的构造，Fluent API 模式下甚至还要额外增加多个 Fluent 接口，一定程度上让代码更加复杂了。\n与其他模式的关联 抽象工厂模式和建造者模式类似，两者都是用来构建复杂的对象，但前者的侧重点是构建对象/产品族，后者的侧重点是对象的分步构建过程。\n 参考 [1] 【Go实现】实践GoF的23种设计模式：SOLID原则, 元闰子\n[2] Design Patterns, Chapter 3. Creational Patterns, GoF\n[3] GO 编程模式：FUNCTIONAL OPTIONS, 酷壳 CoolShell\n[4] Fluent API: Practice and Theory, Ori Roth\n[5] XORM BUILDER, xorm\n[6] 生成器模式, refactoringguru.cn\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-05-05T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：建造者模式"},{"content":" 《从分层架构到微服务架构》是一系列介绍《Fundamentals of Software Architecture》中提到的8种架构模式的文章，这里不会事无巨细地介绍所有的细节，而是会挑选其中关键内容，更多详情请阅读原书。\n往期精彩：\n 从分层架构到微服务架构（一） 从分层架构到微服务架构（二）之分层架构 从分层架构到微服务架构（三）之管道架构 从分层架构到微服务架构（四）之微内核架构   前言 从本文开始，我们进入了《从分层架构到微服务架构》系列中分布式架构的介绍，本文要介绍的是服务化架构（Service-Based Architecture，SBA）。\nSBA 可以看成是单体架构和微服务架构之间的一个折中方案，它也是按照业务领域进行服务划分，但服务划分的粒度相比微服务要更粗。SBA 与微服务架构一大不同是，它允许各个服务间共享同一个数据库实例，这也使得 SBA 在架构上既有单体架构的特点，也有分布式架构的特点，显得更加的灵活。因此，从单体架构演进到 SBA，会比直接演进到微服务架构更加容易。\n架构视图 基础视图 SBA 的基础架构视图分成 3 部分：\n User Interface，作为系统的接入口，接收客户端的请求，并转发到业务服务。。 Domain Services，业务服务按照领域进行划分，分开部署、业务独立。 Database，服务间共享的数据库实例，因为数据库实例只有一个，所以可以支持 ACID 事务。  使用 SBA 的系统通常只会划分 4 ～ 12 个服务，避免产生过多的数据库连接。服务数量不多，也决定了 SBA 中的服务相比微服务架构中的服务有着更粗的粒度。User Interface 与服务间通过远程通信协议来完成业务往来，常见的通信方式有REST、RPC、消息队列等。需要注意的是，SBA 是不允许服务间通信的，这与微服务架构有着本质的区别。\n大多数情况下，SBA 中的服务只有一个或者少量实例，与微服务动辄成百上千个实例有着很大的区别。主要是因为 SBA 服务粒度更粗，无法做到像微服务那样精准的按需扩容，扩容太多反而会导致资源的浪费。\nSBA 的另一大特点是允许所有服务共享同一数据库实例，使得它能够直接将传统单体架构的那一套 SQL 查询逻辑、ACID 事务搬过来，让架构的演进更加的平滑。不过，共享数据也会带来一些问题，比如数据模型变更的影响范围更大，后面会在“**数据拆分”**一节详细讲述。\n拆分 User Interface 在大型系统中，单一的 User Interface 可能导致代码耦合、性能瓶颈等问题，这时候我们可以进一步对它进行拆分。拆分的方法可以是基于业务领域的拆分，业务相关的几个服务使用同一个 User Interface；或者基于服务的拆分，为每个服务都配备一个 User Interface。\n拆分 Database 类似地，我们也可以对数据库进行拆分，可以拆分成几个服务共享一个实例；也可以像微服务架构中那样，每个服务独享一个实例。数据库拆分的原则就是：确保数据是解耦的，不会被其他服务所依赖，避免出现跨库查询或服务间通信。\n增加 API 网关 我们也可以在 User Interface 和 Domain Services 之间增加一个 API 网关层，提供流控、鉴权、指标统计、服务发现等公共能力，进一步提升系统架构的安全性、可靠性、可维护性。\n业务服务的设计 SBA 中的服务具有较粗的粒度，因此在业务服务的架构设计上通常也会用到一些单体架构模式，常见的有分层架构和基于领域的组件化架构。\n不管是分层架构还是组件化架构，通常都需要增加一个 API 层，负责编排和转发来自 User Interface 的业务请求。下面以订单创建流程作为示例。\n假设现在有一个订单服务 OrderService，当它的 API 层接收到来自 User Interface 的订单创建请求时，API 层协调会各个组件依次完成如下的几个业务流程 ：\n 调用订单组件，完成订单ID、订单内容的生成。 调用支付组件，完成用户的扣款。 调用库存组件，更新商品的库存数量。  因为这些业务流程都是在同一个服务内完成，当其中的某个流程异常后，我们很容易通过数据库的 ACID 事务来完成回滚，从而能够确保数据的强一致性。\n相比在微服务架构之下，订单创建请求往往需要订单微服务、支付微服务、库存微服务之间协作来完成，这就涉及到分布式事务，也即 BASE（Basic Availability, Soft state, Eventual consistency） 事务。BASE 事务更加的复杂，而且无法保证数据的强一致性。当然，更粗的服务粒度也会带来服务可用性问题，比如在订单服务例子中，你会因为订单ID生成逻辑的变更而升级整个服务，也会因为库存组件中的一个BUG导致整个服务的故障。\n所以，服务粒度的粗与细，实际上也是数据一致性和服务可用性的一次 trade-off。\n数据拆分 服务间共享数据库使得系统具有更强的数据完整性和一致性，但简单的单库单表数据模型会带来耦合的问题。\n在单库单表的模型下，我们大概率会这么实现，将与数据库操作相关的实体对象、SQL 逻辑全部封装在一个共享的 shared lib 库上，供所有业务服务复用：\n这样的实现方式虽然简单，但是会带来“牵一发而动全身”的问题。假设某个服务所用到的某个字段类型需要变化，势必会修改表结构和 shared lib 库，而这两者是所有服务共用的，因此也就会导致所有服务都需要升级重新上线。这样的耦合会给 SRE 带来极大的困扰，一点也不敏捷。\n更好的方法是根据业务对数据进行拆分，将相对独立的数据拆分成多个表，每个表都有一个独立的 lib 库，对于公共表，则有一个 common lib 库，各服务按需依赖。对于 common lib 库的变更，我们还可以通过版本控制来尽量降低影响范围，但必须在 common lib 进行版本升级时保持向后兼容。\n架构评分 SBA 虽然是分布式架构，但是也保留了单体架构下的一些特点，在架构上具有较高的灵活性，也使得它在各方面的评分都比较高，没有明显的缺点。\nSBA 是一个 domain-partitioned 的架构，因此适合使用领域驱动设计来进行领域限界上下文的划分，进而规划出业务独立的服务。服务间业务独立，而且不会相互间通信，也就意味着具有更好的 Testability。\n前文有提到过，SBA 虽然支持服务实例扩容，但是更粗的服务粒度会导致扩容的性价比并不高，因此 Scalability 和 Elasticity 得分不高。\n Scalability 和 Elasticity的差异：\n Scalability 通常指软件系统在不中断业务的前提下，通过 scale-up 或 scale-out 等手段来应对更高业务负载，强调的是软件系统应对高负载的能力。 Elasticity 通常指硬件系统能够根据实际的业务负载情况，适时增加或减少硬件资源，强调的是硬件资源的高效利用。   总结 如果你打算从单体架构演进到分布式架构，SBA 会是一个不错的选择：\n 相比单体架构，SBA 按照业务进行服务拆分，在业务解耦、开发流程敏捷等方面有着明显的优势。 相比其他分布式架构，SBA 有着更粗的服务粒度，因此也得以减少了服务间的远程调用、网络带宽消耗，受网络故障的影响更小。 服务间共享数据库使得 SBA 支持 ACID 事务，在数据一致性方面具有良好的表现，但我们还是应该尽量按照业务进行分表，避免出现严重的数据耦合。 在架构评分上，SBA 各方面评分都不错，没有明显的缺点，是典型的“六边形战士”。   参考\n Fundamentals of Software Architecture (Chapter 13. Service-Based Architecture Style), Mark Richards, Neal Ford Service-Based Architecture as an Alternative to Microservice Architecture, Matt Fletcher What is the difference between scalability and elasticity?, stackoverflow   ","date":"2022-04-08T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%BA%94%E4%B9%8B%E6%9C%8D%E5%8A%A1%E5%8C%96%E6%9E%B6%E6%9E%84/","title":"从分层架构到微服务架构（五）之服务化架构"},{"content":" 上一篇：【Go实现】实践GoF的23种设计模式：SOLID原则\n简单的分布式应用系统（示例代码工程）：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 简述 GoF 对单例模式（Singleton）的定义如下：\n Ensure a class only has one instance, and provide a global point of access to it.\n 也即，保证一个类只有一个实例，并且为它提供一个全局访问点。\n在程序设计中，有些对象通常只需要一个共享的实例，比如线程池、全局缓存、对象池等。实现共享实例最简单直接的方式就是全局变量。但是，使用全局变量会带来一些问题，比如：\n 客户端程序可以创建同类实例，从而无法保证在整系统上只有一个共享实例。 难以控制对象的访问，比如想增加一个“访问次数统计”的功能就很难，可扩展性较低。 把实现细节暴露给客户端程序，加深了耦合，容易产生霰弹式修改。  对这种全局唯一的场景，更好的是使用单例模式去实现。单例模式能够限制客户端程序创建同类实例，并且可以在全局访问点上扩展或修改功能，而不影响客户端程序。\n但是，并非所有的全局唯一都适用单例模式。比如下面这种场景：\n 考虑需要统计一个API调用的情况，有两个指标，成功调用次数和失败调用次数。这两个指标都是全局唯一的，所以有人可能会将其建模成两个单例SuccessApiMetric和FailApiMetric。按照这个思路，随着指标数量的增多，你会发现代码里类的定义会越来越多，也越来越臃肿。这也是单例模式最常见的误用场景，更好的方法是将两个指标设计成一个对象ApiMetric下的两个实例ApiMetic success和ApiMetic fail。\n 那么，如何判断一个对象是否应该被建模成单例？通常，被建模成单例的对象都有“中心点”的含义，比如线程池就是管理所有线程的中心。所以，在判断一个对象是否适合单例模式时，先思考下，是一个中心点吗？\nUML结构 代码实现 根据单例模式的定义，实现的关键点有两个：\n 限制调用者直接实例化该对象； 为该对象的单例提供一个全局唯一的访问方法。  对于 C++ / Java 而言，只需把对象的构造函数设计成私有的，并提供一个 static 方法去访问该对象的唯一实例即可。但 Go 语言并没有构造函数的概念，也没有 static 方法，所以需要另寻出路。\n我们可以利用 Go 语言 package 的访问规则来实现，将单例对象设计成首字母小写，这样就能限定它的访问范围只在当前package下，模拟了 C++ / Java 的私有构造函数；然后，在当前 package 下实现一个首字母大写的访问函数，也就相当于 static 方法的作用了。\n示例 在简单的分布式应用系统（示例代码工程）中，我们定义了一个网络模块 network，模拟实现了网络报文转发功能。network 的设计也很简单，通过一个哈希表维持了 Endpoint 到 Socket 的映射，报文转发时，通过 Endpoint 寻址到 Socket，再调用 Socket 的 Receive 方法完成转发。\n因为整系统只需一个 network 对象，而且它在领域模型中具有中心点的语义，所以我们很自然地使用单例模式来实现它。单例模式大致可以分成两类，“饿汉模式”和“懒汉模式”。前者是在系统初始化期间就完成了单例对象的实例化；后者则是在调用时才进行延迟实例化，从而一定程度上节省了内存。\n“饿汉模式”实现 // demo/network/network.go package network // 1、设计为小写字母开头，表示只在network包内可见，限制客户端程序的实例化 type network struct { sockets sync.Mapvar instancevar instance } // 2、定义一个包内可见的实例对象，也即单例 var instance = \u0026amp;network{sockets: sync.Map{}} // 3、定义一个全局可见的唯一访问方法 func Instance() *network { return instance } func (n *network) Listen(endpoint Endpoint, socket Socket) error { if _, ok := n.sockets.Load(endpoint); ok { return ErrEndpointAlreadyListened } n.sockets.Store(endpoint, socket) return nil } func (n *network) Send(packet *Packet) error { record, rOk := n.sockets.Load(packet.Dest()) socket, sOk := record.(Socket) if !rOk || !sOk { return ErrConnectionRefuse } go socket.Receive(packet) return nil } 那么，客户端就可以通过 network.Instance() 引用该单例了：\n// demo/sidecar/flowctrl_sidecar.go package sidecar type FlowCtrlSidecar struct {...} // 通过 network.Instance() 直接引用单例 func (f *FlowCtrlSidecar) Listen(endpoint network.Endpoint) error { return network.Instance().Listen(endpoint, f) } ... “懒汉模式”实现 众所周知，“懒汉模式”会带来线程安全问题，可以通过普通加锁，或者更高效的双重检验加锁来优化。不管是哪种方法，都是为了保证单例只会被初始化一次。\ntype network struct {...} // 单例 var instance *network // 定义互斥锁 var mutex = sync.Mutex{} // 普通加锁，缺点是每次调用 Instance() 都需要加锁 func Instance() *network { mutex.Lock() if instance == nil { instance = \u0026amp;network{sockets: sync.Map{}} } mutex.Unlock() return instance } // 双重检验后加锁，实例化后无需加锁 func Instance() *network { if instance == nil { mutex.Lock() if instance == nil { instance = \u0026amp;network{sockets: sync.Map{}} } mutex.Unlock() } return instance } 对于“懒汉模式”，Go 语言还有一个更优雅的实现方式，那就是利用 sync.Once。它有一个 Do 方法，方法声明为 func (o *Once) Do(f func())，其中入参是 func() 的方法类型，Go 会保证该方法仅会被调用一次。利用这个特性，我们就能够实现单例只被初始化一次了。\ntype network struct {...} // 单例 var instance *network // 定义 once 对象 var once = sync.Once{} // 通过once对象确保instance只被初始化一次 func Instance() *network { once.Do(func() { // 只会被调用一次 \tinstance = \u0026amp;network{sockets: sync.Map{}} }) return instance } 扩展 提供多个实例 虽然单例模式从定义上表示每个对象只能有一个实例，但是我们不应该被该定义限制住，还得从模式本身的动机来去理解它。单例模式的一大动机是限制客户端程序对对象进行实例化，至于实例有多少个其实并不重要，根据具体场景来进行建模、设计即可。\n比如在前面的 network 模块中，现在新增一个这样的需求，将网络拆分为互联网和局域网。那么，我们可以这么设计：\ntype network struct {...} // 定义互联网单例 var inetInstance = \u0026amp;network{sockets: sync.Map{}} // 定义局域网单例 var lanInstance = \u0026amp;network{sockets: sync.Map{}} // 定义互联网全局可见的唯一访问方法 func Internet() *network { return inetInstance } // 定义局域网全局可见的唯一访问方法 func Lan() *network { return lanInstance } 虽然上述例子中，network 结构有两个实例，但是本质上还是单例模式，因为它做到了限制客户端实例化，以及为每个单例提供了全局唯一的访问方法。\n提供多种实现 单例模式也可以实现多态，如果你预测该单例未来可能会扩展，那么就可以将它设计成抽象的接口，让客户端依赖抽象，这样，未来扩展时就无需改动客户端程序了。\n比如，我们可以 network 设计为一个抽象接口：\n// network 抽象接口 type network interface { Listen(endpoint Endpoint, socket Socket) error Send(packet *Packet) error } // network 的实现1 type networkImpl1 struct { sockets sync.Map } func (n *networkImpl1) Listen(endpoint Endpoint, socket Socket) error {...} func (n *networkImpl1) Send(packet *Packet) error {...} // networkImpl1 实现的单例 var instance = \u0026amp;networkImpl1{sockets: sync.Map{}} // 定义全局可见的唯一访问方法，注意返回值时network抽象接口！ func Instance() network { return instance } // 客户端使用示例 func client() { packet := network.NewPacket(srcEndpoint, destEndpoint, payload) network.Instance().Send(packet) } 如果未来需要新增一种 networkImpl2 实现，那么我们只需修改 instance 的初始化逻辑即可，客户端程序无需改动：\n// 新增network 的实现2 type networkImpl2 struct {...} func (n *networkImpl2) Listen(endpoint Endpoint, socket Socket) error {...} func (n *networkImpl2) Send(packet *Packet) error {...} // 将单例 instance 修改为 networkImpl2 实现 var instance = \u0026amp;networkImpl2{...} // 单例全局访问方法无需改动 func Instance() network { return instance } // 客户端使用也无需改动 func client() { packet := network.NewPacket(srcEndpoint, destEndpoint, payload) network.Instance().Send(packet) } 有时候，我们还可能需要通过读取配置来决定使用哪种单例实现，那么，我们可以通过 map 来维护所有的实现，然后根据具体配置来选取对应的实现：\n// network 抽象接口 type network interface { Listen(endpoint Endpoint, socket Socket) error Send(packet *Packet) error } // network 具体实现 type networkImpl1 struct {...} type networkImpl2 struct {...} type networkImpl3 struct {...} type networkImpl4 struct {...} // 单例 map var instances = make(map[string]network) // 初始化所有的单例 func init() { instances[\u0026#34;impl1\u0026#34;] = \u0026amp;networkImpl1{...} instances[\u0026#34;impl2\u0026#34;] = \u0026amp;networkImpl2{...} instances[\u0026#34;impl3\u0026#34;] = \u0026amp;networkImpl3{...} instances[\u0026#34;impl4\u0026#34;] = \u0026amp;networkImpl4{...} } // 全局单例访问方法，通过读取配置决定使用哪种实现 func Instance() network { impl := readConf() instance, ok := instances[impl] if !ok { panic(\u0026#34;instance not found\u0026#34;) } return instance } 典型应用场景  日志。每个服务通常都会需要一个全局的日志对象来记录本服务产生的日志。 全局配置。对于一些全局的配置，可以通过定义一个单例来供客户端使用。 唯一序列号生成。唯一序列号生成必然要求整系统只能有一个生成实例，非常合适使用单例模式。 线程池、对象池、连接池等。xxx池的本质就是共享，也是单例模式的常见场景。 全局缓存 \u0026hellip;\u0026hellip;  优缺点 优点 在合适的场景，使用单例模式有如下的优点：\n 整系统只有一个或几个实例，有效节省了内存和对象创建的开销。 通过全局访问点，可以方便地扩展功能，比如新增加访问次数的统计。 对客户端隐藏实现细节，可避免霰弹式修改。  缺点 虽然单例模式相比全局变量有诸多的优点，但它本质上还是一个“全局变量”，还是避免不了全局变量的一些缺点：\n 函数调用的隐式耦合。通常我们都期望从函数的声明中就能知道该函数做了什么、依赖了什么、返回了什么。使用使用单例模式就意味着，无需通过函数传参，就能够在函数中使用该实例。也即将依赖/耦合隐式化了，不利于更好地理解代码。 对测试不友好。通常对一个方法/函数进行测试，我们并不需要知道它的具体实现。但如果方法/函数中有使用单例对象，我们就不得不考虑单例状态的变化了，也即需要考虑方法/函数的具体实现了。 并发问题。共享就意味着可能存在并发问题，我们不仅需要在初始化阶段考虑并发问题，在初始化后更是要时刻注意。因此，在高并发的场景，单例模式也可能存在锁冲突问题。  单例模式虽然简单易用，但也是最容易被滥用的设计模式。它并不是“银弹”，在实际使用时，还需根据具体的业务场景谨慎使用。\n与其他模式的关联 工厂方法模式、抽象工厂模式很多时候都会以单例模式来实现，因为工厂类通常是无状态的，而且全局只需一个实例即可，能够有效避免对象的频繁创建和销毁。\n","date":"2022-04-05T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","title":"【Go实现】实践GoF的23种设计模式：单例模式"},{"content":" 最近在喜马拉雅上听王德峰的中西思想必修课，听到有关中医的哲学思辨，深有感触。本文将结合网上的一些资料和自身的经历，开启一本正经地胡说八道模式。\n 前言 毫无疑问，当前的医疗体系主要是以现代医学，也即常说的西医，作为根基。我们平时去医院看病、体检，基本都是在西医的范畴之内。相比之下，中国传统医学，也即常说的中医，更多的是作为一种养生、调理的辅助手段，比如工作累了就去中医馆做做针灸、推拿等。\n在中医发源地的中国，却形成西医为主、中医为辅的局面，这其中的源头可以追溯到五四运动期间，我们从西方请来了“德先生”和“赛先生”，从此就奠定了我们不断学习西方的文化和技术的基调。在这个基调之下，我们普遍认为西方的文化和技术更先进。因此，当我们采用现代的科学手段去研究中医，却发现中医中的很多概念无法解释时，我们不免会发出这样的疑问：“中医科学吗？”。\n在回答这个问题之前，我们首先需要理解“科学”是什么。\n科学的哲学基础 维基百科中，对现代科学，也即常说的科学，有如下的定义：\n Science is a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe.\n 翻译过来就是，科学是一个系统性的知识体系，它构建并组织了关于解释和预测宇宙运作机制的知识，并强调了其中的可验证性。当然，科学也不等同于寻求绝对无误的真理，而是在现有基础上，摸索式地不断接近真理。\n哲学是科学之源，科学的前身就是古希腊的自然哲学，从前面对科学的解释中，我们也大概能看出柏拉图的理念论的影子。\n不管是古希腊的哲学，还是现代西方哲学，它们的内核都是一样的，那就是知识。西方哲学的主题是知识问题的解决，而如何解决则取决于对世间万物本质的理性的把握，以及概念的确认。所以，我们会看到西方的学者们对浩渺星空的好奇和惊异、宇宙本质问题的痴迷和热情、对思想穷根究底的辩驳和拷问、对逻辑与理性的推崇和赞赏。这些正是现代科学的精神内核。\n在西方的哲学看来，宇宙是由实体构成的，西方的学者会不断寻求该实体的基本单位，“生物-\u0026gt;细胞-\u0026gt;分子-\u0026gt;原子-\u0026gt;质子-\u0026gt;...”就是一个不断寻求的过程。所以西医认为疾病就是实体性的病变，比如流行性感冒就是因为人体感染了流感病毒，这些都是可以通过医学手段检验出来的，满足科学的可验证性。\n中医的哲学基础 中医的哲学基础自然是中国哲学，而中国哲学是与西方哲学截然不同的一套哲学体系。\n在中国哲学看来，宇宙的本质是气，气的变化就是宇宙的真相。相反，西方哲学是将宇宙看成由统一不变的实体所构成，这是中西方哲学的一大差异。气有“阴”和“阳”两个方面，有“金”、“木”、“水”、“火”、“土”五种类型，也即常说的阴阳五行。阴阳五行相生相克，它们之间的转换构成了整个宇宙，这就是中国哲学的宇宙观。\n中国哲学的内核是人生，主题是人生问题的解决，而人生问题的解决基本上取决于我们对天道的体认和觉解。所以，中国哲学的思辨是依靠“感性”，这与西方哲学的“理性”思辨的是两种不同的思辨路径。\n中国哲学强调“天人合一”，自然也会将阴阳五行这套宇宙观映射到我们人体身上，也就形成了中医的理论基础。中医将人的五脏六腑都看成是金木水火土之气，它们彼此之间的相互作用（相生相克）构成了人体。所以，中医认为疾病就是人体内阴阳五行之气的平衡被打破所导致的，治病就是重建人体之气的平衡，也即常说的调理。\n所以中医的精神是调理，西医的精神是解剖、分析和手术。\n中医科学吗？ 再回到“中医科学吗？”这个问题上，根据前文的内容，我们可以发现这个问题本身就是个伪问题的。因为这相当于在拿西方哲学的标准去衡量中国哲学，得到的答案自然是否定的，它们本身就是截然不同的哲学体系。\n下面可以列举一些中医不科学的例子：\n 中医的很多概念，比如气、经脉，是无法通过科学的手段进行检验的，也即在最基本的可验证性上就不成立了。 中医讲求“以形补形”，认为某种植物或动物的真正医药价值，在于它的形状、颜色、质地、名称等与人体器官或疾病是否具有对应性。如果具有对应性，则意味着这个植物或动物对那 个器官或疾病有疗效。这些在现代的生物医学看来同样也是不成立的。 中医古典中的一些偏方在现代科学看来完全就是无稽之谈，比如《本草纲目》有提到鱼骨鲠喉，把渔网煮成汁或烧成灰喝了，就能让鱼骨掉下。  既然中医不科学，那么中医有效吗？\n中医有效吗？ 从个体的角度看，中医是有效的。现在已经有足够多的例子说明在某些病例上，中医能够达到比西医更好的效果。国家在大力推进中医的现代化建设、世界卫生组织把中医药纳入国际医药体系，这些都侧面说明了中医的有效性。另外，一些中医药的成分也得到了科学的验证，最著名的就是屠呦呦发现青蒿素的例子。\n但从整体的角度看，特别是在西方统计学的视角下，中医的有效性是被质疑的。最有力的证据就是中国和欧洲平均寿命的对比：\n从表中可以看出，在现代医学传入中国之前中国人的平均寿命并不高于其他民族， 在古代和近代都只有三十岁左右，现代中国人平均寿命大幅度提高到七十多岁基本上是得益于现代医学。\n但是，就像前文所介绍，中医和科学起源于两套完全不同的哲学体系，用科学的手段衡量中医，注定得不到圆满。国医大师陆广莘也曾表示：\n “中医是个性化的，其治疗是因人而异的，总结和归纳是不符合中医特色的，医生面对的是动态的生命，而不是物，这与西方医学有着本质的区别。”\n 最后 我对中医感到震撼的一次经历是，高中时某次出现莫名其妙的头晕，然后去找一位老中医进行诊断，一坐下就开始把脉，几分钟过后就诊断出问题在头部。这是和西医完全不同的诊断方式，相反在西医的诊断手段下，我的身体并没有任何的问题。\n中医的哲学基础就注定它是一种“感性”的诊断和治疗方式，感性就意味着无法量化，而是依赖长时间的诊断经验来进行领悟。所以，中医的培养方式适合中国传统的师徒相授模式，而不是西方的高等教育批量培养模式。\n中国哲学和西方哲学都是看待宇宙的方式，并没有对错之分。只是目前来看，西方的科学宇宙观是更成功的一方，但也不能将它视为真理。我们还是要辩证地看待中医和中国哲学，而不是以现代科学的标准来评判它的对错。\n最后，我们应该做的是用科学的方法充实自己，但不应该用科学的标准来限制自己。\n 参考\n 王德峰的中西思想必修课，王德峰 科学的定义，维基百科 进一步深刻认识科学与哲学的关系，白春礼 论中医在现代医疗体系中的角色，Joshua Lotz, B.S. A critical examination of the main premises of Traditional Chinese Medicine，Michael Eigenschink 中医不属于物质科学的范畴，中国科学院 《本草纲目》中的偏方是怎么来的，方舟子   ","date":"2022-04-04T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8E%E5%93%B2%E5%AD%A6%E7%9A%84%E8%A7%92%E5%BA%A6%E7%9C%8B%E4%B8%AD%E5%8C%BB/","title":"从哲学的角度看中医"},{"content":" 之前也有写过关于设计模式的文章《使用Go实现GoF的23种设计模式》，但是那个系列写了3篇文章就没再继续了，主要的原因是找不到合适的示例代码。考虑到，如果以类似于“鸭子是否会飞”、“烘焙的制作流程”等贴近生活的事情举例，很难在我们日常的开发中产生联系。（目前应该很少有这些逻辑的软件系统吧）\n《实践GoF的23种设计模式》可以看成是《使用Go实现GoF的23种设计模式》系列的重启，吸取了上次烂尾的教训，本次在写文章之前就已经完成了23种设计模式的示例代码实现。示例代码以我们日常开发中经常碰到的一些技术/问题/场景作为切入点，示范如何运用设计模式来完成相关的实现。\n 前言 从1995年GoF提出23种设计模式到现在，25年过去了，设计模式依旧是软件领域的热门话题。设计模式通常被定义为：\n 设计模式（Design Pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人理解并且保证代码可靠性。\n 从定义上看，设计模式其实是一种经验的总结，是针对特定问题的简洁而优雅的解决方案。既然是经验总结，那么学习设计模式最直接的好处就在于可以站在巨人的肩膀上解决软件开发过程中的一些特定问题。\n学习设计模式的最高境界是吃透它们本质思想，可以做到即使已经忘掉某个设计模式的名称和结构，也能在解决特定问题时信手拈来。设计模式背后的本质思想，就是我们熟知的SOLID原则。如果把设计模式类比为武侠世界里的武功招式，那么SOLID原则就是内功内力。通常来说，先把内功练好，再来学习招式，会达到事半功倍的效果。因此，在介绍设计模式之前，很有必要先介绍一下SOLID原则。\n本文首先会介绍本系列文章中用到的示例代码demo的整体结构，然后开始逐一介绍SOLID原则，也即单一职责原则、开闭原则、里氏替换原则、接口隔离原则和依赖倒置原则。\n一个简单的分布式应用系统  本系列示例代码demo获取地址：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Go-Implementation\n 示例代码demo工程实现了一个简单的分布式应用系统（单机版），该系统主要由以下几个模块组成：\n 网络 Network，网络功能模块，模拟实现了报文转发、socket通信、http通信等功能。 数据库 Db，数据库功能模块，模拟实现了表、事务、dsl等功能。 消息队列 Mq，消息队列模块，模拟实现了基于topic的生产者/消费者的消息队列。 监控系统 Monitor，监控系统模块，模拟实现了服务日志的收集、分析、存储等功能。 边车 Sidecar，边车模块，模拟对网络报文进行拦截，实现access log上报、消息流控等功能。 服务 Service，运行服务，当前模拟实现了服务注册中心、在线商城服务集群、服务消息中介等服务。  示例代码demo工程的主要目录结构如下：\n├── db # 数据库模块，定义Db、Table、TableVisitor等抽象接口和实现 ├── monitor # 监控系统模块，采用插件式的架构风格，当前实现access log日志etl功能 │ ├── config # 监控系统插件配置模块 │ ├── filter # 过滤插件的实现定义 │ ├── input # 输入插件的实现定义 │ ├── output # 输出插件的实现定义 │ ├── pipeline # Pipeline插件的实现定义，一个pipeline表示一个ETL处理流程 │ ├── plugin # 插件抽象接口的定义，比如Plugin、Config等 │ └── model # 监控系统模型对象定义 ├── mq # 消息队列模块 ├── network # 网络模块，模拟网络通信，定义了socket、packet等通用类型/接口  │ └── http # 模拟实现了http通信等服务端、客户端能力 ├── service # 服务模块，定义了服务的基本接口 │ ├── mediator # 服务消息中介，作为服务通信的中转方，实现了服务发现，消息转发的能力 │ ├── registry # 服务注册中心，提供服务注册、去注册、更新、 发现、订阅、去订阅、通知等功能 │ │ └── model # 服务注册/发现相关的模型定义 │ └── shopping # 模拟在线商城服务群的定义，包含订单服务、库存服务、支付服务、发货服务 └── sidecar # 边车模块，对socket进行拦截，提供http access log、流控功能 └── flowctrl # 流控模块，基于消息速率进行随机流控 SRP：单一职责原则 单一职责原则（The Single Responsibility Principle，SRP）应该是SOLID原则中，最容易被理解的一个，但同时也是最容易被误解的一个。很多人会把“将大函数重构成一个个职责单一的小函数”这一重构手法等价为SRP，这是不对的，小函数固然体现了职责单一，但这并不是SRP。\nSRP传播最广的定义应该是Uncle Bob给出的：\n A module should have one, and only one, reason to change.\n 也即，一个模块应该有且只有一个导致其变化的原因。\n这个解释里有2个需要理解的地方：\n（1）如何定义一个模块\n我们通常会把一个源文件定义为最小粒度的模块。\n（2）如何找到这个原因\n一个软件的变化往往是为了满足某个用户的需求，那么这个用户就是导致变化的原因。但是，一个模块的用户/客户端程序往往不只一个，比如Java中的ArrayList类，它可能会被成千上万的程序使用，但我们不能说ArrayList职责不单一。因此，我们应该把“一个用户”改为“一类角色”，比如ArrayList的客户端程序都可以归类为“需要链表/数组功能”的角色。\n于是，Uncle Bob给出了SRP的另一个解释：\n A module should be responsible to one, and only one, actor.\n 有了这个解释，我们就可以理解函数职责单一并不等同于SRP，比如在一个模块有A和B两个函数，它们都是职责单一的，但是函数A的使用者是A类用户，函数B的使用者是B类用户，而且A类用户和B类用户变化的原因都是不一样的，那么这个模块就不满足SRP了。\n下面，以我们的分布式应用系统demo为例进一步探讨。对于Registry类（服务注册中心）来说，它对外提供的基本能力有服务注册、更新、去注册和发现功能，那么，我们可以这么实现：\n// Registry 服务注册中心 type Registry struct { db db.Db server *http.Server localIp string } func (r *Registry) register(req *http.Request) *http.Response {...} func (r *Registry) deregister(req *http.Request) *http.Response {...} func (r *Registry) update(req *http.Request) *http.Response {...} func (r *Registry) discovery(req *http.Request) *http.Response {...} ... 上述实现中，Registry包含了register、update、deregister、discovery等4个主要方法，正好对应了Registry对外提供的能力，看起来已经是职责单一了。\n但是在仔细思考一下就会发现，服务注册、更新和去注册是给专门给服务提供者使用的功能，而服务发现则是专门给服务消费者使用的功能。服务提供者和服务消费者是两类不同的角色，它们产生变化的时间和方向都可能不同。比如：\n 当前服务发现功能是这么实现的：Registry从满足查询条件的所有ServiceProfile中挑选一个返回给服务消费者（也即Registry自己做了负载均衡）。\n假设现在服务消费者提出新的需求：Registry把所有满足查询条件的ServiceProfile都返回，由服务消费者自己来做负载均衡。\n为了实现这样的功能，我们就要修改Registry的代码。按理，服务注册、更新、去注册等功能并不应该受到影响，但因为它们和服务发现功能都在同一个模块（Registry）里，于是被迫也受到影响了，比如可能会代码冲突。\n 因此，更好的设计是将register、update、deregister内聚到一个服务管理模块SvcManagement，discovery则放到另一个服务发现模块SvcDiscovery，服务注册中心Registry再组合svcManagement和svcDiscovery。\n具体实现如下：\n// demo/service/registry/svc_management.go type svcManagement struct { db db.Db ... } func (s *svcManagement) register(req *http.Request) *http.Response {...} func (s *svcManagement) deregister(req *http.Request) *http.Response {...} func (s *svcManagement) update(req *http.Request) *http.Response {...} // demo/service/registry/svc_discovery.go type svcDiscovery struct { db db.Db } func (s *svcDiscovery) discovery(req *http.Request) *http.Response {...} // demo/service/registry/registry.go type Registry struct { db db.Db server *http.Server localIp string svcManagement *svcManagement // 组合svcManagement \tsvcDiscovery *svcDiscovery // 组合svcDiscovery } func (r *Registry) Run() error { ... // 调用svcManagement和svcDiscovery完成服务 \treturn r.server.Put(\u0026#34;/api/v1/service-profile\u0026#34;, r.svcManagement.register). Post(\u0026#34;/api/v1/service-profile\u0026#34;, r.svcManagement.update). Delete(\u0026#34;/api/v1/service-profile\u0026#34;, r.svcManagement.deregister). Get(\u0026#34;/api/v1/service-profile\u0026#34;, r.svcDiscovery.discovery). Put(\u0026#34;/api/v1/subscription\u0026#34;, r.svcManagement.subscribe). Delete(\u0026#34;/api/v1/subscription\u0026#34;, r.svcManagement.unsubscribe). Start() } 除了重复的代码编译，违反SRP还会带来以下2个常见的问题：\n1、代码冲突。程序员A修改了模块的A功能，而程序员B在不知情的情况下也在修改该模块的B功能（因为A功能和B功能面向不同的用户，完全可能由2位不同的程序员来维护），当他们同时提交修改时，代码冲突就会发生（修改了同一个源文件）。\n2、A功能的修改影响了B功能。如果A功能和B功能都使用了模块里的一个公共函数C，现在A功能有新的需求需要修改函数C，那么如果修改人没有考虑到B功能，那么B功能的原有逻辑就会受到影响。\n由此可见，违反SRP会导致软件的可维护性变得极差。但是，我们也不能盲目地进行模块拆分，这样会导致代码过于碎片化，同样也会提升软件的复杂性。比如，在前面的例子中，我们就没有必要再对服务管理模块进行拆分为服务注册模块、服务更新模块和服务去注册模块，一是因为它们面向的用户是一致的；二是在可预见的未来它们要么同时变化，要么都不变。\n因此，我们可以得出这样的结论：\n 如果一个模块面向的都是同一类用户（变化原因一致），那么就没必要进行拆分。 如果缺乏用户归类的判断，那么最好的拆分时机是变化发生时。  SRP是聚合和拆分的一个平衡，太过聚合会导致牵一发动全身，拆分过细又会提升复杂性。要从用户的视角来把握拆分的度，把面向不同用户的功能拆分开。如果实在无法判断/预测，那就等变化发生时再拆分，避免过度的设计。\nOCP：开闭原则 开闭原则（The Open-Close Principle，OCP）中，“开”指的是对扩展开放，“闭”指的是对修改封闭，它的完整解释为：\n A software artifact should be open for extension but closed for modification.\n 通俗地讲就是，一个软件系统应该具备良好的可扩展性，新增功能应当通过扩展的方式实现，而不是在已有的代码基础上修改。\n然而，从字面意思上看，OCP貌似又是自相矛盾的：想要给一个模块新增功能，但是又不能修改它。\n*如何才能打破这个困境呢？*关键是抽象！优秀的软件系统总是建立在良好的抽象的基础上，抽象化可以降低软件系统的复杂性。\n*那么什么是抽象呢？*抽象不仅存在于软件领域，在我们的生活中也随处可见。下面以《语言学的邀请》中的一个例子来解释抽象的含义：\n 假设某农庄有一头叫“阿花”的母牛，那么：\n1、当把它称为“阿花”时，我们看到的是它独一无二的一些特征：身上有很多斑点花纹、额头上还有一个闪电形状的伤疤。\n2、当把它称为母牛时，我们忽略了它的独有特征，看到的是它与母牛“阿黑”，母牛“阿黄”的共同点：是一头牛、雌性的。\n3、当把它称为家畜时，我们又忽略了它作为母牛的特征，而是看到了它和猪、鸡、羊一样的特点：是一个动物，在农庄里圈养。\n4、当把它称为农庄财产时，我们只关注了它和农庄上其他可售对象的共同点：可以卖钱、转让。\n从“阿花”，到母牛，到家畜，再到农庄财产，这就是一个不断抽象化的过程。\n 从上述例子中，我们可以得出这样的结论：\n 抽象就是不断忽略细节，找到事物间共同点的过程。 抽象是分层的，抽象层次越高，细节也就越少。  再回到软件领域，我们也可以把上述的例子类比到数据库上，数据库的抽象层次从低至高可以是这样的：MySQL 8.0版本 -\u0026gt; MySQL -\u0026gt; 关系型数据库 -\u0026gt; 数据库。现在假设有一个需求，需要业务模块将业务数据保存到数据库上，那么就有以下几种设计方案：\n 方案一：把业务模块设计为直接依赖MySQL 8.0版本。因为版本总是经常变化的，如果哪天MySQL升级了版本，那么我们就得修改业务模块进行适配，所以方案一违反了OCP。 方案二：把业务模块设计为依赖MySQL。相比于方案一，方案二消除了MySQL版本升级带来的影响。现在考虑另一种场景，如果因为某些原因公司禁止使用MySQL，必须切换到PostgreSQL，这时我们还是得修改业务模块进行数据库的切换适配。因此，在这种场景下，方案二也违反了OCP。 方案三：把业务模块设计为依赖关系型数据库。到了这个方案，我们基本消除了关系型数据库切换的影响，可以随时在MySQL、PostgreSQL、Oracle等关系型数据库上进行切换，而无须修改业务模块。但是，熟悉业务的你预测未来随着用户量的迅速上涨，关系型数据库很有可能无法满足高并发写的业务场景，于是就有了下面的最终方案。 方案四：把业务模块设计为依赖数据库。这样，不管以后使用MySQL还是PostgreSQL，关系型数据库还是非关系型数据库，业务模块都不需要再改动。到这里，我们基本可以认为业务模块是稳定的，不会受到底层数据库变化带来的影响，满足了OCP。  我们可以发现，上述方案的演进过程，就是我们不断对业务依赖的数据库模块进行抽象的过程，最终设计出稳定的、服务OCP的软件。\n那么，在编程语言中，我们用什么来表示“数据库”这一抽象呢？是接口！\n数据库最常见的几个操作就是CRUD，因此我们可以设计这么一个Db接口来表示“数据库”：\ntype Db interface { Query(tableName string, cond Condition) (*Record, error) Insert(tableName string, record *Record) error Update(tableName string, record *Record) error Delete(tableName string, record *Record) error } 这样，业务模块和数据库模块之间的依赖关系就变成如下图所示：\n满足OCP的另一个关键点就是分离变化，只有先把变化点识别分离出来，我们才能对它进行抽象化。下面以我们的分布式应用系统demo为例，解释如何实现变化点的分离和抽象。\n在demo中，监控系统主要负责对服务的access log进行ETL操作，也即涉及如下3个操作：1）从消息队列中获取日志数据；2）对数据进行加工；3）将加工后的数据存储在数据库上。\n我们把整一个日志数据的处理流程称为pipeline，那么我们可以这么实现：\ntype Pipeline struct { mq Mq db Db ... } func (p *Pipeline) Run() { for atomic.LoadUint32(\u0026amp;p.isClose) != 1 { // 1、从消息队列中获取数据  msg := p.mq.Consume(\u0026#34;monitor.topic\u0026#34;) log := msg.Payload() // 2、对数据进行字段提取操作  matches := p.pattern.FindStringSubmatch(log) if len(matches) != 3 { return event } record := model.NewMonitoryRecord() record.Endpoint = matches[1] record.Type = model.Type(matches[2]) // 3.存储到数据库上  p.db.Insert(\u0026#34;logs_table\u0026#34;, record.Id, record) ... } } 现在考虑新上线一个服务，但是这个服务不支持对接消息队列了，只支持socket传输数据，于是我们得在Pipeline上新增一个InputType来判断是否使用socket输入源：\nfunc (p *Pipeline) Run() { for atomic.LoadUint32(\u0026amp;p.isClose) != 1 { if inputType == input.MqType { // 从消息队列中获取数据  msg := p.mq.Consume(\u0026#34;monitor.topic\u0026#34;) log := msg.Payload() } else { // 使用socket为消息来源  packet := socket.Receice() log := packet.PayLoad().(string) } ... } } 过一段时间，有需求需要给access log打上一个时间戳，方便后续的日志分析，于是我们需要修改Pipeline的数据加工逻辑：\nfunc (p *Pipeline) Run() { for atomic.LoadUint32(\u0026amp;p.isClose) != 1 { ... // 对数据进行字段提取操作  matches := p.pattern.FindStringSubmatch(log) if len(matches) != 3 { return event } record := model.NewMonitoryRecord() record.Endpoint = matches[1] record.Type = model.Type(matches[2]) // 新增一个时间戳字段  record.Timestamp = time.Now().Unix() ... } } 很快，又有一个需求，需要将加工后的数据存储到ES上，方便后续的日志检索，于是我们再次修改了Pipeline的数据存储逻辑：\nfunc (p *Pipeline) Run() { for atomic.LoadUint32(\u0026amp;p.isClose) != 1 { ... if outputType == output.Db { // 存储到ES上  p.db.Insert(\u0026#34;logs_table\u0026#34;, record.Id, record) } else { // 存储到ES上  p.es.Store(record.Id, record) } ... } } 在上述的pipeline例子中，每次新增需求都需要修改Pipeline模块，明显违反了OCP。下面，我们来对它进行优化，使它满足OCP。\n第一步是分离变化点，根据pipeline的业务处理逻辑，我们可以发现3个独立的变化点，数据的获取、加工和存储。第二步，我们对这3个变化点进行抽象，设计出以下3个抽象接口：\n// demo/monitor/input/input_plugin.go // 数据获取抽象接口 type InputPlugin interface { plugin.Plugin Input() (*plugin.Event, error) } // demo/monitor/filter/filter_plugin.go // 数据加工抽象接口 type FilterPlugin interface { plugin.Plugin Filter(event *plugin.Event) *plugin.Event } // demo/monitor/output/output_plugin.go // 数据存储抽象接口 type OutputPlugin interface { plugin.Plugin Output(event *plugin.Event) error } 最后，Pipeline的实现如下，只依赖于InputPlugin、FilterPlugin和OutputPlugin三个抽象接口。后续再有需求变更，只需扩展对应的接口即可，Pipeline无须再变更：\n// demo/monitor/pipeline/pipeline_plugin.go // ETL流程定义 type pipelineTemplate struct { input input.Plugin filter filter.Plugin output output.Plugin ... } func (p *pipelineTemplate) doRun() { ... for atomic.LoadUint32(\u0026amp;p.isClose) != 1 { event, err := p.input.Input() event = p.filter.Filter(event) p.output.Output(event) } ... } OCP是软件设计的终极目标，我们都希望能设计出可以新增功能却不用动老代码的软件。但是100%的对修改封闭肯定是做不到的，另外，遵循OCP的代价也是巨大的。它需要软件设计人员能够根据具体的业务场景识别出那些最有可能变化的点，然后分离出去，抽象成稳定的接口。这要求设计人员必须具备丰富的实战经验，以及非常熟悉该领域的业务场景。否则，盲目地分离变化点、过度地抽象，都会导致软件系统变得更加复杂。\nLSP：里氏替换原则 上一节介绍中，OCP的一个关键点就是抽象，而如何判断一个抽象是否合理，这是里氏替换原则（The Liskov Substitution Principle，LSP）需要回答的问题。\nLSP的最初定义如下：\n If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.\n 简单地讲就是，子类型必须能够替换掉它们的基类型，也即基类中的所有性质，在子类中仍能成立。一个简单的例子：假设有一个函数f，它的入参类型是基类B。同时，基类B有一个派生类D，如果把D的实例传递给函数f，那么函数f的行为功能应该是不变的。\n由此可以看出，违反LSP的后果很严重，会导致程序出现不在预期之内的行为错误。最典型的就是正方形继承自长方形的例子。\n 长方形和正方形例子的详细介绍，请参考【Java实现】实践GoF的23种设计模式：SOLID原则 中的“LSP：里氏替换原则”一节\n 出现违反LSP的设计，主要原因还是我们孤立地进行模型设计，没有从客户端程序的角度来审视该设计是否正确。我们孤立地认为在数学上成立的关系（正方形 IS-A 矩形），在程序中也一定成立，而忽略了客户端程序的使用方法。\n该例子告诉我们：一个模型的正确性或有效性，只能通过客户端程序来体现。\n下面，我们总结一下在继承体系（IS-A）下，要想设计出符合LSP的模型所需要遵循的一些约束：\n 基类应该设计为一个抽象类（不能直接实例化，只能被继承）。 子类应该实现基类的抽象接口，而不是重写基类已经实现的具体方法。 子类可以新增功能，但不能改变基类的功能。 子类不能新增约束，包括抛出基类没有声明的异常。  前面的矩形和正方形的例子中，几乎把这些约束都打破了，从而导致了程序的异常行为：1）Square的基类Rectangle不是一个抽象类，打破约束1；2）Square重写了基类的setWidth和setLength方法，打破约束2；3）Square新增了Rectangle没有的约束，长宽相等，打破约束4。\n除了继承之外，另一个实现抽象的机制是接口。如果我们是面向接口的设计，那么上述的约束1～3其实已经满足了：1）接口本身不具备实例化能力，满足约束1；2）接口没有具体的实现方法（Java中接口的default方法比较例外，本文先不考虑），也就不会被重写，满足约束2；3）接口本身只定义了行为契约，并没有实际的功能，因此也不会被改变，满足约束3。\n因此，使用接口替代继承来实现多态和抽象，能够减少很多不经意的错误。但是面向接口设计仍然需要遵循约束4，下面我们以分布式应用系统demo为例，介绍一个比较隐晦地打破约束4，从而违反了LSP的实现。\n还是以监控系统为例，为例实现ETL流程的灵活配置，我们需要通过配置文件定义pipeline的流程功能（数据从哪获取、需要经过哪些加工、加工后存储到哪里）。当前需要支持json和yaml两种配置文件格式，以yaml配置为例，配置内容是这样的：\n# src/main/resources/pipelines/pipeline_0.yamlname:pipeline_0# pipeline名称type:single_thread# pipeline类型input:# input插件定义（数据从哪里来）name:input_0# input插件名称type:memory_mq# input插件类型context:# input插件的初始化上下文topic:access_log.topicfilter:# filter插件定义（需要经过哪些加工）- name:filter_0# 加工流程filter_0定义，类型为log_to_jsontype:log_to_json- name:filter_1# 加工流程filter_1定义，类型为add_timestamptype:add_timestamp- name:filter_2# 加工流程filter_2定义，类型为json_to_monitor_eventtype:json_to_monitor_eventoutput:# output插件定义（加工后存储到哪里）name:output_0# output插件名称type:memory_db# output插件类型context:# output插件的初始化上下文tableName:monitor_event_0首先我们定义一个Config接口来表示“配置”这一抽象:\n// demo/monitor/plugin/plugin.go packet plugin // Config 插件配置抽象接口 type Config interface { Load(conf string) error } 另外，上述配置中的input、filter、output子项，可以认为是input.Plugin、filter.Plugin、output.Plugin插件的配置项，由Pipeline插件的配置项组合在一起，因此我们定义了如下几个Config的实现类：\n// demo/monitor/config/config.go package config type item struct { Name string `json:\u0026#34;name\u0026#34; yaml:\u0026#34;name\u0026#34;` PluginType string `json:\u0026#34;type\u0026#34; yaml:\u0026#34;type\u0026#34;` Ctx plugin.Context `json:\u0026#34;context\u0026#34; yaml:\u0026#34;context\u0026#34;` loadConf func(conf string, item interface{}) error // 区分yaml和json的加载方式 } // 输入插件配置 type Input item func (i *Input) Load(conf string) error { return i.loadConf(conf, i) } // 过滤插件配置 type Filter item func (f *Filter) Load(conf string) error { return f.loadConf(conf, f) } // 输出插件配置 type Output item func (o *Output) Load(conf string) error { return o.loadConf(conf, o) } // Pipeline插件配置 type Pipeline struct { item `yaml:\u0026#34;,inline\u0026#34;` // yaml嵌套时需要加上,inline \tInput Input `json:\u0026#34;input\u0026#34; yaml:\u0026#34;input\u0026#34;` Filters []Filter `json:\u0026#34;filters\u0026#34; yaml:\u0026#34;filters,flow\u0026#34;` Output Output `json:\u0026#34;output\u0026#34; yaml:\u0026#34;output\u0026#34;` } func (p *Pipeline) Load(conf string) error { return p.loadConf(conf, p) } 因为涉及到从配置到对象的实例化过程，自然会想到使用工厂方法模式来创建对象。另外因为pipeline.Pipeline、input.Plugin、filter.Plugin和output.Plugin都实现了Plugin接口，我们也很容易想到定义一个PluginFactory接口来表示“插件工厂”这一抽象，具体的插件工厂再实现该接口：\n// 插件工厂接口，根据配置实例化插件 type PluginFactory interface { Create(config plugin.Config) plugin.Plugin } // input插件工厂 type InputPluginFactory struct {} func (i *InputPluginFactory) Create(config plugin.Config) plugin.Plugin { conf := config.(*config.Input) ... // input插件实例化过程 } // filter插件工厂 type FilterPluginFactory struct {} func (f *FilterPluginFactory) Create(config plugin.Config) plugin.Plugin { conf := config.(*config.Filter) ... // filter插件实例化过程 } // output插件工厂 type OutputPluginFactory struct {} func (o *OutputPluginFactory) Create(config plugin.Config) plugin.Plugin { conf := config.(*config.Output) ... // output插件实例化过程 } // pipeline插件工厂 type PipelinePluginFactory struct {} func (p *PipelinePluginFactory) Create(config plugin.Config) plugin.Plugin { conf := config.(*config.Pipeline) ... // pipeline插件实例化过程 } 最后，通过PipelineFactory来创建Pipline对象：\nconf := \u0026amp;config.Pipeline{...} pipeline := NewPipelinePluginFactory().Create(conf) ... 到目前为止，上述的设计看起来是合理的，运行也没有问题。\n但是，细心的读者可能会发现，每个插件工厂子类的Create方法的第一行代码都是一个转型语句，比如PipelineFactory的是conf := config.(*config.Pipeline)。所以，上一段代码能够正常运行的前提是：传入PipelineFactory.Create方法的入参必须是*config.Pipeline 。如果客户端程序传入*config.Input的实例，PipelineFactory.Create方法将会抛出转型失败的异常。\n上述这个例子就是一个违反LSP的典型场景，虽然在约定好的前提下，程序可以运行正确，但是如果有客户端不小心破坏了这个约定，就会带来程序行为异常（我们永远无法预知客户端的所有行为）。\n要纠正这个问题也很简单，就是去掉PluginFactory这一层抽象，让PipelineFactory.Create等工厂方法的入参声明为具体的配置类，比如PipelineFactory可以这么实现：\n// pipeline插件工厂 type PipelinePluginFactory struct {} func (p *PipelinePluginFactory) Create(config *config.Pipeline) plugin.Plugin { ... // pipeline插件实例化过程 } 从上述几个例子中，我们可以看出遵循LSP的重要性，而设计出符合LSP的软件的要点就是，根据该软件的使用者行为作出的合理假设，以此来审视它是否具备有效性和正确性。\nISP：接口隔离原则 接口隔离原则（The Interface Segregation Principle，ISP）是关于接口设计的一项原则，这里的“接口”并不单指Java或Go上使用interface声明的狭义接口，而是包含了狭义接口、抽象类、具象类等在内的广义接口。它的定义如下：\n Client should not be forced to depend on methods it does not use.\n 也即，一个模块不应该强迫客户程序依赖它们不想使用的接口，模块间的关系应该建立在最小的接口集上。\n下面，我们通过一个例子来详细介绍ISP。\n上图中，Client1、Client2、Client3都依赖了Class1，但实际上，Client1只需使用Class1.func1方法，Client2只需使用Class1.func2，Client3只需使用Class1.func3，那么这时候我们就可以说该设计违反了ISP。\n违反ISP主要会带来如下2个问题：\n 增加模块与客户端程序的依赖，比如在上述例子中，虽然Client2和Client3都没有调用func1，但是当Class1修改func1还是必须通知Client1～3，因为Class1并不知道它们是否使用了func1。 产生接口污染，假设开发Client1的程序员，在写代码时不小心把func1打成了func2，那么就会带来Client1的行为异常。也即Client1被func2给污染了。  为了解决上述2个问题，我们可以把func1、func2、func3通过接口隔离开：\n接口隔离之后，Client1只依赖了Interface1，而Interface1上只有func1一个方法，也即Client1不会受到func2和func3的污染；另外，当Class1修改func1之后，它只需通知依赖了Interface1的客户端即可，大大降低了模块间耦合。\n实现ISP的关键是将大接口拆分成小接口，而拆分的关键就是接口粒度的把握。想要拆分得好，就要求接口设计人员对业务场景非常熟悉，对接口使用的场景了如指掌。否则孤立地设计接口，很难满足ISP。\n下面，我们以分布式应用系统demo为例，来进一步介绍ISP的实现。\n一个消息队列模块通常包含生产（produce）和消费（consumer）两种行为，因此我们设计了Mq消息队列抽象接口，包含Produce和Consume两个方法：\n// Mq 消息队列接口 type Mq interface { Consume(topic Topic) (*Message, error) Produce(message *Message) error } // 当前提供MemoryMq内存消息队列的实现 type MemoryMq struct {...} func (m *memoryMq) Consume(topic Topic) (*Message, error) {...} func (m *memoryMq) Produce(message *Message) error {...} 当前demo中使用接口的模块有2个，分别是作为消费者的MemoryMqInput和作为生产者的AccessLogSidecar：\ntype MemoryMqInput struct { topic mq.Topic consumer mq.Mq // 同时依赖了Consume和Produce } type AccessLogSidecar struct { socket network.Socket producer mq.Mq // 同时依赖了Consume和Produce \ttopic mq.Topic } 从领域模型上看，Mq接口的设计确实没有问题，它就应该包含consume和produce两个方法。但是从客户端程序的角度上看，它却违反了ISP，对MemoryMqInput来说，它只需要consume方法；对AccessLogSidecar来说，它只需要produce方法。\n一种设计方案是把Mq接口拆分成2个子接口Consumable和Producible，让MemoryMq直接实现Consumable和Producible：\n// Consumable 消费接口，从消息队列中消费数据 type Consumable interface { Consume(topic Topic) (*Message, error) } // Producible 生产接口，向消息队列生产消费数据 type Producible interface { Produce(message *Message) error } 仔细思考一下，就会发现上面的设计不太符合消息队列的领域模型，因为Mq的这个抽象确实应该存在的。\n更好的设计应该是保留Mq抽象接口，让Mq继承自Consumable和Producible，这样的分层设计之后，既能满足ISP，又能让实现符合消息队列的领域模型：\n具体实现如下：\n// Mq 消息队列接口，继承了Consumable和Producible，同时又consume和produce两种行为 type Mq interface { Consumable Producible } type MemoryMqInput struct { topic mq.Topic consumer mq.Consumable // 只依赖Consumable } type AccessLogSidecar struct { socket network.Socket producer mq.Producible // 只依赖Producible \ttopic mq.Topic } 接口隔离可以减少模块间耦合，提升系统稳定性，但是过度地细化和拆分接口，也会导致系统的接口数量的上涨，从而产生更大的维护成本。接口的粒度需要根据具体的业务场景来定，可以参考单一职责原则，将那些为同一类客户端程序提供服务的接口合并在一起。\nDIP：依赖倒置原则 《Clean Architecture》中介绍OCP时有提过：如果要模块A免于模块B变化的影响，那么就要模块B依赖于模块A。这句话貌似是矛盾的，模块A需要使用模块B的功能，怎么会让模块B反过来依赖模块A呢？这就是依赖倒置原则（The Dependency Inversion Principle，DIP）所要解答的问题。\nDIP的定义如下：\n  High-level modules should not import anything from low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details (concrete implementations) should depend on abstractions.   翻译过来，就是：\n 1、高层模块不应该依赖低层模块，两者都应该依赖抽象\n2、抽象不应该依赖细节，细节应该依赖抽象\n 在DIP的定义里，出现了高层模块、低层模块、抽象、细节等4个关键字，要弄清楚DIP的含义，理解者4个关键字至关重要。\n（1）高层模块和低层模块\n一般地，我们认为高层模块是包含了应用程序核心业务逻辑、策略的模块，是整个应用程序的灵魂所在；低层模块通常是一些基础设施，比如数据库、Web框架等，它们主要为了辅助高层模块完成业务而存在。\n（2）抽象和细节\n在前文“OCP：开闭原则”一节中，我们可以知道，抽象就是众多细节中的共同点，抽象就是不断忽略细节的出来的。\n现在再来看DIP的定义，对于第2点我们不难理解，从抽象的定义来看，抽象是不会依赖细节的，否则那就不是抽象了；而细节依赖抽象往往都是成立的。\n理解DIP的关键在于第1点，按照我们正向的思维，高层模块要借助低层模块来完成业务，这必然会导致高层模块依赖低层模块。但是在软件领域里，我们可以把这个依赖关系倒置过来，这其中的关键就是抽象。我们可以忽略掉低层模块的细节，抽象出一个稳定的接口，然后让高层模块依赖该接口，同时让低层模块实现该接口，从而实现了依赖关系的倒置：\n之所以要把高层模块和底层模块的依赖关系倒置过来，主要是因为作为核心的高层模块不应该受到低层模块变化的影响。高层模块的变化原因应当只能有一个，那就是来自软件用户的业务变更需求。\n下面，我们通过分布式应用系统demo来介绍DIP的实现。\n对于服务注册中心Registry来说，当有新的服务注册上来时，它需要把服务信息（如服务ID、服务类型等）保存下来，以便在后续的服务发现中能够返回给客户端。因此，Registry需要一个数据库来辅助它完成业务。刚好，我们的数据库模块实现了一个内存数据库MemoryDb，于是我们可以这么实现Registry：\ntype Registry struct { db db.MemoryDb // 直接依赖MemoryDb \tserver *http.Server localIp string svcManagement *svcManagement svcDiscovery *svcDiscovery } 按照上面的设计，模块间的依赖关系是Registry依赖于MemoryDb，也即高层模块依赖于低层模块。这种依赖关系是脆弱的，如果哪天需要把存储服务信息的数据库从MemoryDb改成DiskDb，那么我们也得改Registry的代码：\ntype Registry struct { db db.DiskDb // 改成依赖DiskDb \tserver *http.Server localIp string svcManagement *svcManagement svcDiscovery *svcDiscovery } 更好的设计应该是把Registry和MemoryDb的依赖关系倒置过来，首先我们需要从细节MemoryDb抽象出一个稳定的接口Db：\n更好的设计应该是把Registry和MemoryDb的依赖关系倒置过来，首先我们需要从细节MemoryDb抽象出一个稳定的接口Db：\n// Db 数据库抽象接口 type Db interface { Query(tableName string, primaryKey interface{}, result interface{}) error Insert(tableName string, primaryKey interface{}, record interface{}) error Update(tableName string, primaryKey interface{}, record interface{}) error Delete(tableName string, primaryKey interface{}) error ... } 接着，我们让Registry依赖Db接口，而MemoryDb实现Db接口，以此来完成依赖倒置：\ntype Registry struct { db db.Db // 依赖Db抽象接口 \tserver *http.Server localIp string svcManagement *svcManagement svcDiscovery *svcDiscovery } // MemoryDb 实现Db接口 type MemoryDb struct { tables sync.Map // key为tableName，value为table } func (m *memoryDb) Query(tableName string, primaryKey interface{}, result interface{}) error {...} func (m *memoryDb) Insert(tableName string, primaryKey interface{}, record interface{}) error {...} func (m *memoryDb) Update(tableName string, primaryKey interface{}, record interface{}) error {...} func (m *memoryDb) Delete(tableName string, primaryKey interface{}) error {...} 当高层模块依赖抽象接口时，总得在某个时候，某个地方把实现细节（低层模块）注入到高层模块上。在上述例子中，我们选择在main函数上，在创建Registry对象时，把MemoryDb注入进去。\n一般地，我们都会在main/启动函数上完成依赖注入，常见的注入的方式有以下几种：\n 构造函数注入（Registry所使用的方法） setter方法注入 提供依赖注入的接口，客户端直调用该接口即可 通过框架进行注入，比如Spring框架中的注解注入能力  另外，DIP不仅仅适用于模块/类/接口设计，在架构层面也同样适用，比如DDD的分层架构和Uncle Bob的整洁架构，都是运用了DIP：\n当然，DIP并不是说高层模块是只能依赖抽象接口，它的本意应该是依赖稳定的接口/抽象类/具象类。如果一个具象类是稳定的，比如Java中的String，那么高层模块依赖它也没有问题；相反，如果一个抽象接口是不稳定的，经常变化，那么高层模块依赖该接口也是违反DIP的，这时候应该思考下接口是否抽象合理。\n最后 本文花了很长的篇幅讨论了23种设计模式背后的核心思想 —— SOLID原则，它能指导我们设计出高内聚、低耦合的软件系统。但是它毕竟只是原则，如何落地到实际的工程项目上，还是需要参考成功的实践经验。而这些实践经验正是接下来我们要探讨的设计模式。\n学习设计模式最好的方法就是实践，在《实践GoF的23种设计模式》后续的文章，我们将以本文介绍的分布式应用系统demo作为实践示范，介绍23种设计模式的程序结构、适用场景、实现方法、优缺点等，让大家对设计模式有个更深入的理解，能够用对、不滥用设计模式。\n 参考\n Clean Architecture, Robert C. Martin (“Uncle Bob”) 敏捷软件开发：原则、模式与实践, Robert C. Martin (“Uncle Bob”) 使用Go实现GoF的23种设计模式, 元闰子 【Java实现】实践GoF的23种设计模式：SOLID原则 , 元闰子 SOLID原则精解之里氏替换原则LSP, 人民副首席码仔  更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-03-13T00:00:00Z","permalink":"https://www.yrunz.com/p/go%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fsolid%E5%8E%9F%E5%88%99/","title":"【Go实现】实践GoF的23种设计模式：SOLID原则"},{"content":"前言 说起网络通信协议，相信大家对 TCP 和 HTTP 都很熟悉，它们可以说是当今互联网通信的基石。但是，在网络安全方面，它们却是有着很大安全风险：\n 窃听风险。第三方攻击者可以随意窃听通信内容，比如获取支付账号密码。 冒充风险。第三方攻击者可以冒充他人身份与你通信，比如冒充银行网站以窃取银行账号密码。 篡改风险。第三方攻击者可以随意修改通信内容，比如在响应上加入钓鱼网址。  为此，SSL/TLS 协议应运而生。SSL/TLS 是建立在传输层之上、应用层之下的安全通信协议，它主要的设计意图就是消除上述几种安全风险，保证网络通信安全。我们熟知的 HTTPS 就是 HTTP + SSL/TLS 构建的，可以说 SSL/TLS 是当今互联网安全通信的基石。\n那么，现在假如让你来设计 SSL/TLS 协议，你会怎么设计呢？\n 本文将从设计者的视角介绍如何一步步设计出一个简易版的 SSL/TLS 的过程，在文章的最后，再简单介绍 TLS 1.2 版本的工作机制，以此帮助大家对 SSL/TLS 协议的基本原理有一个更深入的理解。\n 基于对称加密算法的数据加密 窃听风险主要是因为通信双方在网络上明文传输数据，导致攻击者可以通过简单网络抓包就能获取到通信的内容。\n要解决窃听风险，就最好的方法就是对数据进行加密。也即客户端在把数据发送出去之前，先对数据进行加密；服务端收到密文之后，再进行解密还原数据。这样就能避免在网络上传播明文，从而可以防止第三方攻击者的窃听。\n提到加密算法，很多人首先会想到对称加密算法，它以简单和高效著称。对称加密指的是加密和解密都使用同一份密钥，常见的算法有 DES、AES 等。\n现在，我们试着使用对称加密算法来实现安全通信：\n使用对称密钥加密的前提是，通信双方都必须用同一份密钥来对数据进行加密。主要有线下和线上密钥交换两种方案可以达到该目的：\n 线下密钥交换，也即通信双方线下约定好当面交换密钥（比如通过U盘作为媒介）。该方案可以保证密钥交换的安全性，但是很难推广使用。因为在绝大多数场景中，客户端和服务端都不可能碰面。 线上密钥交换，也即通过网络来传输密钥。但在网络明文传输密钥同样也会被攻击者拦截，这样的加密也没有意义了。  因此，单纯的对称加密并不能满足通信安全的要求，我们还要继续优化\u0026hellip;\u0026hellip;\n基于非对称加密算法的数据加密 非对称加密算法指的是加密和解密使用不同的密钥，这两个不同的密钥组成一个密钥对，也即公钥和私钥。公钥是公开的密钥，所有人都能获取到；私钥则是保密的。当我们使用公钥对数据进行加密后，只有对应的私钥才能完成解密。常见的非对称加密算法有 RSA、ECC 等。\n现在，我们试着使用非对称加密算法来实现安全通信：\n通过非对称加密算法，我们既能实现对数据的加密，又能解决密钥交换的问题，从而消除了窃听风险。但是，非对称加密算法最大的缺点，就是加解密速度很慢，相比于对称加密算法要慢1000多倍。因此，非对称加密算法通常只适用于对少量数据的加密。\n到目前为止，单纯地使用对称加密算法或非对称加密算法都无法满足要求，还需要继续优化\u0026hellip;\u0026hellip;\n基于对称加密+非对称加密算法的数据加密 既然对称加密算法加解密速度快，但存在密钥交换的问题；而非对称加密算法可以解决密钥交换问题，但加解密速度慢。那么我们可以把两种算法结合起来，也即通过对称加密算法进行数据加密，在交换对称密钥时，使用非对称加密算法来加密对称密钥，确保密钥在网络传输过程中不会被攻击者窃听。\n现在，我们试着使用对称加密+非对称加密算法来实现安全通信：\n使用对称加密+非对称加密算法的方案，我们消除了窃听风险，也不会存在加解密性能问题，但是还是无法消除冒充风险。\n考虑如下场景：\n 攻击者把服务端的公钥拦截，并保存下来。 攻击者伪造成服务端，把自己的公钥发送给客户端。 攻击者拦截使用非法公钥加密后的对称密钥，解密后得到对称密钥明文，并保存下来 攻击者使用服务端公钥重新加密对称密钥，伪造成客户端发送给服务端。  这番操作后，攻击者就能在客户端和服务端都不知情的情况下，得到了对称密钥。在这种场景下，攻击者从被动攻击的窃听，转为主动攻击的冒充，让客户端和服务端都误以为一直在跟对方通信。\n因此，我们需要找到一种方法，让客户端能够确保自己收到的公钥，一定是真实的服务端发送过来的，也即能够认证“服务端”的真实身份\u0026hellip;\u0026hellip;\n基于CA证书的身份认证 数字证书概述 引用百度百科的定义：\n 数字证书是指在互联网通讯中标志通讯各方身份信息的一个数字认证，人们可以在网上用它来识别对方的身份。\n 数字证书（Digital Certificate）就好比现实世界中的身份证，用于标识一个网络用户（人、公司、服务器等）的合法身份。就像身份证必须由公安局来颁发，可信的数字证书也必须由一个权威机构来颁发，该机构就是证书授权中心（Certificate Authority，CA），CA 颁发的数字证书我们通常称作 CA 证书。\n一个 CA 证书主要包含申请者的公钥、申请者的信息、签发机构 CA 的信息、有效时间、证书序列号等明文信息，同时也包含一个 CA 的数字签名，正是该签名的存在才证明了该证书的有效性。\n数字签名建立在非对称加密算法的基础上，CA 在颁发证书时，会先将证书的明文信息用指定的算法（比如 SHA256 算法）计算出一个数字摘要，再使用 CA 的私钥对摘要进行加密，形成签名。\n而证书的验证主要包含如下两部分：\n 检查证书的明文信息是否有效，比如证书是否过期、域名是否一致等。 用 CA 公布的公钥对证书签名进行解密，得到数字摘要1。再使用同样的算法对证书明文信息计算得出数字摘要2。对比数字摘要1和数字摘要2是否相等。   颁发证书的机构并非只有一个，比如机构 A 可以用 CA 颁发的根证书去给机构 B 颁发二级证书；机构 B 又可以用二级证书去给机构 C 颁发三级证书，以此类推，也即所谓的证书链。\n 使用CA证书认证通信双方的身份 现在，我们加入 CA 证书来认证通信双方的身份：\n引入 CA 证书之后，服务端的公钥就放在它提供的证书之中，当客户端验证服务端证书通过后，也就说明其中的公钥确实是来自服务端的合法公钥。这样，后续的通信流程就可以正常地进行了。\n然而，如果对称密钥一直不变的话，攻击者还是很有可能暴力破解出对称密钥。因此，我们还需要最好能够实现每次连接的对称密钥都是不同的\u0026hellip;\u0026hellip;\n使用随机数来生成对称密钥 为了使每次连接的对称密钥都不同，我们可以引入随机数来生成对称密钥，保证它的随机性。但是，考虑到当前计算机生成的随机数都是伪随机数，为了进一步提升随机性，我们可以通过生成多个随机数来达到此目的。\n我们可以这么设计：\n 客户端和服务端先各生成一个随机数（随机数1和随机数2），在 ClientHello 和 ServerHello 报文中完成交换。 客户端在验证完服务端的身份后，再生成随机数3，通过服务端的公钥加密发给服务端。（此时，通信双方都拥有了 3 个一样随机数） 客户端和服务端再根据这 3 个随机数，生成最终的对称密钥。  这样通过 3 个随机数来生成的密钥，就能较好地保证了密钥的随机性，降低被攻击者破解的可能。\n 虽然随机数1和随机数2是明文传输，但随机数3是密传输，也就能够保证攻击者很难破解到密钥。\n 到目前为止，我们已经通过多种手段成功阻止了攻击者窃听客户端和服务端之间的通信内容。但是，如果攻击者并不以窃听通信内容为目的，而是单纯地想搞破坏。比如，攻击者拦截了 ClientHello 报文，把其中的随机数1改成了随机数4，这样就会导致客户端和服务端生成的密钥不一致。在此场景下，虽然连接已经建立起来了，但是客户端和服务端还是无法正常地通信：\n为此，我们需要一种机制，校验连接建立阶段（握手阶段）所有消息的正确性，防止建立错误的连接\u0026hellip;\u0026hellip;\n校验握手消息的正确性 我们可以利用数字摘要来校验所有握手消息的正确性，也即，在握手阶段的最后，通信双方都通过 Hash 算法（比如 SHA256）对自己收到的和发送的所有消息计算出数字摘要，然后使用前面协商好的对称密钥对该数字摘要进行加密，发送给对方。\n当收到对方发过来的数字摘要密文后，先用对称密钥对其进行解密，如果解密成功，说明密钥生成没问题；接着对比双方的数字摘要是否一致，如果一致，说明握手阶段的消息没有被篡改过，也即可以建立起正确的连接了。\n到现在，我们基本上已经消除了窃听风险（通过数据加密）、冒充风险（通过证书认证）和篡改风险（通过数字摘要）。但是，为了建立起安全通信通道，我们需要经历多次消息交互、加解密、身份认证等步骤，对性能有一定的损耗。\n因为经历过一次握手之后，密钥已经协商好，并且双方都保存了下来。下次连接建立时，完全可以沿用上次握手协商好的密钥，从而避免了重新协商密钥，提升了性能。我们需要一种重用会话的机制来提升协议的性能\u0026hellip;\u0026hellip;\n重用会话来提升性能 为了达到沿用上次协商好的密钥的目的，我们为每次连接都分配一个会话 ID。\n 在初次创建连接时，由服务端生成，并通过 ServerHello 返回给客户端。 在下一次创建连接时，客户端通过 ClientHello 把该会话 ID 发给服务端，表示希望重用该会话。 服务端在收到该会话 ID 后，就可以发送 Finished 消息，表示同意了会话重用，也即可以沿用上次会话协商好的密钥进行安全通信了。  到这里，我们已经完成了一个简易版的 SSL/TLS 协议的设计，真实的 SSL/TLS 协议当然没这么简单，但是里面的核心思想和基本原理都是类似的。只是 SSL/TLS 为了更好的安全性、扩展性和易用性等增加了一些机制，比如支持多种加密算法、使用 MAC 替代普通的数字摘要完成完整性校验。\n下面，我们将简单介绍真实的 SSL/TLS 协议的工作机制。\nSSL/TLS协议机制概述 SSL 协议（Secure Sockets Layer）是 TLS（Transport Layer Security）协议的前身，它们的版本演进如下，当前最新的版本为 TLS 1.3 版本。本节，我们将以当前使用最广泛的 TLS 1.2 版本作为分析对象，介绍 SSL/TLS 的基本工作机制。\n SSL 1.0版本 -\u0026gt; SSL 2.0版本 -\u0026gt; SSL 3.0版本 -\u0026gt; TLS 1.0版本 -\u0026gt; TLS 1.1版本 -\u0026gt; TLS 1.2版本 -\u0026gt; TLS 1.3版本\n SSL/TLS协议总览 SSL/TLS 协议位于网络协议栈中传输层和应用层之间，它内部又可以分为 2 层，总共 5 种子协议：\nRecord协议 最底层的 Record 协议负责对上层子协议的封装，提供安全通信的能力：\n 私密连接。使用对称加密算法（比如 AES、RC4 等）来加密数据，而且在每次连接中，通信双方协商出来的加密密钥都是不同的，以此达到更好的安全性。另外，Record 协议也可以提供不加密的封装，比如在握手阶段的 Hello 报文。 可靠连接。使用 MAC（Message Authentication Code，消息验证码，TLS 目前使用的 HMAC 也属于 MAC 的一种）为数据提供完整性校验。同样，在握手阶段也可以不使用该功能。  Handshake 协议 上层的 Handshake 协议用在握手阶段，为通信双方提供身份认证、加密算法和密钥协商的能力：\n 身份认证。基于 CA 证书完成对端的身份认证，其中用到了非对称加密技术（比如 RSA、DES 等）。该功能是可选的，但通常的做法是至少进行单向认证。 安全参数的协商。完成用于安全参数的协商（比如加密算法、哈希算法、密钥等），并且能够保证在协商过程中，攻击者无法获取密钥。 可靠协商。确保在安全参数等协商过程中，攻击者无法对报文实施篡改。  Handshake 协议包含了如下几种报文类型：ClientHello、SeverHello、Certificate、ServerKeyExchange、CertificateRequest、ServerHelloDone、ClientKeyExchange、CertificateVerify、ChangeCipherSpec、Finished。\nChange Cipher Spec协议 Change Cipher Spec 协议也用在握手阶段，当通信的一方发出Change Cipher Spec 报文时，就表示密钥已经协商好，从下一条消息开始，使用该密钥来进行加密传输。\nAlert 协议 Alert 协议只有在连接异常时才会用上，当前协议定义的 Alert 消息类型如下：\nclose_notify: 表示发送方不会再发送任何消息，用于正常关闭连接，类似于TCP中的FIN报文 unexpected_message: 收到不在预期之内的消息 bad_record_mac: 收到的消息中MAC不正确，表示消息已经被篡改过 decryption_failed_RESERVED: 解密失败，用于TLS的早期版本 record_overflow: 消息长度溢出，密文长度不超过2^14+2048字节；压缩后的明文不超过2^14+1024字节 decompression_failure: 使用压缩功能时，解压失败 handshake_failure: 握手阶段无法协商出正确的安全参数 no_certificate_RESERVED: 为了兼容SSL 3.0版本，TLS不再使用 bad_certificate: 证书签名认证失败 unsupported_certificate: 收到不支持的证书类型 certificate_revoked: 收到被废弃的证书 certificate_expired: 收到过期的证书 certificate_unknown: 除上述4种情况外，其他证书异常场景 illegal_parameter: 握手阶段报文的参数非法，比如范围溢出等 unknown_ca: 不可信任的CA颁发的证书 access_denied: 证书校验通过，但发送方却拒绝继续握手 decode_error: 消息解码失败 decrypt_error: 握手阶段安全相关的步骤失败，比如签名校验失败、Finished消息校验失败等 export_restriction_RESERVED: 早期的TLS版本使用 protocol_version: 协议版本不支持 insufficient_security: 服务端要求的安全算法，客户端无法满足 internal_error: 协议内部错误 user_canceled: 用户非正常主动关闭连接 no_renegotiation: 拒绝重新握手 unsupported_extension: 不支持的扩展 Application Data 协议 Application Data 协议用在通信阶段，封装了应用层的数据，经由 Record 协议封装之后，通过 TCP 协议转发出去。\nSSL/TLS 协议的握手过程 第一次握手  客户端向服务端发送 ClientHello 报文发起连接建立，其中携带了如下内容：  Version: 客户端支持的TLS协议版本 Random: 客户端生成的随机数，随后用于生成 master secret SessionID: 会话 ID，如果不为空，表示客户端想重用该会话 CipherSuites: 客户端支持的加密套件列表，在 SessionID 为空时必须携带 CompressionMethods: 客户端支持的压缩算法列表 Extensions: 扩展内容    第二次握手   服务端向客户端发送 ServerHello 报文，其中携带了如下内容：\n Version: 选定的 TLS 版本，选择通信双方都支持的最高版本 Random: 服务端生成的随机数，随后用于生成 master secret SessionID: 会话 ID，如果为空，表示服务端开启新的会话，并且不希望被重用；如果与客户端带过来的 SessionID 一样，表示重用该会话；否则，开启一个新的会话，并且在未来可能会被重用 CipherSuite: 选定的加密套件 CompressionMethod: 选定的压缩算法 Extensions: 扩展内容    服务端向客户端发送 Certificate 报文，其中携带了服务端的证书，证书必须是 x.509 标准格式，包含服务端公钥、服务端域名、签发方信息、有效期等信息。\n 可选，客户端需要通过证书来认证服务端身份时发送\n   服务端向客户端发送 Server Key Exchange 报文，其中携带了客户端用于生成 premaster secret 的安全参数。\n 可选，当 Certificate 报文中携带的信息无法支撑客户端生成 premaster secret 时发送\n   服务端向客户端发送 CertificateRequest 报文，索求客户端证书，其中包含了期望的证书类型、签名算法和CA列表。\n 可选，开启双向认证时发送\n   服务端向客户端发送 ServerHelloDone 报文，表示当前服务端已经把所有与密钥交换相关的内容都发送完毕。\n  第三次握手   客户端向服务端发送 Certificate 报文，其中携带了客户端证书。\n 可选，收到服务端的 CertificateRequest 报文时发送\n   客户端向服务端发送 ClientKeyExchange 报文，其中包含了使用服务端公钥加密后的 premaster secret （随机数），随后用于生成master secret。\n  客户端向服务端发送 CertificateVerify 报文，其中包含了对通信双方到目前为止所有握手报文的数字签名，用于证明自己拥有的私钥与之前发送的证书中的公钥相对应。\n 可选，给服务端发送 Certificate 报文时发送\n   客户端向服务端发送 ChangeCipherSpec 报文，表示从下条消息开始进行加密传输。\n  客户端向服务端发送 Finished 报文，加密传输，其中包含了所有握手消息的数字摘要，用于防篡改。\n  第四次握手  服务端向客户端发送 ChangeCipherSpec 报文，表示从下条消息开始进行加密传输。 服务端向客户端发送 Finished 报文，加密传输，其中包含了所有握手消息的数字摘要，用于防篡改。  最后 SSL/TLS 协议也并非绝对安全，它也有许多漏洞被黑客们不断地挖掘出来，当然，SSL/TLS 协议也在不断地完善。2018 年发布的 TLS 1.3 版本就在 TLS 1.2 版本的基础上做了许多增强。比如，在性能上，握手阶段从 2-RTT 缩减为 1-RTT，并支持 0-RTT 模式；在安全上，ServerHello 报文之后就开始加密传输、一些不安全的加密套件也不再支持（比如静态 RSA、Diffie-Hellman 等）。\n虽然 TLS 1.3 版本机制上改变了很多，但是基本原理还是一样的。因此，把 SSL/TLS 协议原理理解透了，后续不管版本再怎么演进，我们都能快速完成协议机制的学习。\n 参考\nThe Transport Layer Security (TLS) Protocol Version 1.2，RFC 5246\nThe Transport Layer Security (TLS) Protocol Version 1.3，RFC 8446\nSSL/TLS 协议运行机制的概述，阮一峰\nOverview of SSL/TLS Encryption， MicroSoft Document\nThe First Few Milliseconds of an HTTPS Connection，Jeff Moser\n为什么 HTTPS 需要 7 次握手以及 9 倍时延，面向信仰编程\nHTTPS权威指南，杨洋、李振宇等\n数字证书, 百度百科\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-03-05T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%81%87%E5%A6%82%E8%AE%A9%E4%BD%A0%E6%9D%A5%E8%AE%BE%E8%AE%A1ssl/tls%E5%8D%8F%E8%AE%AE/","title":"假如让你来设计SSL/TLS协议"},{"content":" 之前也有写过关于设计模式的文章《使用Go实现GoF的23种设计模式》，但是那个系列写了3篇文章就没在继续了，主要的原因是找不到合适的示例代码。考虑到，如果以类似于“鸭子是否会飞”、“烘培的制作流程”等贴近生活的事情举例，很难在我们日常的开发中产生联系。（目前应该很少有这些逻辑的软件系统吧）\n《实践GoF的23种设计模式》可以看成是《使用Go实现GoF的23种设计模式》系列的重启，吸取了上次烂尾的教训，本次在写文章之前就已经完成了23种设计模式的示例代码实现。和上次不同，本次示例代码使用Java实现，以我们日常开发中经常碰到的一些技术/问题/场景作为切入点，示范如何运用设计模式来完成相关的实现。\n 前言 从1995年GoF提出23种设计模式到现在，25年过去了，设计模式依旧是软件领域的热门话题。设计模式通常被定义为：\n 设计模式（Design Pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人理解并且保证代码可靠性。\n 从定义上看，设计模式其实是一种经验的总结，是针对特定问题的简洁而优雅的解决方案。既然是经验总结，那么学习设计模式最直接的好处就在于可以站在巨人的肩膀上解决软件开发过程中的一些特定问题。\n学习设计模式的最高境界是吃透它们本质思想，可以做到即使已经忘掉某个设计模式的名称和结构，也能在解决特定问题时信手拈来。设计模式背后的本质思想，就是我们熟知的SOLID原则。如果把设计模式类比为武侠世界里的武功招式，那么SOLID原则就是内功内力。通常来说，先把内功练好，再来学习招式，会达到事半功倍的效果。因此，在介绍设计模式之前，很有必要先介绍一下SOLID原则。\n本文首先会介绍本系列文章中用到的示例代码demo的整体结构，然后开始逐一介绍SOLID原则，也即单一职责原则、开闭原则、里氏替换原则、接口隔离原则和依赖倒置原则。\n一个简单的分布式应用系统  本系列示例代码demo获取地址：https://github.com/ruanrunxue/Practice-Design-Pattern\u0026ndash;Java-Implementation\n 示例代码demo工程实现了一个简单的分布式应用系统（单机版），该系统主要由以下几个模块组成：\n 网络 Network，网络功能模块，模拟实现了报文转发、socket通信、http通信等功能。 数据库 Db，数据库功能模块，模拟实现了表、事务、dsl等功能。 消息队列 Mq，消息队列模块，模拟实现了基于topic的生产者/消费者的消息队列。 监控系统 Monitor，监控系统模块，模拟实现了服务日志的收集、分析、存储等功能。 边车 Sidecar，边车模块，模拟对网络报文进行拦截，实现access log上报、消息流控等功能。 服务 Service，运行服务，当前模拟实现了服务注册中心、在线商城服务集群、服务消息中介等服务。  示例代码demo工程的主要目录结构如下：\n├── db # 数据库模块，定义Db、Table、TableVisitor等抽象接口 【@单例模式】 │ ├── cache # 数据库缓存代理，为Db新增缓存功能 【@代理模式】 │ ├── console # 数据库控制台实现，支持dsl语句查询和结果显示 【@适配器模式】 │ ├── dsl # 实现数据库dsl语句查询能力，当前只支持select语句查询 【@解释器模式】 │ ├── exception # 数据库模块相关异常定义 │ ├── iterator # 遍历表迭代器，包含按序遍历和随机遍历 【@迭代器模式】 │ └── transaction # 实现数据库的事务功能，包括执行、提交、回滚等 【@命令模式】【@备忘录模式】 ├── monitor # 监控系统模块，采用插件式的架构风格，当前实现access log日志etl功能 │ ├── config # 监控系统插件配置模块 【@抽象工厂模式】【@组合模式】 │ │ ├── json # 实现基于json格式文件的配置加载功能 │ │ └── yaml # 实现基于yaml格式文件的配置加载功能 │ ├── entity # 监控系统实体对象定义 │ ├── exception # 监控系统相关异常 │ ├── filter # Filter插件的实现定义 【@责任链模式】 │ ├── input # Input插件的实现定义 【@策略模式】 │ ├── output # Output插件的实现定义 │ ├── pipeline # Pipeline插件的实现定义，一个pipeline表示一个ETL处理流程 【@桥接模式】 │ ├── plugin # 插件抽象接口定义 │ └── schema # 监控系统相关的数据表定义  ├── mq # 消息队列模块 ├── network # 网络模块，模拟网络通信，定义了socket、packet等通用类型/接口 【@观察者模式】 │ └── http # 模拟实现了http通信等服务端、客户端能力 ├── service # 服务模块，定义了服务的基本接口 │ ├── mediator # 服务消息中介，作为服务通信的中转方，实现了服务发现，消息转发的能力 【@中介者模式】 │ ├── registry # 服务注册中心，提供服务注册、去注册、更新、 发现、订阅、去订阅、通知等功能 │ │ ├── entity # 服务注册/发现相关的实体定义 【@原型模式】【@建造者模式】 │ │ └── schema # 服务注册中心相关的数据表定义 【@访问者模式】【@享元模式】 │ └── shopping # 模拟在线商城服务群的定义，包含订单服务、库存服务、支付服务、发货服务 【@外观模式】 └── sidecar # 边车模块，对socket进行拦截，提供http access log、流控功能 【@装饰者模式】【@工厂模式】 └── flowctrl # 流控模块，基于消息速率进行随机流控 【@模板方法模式】【@状态模式】 SRP：单一职责原则 单一职责原则（The Single Responsibility Principle，SRP）应该是SOLID原则中，最容易被理解的一个，但同时也是最容易被误解的一个。很多人会把“将大函数重构成一个个职责单一的小函数”这一重构手法等价为SRP，这是不对的，小函数固然体现了职责单一，但这并不是SRP。\nSRP传播最广的定义应该是Uncle Bob给出的：\n A module should have one, and only one, reason to change.\n 也即，一个模块应该有且只有一个导致其变化的原因。\n这个解释里有2个需要理解的地方：\n（1）如何定义一个模块\n我们通常会把一个源文件定义为最小粒度的模块。\n（2）如何找到这个原因\n一个软件的变化往往是为了满足某个用户的需求，那么这个用户就是导致变化的原因。但是，一个模块的用户/客户端程序往往不只一个，比如Java中的ArrayList类，它可能会被成千上万的程序使用，但我们不能说ArrayList职责不单一。因此，我们应该把“一个用户”改为“一类角色”，比如ArrayList的客户端程序都可以归类为“需要链表/数组功能”的角色。\n于是，Uncle Bob给出了SRP的另一个解释：\n A module should be responsible to one, and only one, actor.\n 有了这个解释，我们就可以理解函数职责单一并不等同于SRP，比如在一个模块有A和B两个函数，它们都是职责单一的，但是函数A的使用者是A类用户，函数B的使用者是B类用户，而且A类用户和B类用户变化的原因都是不一样的，那么这个模块就不满足SRP了。\n下面，以我们的分布式应用系统demo为例进一步探讨。对于Registry类（服务注册中心）来说，它对外提供的基本能力有服务注册、更新、去注册和发现功能，那么，我们可以这么实现：\n// demo/src/main/java/com/yrunz/designpattern/service/Registry.java public class Registry implements Service { private final HttpServer httpServer; private final Db db; ... @Override public void run() { httpServer.put(\u0026#34;/api/v1/service-profile\u0026#34;, this::register) .post(\u0026#34;/api/v1/service-profile\u0026#34;, this::update) .delete(\u0026#34;/api/v1/service-profile\u0026#34;, this::deregister) .get(\u0026#34;/api/v1/service-profile\u0026#34;, this::discovery) .start(); } // 服务注册  private HttpResp register(HttpReq req) { ... } // 服务更新  private HttpResp update(HttpReq req) { ... } // 服务去注册  private HttpResp deregister(HttpReq req) { ... } // 服务发现  private HttpResp discovery(HttpReq req) { ... } } 上述实现中，Registry包含了register、update、deregister、discovery等4个主要方法，正好对应了Registry对外提供的能力，看起来已经是职责单一了。\n但是在仔细思考一下就会发现，服务注册、更新和去注册是给专门给服务提供者使用的功能，而服务发现则是专门给服务消费者使用的功能。服务提供者和服务消费者是两类不同的角色，它们产生变化的时间和方向都可能不同。比如：\n 当前服务发现功能是这么实现的：Registry从满足查询条件的所有ServiceProfile中挑选一个返回给服务消费者（也即Registry自己做了负载均衡）。\n假设现在服务消费者提出新的需求：Registry把所有满足查询条件的ServiceProfile都返回，由服务消费者自己来做负载均衡。\n为了实现这样的功能，我们就要修改Registry的代码。按理，服务注册、更新、去注册等功能并不应该受到影响，但因为它们和服务发现功能都在同一个模块（Registry）里，于是被迫也受到影响了，比如可能会代码冲突。\n 因此，更好的设计是将register、update、deregister内聚到一个服务管理模块SvcManagement，discovery则放到另一个服务发现模块SvcDiscovery，服务注册中心Registry再组合SvcManagement和SvcDiscovery。\n具体实现如下：\n// demo/src/main/java/com/yrunz/designpattern/service/SvcManagement.java class SvcManagement { private final Db db; ... // 服务注册  HttpResp register(HttpReq req) { ... } // 服务更新  HttpResp update(HttpReq req) { ... } // 服务去注册  HttpResp deregister(HttpReq req) { ... } } // demo/src/main/java/com/yrunz/designpattern/service/SvcDiscovery.java class SvcDiscovery { private final Db db; ... // 服务发现  HttpResp discovery(HttpReq req) { ... } } // demo/src/main/java/com/yrunz/designpattern/service/Registry.java public class Registry implements Service { private final HttpServer httpServer; private final SvcManagement svcManagement; private final SvcDiscovery svcDiscovery; ... @Override public void run() { // 使用子模块的方法完成具体业务  httpServer.put(\u0026#34;/api/v1/service-profile\u0026#34;, svcManagement::register) .post(\u0026#34;/api/v1/service-profile\u0026#34;, svcManagement::update) .delete(\u0026#34;/api/v1/service-profile\u0026#34;, svcManagement::deregister) .get(\u0026#34;/api/v1/service-profile\u0026#34;, svcDiscovery::discovery) .start(); } } 除了重复的代码编译，违反SRP还会带来以下2个常见的问题：\n1、代码冲突。程序员A修改了模块的A功能，而程序员B在不知情的情况下也在修改该模块的B功能（因为A功能和B功能面向不同的用户，完全可能由2位不同的程序员来维护），当他们同时提交修改时，代码冲突就会发生（修改了同一个源文件）。\n2、A功能的修改影响了B功能。如果A功能和B功能都使用了模块里的一个公共函数C，现在A功能有新的需求需要修改函数C，那么如果修改人没有考虑到B功能，那么B功能的原有逻辑就会受到影响。\n由此可见，违反SRP会导致软件的可维护性变得极差。但是，我们也不能盲目地进行模块拆分，这样会导致代码过于碎片化，同样也会提升软件的复杂性。比如，在前面的例子中，我们就没有必要再对服务管理模块进行拆分为服务注册模块、服务更新模块和服务去注册模块，一是因为它们面向都用户是一致的；二是在可预见的未来它们要么同时变化，要么都不变。\n因此，我们可以得出这样的结论：\n 如果一个模块面向的都是同一类用户（变化原因一致），那么就没必要进行拆分。 如果缺乏用户归类的判断，那么最好的拆分时机是变化发生时。  SRP是聚合和拆分的一个平衡，太过聚合会导致牵一发动全身，拆分过细又会提升复杂性。要从用户的视角来把握拆分的度，把面向不同用户的功能拆分开。如果实在无法判断/预测，那就等变化发生时再拆分，避免过度的设计。\nOCP：开闭原则 开闭原则（The Open-Close Principle，OCP）中，“开”指的是对扩展开放，“闭”指的是对修改封闭，它的完整解释为：\n A software artifact should be open for extension but closed for modification.\n 通俗地讲就是，一个软件系统应该具备良好的可扩展性，新增功能应当通过扩展的方式实现，而不是在已有的代码基础上修改。\n然而，从字面意思上看，OCP貌似又是自相矛盾的：想要给一个模块新增功能，但是有不能修改它。\n*如何才能打破这个困境呢？*关键是抽象！优秀的软件系统总是建立在良好的抽象的基础上，抽象化可以降低软件系统的复杂性。\n*那么什么是抽象呢？*抽象不仅存在与软件领域，在我们的生活中也随处可见。下面以《语言学的邀请》中的一个例子来解释抽象的含义：\n 假设某农庄有一头叫“阿花”的母牛，那么：\n1、当把它称为“阿花”时，我们看到的是它独一无二的一些特征：身上有很多斑点花纹、额头上还有一个闪电形状的伤疤。\n2、当把它称为母牛时，我们忽略了它的独有特征，看到的是它与母牛“阿黑”，母牛“阿黄”的共同点：是一头牛、雌性的。\n3、当把它称为家畜时，我们又忽略了它作为母牛的特征，而是看到了它和猪、鸡、羊一样的特点：是一个动物，在农庄里圈养。\n4、当把它称为农庄财产时，我们只关注了它和农庄上其他可售对象的共同点：可以卖钱、转让。\n从“阿花”，到母牛，到家畜，再到农庄财产，这就是一个不断抽象化的过程。\n 从上述例子中，我们可以得出这样的结论：\n 抽象就是不断忽略细节，找到事物间共同点的过程。 抽象是分层的，抽象层次越高，细节也就越少。  在回到软件领域，我们也可以把上述的例子类比到数据库上，数据库的抽象层次从低至高可以是这样的：MySQL 8.0版本 -\u0026gt; MySQL -\u0026gt; 关系型数据库 -\u0026gt; 数据库。现在假设有一个需求，需要业务模块将业务数据保存到数据库上，那么就有以下几种设计方案：\n 方案一：把业务模块设计为直接依赖MySQL 8.0版本。因为版本总是经常变化的，如果哪天MySQL升级了版本，那么我们就得修改业务模块进行适配，所以方案一违反了OCP。 方案二：把业务模块设计为依赖MySQL。相比于方案一，方案二消除了MySQL版本升级带来的影响。现在考虑另一种场景，如果因为某些原因公司禁止使用MySQL，必须切换到PostgreSQL，这时我们还是得修改业务模块进行数据库的切换适配。因此，在这种场景下，方案二也违反了OCP。 方案三：把业务模块设计为依赖关系型数据库。到了这个方案，我们基本消除了关系型数据库切换的影响，可以随时在MySQL、PostgreSQL、Oracle等关系型数据库上进行切换，而无须修改业务模块。但是，熟悉业务的你预测未来随着用户量的迅速上涨，关系型数据库很有可能无法满足高并发写的业务场景，于是就有了下面的最终方案。 方案四：把业务模块设计为依赖数据库。这样，不管以后使用MySQL还是PostgreSQL，关系型数据库还是非关系型数据库，业务模块都不需要再改动。到这里，我们基本可以认为业务模块是稳定的，不会受到底层数据库变化带来的影响，满足了OCP。  我们可以发现，上述方案的演进过程，就是我们不断对业务依赖的数据库模块进行抽象的过程，最终设计出稳定的、服务OCP的软件。\n那么，在编程语言中，我们用什么来表示“数据库”这一抽象呢？是接口！\n数据库最常见的几个操作就是CRUD，因此我们可以设计这么一个Db接口来表示“数据库”：\npublic interface Db { Record query(String tableName, Condition cond); void insert(String tableName, Record record); void update(String tableName, Record record); void delete(String tableName, Record record); } 这样，业务模块和数据库模块之间的依赖关系就变成如下图所示：\n满足OCP的另一个关键点就是分离变化，只有先把变化点识别分离出来，我们才能对它进行抽象化。下面以我们的分布式应用系统demo为例，解释如何实现变化点的分离和抽象。\n在demo中，监控系统主要负责对服务的access log进行ETL操作，也即涉及如下3个操作：1）从消息队列中获取日志数据；2）对数据进行加工；3）将加工后的数据存储在数据库上。\n我们把整一个日志数据的处理流程称为pipeline，那么我们可以这么实现：\npublic class Pipeline implements Plugin { private Mq mq; private Db db; ... public void run() { while (!isClose.get()) { // 1、从消息队列中获取数据  Message msg = mq.consume(\u0026#34;monitor.topic\u0026#34;); String accessLog = msg.payload(); // 2、对数据进行清理操作，转换为json字符串对格式  ObjectNode logJson = new ObjectNode(JsonNodeFactory.instance); logJson.put(\u0026#34;content\u0026#34;, accessLog); String data = logJson.asText(); // 3、存储到数据库上  db.insert(\u0026#34;logs_table\u0026#34;, logId, data); } } ... } 现在考虑新上线一个服务，但是这个服务不支持对接消息队列了，只支持socket传输数据，于是我们得在Pipeline上新增一个InputType来判断是否适用socket输入源：\npublic class Pipeline implements Plugin { ... public void run() { while (!isClose.get()) { String accessLog; // 使用消息队列为消息来源  if (inputType == InputType.MQ) { Message msg = mq.consume(\u0026#34;monitor.topic\u0026#34;); accessLog = msg.payload(); } else { // 使用socket为消息来源  Packet packet = socket.receive(); accessLog = packet.payload().toString(); } ... } } } 过一段时间，有需求需要给access log打上一个时间戳，方便后续的日志分析，于是我们需要修改Pipeline的数据加工逻辑：\npublic class Pipeline implements Plugin { ... public void run() { while (!isClose.get()) { ... // 对数据进行清理操作，转换为json字符串对格式  ObjectNode logJson = new ObjectNode(JsonNodeFactory.instance); logJson.put(\u0026#34;content\u0026#34;, accessLog); // 新增一个时间戳字段  logJson.put(\u0026#34;timestamp\u0026#34;, Instant.now().getEpochSecond()); String data = logJson.asText(); ... } } } 很快，又有一个需求，需要将加工后的数据存储到ES上，方便后续的日志检索，于是我们再次修改了Pipeline的数据存储逻辑：\npublic class Pipeline implements Plugin { ... public void run() { while (!isClose.get()) { ... // 存储到ES上  if (outputType == OutputType.DB) { db.insert(\u0026#34;logs_table\u0026#34;, logId, data); } else { // 存储到ES上  es.store(logId, data) } } } } 在上述的pipeline例子中，每次新增需求都需要修改Pipeline模块，明显违反了OCP。下面，我们来对它进行优化，使它满足OCP。\n第一步是分离变化点，根据pipeline的业务处理逻辑，我们可以发现3个独立的变化点，数据的获取、加工和存储。第二步，我们对这3个变化点进行抽象，设计出以下3个抽象接口：\n// demo/src/main/java/com/yrunz/designpattern/monitor/input/InputPlugin.java // 数据获取抽象接口 public interface InputPlugin extends Plugin { Event input(); void setContext(Config.Context context); } // demo/src/main/java/com/yrunz/designpattern/monitor/filter/FilterPlugin.java // 数据加工抽象接口 public interface FilterPlugin extends Plugin { Event filter(Event event); } // demo/src/main/java/com/yrunz/designpattern/monitor/output/OutputPlugin.java // 数据存储抽象接口 public interface OutputPlugin extends Plugin { void output(Event event); void setContext(Config.Context context); } 最后，Pipeline的实现如下，只依赖于InputPlugin、FilterPlugin和OutputPlugin三个抽象接口。后续再有需求变更，只需扩展对应的接口即可，Pipeline无须再变更：\n// demo/src/main/java/com/yrunz/designpattern/monitor/pipeline/Pipeline.java // ETL流程定义 public class Pipeline implements Plugin { final InputPlugin input; final FilterPlugin filter; final OutputPlugin output; final AtomicBoolean isClose; public Pipeline(InputPlugin input, FilterPlugin filter, OutputPlugin output) { this.input = input; this.filter = filter; this.output = output; this.isClose = new AtomicBoolean(false); } // 运行pipeline  public void run() { while (!isClose.get()) { Event event = input.input(); event = filter.filter(event); output.output(event); } } ... } OCP是软件设计的终极目标，我们都希望能设计出可以新增功能却不用动老代码的软件。但是100%的对修改封闭肯定是做不到的，另外，遵循OCP的代价也是巨大的。它需要软件设计人员能够根据具体的业务场景识别出那些最有可能变化的点，然后分离出去，抽象成稳定的接口。这要求设计人员必须具备丰富的实战经验，以及非常熟悉该领域的业务场景。否则，盲目地分离变化点、过度地抽象，都会导致软件系统变得更加复杂。\nLSP：里氏替换原则 上一节介绍中，OCP的一个关键点就是抽象，而如何判断一个抽象是否合理，这是里氏替换原则（The Liskov Substitution Principle，LSP）需要回答的问题。\nLSP的最初定义如下：\n If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.\n 简单地讲就是，子类型必须能够替换掉它们的基类型，也即基类中的所有性质，在子类中仍能成立。一个简单的例子：假设有一个函数f，它的入参类型是基类B。同时，基类B有一个派生类D，如果把D的实例传递给函数f，那么函数f的行为功能应该是不变的。\n由此可以看出，违反LSP的后果很严重，会导致程序出现不在预期之内的行为错误。下面，我们看一个经典反面例子，矩形与正方形。\n假设现在有矩形Rectangle，可以通过setWidth方法设置宽度，setLength方法设置长度，area方法得到矩形面积：\n// 矩形定义 public class Rectangle { private int width; // 宽度  private int length; // 长度  // 设置宽度  public void setWidth(int width) { this.width = width; } // 设置长度  public void setLength(int length) { this.length = length; } // 返回矩形面积  public int area() { return width * length; } } 另外，有一个客户端程序Cient，它的方法f以Rectangle作为入参，逻辑为校验矩形的逻辑：\n// 客户端程序 public class Client { // 校验矩形面积为长*宽  public void f(Rectangle rectangle) { rectangle.setWidth(5); rectangle.setLength(4); if (rectangle.area() != 20) { throw new RuntimeException(\u0026#34;rectangle\u0026#39;s area is invalid\u0026#34;); } System.out.println(\u0026#34;rectangle\u0026#39;s area is valid\u0026#34;); } } // 运行程序 public static void main(String[] args) { Rectangle rectangle = new Rectangle(); Client client = new Client(); client.f(rectangle); } // 运行结果： // rectangle\u0026#39;s area is valid 现在，我们打算新增一种新的类型，正方形Square。因为从数学上看，正方形也是矩形的一种，因此我们让Square继承了Rectangle。另外，正方形要求长宽一致，因此Square重写了setWidth和setLength方法：\n// 正方形，长宽相等 public class Square extends Rectangle { // 设置宽度  public void setWidth(int width) { this.width = width; // 长宽相等，因此同时设置长度  this.length = width; } // 设置长度  public void setLength(int length) { this.length = length; // 长宽相等，因此同时设置长度  this.width = length; } } 下面，我们把Square实例化后作为入参传入Cient.f上：\npublic static void main(String[] args) { Square square = new Square(); Client client = new Client(); client.f(square); } // 运行结果: // Exception in thread \u0026#34;main\u0026#34; java.lang.RuntimeException: rectangle\u0026#39;s area is invalid // at com.yrunz.designpattern.service.mediator.Client.f(Client.java:8) // at com.yrunz.designpattern.service.mediator.Client.main(Client.java:16) 我们发现Cient.f的行为发生了变化，子类型Square并不能替代基类型Rectangle，违反了LSP。\n出现上面的这种违反LSP的设计，主要原因还是我们孤立地进行模型设计，没有从客户端程序的角度来审视该设计是否正确。我们孤立地认为在数学上成立的关系（正方形 IS-A 矩形），在程序中也一定成立，而忽略了客户端程序的使用方法（先设置宽度为5，长度为4，然后校验面积为20）。\n这个例子告诉我们：一个模型的正确性或有效性，只能通过客户端程序来体现。\n下面，我们总结一下在继承体系（IS-A）下，要想设计出符合LSP的模型所需要遵循的一些约束：\n 基类应该设计为一个抽象类（不能直接实例化，只能被继承）。 子类应该实现基类的抽象接口，而不是重写基类已经实现的具体方法。 子类可以新增功能，但不能改变基类的功能。 子类不能新增约束，包括抛出基类没有声明的异常。  前面的矩形和正方形的例子中，几乎把这些约束都打破了，从而导致了程序的异常行为：1）Square的基类Rectangle不是一个抽象类，打破约束1；2）Square重写了基类的setWidth和setLength方法，打破约束2；3）Square新增了Rectangle没有的约束，长宽相等，打破约束4。\n除了继承之外，另一个实现抽象的机制是接口。如果我们是面向接口的设计，那么上述的约束1～3其实已经满足了：1）接口本身不具备实例化能力，满足约束1；2）接口没有具体的实现方法（Java中接口的default方法比较例外，本文先不考虑），也就不会被重写，满足约束2；3）接口本身只定义了行为契约，并没有实际的功能，因此也不会被改变，满足约束3。\n因此，使用接口替代继承来实现多态和抽象，能够减少很多不经意的错误。但是面向接口设计仍然需要遵循约束4，下面我们以分布式应用系统demo为例，介绍一个比较隐晦地打破约束4，从而违反了LSP的实现。\n还是以监控系统为例，为例实现ETL流程的灵活配置，我们需要通过配置文件定义pipeline的流程功能（数据从哪获取、需要经过哪些加工、加工后存储到哪里）。当前需要支持json和yaml两种配置文件格式，以yaml配置为例，配置内容是这样的：\n# src/main/resources/pipelines/pipeline_0.yamlname:pipeline_0# pipeline名称type:single_thread# pipeline类型input:# input插件定义（数据从哪里来）name:input_0# input插件名称type:memory_mq# input插件类型context:# input插件的初始化上下文topic:access_log.topicfilter:# filter插件定义（需要经过哪些加工）- name:filter_0# 加工流程filter_0定义，类型为log_to_jsontype:log_to_json- name:filter_1# 加工流程filter_1定义，类型为add_timestamptype:add_timestamp- name:filter_2# 加工流程filter_2定义，类型为json_to_monitor_eventtype:json_to_monitor_eventoutput:# output插件定义（加工后存储到哪里）name:output_0# output插件名称type:memory_db# output插件类型context:# output插件的初始化上下文tableName:monitor_event_0首先我们定义一个Config接口来表示“配置”这一抽象:\n// demo/src/main/java/com/yrunz/designpattern/monitor/config/Config.java public interface Config { // 从json字符串中加载配置  void load(String conf); } 另外，上述配置中的input、filter、output子项，可以认为是InputPlugin、FilterPlugin、OutputPlugin插件的配置项，由Pipeline插件的配置项组合在一起，因此我们定义了如下几个Config的抽象类：\n// demo/src/main/java/com/yrunz/designpattern/monitor/config/InputConfig.java public abstract class InputConfig implements Config { protected String name; protected InputType type; protected Context ctx; // 子类实现具体加载逻辑，支持yaml和json的加载方式  @Override public abstract void load(String conf); ... } // demo/src/main/java/com/yrunz/designpattern/monitor/config/FilterConfig.java public abstract class FilterConfig implements Config { protected List\u0026lt;Item\u0026gt; items; // 子类实现具体加载逻辑，支持yaml和json的加载方式  @Override public abstract void load(String conf); ... } // demo/src/main/java/com/yrunz/designpattern/monitor/config/OutputConfig.java public abstract class OutputConfig implements Config { protected String name; protected OutputType type; protected Context ctx; // 子类实现具体加载逻辑，支持yaml和json的加载方式  @Override abstract public void load(String conf); ... } // demo/src/main/java/com/yrunz/designpattern/monitor/config/PipelineConfig.java public abstract class PipelineConfig implements Config { protected String name; protected PipelineType type; protected final InputConfig inputConfig; protected final FilterConfig filterConfig; protected final OutputConfig outputConfig; // 子类实现具体加载逻辑，支持yaml和json的加载方式  @Override public abstract void load(String conf); } 最后再实现具体的基于json和yaml的子类：\n// json方式加载Config子类目录：src/main/java/com/yrunz/designpattern/monitor/config/json public class JsonInputConfig extends InputConfig {...} public class JsonFilterConfig extends FilterConfig {...} public class JsonOutputConfig extends OutputConfig {...} public class JsonPipelineConfig extends PipelineConfig {...} // yaml方式加载Config子类目录：src/main/java/com/yrunz/designpattern/monitor/config/yaml public class YamlInputConfig extends InputConfig {...} public class YamlFilterConfig extends FilterConfig {...} public class YamlOutputConfig extends OutputConfig {...} public class YamlPipelineConfig extends PipelineConfig {...} 因为涉及到从配置到对象的实例化过程，自然会想到使用工厂模式来创建对象。另外因为Pipeline、InputPlugin、FilterPlugin和OutputPlugin都实现了Plugin接口，我们也很容易想到定义一个PluginFactory接口来表示“插件工厂”这一抽象，具体的插件工厂再实现该接口：\n// 插件工厂接口，根据配置实例化插件 public interface PluginFactory { Plugin create(Config config); } // input插件工厂 public class InputPluginFactory implements PluginFactory { ... @Override public InputPlugin create(Config config) { InputConfig conf = (InputConfig) config; try { Class\u0026lt;?\u0026gt; inputClass = Class.forName(conf.type().classPath()); InputPlugin input = (InputPlugin) inputClass.getConstructor().newInstance(); input.setContext(conf.context()); return input; } ... } } // filter插件工厂 public class FilterPluginFactory implements PluginFactory { ... @Override public FilterPlugin create(Config config) { FilterConfig conf = (FilterConfig) config; FilterChain filterChain = FilterChain.empty(); String name = \u0026#34;\u0026#34;; try { for (FilterConfig.Item item : conf.items()) { name = item.name(); Class\u0026lt;?\u0026gt; filterClass = Class.forName(item.type().classPath()); FilterPlugin filter = (FilterPlugin) filterClass.getConstructor().newInstance(); filterChain.add(filter); } } ... } } // output插件工厂 public class OutputPluginFactory implements PluginFactory { ... @Override public OutputPlugin create(Config config) { OutputConfig conf = (OutputConfig) config; try { Class\u0026lt;?\u0026gt; outputClass = Class.forName(conf.type().classPath()); OutputPlugin output = (OutputPlugin) outputClass.getConstructor().newInstance(); output.setContext(conf.context()); return output; } ... } } // pipeline插件工厂 public class PipelineFactory implements PluginFactory { ... @Override public Pipeline create(Config config) { PipelineConfig conf = (PipelineConfig) config; InputPlugin input = InputPluginFactory.newInstance().create(conf.input()); FilterPlugin filter = FilterPluginFactory.newInstance().create(conf.filter()); OutputPlugin output = OutputPluginFactory.newInstance().create(conf.output()); ... } } 最后，通过PipelineFactory来实创建Pipline对象：\nConfig config = YamlPipelineConfig.of(YamlInputConfig.empty(), YamlFilterConfig.empty(), YamlOutputConfig.empty()); config.load(Files.readAllBytes(\u0026#34;pipeline_0.yaml\u0026#34;)); Pipeline pipeline = PipelineFactory.newInstance().create(config); assertNotNull(pipeline); // 运行结果： Pass 到目前为止，上述的设计看起来是合理的，运行也没有问题。\n但是，细心的读者可能会发现，每个插件工厂子类的create方法的第一行代码都是一个转型语句，比如PipelineFactory的是PipelineConfig conf = (PipelineConfig) config;。所以，上一段代码能够正常运行的前提是：传入PipelineFactory.create方法的入参必须是PipelineConfig 。如果客户端程序传入InputConfig的实例，PipelineFactory.create方法将会抛出转型失败的异常。\n上述这个例子就是一个违反LSP的典型场景，虽然在约定好的前提下，程序可以运行正确，但是如果有客户端不小心破坏了这个约定，就会带来程序行为异常（我们永远无法预知客户端的所有行为）。\n要纠正这个问题也很简单，就是去掉PluginFactory这一层抽象，让PipelineFactory.create等工厂方法的入参声明为具体的配置类，比如PipelineFactory可以这么实现：\n// demo/src/main/java/com/yrunz/designpattern/monitor/pipeline/PipelineFactory.java // pipeline插件工厂，不在实现PluginFactory接口 public class PipelineFactory { ... // 工厂方法入参为PipelineConfig实现类，消除转型  public Pipeline create(PipelineConfig config) { InputPlugin input = InputPluginFactory.newInstance().create(config.input()); FilterPlugin filter = FilterPluginFactory.newInstance().create(config.filter()); OutputPlugin output = OutputPluginFactory.newInstance().create(config.output()); ... } } 从上述几个例子中，我们可以看出遵循LSP的重要性，而设计出符合LSP的软件的要点就是，根据该软件的使用者行为作出的合理假设，以此来审视它是否具备有效性和正确性。\nISP：接口隔离原则 接口隔离原则（The Interface Segregation Principle，ISP）是关于接口设计的一项原则，这里的“接口”并不单指Java或Go上使用interface声明的狭义接口，而是包含了狭义接口、抽象类、具象类等在内的广义接口。它的定义如下：\n Client should not be forced to depend on methods it does not use.\n 也即，一个模块不应该强迫客户程序依赖它们不想使用的接口，模块间的关系应该建立在最小的接口集上。\n下面，我们通过一个例子来详细介绍ISP。\n上图中，Client1、Client2、Client3都依赖了Class1，但实际上，Client1只需使用Class1.func1方法，Client2只需使用Class1.func2，Client3只需使用Class1.func3，那么这时候我们就可以说该设计违反了ISP。\n违反ISP主要会带来如下2个问题：\n 增加模块与客户端程序的依赖，比如在上述例子中，虽然Client2和Client3都没有调用func1，但是当Class1修改func1还是必须通知Client1～3，因为Class1并不知道它们是否使用了func1。 产生接口污染，假设开发Client1的程序员，在写代码时不小心把func1打成了func2，那么就会带来Client1的行为异常。也即Client1被func2给污染了。  为了解决上述2个问题，我们可以把func1、func2、func3通过接口隔离开：\n接口隔离之后，Client1只依赖了Interface1，而Interface1上只有func1一个方法，也即Client1不会受到func2和func3的污染；另外，当Class1修改func1之后，它只需通知依赖了Interface1的客户端即可，大大降低了模块间耦合。\n实现ISP的关键是将大接口拆分成小接口，而拆分的关键就是接口粒度的把握。想要拆分得好，就要求接口设计人员对业务场景非常熟悉，对接口使用的场景了如指掌。否则孤立地设计接口，很难满足ISP。\n下面，我们以分布式应用系统demo为例，来进一步介绍ISP的实现。\n一个消息队列模块通常包含生产（produce）和消费（consumer）两种行为，因此我们设计了Mq消息队列抽象接口，包含produce和consume两个方法：\n// 消息队列接口 public interface Mq { Message consume(String topic); void produce(Message message); } // demo/src/main/java/com/yrunz/designpattern/mq/MemoryMq.java // 当前提供MemoryMq内存消息队列的实现 public class MemoryMq implements Mq {...} 当前demo中使用接口的模块有2个，分别是作为消费者的MemoryMqInput和作为生产者的AccessLogSidecar：\npublic class MemoryMqInput implements InputPlugin { private String topic; private Mq mq; ... @Override public Event input() { Message message = mq.consume(topic); Map\u0026lt;String, String\u0026gt; header = new HashMap\u0026lt;\u0026gt;(); header.put(\u0026#34;topic\u0026#34;, topic); return Event.of(header, message.payload()); } ... } public class AccessLogSidecar implements Socket { private final Mq mq; private final String topic ... @Override public void send(Packet packet) { if ((packet.payload() instanceof HttpReq)) { String log = String.format(\u0026#34;[%s][SEND_REQ]send http request to %s\u0026#34;, packet.src(), packet.dest()); Message message = Message.of(topic, log); mq.produce(message); } ... } ... } 从领域模型上看，Mq接口的设计确实没有问题，它就应该包含consume和produce两个方法。但是从客户端程序的角度上看，它却违反了ISP，对MemoryMqInput来说，它只需要consume方法；对AccessLogSidecar来说，它只需要produce方法。\n一种设计方案是把Mq接口拆分成2个子接口Consumable和Producible，让MemoryMq直接实现Consumable和Producible：\n// demo/src/main/java/com/yrunz/designpattern/mq/Consumable.java // 消费者接口，从消息队列中消费数据 public interface Consumable { Message consume(String topic); } // demo/src/main/java/com/yrunz/designpattern/mq/Producible.java // 生产者接口，向消息队列生产消费数据 public interface Producible { void produce(Message message); } // 当前提供MemoryMq内存消息队列的实现 public class MemoryMq implements Consumable, Producible {...} 仔细思考一下，就会发现上面的设计不太符合消息队列的领域模型，因为Mq的这个抽象确实应该存在的。\n更好的设计应该是保留Mq抽象接口，让Mq继承自Consumable和Producible，这样的分层设计之后，既能满足ISP，又能让实现符合消息队列的领域模型：\n具体实现如下：\n// demo/src/main/java/com/yrunz/designpattern/mq/Mq.java // 消息队列接口，继承了Consumable和Producible，同时又consume和produce两种行为 public interface Mq extends Consumable, Producible {} // 当前提供MemoryMq内存消息队列的实现 public class MemoryMq implements Mq {...} // demo/src/main/java/com/yrunz/designpattern/monitor/input/MemoryMqInput.java public class MemoryMqInput implements InputPlugin { private String topic; // 消费者只依赖Consumable接口  private Consumable consumer; ... @Override public Event input() { Message message = consumer.consume(topic); Map\u0026lt;String, String\u0026gt; header = new HashMap\u0026lt;\u0026gt;(); header.put(\u0026#34;topic\u0026#34;, topic); return Event.of(header, message.payload()); } ... } // demo/src/main/java/com/yrunz/designpattern/sidecar/AccessLogSidecar.java public class AccessLogSidecar implements Socket { // 生产者只依赖Producible接口  private final Producible producer; private final String topic ... @Override public void send(Packet packet) { if ((packet.payload() instanceof HttpReq)) { String log = String.format(\u0026#34;[%s][SEND_REQ]send http request to %s\u0026#34;, packet.src(), packet.dest()); Message message = Message.of(topic, log); producer.produce(message); } ... } ... } 接口隔离可以减少模块间耦合，提升系统稳定性，但是过度地细化和拆分接口，也会导致系统的接口数量的上涨，从而产生更大的维护成本。接口的粒度需要根据具体的业务场景来定，可以参考单一职责原则，将那些为同一类客户端程序提供服务的接口合并在一起。\nDIP：依赖倒置原则 《Clean Architecture》中介绍OCP时有提过：如果要模块A免于模块B变化的影响，那么就要模块B依赖于模块A。这句话貌似是矛盾的，模块A需要使用模块B的功能，怎么会让模块B反过来依赖模块A呢？这就是依赖倒置原则（The Dependency Inversion Principle，DIP）所要解答的问题。\nDIP的定义如下：\n  High-level modules should not import anything from low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details (concrete implementations) should depend on abstractions.   翻译过来，就是：\n 1、高层模块不应该依赖低层模块，两者都应该依赖抽象\n2、抽象不应该依赖细节，细节应该依赖抽象\n 在DIP的定义里，出现了高层模块、低层模块、抽象、细节等4个关键字，要弄清楚DIP的含义，理解者4个关键字至关重要。\n（1）高层模块和低层模块\n一般地，我们认为高层模块是包含了应用程序核心业务逻辑、策略的模块，是整个应用程序的灵魂所在；低层模块通常是一些基础设施，比如数据库、Web框架等，它们主要为了辅助高层模块完成业务而存在。\n（2）抽象和细节\n在前文“OCP：开闭原则”一节中，我们可以知道，抽象就是众多细节中的共同点，抽象就是不断忽略细节的出来的。\n现在再来看DIP的定义，对于第2点我们不难理解，从抽象的定义来看，抽象是不会依赖细节的，否则那就不是抽象了；而细节依赖抽象往往都是成立的。\n理解DIP的关键在于第1点，按照我们正向的思维，高层模块要借助低层模块来完成业务，这必然会导致高层模块依赖低层模块。但是在软件领域里，我们可以把这个依赖关系倒置过来，这其中的关键就是抽象。我们可以忽略掉低层模块的细节，抽象出一个稳定的接口，然后让高层模块依赖该接口，同时让低层模块实现该接口，从而实现了依赖关系的倒置：\n之所以要把高层模块和底层模块的依赖关系倒置过来，主要是因为作为核心的高层模块不应该受到低层模块变化的影响。高层模块的变化原因应当只能有一个，那就是来自软件用户的业务变更需求。\n下面，我们通过分布式应用系统demo来介绍DIP的实现。\n对于服务注册中心Registry来说，当有新的服务注册上来时，它需要把服务信息（如服务ID、服务类型等）保存下来，以便在后续的服务发现中能够返回给客户端。因此，Registry需要一个数据库来辅助它完成业务。刚好，我们的数据库模块实现了一个内存数据库MemoryDb，于是我们可以这么实现Registry：\n// 服务注册中心 public class Registry implements Service { ... // 直接依赖MemoryDb  private final MemoryDb db; private final SvcManagement svcManagement; private final SvcDiscovery svcDiscovery; private Registry(...) { ... // 初始化MemoryDb  this.db = MemoryDb.instance(); this.svcManagement = new SvcManagement(localIp, this.db, sidecarFactory); this.svcDiscovery = new SvcDiscovery(this.db); } ... } // 内存数据库 public class MemoryDb { private final Map\u0026lt;String, Table\u0026lt;?, ?\u0026gt;\u0026gt; tables; ... // 查询表记录  public \u0026lt;PrimaryKey, Record\u0026gt; Optional\u0026lt;Record\u0026gt; query(String tableName, PrimaryKey primaryKey) { Table\u0026lt;PrimaryKey, Record\u0026gt; table = (Table\u0026lt;PrimaryKey, Record\u0026gt;) tableOf(tableName); return table.query(primaryKey); } // 插入表记录  public \u0026lt;PrimaryKey, Record\u0026gt; void insert(String tableName, PrimaryKey primaryKey, Record record) { Table\u0026lt;PrimaryKey, Record\u0026gt; table = (Table\u0026lt;PrimaryKey, Record\u0026gt;) tableOf(tableName); table.insert(primaryKey, record); } // 更新表记录  public \u0026lt;PrimaryKey, Record\u0026gt; void update(String tableName, PrimaryKey primaryKey, Record record) { Table\u0026lt;PrimaryKey, Record\u0026gt; table = (Table\u0026lt;PrimaryKey, Record\u0026gt;) tableOf(tableName); table.update(primaryKey, record); } // 删除表记录  public \u0026lt;PrimaryKey\u0026gt; void delete(String tableName, PrimaryKey primaryKey) { Table\u0026lt;PrimaryKey, ?\u0026gt; table = (Table\u0026lt;PrimaryKey, ?\u0026gt;) tableOf(tableName); table.delete(primaryKey); } ... } 按照上面的设计，模块间的依赖关系是Registry依赖于MemoryDb，也即高层模块依赖于低层模块。这种依赖关系是脆弱的，如果哪天需要把存储服务信息的数据库从MemoryDb改成DiskDb，那么我们也得改Registry的代码：\n// 服务注册中心 public class Registry implements Service { ... // 改成依赖DiskDb  private final DiskDb db; ... private Registry(...) { ... // 初始化DiskDb  this.db = DiskDb.instance(); this.svcManagement = new SvcManagement(localIp, this.db, sidecarFactory); this.svcDiscovery = new SvcDiscovery(this.db); } ... } 更好的设计应该是把Registry和MemoryDb的依赖关系倒置过来，首先我们需要从细节MemoryDb抽象出一个稳定的接口Db：\n// demo/src/main/java/com/yrunz/designpattern/db/Db.java // DB抽象接口 public interface Db { \u0026lt;PrimaryKey, Record\u0026gt; Optional\u0026lt;Record\u0026gt; query(String tableName, PrimaryKey primaryKey); \u0026lt;PrimaryKey, Record\u0026gt; void insert(String tableName, PrimaryKey primaryKey, Record record); \u0026lt;PrimaryKey, Record\u0026gt; void update(String tableName, PrimaryKey primaryKey, Record record); \u0026lt;PrimaryKey\u0026gt; void delete(String tableName, PrimaryKey primaryKey); ... } 接着，我们让Registry依赖Db接口，而MemoryDb实现Db接口，以此来完成依赖倒置：\n// demo/src/main/java/com/yrunz/designpattern/service/registry/Registry.java // 服务注册中心 public class Registry implements Service { ... // 只依赖于Db抽象接口  private final Db db; private final SvcManagement svcManagement; private final SvcDiscovery svcDiscovery; private Registry(..., Db db) { ... // 依赖注入Db  this.db = db; this.svcManagement = new SvcManagement(localIp, this.db, sidecarFactory); this.svcDiscovery = new SvcDiscovery(this.db); } ... } // demo/src/main/java/com/yrunz/designpattern/db/MemoryDb.java // 内存数据库，实现Db抽象接口 public class MemoryDb implements Db { private final Map\u0026lt;String, Table\u0026lt;?, ?\u0026gt;\u0026gt; tables; ... // 查询表记录  @Override public \u0026lt;PrimaryKey, Record\u0026gt; Optional\u0026lt;Record\u0026gt; query(String tableName, PrimaryKey primaryKey) {...} // 插入表记录  @Override public \u0026lt;PrimaryKey, Record\u0026gt; void insert(String tableName, PrimaryKey primaryKey, Record record) {...} // 更新表记录  @Override public \u0026lt;PrimaryKey, Record\u0026gt; void update(String tableName, PrimaryKey primaryKey, Record record) {...} // 删除表记录  @Override public \u0026lt;PrimaryKey\u0026gt; void delete(String tableName, PrimaryKey primaryKey) {...} ... } // demo/src/main/java/com/yrunz/designpattern/Example.java public class Example { // 在main函数中完成依赖注入  public static void main(String[] args) { ... // 将MemoryDb.instance()注入到Registry上  Registry registry = Registry.of(..., MemoryDb.instance()); registry.run(); } } 当高层模块依赖抽象接口时，总得在某个时候，某个地方把实现细节（低层模块）注入到高层模块上。在上述例子中，我们选择在main函数上，在创建Registry对象时，把MemoryDb注入进去。\n一般地，我们都会在main/启动函数上完成依赖注入，常见的注入的方式有以下几种：\n 构造函数注入（Registry所使用的方法） setter方法注入 提供依赖注入的接口，客户端直调用该接口即可 通过框架进行注入，比如Spring框架中的注解注入能力  另外，DIP不仅仅适用于模块/类/接口设计，在架构层面也同样适用，比如DDD的分层架构和Uncle Bob的整洁架构，都是运用了DIP：\n当然，DIP并不是说高层模块是只能依赖抽象接口，它的本意应该是依赖稳定的接口/抽象类/具象类。如果一个具象类是稳定的，比如Java中的String，那么高层模块依赖它也没有问题；相反，如果一个抽象接口是不稳定的，经常变化，那么高层模块依赖该接口也是违反DIP的，这时候应该思考下接口是否抽象合理。\n最后 本文花了很长的篇幅讨论了23种设计模式背后的核心思想 —— SOLID原则，它能指导我们设计出高内聚、低耦合的软件系统。但是它毕竟只是原则，如何落地到实际的工程项目上，还是需要参考成功的实践经验。而这些实践经验正是接下来我们要探讨的设计模式。\n学习设计模式最好的方法就是实践，在《实践GoF的23种设计模式》后续的文章里，我们将以本文介绍的分布式应用系统demo作为实践示范，介绍23种设计模式的程序结构、适用场景、实现方法、优缺点等，让大家对设计模式有个更深入的理解，能够用对、不滥用设计模式。\n 参考\n Clean Architecture, Robert C. Martin (“Uncle Bob”) 敏捷软件开发：原则、模式与实践, Robert C. Martin (“Uncle Bob”) 使用Go实现GoF的23种设计模式, 元闰子 SOLID原则精解之里氏替换原则LSP, 人民副首席码仔  更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-02-26T00:00:00Z","permalink":"https://www.yrunz.com/p/java%E5%AE%9E%E7%8E%B0%E5%AE%9E%E8%B7%B5gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fsolid%E5%8E%9F%E5%88%99/","title":"【Java实现】实践GoF的23种设计模式：SOLID原则"},{"content":"新年将至，照例还是要对过去的2021年做个小结。在过去的一年里，读过的书不多，写过的文章也少，生活倒是有不少感悟。\n阅读                         2021年读过的书不多，从数量上看，比起往年还是少了些。一方面是懒惰的天性驱使；另一方面也是读得更慢了。以前读书很多时候是为了追求知识广度，走马观花浏览一遍，留个大致的印象便算完事。久而久之，虽然明面上读了不少书，但是知识倒是没涨多少。\n为此，自己也在不断思考如何更好地读书，于是开始尝试做笔记，在读书过程中把关键知识和自己的思考记录下来。然后发现，读书笔记不仅仅有助于加深对知识的理解，而且为文章的写作提供了很好的素材。于是就逐渐养成了读书过程中做笔记的习惯，读书的速度也就慢下来了。\n 《Fundamentals of Software Architecture》：被称为是架构师的入门指南，重点介绍了当今常见的8种架构模式。每种架构模式都有其优缺点以及适用场景，并不存在所谓的“银弹”。正如作者书中提到，Everything in software architecture is a trade-off。 《Microservices vs Service-Oriented Architecture》：可作为《Fundamentals of Software Architecture》的延伸阅读材料，重点对比了微服务架构和基于服务的架构之间的优缺点，有助于加深对两种架构的异同点的理解。 《Operating Systems: Three Easy Pieces》：读过的写得最好的操作系统书籍，作者把复杂的基本原理介绍得通俗易懂，又不乏深度。整本书条理清晰，非常值得一读，中文版被翻译成《操作系统导论》。 《软件架构设计：大型网站技术架构与业务架构融合之道》：同样是以架构设计为主题，相比于《Fundamentals of Software Architecture》，这本更“接地气”，不仅介绍了高并发、数据一致性等常用问题的解决方法，还介绍了诸如操作系统、数据库、网络等基础知识。 《凤凰架构》：周志明老师的又一力作，从架构的视角介绍了如何构建大型分布式系统，全书的话题涉猎很广，基本把分布式系统所能涉及的知识点都讲解了，比如远程服务调用、事务、安全、一致性等。书中罗列了很多参考阅读材料，可作为进阶架构师的一本导航书，如果把其中提到的知识点都研究透，那么可以就成为专家了。 《The Programmer\u0026rsquo;s Brain》：从认知科学的角度教你如何更好地阅读代码、理解代码、编写代码，对于程序员新手来说值得一读。书中提到的很多学习程序的方法，感觉就是将有经验的程序员的一些学习方法，结合认知科学的理论更好地呈现了出来。 《吴军阅读与写作讲义》：某天在一家书店上花了一下午的时间浏览完这本书的上半部分——“如何阅读和写作”，书中讨论的正是理工科学生容易忽视的阅读、写作、表达等软能力。 《邓小平时代》：读完本书，一方面被邓小平的坚韧、格局、领导力所屈服，另一方面也看到了我党一路走来也是在不断地犯错-反思-改正-进步。恰逢2021年是我党建党100周年，这一年里也看了很多关于党史的影视节目，对我党历史也有了更深刻的了解。从觉醒年代，到北伐战争，然后长征、抗日、大决战、抗美援朝、文革、改革开放，一路走来，我党在黑暗中不断摸索前行，磕磕碰碰，逐渐找到一条通往光明的道路。 《刘擎西方现代思想讲义》：通过介绍十多位西方思想家的思想结晶，将西方现代思想从启蒙逐渐走向成熟的过程呈现给读者。随着物质生活的满足，现代人也慢慢开始寻找人生的意义，“我是谁”，“我在做什么”，“我为什么这么做“，这些问题，那些伟大的思想家都有想过，读完这本书，也许会找到一些答案。   前些天有幸听了一场“哲学王子”王德峰的讲座，感触很大。中国的哲学（主要是孔子的儒家思想）和西方的哲学（主要是柏拉图的理念论）差别还是蛮大的，这也决定了西方和中国发展道路的不同。西方强调改变世界，中国则是强调天人合一。虽然目前结果来看，西方会更成功一些，但是天人合一的可持续发展也许更有潜力。\n  《人体简史》：印象最深的是书中最后关于衰老和死亡的描述，对于我们大多数人来说，死亡是能想象出的最可怕的事情，但是对于宇宙来说，人的死亡只不过又是物质的一次循环罢了。 “一具尸体仍然生机勃勃，只不过，它不再是你的生命。它属于你留下的细菌，以及其他蜂拥而至的细菌”。 《认知觉醒》：早冥读写跑，人生五件套；做每一件事情都要专注事情本身；坚持每日反思，每日计划。作者所提倡的这些虽然很难全部做到，但是至少在心里留下了个烙印，也在不断尝试在这个快节奏的生活里，学着慢下来专注和思考。 《巨人的陨落》、《世界的凛冬》、《永恒的边缘》：肯福莱特先生的三部史诗巨作，以小人物的视角讲述从一战到冷战的西方世界历史发展之路。在历史的滚滚车轮里，每一个迈向死亡的生命都在热烈地生长。这是对有声书的首次尝试，惠天和言亮老师（非星凡文化@喜马拉雅）的双人播讲体验极好，是通勤路上的必备小伴侣。除了小说剧情之外，两位老师以知识卡片的形式延伸了很多历史知识和人性感悟，非常值得一听。  写作 2021年只写了10篇文章，产出还是一如既往的少。而且一些打算写成系列的文章写着写着都烂尾断更了（2020年的《使用Go实现GoF的23种设计模式》系列，2021年的《从分层架构到微服务架构》系列），许多朋友催更也无果。倒不是因为偷懒，而是那份兴致很难再提起了，毕竟人总是喜新厌旧的😄。这也促使我后面宁愿写长文，也轻易不会再写系列短文。\n 《如何高效编写Go单元测试（一）》、《如何高效编写Go单元测试（二）》：少有写完的系列文章。虽然Go官方已经提供了单元测试能力（test标准库），但是对用惯了Java成熟的单元测试框架的我来说，原生的go test的功能还是很单薄。于是就查找了一些资料，把当前Go语言下比较流行的单元测试框架的用法总结成了这两篇文章。 《从分层架构到微服务架构（一）》、《从分层架构到微服务架构（二）之分层架构》、《从分层架构到微服务架构（三）之管道架构》、《从分层架构到微服务架构（四）之微内核架构》：第一烂尾系列，本来打算写九篇的，结果写到第四篇就停止了。这几篇文章都是对《Fundamentals of Software Architecture》这本书的总结笔记，主要介绍8种常见的软件架构模式，对比各种架构模式的优缺点，帮助大家更好地做架构选型。感兴趣的建议直接阅读原书，后面的更新也会尽量补上。 《教你写好技术文章》：从2019年底开始写技术文章，到如今已经两年多了，这期间深感技术写作给自己带来的好处。在五一假期心血来潮，就把这两年来一些技术写作的感悟、方法记录下来。写好文章的方法很多，但最简单，也是最有效的方法还是：不要停止写作。 《《认知觉醒》的读后感》：读完《认知觉醒》这本书后，感触颇大，于是就有了这篇读后感。《认知觉醒》是一本关于如何学习成长的书籍，书中介绍的很多高效成长方法都很实用，虽然很难坚持便是了。 《探索CPU的调度原理》：这篇是《Operating Systems: Three Easy Pieces》一书中关于CPU调度原理的关键知识点总结。个人感觉这是全书写得最好的一个篇章，读完之后有种豁然开朗的感觉。作者从最简单的FIFO调度说起，到最后的CFS完全公平调度，层层递进，阅读体验极好，知识密度也很大。 《实现DCI架构》：这篇文章来源于今年工作中的代码重构实践。在某些场景下，使用DDD中的战术建模设计出来的代码会存在“上帝类”、可维护性差等问题，主要原因还是DDD和传统的面向对象编程在对行为的建模上有所欠缺，这也导致了贫血模型和充血模型之争。于是，通过查阅资料找到了DCI建模方法，它可以看成是DDD战术建模的一种辅助。将DCI架构总结成一句话就是：领域对象（Object）在不同的场景（Context）中扮演（Cast）不同的角色（Role），角色之间通过交互（Interactive）来完成具体的业务逻辑。 《探索OS的内存管理原理》：同样也是《Operating Systems: Three Easy Pieces》的读书笔记，是关于内存管理篇章的总结提炼，介绍了独占式内存管理、段式内存管理、页式内存管理、TLB等基本原理，理解这些原理，对于写出高效程序有很大的好处。  生活 旅行 2021年只有国庆期间去了一趟云南旅行，玉龙雪山、涑河古镇、泸沽湖、丽江古城、虎跳峡、松赞林寺、普达措森林公园，6天的时间不长，但该去的景点基本也都去了，度过了开心的几天。2015年冬天也去过一次云南，也是6天时间，走的是大理-香格里拉路线。游玩的景点不多，因为当时真的是穷游：住在刚下过暴雪但没有热水的青旅、到了雪山下却没钱坐缆车上去、没钱打车只能步行6公里\u0026hellip;..对比今年的这次旅行，只能说预算充足真的好，2022年还要继续加油赚钱！\n徒步 2021年徒步了4次，都是在深圳，有艰难的东西冲穿越、登顶大雁岭，也有养生的爬南山、走梧桐绿道。最近几年基本每年都会去徒步几次，深感徒步是一件痛并快乐着的活动，特别是攀山越岭，攀登的过程是痛苦的，但是登顶的瞬间又会豁然开朗。除了看到了绝美的景色和呼吸到新鲜的空气外，更是因为成功的喜悦：在自己征服过的山的名单里，又多了一座山。\n电影 2021年完整看完的电影比较少，更多的是通过观看B站UP主@木鱼水心和@电影最TOP的影视解说栏目来速览剧情，在2位UP主的熏陶下，感觉自己的电影鉴赏水平也提升了不少😄。电影也是一门艺术，好的电影确实能够引人深思，但也需要一定的电影鉴赏能力和背景知识才能理解导演的用意，就像阅读理解能力之于阅读。\n生命 在过去的一年里，有亲人在医生断言机会渺茫的时候挺了过来，也有好友没能抵住病魔在花样的年纪离我们而去。人的生命是何等的脆弱，健康与疾病，生与死往往都只在一瞬之间。现在能做的，也就是好好珍惜当下，早点养生，健康生活。\n最后，如果新年有什么期望的话，那就是大家身体健康，凡事多加思考。\n","date":"2022-01-31T00:00:00Z","permalink":"https://www.yrunz.com/p/2021%E5%B9%B4%E5%B0%8F%E7%BB%93/","title":"2021年小结"},{"content":"前言 内存作为计算机系统的组成部分，跟开发人员的日常开发活动有着密切的联系，我们平时遇到的Segment Fault、OutOfMemory、Memory Leak、GC等都与它有关。本文所说的内存，指的是计算机系统中的主存（Main Memory），它位于存储金字塔中CPU缓存和磁盘之间，是程序运行不可或缺的一部分。\n在计算机系统中，主存通常都是由操作系统（OS）来管理，而内存管理的细则对开发者来说是无感的。对于一个普通的开发者，他只需懂得如何调用编程语言的接口来进行内存申请和释放，即可写出一个可用的应用程序。如果你使用的是带有垃圾回收机制的语言，如Java和Go，甚至都不用主动释放内存。但如果你想写出高效应用程序，熟悉OS的内存管理原理就变得很有必要了。\n下面，我们将从最简单的内存管理原理说起，带大家一起窥探OS的内存管理机制，由此熟悉底层的内存管理机制，写出高效的应用程序。\n独占式内存管理 早期的单任务系统中，同一时刻只能有一个应用程序独享所有的内存（除开OS占用的内存），因此，内存管理可以很简单，只需在内存上划分两个区域：\n在多任务系统中，计算机系统已经可以做到多个任务并发运行。如果还是按照独占式的管理方式，那么每次任务切换时，都会涉及多次内存和磁盘之间的数据拷贝，效率极其低下：\n最直观的解决方法就是让所有程序的数据都常驻在内存中（假设内存足够大），这样就能避免数据拷贝了：\n但这样又会带来另一个问题，程序之间的内存地址空间是没有隔离的，也就是程序A可以修改程序B的内存数据。这样的一个重大的安全问题是用户所无法接受的，要解决该问题，就要借助虚拟化的力量了。\n虚拟地址空间 为了实现程序间内存的隔离，OS对物理内存做了一层虚拟化。OS为每个程序都虚拟化出一段内存空间，这段虚拟内存空间会映射到一段物理内存上。但对程序自身而言，它只能看到自己的虚拟地址空间，也就有独占整个内存的错觉了。\n上图中，虚拟内存空间分成了三个区域，其中Code区域存储的是程序代码的机器指令；Heap区域存储程序运行过程中动态申请的内存；Stack区域则是存储函数入参、局部变量、返回值等。Heap和Stack会在程序运行过程中不断增长，分别放置在虚拟内存空间的上方和下方，并往相反方向增长。\n从虚拟地址空间到物理地址空间的映射，需要一个转换的过程，完成这个转换运算的部件就是MMU（memory management unit），也即内存管理单元，它位于CPU芯片之内。\n要完成从虚拟地址到物理地址到转换，MMU需要base和bound两个寄存器。其中base寄存器用来存储程序在物理内存上的基地址，比如在图5中，程序A的基地址就是192KB；bound寄存器（有时候也叫limit寄存器）则保存虚拟地址空间的Size，主要用来避免越界访问，比如图5中程序A的size值为64K。那么，基于这种方式的地址转换公式是这样的：\n 物理地址 = 虚拟地址 + 基地址\n 以图5中程序A的地址转换为例，当程序A尝试访问超过其bound范围的地址时，物理地址会转换失败：\n现在，我们再次仔细看下程序A的物理内存分布，如下图7所示，中间有很大的一段空闲内存是“已申请，未使用”的空闲状态。这也意味着即使这部分是空闲的，也无法再次分配给其他程序使用，这是一种巨大的空间浪费！为了解决这个内存利用率低下的问题，我们熟悉的段式内存管理出现了。\n段式内存管理 在上一节中，我们发现如果以程序为单位去做内存管理，会存在内存利用率不足的问题。为了解决该问题，段式内存管理被引入。段（Segment）是逻辑上的概念，本质上是一块连续的、有一定大小限制的内存区域，前文中，我们一共提到过3个段：Code、Heap和Stack。\n段式内存管理以段为单位进行管理，它允许OS将每个段灵活地放置在物理内存的空闲位置上，因此也避免了“已申请，未使用”的内存区域出现：\n地址转换 从上图8可知，段式内存管理中程序的物理内存空间可能不再连续了，因此为了实现从虚拟地址到物理地址到转换，MMU需要为每个段都提供一对base-bound寄存器，比如：\n给一个虚拟地址，MMU是如何知道该地址属于哪个段，从而根据对应的base-bound寄存器转换为对应的物理地址呢？\n假设虚拟地址有16位，因为只有3个段，因此，我们可以使用虚拟地址的高2位来作为段标识，比如00表示Code段，01表示Heap段，11表示Stack段。这样MMU就能根据虚拟地址来找到对应段的base-bound寄存器了：\n但这样还不是能够顺利的将虚拟地址转换为物理地址，我们忽略了重要的一点：Heap段和Stack段的增长方向是相反的，这也意味着两者的地址转换方式是不一样的。因此，我们还必须在虚拟地址中多使用一位来标识段的增长方向，比如0表示向上（低地址方向）增长，1表示向下（高地址方向）增长：\n下面，看一组段式内存管理地址转换的例子：\n那么，总结段式内存管理的地址转换算法如下：\n// 获取当前虚拟地址属于哪个段 Segment = (VirtualAddress \u0026amp; SEG_MASK) \u0026gt;\u0026gt; SEG_SHIFT // 得到段内偏移量 Offset = VirtualAddress \u0026amp; OFFSET_MASK // 获得内存增长的方向 GrowsDirection = VirtualAddress \u0026amp; GROWS_DIRECTION_MASK // 有效性校验 if (Offset \u0026gt;= Bounds[Segment]) RaiseException(PROTECTION_FAULT) else if (GrowsDirection == 0) { PhysAddr = Base[Segment] + Offset } else { PhysAddr = Base[Segment] - Offset } 内存共享和保护 段式内存管理还可以很方便地支持内存共享，从而达到节省内存的目的。比如，如果存在多个程序都是同一个可执行文件运行起来的，那么这些程序是可以共享Code段的。为了实现这个功能，我们可以在虚拟地址上设置保护位，当保护位为只读时，表示该段可以共享。另外，如果程序修改了只读的段，则转换地址失败，因此也可以达到内存保护的目的。\n内存碎片 段式内存管理的最明显的缺点就是容易产生内存碎片，这是因为在系统上运行的程序的各个段的大小往往都不是固定的，而且段的分布也不是连续的。当系统的内存碎片很多时，内存的利用率也会急剧下降，对外表现就是虽然系统看起来还有很多内存，却无法再运行起一个程序。\n解决内存碎片的方法之一是定时进行碎片整理：\n但是碎片整理的代价极大，一方面需要进行多次内存拷贝；另一方面，在拷贝过程中，正在运行的程序必须停止，这对于一些以人机交互任务为主的应用程序，将会极大影响用户体验。\n另一个解决方法就是接下来要介绍的页式内存管理。\n页式内存管理 页式内存管理的思路，是将虚拟内存和物理内存都划分为多个固定大小的区域，这些区域我们称之为页（Page）。页是内存的最小分配单位，一个应用程序的虚拟页可以存放在任意一个空闲的物理页中。\n 物理内存中的页，我们通常称之为页帧（Page Frame）\n 因为页的大小是固定的，而且作为最小的分配单位，这样就可以解决段式内存管理中内存碎片的问题了。\n 但页内仍然有可能存在内存碎片。\n 地址转换 页式内存管理使用页表（Page Table）来进行虚拟地址到物理地址到转换，地址转换的关键步骤如下：\n1）根据虚拟页找到对应的物理页帧\n每个虚拟页都有一个编号，叫做VPN（Virtual Page Number）；相应的，每个物理页帧也有一个编号，叫做PFN（Physical Frame Number）。页表存储的就是VPN到PFN的映射关系。\n2）找到地址在物理页帧内的偏移（Offset）\n地址在物理页帧内的偏移与在虚拟页内的偏移保持一致。\n我们可以将虚拟地址划分成两部分，分别存储VPN和Offset，这样就能通过VPN找到PFN，从而得到PFN+Offset的实际物理地址了。\n比如，假设虚拟内存空间大小为64Byte（6位地址），页的大小为16Byte，那么整个虚拟内存空间一共有4个页。因此我们可以使用高2位来存储VPN，低4位存储Offset：\n下面看一个转换例子，VPN（01）通过页表找到对应的PFN（111），虚拟地址和物理地址的页内偏移都是0100，那么虚拟地址010100对应的物理地址就是1110100了。\n页表和页表项 OS为每个程序都分配了一个页表，存储在内存当中，页表里由多个页表项（PTE，Page Table Entry）组成。我们可以把页表看成是一个数组，数组的元素为PTE：\n以x86系统下的PTE组成为例，PTE一共占32位，除了PFN之外，还有一些比较重要的信息，比如P（Present）标识当前页是否位于内存上（或是磁盘上）；R/W（Read/Write）标识当前页是否允许读写（或是只读）；U/S（User/Supervisor）标识当前页是否允许用户态访问；A（Access）标识当前页是否被访问过，在判断当前页是否为热点数据、页换出时特别有用；D（Dirty）标识当前页是否被修改过。\n页式内存管理的缺点 地址转换效率低 根据前文介绍，我们可以总结页式内存管理机制下地址转换的算法如下：\n// 从虚拟地址上得到VPN VPN = (VirtualAddress \u0026amp; VPN_MASK) \u0026gt;\u0026gt; SHIFT // 找到VPN对应的PTE的内存地址 PTEAddr = PTBR + (VPN * sizeof(PTE)) // 访问主存，获取PTE PTE = AccessMemory(PTEAddr) // 有效性校验 if (PTE.Valid == False) RaiseException(INVALID_ACCESS) else // 获取页内偏移量  offset = VirtualAddress \u0026amp; OFFSET_MASK // 计算得出物理地址  PhysAddr = (PTE.PFN \u0026lt;\u0026lt; PFN_SHIFT) | offset 我们发现，每次地址转换都会访问一次主存来获取页表，比段式内存管理（无主存访问）低效很多。\n占用空间大 假设地址空间为32-bit，页的大小固定为4KB，那么整个地址空间一共有$2^{32}/4KB=2^{20}$个页表，也即页表一共有$2^{20}$个PTE。现假设每个PTE大小为4-byte，那么每个页表占用4MB的内存。如果整个系统中有100个程序在运行，那么光是页表就占用了400MB的内存，这同样是用户无法接受的。\n接下来，我们将介绍如何去优化页式内存管理的这两个显著缺点。\n让页式管理的地址转换更快 TLB：Translation-Lookaside Buffer 根据前文所述，页式内存管理地址转换因为多了一次主存访问，导致效率很低。如果能够避免或者减少对主存的访问，那么就能让地址转换更快了。\n很多人应该都可以想到通过增加缓存的方式提升效率，比如为避免频繁查询磁盘，我们一般在内存中增加一层缓存来提升数据访问效率。那么为了提升访问主存中数据的效率，自然应该在离CPU更近的地方增加一层缓存。这个离CPU更近的地方，就是前文提到的位于CPU芯片之内的MMU。而这个高速缓存，就是TLB（Translation-Lookaside Buffer），它缓存了VPN到PFN到映射关系，类似于这样：\n增加TLB之后，地址转换的算法如下：\nVPN = (VirtualAddress \u0026amp; VPN_MASK) \u0026gt;\u0026gt; SHIFT (Success, TlbEntry) = TLB_Lookup(VPN) if (Success == True) // TLB Hit  if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress \u0026amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN \u0026lt;\u0026lt; SHIFT) | Offset else RaiseException(PROTECTION_FAULT) else // TLB Miss  PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() 从上述算法可以发现，在TLB缓存命中（TLB Hit）时，能够避免直接访问主存，从而提升了地址转换的效率；但是在TLB缓存不命中（TLB Miss）时，仍然需要访问一次主存，而且还要往TLB中插入从主存中查询到的PFN，效率变得更低了。因此，我们必须尽量避免TLB Miss的出现。\n更好地利用TLB 下面，我们通过一个数组遍历的例子来介绍如何更好地利用TLB。\n假设我们要进行如下的一次数组遍历：\nint sum = 0; for (i = 0; i \u0026lt; 10; i++) { sum += a[i]; } 数组的内存的分布如下：\na[0]~a[2]位于Page 5上，a[3]~a[6]位于Page 6上，a[7]~a[8]位于Page 7上。当我们首先访问a[0]时，由于Page 5并未在TLB缓存里，所以会先出现一次TLB Miss，接下来的a[1]和a[2]都是TLB Hit；同理，访问a[3]和a[7]时都是TLB Miss，a[4]~a[6]和a[8]~a[9]都是TLB Hit。所以，整个数组遍历下来，TLB的缓存命中情况为：Miss，Hit，Hit，Miss，Hit，Hit，Hit，Miss，Hit，Hit，TLB缓存命中率为70%。我们发现，访问同一页上的数据TLB的缓存更易命中，这就是空间局部性的原理。\n接下来，我们再次重新遍历一次数组，由于经过上一次之后Page 5 ～ Page 7的转换信息已经在TLB缓存里里，所以第二次遍历的TLB命中情况为：Hit，Hit，Hit，Hit，Hit，Hit，Hit，Hit，Hit，Hit，TLB缓存命中率为100%！这就是时间局部性的原理，短时间内访问同一内存数据也能够提升TLB缓存命中率。\nTLB的上下文切换 因为TLB缓存的是当前正在运行程序的上下文信息，当出现程序切换时，TLB里面的上下文信息也必须更新，否则地址转换就会异常。解决方法主要有2种：\n 方法1：每次程序切换都清空TLB缓存（Flush TLB），让程序在运行过程中重新建立缓存。 方法2：允许TLB缓存多个程序的上下文信息，并通过ASID（address space identifier，地址空间标识符，可以理解为程序的PID）做区分。  方法1实现简单，但是每次程序切换都需要重新预热一遍缓存，效率较低，主流的做法是采用方法2。\n 需要注意的是TLB是嵌入到CPU芯片之内的，对于多核系统而言，如果程序在CPU之间来回切换，也是需要重新建立TLB缓存！因此，把一个程序绑定在一个固定的核上有助于提升性能。\n 让页表更小 大页内存 降低页表大小最简单的方法就是让页更大。前文的例子中，地址空间为32-bit，页的大小为4KB，PTE的大小为4-byte，那么每个页表需要4MB的内存空间。现在，我们把页的大小增加到16KB，其他保持不变，那么每个页表只需要$2^{32}/16KB=2^{18} $个PTE，也即1MB内存，内存占用降低了4倍。\n大页内存对TLB的使用也有优化效果，因TLB能够缓存的上下文数量是固定的，当页的数量更少时，上下文换出的频率会降低，TLB的缓存命中率也就增加了，从而让地址转换的效率更高。\n段页式内存管理 根据前文所述，程序的地址空间中，堆与栈之间的空间很多时候都是处于未使用状态。对应到页表里，就是有很大一部分的PTE是invalid状态。但因为页表要涵盖整个地址空间的范围，这部分invalid的PTE只能留在页表中，从而造成了很大的空间浪费。\n前文中，我们通过段式内存管理解决了堆与栈之间内存空间的浪费问题。对应到页表中，我们也可以为页式内存管理引入段式管理的方式，也即段页式内存管理，解决页表空间浪费的问题。\n具体的方法是，为程序的地址空间划分出多个段，比如Code、Heap、Stack等。然后，在每个段内单独进行页式管理，也即为每个段引入一个页表：\n从上图可知，将页表分段之后，页表不再需要记录那些处于空闲状态的页的PTE，从而节省了内存空间的消耗。\n多级页表 降低页表大小另一个常见的方法就是多级页表（Multi-level Page Table），多级页表的思路也是减少处于空闲状态的页的PTE数量，但方法与段页式内存管理不同。如果说段页式内存管理可以看成是将页表分段，那么多级页表则可以看成是将页表分页。\n具体的做法是将页表按照一定大小分成多个部分（页目录，Page Directory，PD），如果某个页目录下所有的页都是处于空闲状态，则无须为该页目录下的页申请PTE。\n以二级页表为例，下图对比了普通页表和多级页表的构成差异：\n下面，我们再对比一下普通页表和多级页表的空间消耗。还是假设地址空间为32-bit，页的大小为4KB，PTE的大小为4-byte，一共有$2^{20}$个页，那么普通页表需要4MB的内存空间。现在，我们将$2^{20}$个页切分为$2^{10}$份，也即有$2^{10}$个页目录，每个页目录下管理$2^{10}$个页，也即有$2^{10}$个PDE（Page Directory Entry）。假设PDE也占4-byte内存，且根据20/80定律假设有80%的页处于空闲状态，那么二级页表只需要0.804MB！(${2^{10}*4}$${+2^{20}4(1-80%)}$)\n由此可见，多级页表能够有效降低页表的内存消耗。多级页表在实际运用中还是较为常见的，比如Linux系统采用的就是4级页表的结构。\nSwap Sapce: 磁盘交换区 到目前为止，我们都是假设物理内存足够大，可以容纳所有程序的虚拟内存空间。然而，这往往是不切实际的，以32-bit地址空间为例，一个程序的虚拟内存为4G，假设有100个程序，那么一共需要400G的物理内存（忽略共享部分）！另外，程序运行过程中，并不是一直都需要所有的页，很多时候只需要其中的一小部分。\n因此，如果我们可以先把那些暂时用不到的页先存在磁盘上，等需要用到时再加载到内存上，那么就可以节省很多物理内存。磁盘中用来存放这些页的区域，被称作Swap Sapce，也即交换区。\n在这种机制之下，当程序访问某一个地址，而这个地址所在的页又不在内存上时，就会触发缺页（Page Fault）中断。就像TLB缓存不命中时会带来额外的开销一样，缺页也会导致内存的访问效率降低。因为在处理缺页中断时，OS必须从磁盘交换区上把数据加载到内存上；而且当空闲内存不足时，OS还必须将内存上的某些页换出到交换区中。这一进一出的磁盘IO访问也直接导致缺页发生时，内存访问的效率下降许多。\n因此，在空闲内存不足时，页的换出策略显得极为重要。如果把一个即将要被访问的页换出到交换区上，就会带来本可避免的无谓消耗。页的换出策略很多，常见的有FIFO（先进先出）、Random（随机）、LRU（最近最少使用）、LFU（最近最不经常使用）等。在常见的工作负载下，FIFO和Random算法的效果较差，实际用的不多；LRU和LFU算法都是建立在历史内存访问统计的基础上，因此表现较前两者好些，实际应用也多一些。目前很多主流的操作系统的页换出算法都是在LRU或LFU的基础上进行优化改进的结果。\n最后 本文主要介绍了OS内存管理的一些基本原理，从独占式内存管理，到页式内存管理，这过程中经历了许多次优化。这其中的每一种优化手段，都朝着如下3个目标前进：\n1、透明化（transparency）。内存管理的细节对程序不可见，换句话说，程序可以自认为独占整个内存空间。\n2、效率（efficiency ）。地址转换和内存访问的效率要高，不能让程序运行太慢；空间利用效率也要高，不能占用太多空闲内存。\n3、保护（protection）。保证OS自身不受应用程序的影响；应用程序之间也不能相互影响。\n当然，目前主流的操作系统（如Linux、MacOS等）的内存管理机制要比本文介绍的原理复杂许多，但本质原理依然离不开本文所描述的几种基础的内存管理原理。\n 参考\n1、Operating Systems: Three Easy Pieces, Remzi H Arpaci-Dusseau / Andrea C Arpaci-Dusseau\n2、为什么 HugePages 可以提升数据库性能 , 面向信仰编程\n3、探索CPU的调度原理, 元闰子的邀请\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2022-01-09T00:00:00Z","permalink":"https://www.yrunz.com/p/%E6%8E%A2%E7%B4%A2os%E7%9A%84%E5%86%85%E5%AD%98%E5%8E%9F%E7%90%86/","title":"探索OS的内存原理"},{"content":"前言 在面向对象编程的理念里，应用程序是对现实世界的抽象，我们经常会将现实中的事物建模为编程语言中的类/对象（“是什么”），而事物的行为则建模为方法（“做什么”）。面向对象编程有三大基本特性（封装、继承/组合、多态）和五大基本原则（单一职责原则、开放封闭原则、里氏替换原则、依赖倒置原则、接口分离原则），但知道这些还并不足以让我们设计出好的程序，于是很多方法论就涌现了出来。\n近来最火的当属领域驱动设计（DDD），其中战术建模提出的实体、值对象、聚合等建模方法，能够很好的指导我们设计出符合现实世界的领域模型。但DDD也不是万能的，在某些应用场景下，按照传统的战术建模/面向对象方法设计出来的程序，也会存在可维护性差、违反单一职责原则等问题。\n本文介绍的DCI建模方法可以看成是战术建模的一种辅助，在某些场景下，它可以很好的弥补DDD战术建模的一些缺点。接下来，我们将会通过一个案例来介绍DCI是如何解决DDD战术建模的这些缺点的。\n 本文涉及的代码归档在github项目：https://github.com/ruanrunxue/DCI-Architecture-Implementation\n 案例 考虑一个普通人的生活日常，他会在学校上课，也会趁着暑假去公司工作，在工作之余去公园游玩，也会像普通人一样在家吃喝玩乐。当然，一个人的生活还远不止这些，为了讲解方便，本文只针对这几个典型的场景进行建模示例。\n使用DDD建模 按照DDD战术建模的思路，首先，我们会列出该案例的通用语言：\n 人、身份证、银行卡、家、吃饭、睡觉、玩游戏、学校、学生卡、学习、考试、公司、工卡、上班、下班、公园、购票、游玩\n 接着，我们使用战术建模技术（值对象、实体、聚合、领域服务、资源库）对通用语言进行领域建模。\nDDD建模后的代码目录结构如下：\n- aggregate:聚合- company.go- home.go- park.go- school.go- entity:实体- people.go- vo:值对象- account.go- identity_card.go- student_card.go- work_card.go我们将身份证、学生卡、工卡、银行卡这几个概念，建模为值对象（Value Object）：\npackage vo // 身份证 type IdentityCard struct { Id uint32 Name string } // 学生卡 type StudentCard struct { Id uint32 Name string School string } // 工卡 type WorkCard struct { Id uint32 Name string Company string } // 银行卡 type Account struct { Id uint32 Balance int } ... 接着我们将人建模成实体（Entity），他包含了身份证、学生卡等值对象，也具备吃饭、睡觉等行为：\npackage entity // 人 type People struct { vo.IdentityCard vo.StudentCard vo.WorkCard vo.Account } // 学习 func (p *People) Study() { fmt.Printf(\u0026#34;Student %+v studying\\n\u0026#34;, p.StudentCard) } // 考试 func (p *People) Exam() { fmt.Printf(\u0026#34;Student %+v examing\\n\u0026#34;, p.StudentCard) } // 吃饭 func (p *People) Eat() { fmt.Printf(\u0026#34;%+v eating\\n\u0026#34;, p.IdentityCard) p.Account.Balance-- } // 睡觉 func (p *People) Sleep() { fmt.Printf(\u0026#34;%+v sleeping\\n\u0026#34;, p.IdentityCard) } // 玩游戏 func (p *People) PlayGame() { fmt.Printf(\u0026#34;%+v playing game\\n\u0026#34;, p.IdentityCard) } // 上班 func (p *People) Work() { fmt.Printf(\u0026#34;%+v working\\n\u0026#34;, p.WorkCard) p.Account.Balance++ } // 下班 func (p *People) OffWork() { fmt.Printf(\u0026#34;%+v getting off work\\n\u0026#34;, p.WorkCard) } // 购票 func (p *People) BuyTicket() { fmt.Printf(\u0026#34;%+v buying a ticket\\n\u0026#34;, p.IdentityCard) p.Account.Balance-- } // 游玩 func (p *People) Enjoy() { fmt.Printf(\u0026#34;%+v enjoying park scenery\\n\u0026#34;, p.IdentityCard) } 最后，我们将学校、公司、公园、家建模成聚合（Aggregate），聚合由一个或多个实体、值对象组合而成，组织它们完成具体的业务逻辑：\npackage aggregate // 家 type Home struct { me *entity.People } func (h *Home) ComeBack(p *entity.People) { fmt.Printf(\u0026#34;%+v come back home\\n\u0026#34;, p.IdentityCard) h.me = p } // 执行Home的业务逻辑 func (h *Home) Run() { h.me.Eat() h.me.PlayGame() h.me.Sleep() } // 学校 type School struct { Name string students []*entity.People } func (s *School) Receive(student *entity.People) { student.StudentCard = vo.StudentCard{ Id: rand.Uint32(), Name: student.IdentityCard.Name, School: s.Name, } s.students = append(s.students, student) fmt.Printf(\u0026#34;%s Receive stduent %+v\\n\u0026#34;, s.Name, student.StudentCard) } // 执行School的业务逻辑 func (s *School) Run() { fmt.Printf(\u0026#34;%s start class\\n\u0026#34;, s.Name) for _, student := range s.students { student.Study() } fmt.Println(\u0026#34;students start to eating\u0026#34;) for _, student := range s.students { student.Eat() } fmt.Println(\u0026#34;students start to exam\u0026#34;) for _, student := range s.students { student.Exam() } fmt.Printf(\u0026#34;%s finish class\\n\u0026#34;, s.Name) } // 公司 type Company struct { Name string workers []*entity.People } func (c *Company) Employ(worker *entity.People) { worker.WorkCard = vo.WorkCard{ Id: rand.Uint32(), Name: worker.IdentityCard.Name, Company: c.Name, } c.workers = append(c.workers, worker) fmt.Printf(\u0026#34;%s Employ worker %s\\n\u0026#34;, c.Name, worker.WorkCard.Name) } // 执行Company的业务逻辑 func (c *Company) Run() { fmt.Printf(\u0026#34;%s start work\\n\u0026#34;, c.Name) for _, worker := range c.workers { worker.Work() } fmt.Println(\u0026#34;worker start to eating\u0026#34;) for _, worker := range c.workers { worker.Eat() } fmt.Println(\u0026#34;worker get off work\u0026#34;) for _, worker := range c.workers { worker.OffWork() } fmt.Printf(\u0026#34;%s finish work\\n\u0026#34;, c.Name) } // 公园 type Park struct { Name string enjoyers []*entity.People } func (p *Park) Welcome(enjoyer *entity.People) { fmt.Printf(\u0026#34;%+v come to park %s\\n\u0026#34;, enjoyer.IdentityCard, p.Name) p.enjoyers = append(p.enjoyers, enjoyer) } // 执行Park的业务逻辑 func (p *Park) Run() { fmt.Printf(\u0026#34;%s start to sell tickets\\n\u0026#34;, p.Name) for _, enjoyer := range p.enjoyers { enjoyer.BuyTicket() } fmt.Printf(\u0026#34;%s start a show\\n\u0026#34;, p.Name) for _, enjoyer := range p.enjoyers { enjoyer.Enjoy() } fmt.Printf(\u0026#34;show finish\\n\u0026#34;) } 那么，根据上述方法建模出来的模型是这样的：\n模型的运行方法如下：\npaul := entity.NewPeople(\u0026#34;Paul\u0026#34;) mit := aggregate.NewSchool(\u0026#34;MIT\u0026#34;) google := aggregate.NewCompany(\u0026#34;Google\u0026#34;) home := aggregate.NewHome() summerPalace := aggregate.NewPark(\u0026#34;Summer Palace\u0026#34;) // 上学 mit.Receive(paul) mit.Run() // 回家 home.ComeBack(paul) home.Run() // 工作 google.Employ(paul) google.Run() // 公园游玩 summerPalace.Welcome(paul) summerPalace.Run() 贫血模型 VS 充血模型（工程派 VS 学院派） 上一节中，我们使用DDD的战术建模完成了该案例领域模型。模型的核心是People实体，它有IdentityCard、StudentCard等数据属性，也有Eat()、Study()、Work()等业务行为 ，非常符合现实世界中定义。这也是学院派所倡导的，同时拥有数据属性和业务行为的充血模型。\n然而，充血模型并非完美，它也有很多问题，比较典型的是这两个：\n问题一：上帝类\nPeople这个实体包含了太多的职责，导致它变成了一个名副其实的上帝类。试想，这里还是裁剪了很多“人”所包含的属性和行为，如果要建模一个完整的模型，其属性和方法之多，无法想象。上帝类违反了单一职责原则，会导致代码的可维护性变得极差。\n问题二：模块间耦合\nSchool与Company本应该是相互独立的，School不必关注上班与否，Company也不必关注考试与否。但是现在因为它们都依赖了People这个实体，School可以调用与Company相关的Work()和OffWork()方法，反之亦然。这导致模块间产生了不必要的耦合，违反了接口隔离原则。\n这些问题都是工程派不能接受的，从软件工程的角度，它们会使得代码难以维护。解决这类问题的方法，比较常见的是对实体进行拆分，比如将实体的行为建模成领域服务，像这样：\ntype People struct { vo.IdentityCard vo.StudentCard vo.WorkCard vo.Account } type StudentService struct{} func (s *StudentService) Study(p *entity.People) { fmt.Printf(\u0026#34;Student %+v studying\\n\u0026#34;, p.StudentCard) } func (s *StudentService) Exam(p *entity.People) { fmt.Printf(\u0026#34;Student %+v examing\\n\u0026#34;, p.StudentCard) } type WorkerService struct{} func (w *WorkerService) Work(p *entity.People) { fmt.Printf(\u0026#34;%+v working\\n\u0026#34;, p.WorkCard) p.Account.Balance++ } func (w *WorkerService) OffWOrk(p *entity.People) { fmt.Printf(\u0026#34;%+v getting off work\\n\u0026#34;, p.WorkCard) } // ... 这种建模方法，解决了上述两个问题，但也变成了所谓的贫血模型：People变成了一个纯粹的数据类，没有任何业务行为。在人的心理上，这样的模型并不能在建立起对现实世界的对应关系，不容易让人理解，因此被学院派所抵制。\n到目前为止，贫血模型和充血模型都有各有优缺点，工程派和学院派谁都无法说服对方。接下来，轮到本文的主角出场了。\nDCI架构 DCI（Data，Context，Interactive）架构是一种面向对象的软件架构模式，在《The DCI Architecture: A New Vision of Object-Oriented Programming》一文中被首次提出。与传统的面向对象相比，DCI能更好地对数据和行为之间的关系进行建模，从而更容易被人理解。\n Data，也即数据/领域对象，用来描述系统“是什么”，通常采用DDD中的战术建模来识别当前模型的领域对象，等同于DDD分层架构中的领域层。 Context，也即场景，可理解为是系统的Use Case，代表了系统的业务处理流程，等同于DDD分层架构中的应用层。 Interactive，也即交互，是DCI相对于传统面向对象的最大发展，它认为我们应该显式地对领域对象（Object）在每个业务场景（Context）中扮演（Cast）的角色（Role）进行建模。Role代表了领域对象在业务场景中的业务行为（“做什么”），Role之间通过交互完成完整的义务流程。   这种角色扮演的模型我们并不陌生，在现实的世界里也是随处可见，比如，一个演员可以在这部电影里扮演英雄的角色，也可以在另一部电影里扮演反派的角色。\n DCI认为，对Role的建模应该是面向Context的，因为特定的业务行为只有在特定的业务场景下才会有意义。通过对Role的建模，我们就能够将领域对象的方法拆分出去，从而避免了上帝类的出现。最后，领域对象通过组合或继承的方式将Role集成起来，从而具备了扮演角色的能力。\nDCI架构一方面通过角色扮演模型使得领域模型易于理解，另一方面通过“小类大对象”的手法避免了上帝类的问题，从而较好地解决了贫血模型和充血模型之争。另外，将领域对象的行为根据Role拆分之后，模块更加的高内聚、低耦合了。\n使用DCI建模 回到前面的案例，使用DCI的建模思路，我们可以将“人”的几种行为按照不同的角色进行划分。吃完、睡觉、玩游戏，是作为人类角色的行为；学习、考试，是作为学生角色的行为；上班、下班，是作为员工角色的行为；购票、游玩，则是作为游玩者角色的行为。“人”在家这个场景中，充当的是人类的角色；在学校这个场景中，充当的是学生的角色；在公司这个场景中，充当的是员工的角色；在公园这个场景中，充当的是游玩者的角色。\n 需要注意的是，学生、员工、游玩者，这些角色都应该具备人类角色的行为，比如在学校里，学生也需要吃饭。\n 最后，根据DCI建模出来的模型，应该是这样的：\n在DCI模型中，People不再是一个包含众多属性和方法的“上帝类”，这些属性和方法被拆分到多个Role中实现，而People由这些Role组合而成。\n另外，School与Company也不再耦合，School只引用了Student，不能调用与Company相关的Worker的Work()和OffWorker()方法。\n代码实现DCI模型 DCI建模后的代码目录结构如下；\n- context:场景- company.go- home.go- park.go- school.go- object:对象- people.go- data:数据- account.go- identity_card.go- student_card.go- work_card.go- role:角色- enjoyer.go- human.go- student.go- worker.go从代码目录结构上看，DDD和DCI架构相差并不大，aggregate目录演变成了context目录；vo目录演变成了data目录；entity目录则演变成了object和role目录。\n首先，我们实现基础角色Human，Student、Worker、Enjoyer都需要组合它：\npackage role // 人类角色 type Human struct { data.IdentityCard data.Account } func (h *Human) Eat() { fmt.Printf(\u0026#34;%+v eating\\n\u0026#34;, h.IdentityCard) h.Account.Balance-- } func (h *Human) Sleep() { fmt.Printf(\u0026#34;%+v sleeping\\n\u0026#34;, h.IdentityCard) } func (h *Human) PlayGame() { fmt.Printf(\u0026#34;%+v playing game\\n\u0026#34;, h.IdentityCard) } 接着，我们再实现其他角色，需要注意的是，Student、Worker、Enjoyer不能直接组合Human，否则People对象将会有4个Human子对象，与模型不符：\n// 错误的实现 type Worker struct { Human } func (w *Worker) Work() { fmt.Printf(\u0026#34;%+v working\\n\u0026#34;, w.WorkCard) w.Balance++ } ... type People struct { Human Student Worker Enjoyer } func main() { people := People{} fmt.Printf(\u0026#34;People: %+v\u0026#34;, people) } // 结果输出, People中有4个Human： // People: {Human:{} Student:{Human:{}} Worker:{Human:{}} Enjoyer:{Human:{}}} 为解决该问题，我们引入了xxxTrait接口：\n// 人类角色特征 type HumanTrait interface { CastHuman() *Human } // 学生角色特征 type StudentTrait interface { CastStudent() *Student } // 员工角色特征 type WorkerTrait interface { CastWorker() *Worker } // 游玩者角色特征 type EnjoyerTrait interface { CastEnjoyer() *Enjoyer } Student、Worker、Enjoyer组合HumanTrait，并通过Compose(HumanTrait)方法进行特征注入，只要在注入的时候保证Human是同一个，就可以解决该问题了。\n// 学生角色 type Student struct { // Student同时也是个普通人，因此组合了Human角色 \tHumanTrait data.StudentCard } // 注入人类角色特征 func (s *Student) Compose(trait HumanTrait) { s.HumanTrait = trait } func (s *Student) Study() { fmt.Printf(\u0026#34;Student %+v studying\\n\u0026#34;, s.StudentCard) } func (s *Student) Exam() { fmt.Printf(\u0026#34;Student %+v examing\\n\u0026#34;, s.StudentCard) } // 员工角色 type Worker struct { // Worker同时也是个普通人，因此组合了Human角色 \tHumanTrait data.WorkCard } // 注入人类角色特征 func (w *Worker) Compose(trait HumanTrait) { w.HumanTrait = trait } func (w *Worker) Work() { fmt.Printf(\u0026#34;%+v working\\n\u0026#34;, w.WorkCard) w.CastHuman().Balance++ } func (w *Worker) OffWork() { fmt.Printf(\u0026#34;%+v getting off work\\n\u0026#34;, w.WorkCard) } // 游玩者角色 type Enjoyer struct { // Enjoyer同时也是个普通人，因此组合了Human角色 \tHumanTrait } // 注入人类角色特征 func (e *Enjoyer) Compose(trait HumanTrait) { e.HumanTrait = trait } func (e *Enjoyer) BuyTicket() { fmt.Printf(\u0026#34;%+v buying a ticket\\n\u0026#34;, e.CastHuman().IdentityCard) e.CastHuman().Balance-- } func (e *Enjoyer) Enjoy() { fmt.Printf(\u0026#34;%+v enjoying scenery\\n\u0026#34;, e.CastHuman().IdentityCard) } 最后，实现People这一领域对象：\npackage object type People struct { // People对象扮演的角色 \trole.Human role.Student role.Worker role.Enjoyer } // People实现了HumanTrait、StudentTrait、WorkerTrait、EnjoyerTrait等特征接口 func (p *People) CastHuman() *role.Human { return \u0026amp;p.Human } func (p *People) CastStudent() *role.Student { return \u0026amp;p.Student } func (p *People) CastWorker() *role.Worker { return \u0026amp;p.Worker } func (p *People) CastEnjoyer() *role.Enjoyer { return \u0026amp;p.Enjoyer } // People在初始化时，完成对角色特征的注入 func NewPeople(name string) *People { // 一些初始化的逻辑... \tpeople.Student.Compose(people) people.Worker.Compose(people) people.Enjoyer.Compose(people) return people } 进行角色拆分之后，在实现Home、School、Company、Park等场景时，只需依赖相应的角色即可，不再需要依赖People这一领域对象：\n// 家 type Home struct { me *role.Human } func (h *Home) ComeBack(human *role.Human) { fmt.Printf(\u0026#34;%+v come back home\\n\u0026#34;, human.IdentityCard) h.me = human } // 执行Home的业务逻辑 func (h *Home) Run() { h.me.Eat() h.me.PlayGame() h.me.Sleep() } // 学校 type School struct { Name string students []*role.Student } func (s *School) Receive(student *role.Student) { // 初始化StduentCard逻辑 ... \ts.students = append(s.students, student) fmt.Printf(\u0026#34;%s Receive stduent %+v\\n\u0026#34;, s.Name, student.StudentCard) } // 执行School的业务逻辑 func (s *School) Run() { fmt.Printf(\u0026#34;%s start class\\n\u0026#34;, s.Name) for _, student := range s.students { student.Study() } fmt.Println(\u0026#34;students start to eating\u0026#34;) for _, student := range s.students { student.CastHuman().Eat() } fmt.Println(\u0026#34;students start to exam\u0026#34;) for _, student := range s.students { student.Exam() } fmt.Printf(\u0026#34;%s finish class\\n\u0026#34;, s.Name) } // 公司 type Company struct { Name string workers []*role.Worker } func (c *Company) Employ(worker *role.Worker) { // 初始化WorkCard逻辑 ...  c.workers = append(c.workers, worker) fmt.Printf(\u0026#34;%s Employ worker %s\\n\u0026#34;, c.Name, worker.WorkCard.Name) } // 执行Company的业务逻辑 func (c *Company) Run() { fmt.Printf(\u0026#34;%s start work\\n\u0026#34;, c.Name) for _, worker := range c.workers { worker.Work() } fmt.Println(\u0026#34;worker start to eating\u0026#34;) for _, worker := range c.workers { worker.CastHuman().Eat() } fmt.Println(\u0026#34;worker get off work\u0026#34;) for _, worker := range c.workers { worker.OffWork() } fmt.Printf(\u0026#34;%s finish work\\n\u0026#34;, c.Name) } // 公园 type Park struct { Name string enjoyers []*role.Enjoyer } func (p *Park) Welcome(enjoyer *role.Enjoyer) { fmt.Printf(\u0026#34;%+v come park %s\\n\u0026#34;, enjoyer.CastHuman().IdentityCard, p.Name) p.enjoyers = append(p.enjoyers, enjoyer) } // 执行Park的业务逻辑 func (p *Park) Run() { fmt.Printf(\u0026#34;%s start to sell tickets\\n\u0026#34;, p.Name) for _, enjoyer := range p.enjoyers { enjoyer.BuyTicket() } fmt.Printf(\u0026#34;%s start a show\\n\u0026#34;, p.Name) for _, enjoyer := range p.enjoyers { enjoyer.Enjoy() } fmt.Printf(\u0026#34;show finish\\n\u0026#34;) } 模型的运行方法如下：\npaul := object.NewPeople(\u0026#34;Paul\u0026#34;) mit := context.NewSchool(\u0026#34;MIT\u0026#34;) google := context.NewCompany(\u0026#34;Google\u0026#34;) home := context.NewHome() summerPalace := context.NewPark(\u0026#34;Summer Palace\u0026#34;) // 上学 mit.Receive(paul.CastStudent()) mit.Run() // 回家 home.ComeBack(paul.CastHuman()) home.Run() // 工作 google.Employ(paul.CastWorker()) google.Run() // 公园游玩 summerPalace.Welcome(paul.CastEnjoyer()) summerPalace.Run() 写在最后 从前文所描述的场景中，我们可以发现传统的DDD/面向对象设计方法在对行为进行建模方面存在着不足，进而导致了所谓的贫血模型和充血模型之争。\nDCI架构的出现很好的弥补了这一点，它通过引入角色扮演的思想，巧妙地解决了充血模型中上帝类和模块间耦合问题，而且不影响模型的正确性。当然，DCI架构也不是万能的，在行为较少的业务模型中，使用DCI来建模并不合适。\n最后，将DCI架构总结成一句话就是：领域对象（Object）在不同的场景（Context）中扮演（Cast）不同的角色（Role），角色之间通过交互（Interactive）来完成具体的业务逻辑。\n 参考\nThe DCI Architecture: A New Vision of Object-Oriented Programming, Trygve Reenskaug, James O. Coplien\n软件设计的演变过程, _张晓龙_\nImplement Domain Object in Golang, _张晓龙_\nDCI: 代码的可理解性, chelsea\nDCI in C++, MagicBowen\n更多文章请关注微信公众号：元闰子的邀请\n ","date":"2021-10-10T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%AE%9E%E7%8E%B0dci%E6%9E%B6%E6%9E%84/","title":"实现DCI架构"},{"content":"前言 软件工程师们总习惯把OS（Operating System，操作系统）当成是一个非常值得信赖的管家，我们只管把程序托管到OS上运行，却很少深入了解操作系统的运行原理。确实，OS作为一个通用的软件系统，在大多数的场景下都表现得足够的优秀。但仍会有一些特殊的场景，需要我们对OS进行各项调优，才能让业务系统更高效地完成任务。这就要求我们必须深入了解OS的原理，不仅仅只会使唤这个管家，还能懂得如何让管家做得更好。\nOS是一个非常庞大的软件系统，本文主要探索其中的冰山一角：CPU的调度原理。\n说起CPU的调度原理，很多人的第一反应是基于时间片的调度，也即每个进程都有占用CPU运行的时间片，时间片用完之后，就让出CPU给其他进程。至于OS是如何判断一个时间片是否用完的、如何切换到另一个进程等等更深层的原理，了解的人似乎并不多。\n其实，基于时间片的调度只是众多CPU的调度算法的一类，本文将会从最基础的调度算法说起，逐个分析各种主流调度算法的原理，带大家一起探索CPU调度的奥秘。\nCPU的上下文切换 在探索CPU调度原理之前，我们先了解一下CPU的上下文切换，它是CPU调度的基础。\n如今的OS几乎都支持\u0026quot;同时\u0026quot;运行远大于CPU数量的任务，OS会将CPU轮流分配给它们使用。这就要求OS必须知道从哪里加载任务，以及加载后从哪里开始运行，而这些信息都保存在CPU的寄存器中，其中即将执行的下一条指令的地址被保存在程序计数器（PC）这一特殊寄存器上。我们将寄存器的这些信息称为CPU的上下文，也叫硬件上下文。\nOS在切换运行任务时，将上一任务的上下文保存下来，并将即将运行的任务的上下文加载到CPU寄存器上的这一动作，被称为CPU上下文切换。\n CPU上下文属于进程上下文的一部分，我们常说的进程上下文由如下两部分组成：\n 用户级上下文：包含进程的运行时堆栈、数据块、代码块等信息。 系统级上下文：包含进程标识信息、进程现场信息（CPU上下文）、进程控制信息等信息。   这涉及到两个问题：（1）上一任务的CPU上下文如何保存下来？（2）什么时候执行上下文切换？\n问题1: 上一任务的CPU上下文如何保存下来？\nCPU上下文会被保存在进程的内核空间（kernel space）上。OS在给每个进程分配虚拟内存空间时，会分配一个内核空间，这部分内存只能由内核代码访问。OS在切换CPU上下文前，会先将当前CPU的通用寄存器、PC等进程现场信息保存在进程的内核空间上，待下次切换时，再取出重新装载到CPU上，以恢复任务的运行。\n问题2: 什么时候执行上下文切换？\nOS要想进行任务上下文切换，必须占用CPU来执行切换逻辑。然而，用户程序运行的过程中，CPU已经被用户程序所占用，也即OS在此刻并未处于运行状态，自然也无法执行上下文切换。针对该问题，有两种解决策略，协作式策略与抢占式策略。\n协作式策略依赖用户程序主动让出CPU，比如执行系统调用（System Call）或者出现除零等异常。但该策略并不靠谱，如果用户程序没有主动让出CPU，甚至是恶意死循环，那么该程序将会一直占用CPU，唯一的恢复手段就是重启系统了。\n抢占式策略则依赖硬件的定时中断机制（Timer Interrupt），OS会在初始化时向硬件注册中断处理回调（Interrupt Handler）。当硬件产生中断时，硬件会将CPU的处理权交给来OS，OS就可以在中断回调上实现CPU上下文的切换。\n调度的衡量指标 对于一种CPU调度算法的好坏，一般都通过如下两个指标来进行衡量：\n 周转时间（turnaround time），指从任务到达至任务完成之间的时间，即$T_{turnaround}=T_{completiong}-T_{arrival}$ 响应时间（response time），指从任务到达至任务首次被调度的时间，即$T_{response}=T_{firstrun}-T_{arrival}$  两个指标从某种程度上是对立的，要求高的平均周转时间，必然会降低平均响应时间。具体追求哪种指标与任务类型有关，比如程序编译类的任务，要求周转时间要小，尽可能快的完成编译；用户交互类的任务，则要求响应时间要小，避免影响用户体验。\n工作负载假设 OS上的工作负载（也即各类任务运行的状况）总是千变万化的，为了更好的理解各类CPU调度算法原理，我们先对工作负载进行来如下几种假设：\n 假设1：所有任务都运行时长都相同。 假设2：所有任务的开始时间都是相同的 假设3：一旦任务开始，就会一直运行，直至任务完成。 假设4：所有任务只使用CPU资源（比如不产生I/O操作）。 假设5：预先知道所有任务的运行时长。  准备工作已经做好，下面我们开始进入CPU调度算法的奇妙世界。\nFIFO：先进先出 FIFO（First In First Out，先进先出）调度算法以原理简单，容易实现著称，它先调度首先到达的任务直至结束，然后再调度下一个任务，以此类推。如果有多个任务同时到达，则随机选一个。\n在我们假设的工作负载状况下，FIFO效率良好。比如有A、B、C三个任务满足上述所有负载假设，每个任务运行时长为10s，在t=0时刻到达，那么任务调度情况是这样的：\n根据FIFO的调度原理，A、B、C分别在10、20、30时刻完成任务，平均周转时间为20s（ $\\frac {10+20+30}{3}$），效果很好。\n然而现实总是残酷的，如果假设1被打破，比如A的运行时间变成100s，B和C的还是10s，那么调度情况是这样的：\n根据FIFO的调度原理，由于A的运行时间过长，B和C长时间得不到调度，导致平均周转时间恶化为110（ $\\frac {100+110+120}{3}$）。\n因此，FIFO调度策略在任务运行时间差异较大的场景下，容易出现任务饿死的问题！\n针对这个问题，如果运行时间较短的B和C先被调度，问题就可以解决了，这正是SJF调度算法的思想。\nSJF：最短任务优先 SJF（Shortest Job First，最短任务优先）从相同到达时间的多个任务中选取运行时长最短的一个任务进行调度，接着再调度第二短的任务，以此类推。\n针对上一节的工作负载，使用SJF进行调度的情况如下，周转时间变成了50s（ $\\frac {10+20+120}{3}$），相比FIFO的110s，有了2倍多的提升。\n让我们继续打破假设2，A在t=0时刻，B和C则在t=10时刻到达，那么调度情况会变成这样：\n因为任务B和C比A后到，它们不得不一直等待A运行结束后才有机会调度，即使A需要长时间运行。周转时间恶化为103.33s（$\\frac {100+(110-10)+(120-10)}{3}$），再次出现任务饿死的问题！\nSTCF：最短时间完成优先 为了解决SJF的任务饿死问题，我们需要打破假设3，也即任务在运行过程中是允许被打断的。如果B和C在到达时就立即被调度，问题就解决了。这属于抢占式调度，原理就是CPU上下文切换一节提到的，在中断定时器到达之后，OS完成任务A和B的上下文切换。\n我们在协作式调度的SJF算法的基础上，加上抢占式调度算法，就演变成了STCF算法（Shortest Time-to-Completion First，最短时间完成优先），调度原理是当运行时长较短的任务到达时，中断当前的任务，优先调度运行时长较短的任务。\n使用STCF算法对该工作负载进行调度的情况如下，周转时间优化为50s（$\\frac {120+(20-10)+(30-10)}{3}$），再次解决了任务饿死问题！\n到目前为止，我们只关心了周转时间这一衡量指标，那么FIFO、SJF和STCF调度算法的响应时间又是多长呢？\n不妨假设A、B、C三个任务都在t=0时刻到达，运行时长都是5s，那么这三个算法的调度情况如下，平均响应时长为5s（$\\frac {0+(5-0)+(10-0)}{3}$）：\n更糟糕的是，随着任务运行时长的增长，平均响应时长也随之增长，这对于交互类任务来说将会是灾难性的，严重影响用户体验。该问题的根源在于，当任务都同时到达且运行时长相同时，最后一个任务必须等待其他任务全部完成之后才开始调度。\n为了优化响应时间，我们熟悉的基于时间片的调度出现了。\nRR：基于时间片的轮询调度 RR（Round Robin，轮训）算法给每个任务分配一个时间片，当任务的时间片用完之后，调度器会中断当前任务，切换到下一个任务，以此类推。\n 需要注意的是，时间片的长度设置必须是中断定时器的整数倍，比如中断定时器时长为2ms，那么任务的时间片可以设置为2ms、4ms、6ms \u0026hellip; 否则即使任务的时间片用完之后，定时中断没发生，OS也无法切换任务。\n 现在，使用RR进行调度，给A、B、C分配一个1s的时间片，那么调度情况如下，平均响应时长为1s（$\\frac {0+(1-0)+(2-0)}{3}$）：\n从RR的调度原理可以发现，把时间片设置得越小，平均响应时间也越小。但随着时间片的变小，任务切换的次数也随之上升，也就是上下文切换的消耗会变大。因此，时间片大小的设置是一个trade-off的过程，不能一味追求响应时间而忽略CPU上下文切换带来的消耗。\n CPU上下文切换的消耗，不只是保存和恢复寄存器所带来的消耗。程序在运行过程中，会逐渐在CPU各级缓存、TLB、分支预测器等硬件上建立属于自己的缓存数据。当任务被切换后，就意味着又得重来一遍缓存预热，这会带来巨大的消耗。\n 另外，RR调度算法的周转时间为14s（$\\frac {(13-0)+(14-0)+(15-0)}{3}$），相比于FIFO、SJF和STCF的10s（$\\frac {(5-0)+(10-0)+(15-0)}{3}$）差了不少。这也验证了之前所说的，周转时间和响应时间在某种程度上是对立的，如果想要优化周转时间，建议使用SJF和STCF；如果想要优化响应时间，则建议使用RR。\nI/O操作对调度的影响 到目前为止，我们并未考虑任何的I/O操作。我们知道，当触发I/O操作时，进程并不会占用CPU，而是阻塞等待I/O操作的完成。现在让我们打破假设4，考虑任务A和B都在t=0时刻到达，运行时长都是50ms，但A每隔10ms执行一次阻塞10ms的I/O操作，而B没有I/O。\n如果使用STCF进行调度，调度的情况是这样的：\n从上图看出，任务A和B的调度总时长达到了140ms，比实际A和B运行时长总和100ms要大。而且A阻塞在I/O操作期间，调度器并没有切换到B，导致了CPU的空转！\n要解决该问题，只需使用RR的调度算法，给任务A和B分配10ms的时间片，这样当A阻塞在I/O操作时，就可以调度B，而B用完时间片后，恰好A也从I/O阻塞中返回，以此类推，调度总时长优化至100ms。\n该调度方案是建立在假设5之上的，也即要求调度器预先知道A和B的运行时长、I/O操作时间长等信息，才能如此充分地利用CPU。然而，实际的情况远比这复杂，I/O阻塞时长不会每次都一样，调度器也无法准确知道A和B的运行信息。当假设5也被打破时，调度器又该如何实现才能最大程度保证CPU利用率，以及调度的合理性呢？\n接下来，我们将介绍一个能够在所有工作负载假设被打破的情况下依然表现良好，被许多现代操作系统采用的CPU调度算法，MLFQ。\nMLFQ：多级反馈队列 MLFQ（Multi-Level Feedback Queue，多级反馈队列）调度算法的目标如下：\n 优化周转时间。 降低交互类任务的响应时间，提升用户体验。  从前面分析我们知道，要优化周转时间，可以优先调度运行时长短的任务（像SJF和STCF的做法）；要优化响应时间，则采用类似RR的基于时间片的调度。然而，这两个目标看起来是矛盾的，要降低响应时间，必然会增加周转时间。\n那么对MLFQ来说，就需要解决如下两个问题：\n 在不预先清楚任务的运行信息（包括运行时长、I/O操作等）的前提下，如何权衡周转时间和响应时间？ 如何从历史调度中学习，以便未来做出更好的决策？  划分任务的优先级 MLFQ与前文介绍的几种调度算法最显著的特点就是新增了优先级队列存放不同优先级的任务，并定下了如下两个规则：\n 规则1：如果Priority(A) \u0026gt; Priority(B)，则调度A 规则2：如果Priority(A) = Priority(B)，则按照RR算法调度A和B  优先级的变化 MLFQ必须考虑改变任务的优先级，否则根据 规则1 和 规则2 ，对于上图中的任务C，在A和B运行结束之前，C都不会获得运行的机会，导致C的响应时间很长。因此，可以定下了如下几个优先级变化规则：\n 规则3：当一个新的任务到达时，将它放到最高优先级队列中 规则4a：如果任务A运行了一个时间片都没有主动让出CPU（比如I/O操作），则优先级降低一级 规则4b：如果任务A在时间片用完之前，有主动让出CPU，则优先级保持不变   规则3主要考虑到让新加入的任务都能得到调度机会，避免出现任务饿死的问题\n规则4a和4b主要考虑到，交互类任务大都是short-running的，并且会频繁让出CPU，因此为了保证响应时间，需要保持现有的优先级；而CPU密集型任务，往往不会太关注响应时间，因此可以降低优先级。\n 按照上述规则，当一个long-running任务A到达时，调度情况是这样的：\n如果在任务A运行到t=100时，short-time任务B到达，调度情况是这样的：\n从上述调度情况可以看出，MLFQ具备了STCF的优点，即可以优先完成short-running任务的调度，缩短了周转时间。\n如果任务A运行到t=100时，交互类任务C到达，那么调度情况是这样的：\nMLFQ会在任务处于阻塞时按照优先级选择其他任务运行，避免CPU空转。因此，在上图中，当任务C处于I/O阻塞状态时，任务A得到了运行时间片，当任务C从I/O阻塞上返回时，A再次挂起，以此类推。另外，因为任务C在时间片之内出现主动让出CPU的行为，C的优先级一直保持不变，这对于交互类任务而言，有效提升了用户体验。\nCPU密集型任务饿死问题 到目前为止，MLFQ似乎能够同时兼顾周转时间，以及交互类任务的响应时间，它真的完美了吗？\n考虑如下场景，任务A运行到t=100时，交互类任务C和D同时到达，那么调度情况会是这样的：\n由此可见，如果当前系统上存在很多交互类任务时，CPU密集型任务将会存在饿死的可能！\n为了解决该问题，可以设立了如下规则：\n 规则5：系统运行S时长之后，将所有任务放到最高优先级队列上（Priority Boost）  加上该规则之后，假设设置S为50ms，那么调度情况是这样的，饿死问题得到解决！\n恶意任务问题 考虑如下一个恶意任务E，为了长时间占用CPU，任务E在时间片还剩1%时故意执行I/O操作，并很快返回。根据规则4b，E将会维持在原来的最高优先级队列上，因此下次调度时仍然获得调度优先权：\n为了解决该问题，我们需要将规则4调整为如下规则：\n 规则4：给每个优先级分配一个时间片，当任务用完该优先级的时间片后，优先级降一级  应用新的规则4后，相同的工作负载，调度情况变成了如下所述，不再出现恶意任务E占用大量CPU的问题。\n到目前为止，MLFQ的基本原理已经介绍完，最后，我们总结下MLFQ最关键的5项规则：\n 规则1：如果Priority(A) \u0026gt; Priority(B)，则调度A 规则2：如果Priority(A) = Priority(B)，则按照RR算法调度A和B 规则3：当一个新的任务到达时，将它放到最高优先级队列中 规则4：给每个优先级分配一个时间片，当任务用完该优先级的时间片后，优先级降一级 规则5：系统运行S时长之后，将所有任务放到最高优先级队列上（Priority Boost）  现在，再回到本节开始时提出的两个问题：\n1、在不预先清楚任务的运行信息（包括运行时长、I/O操作等）的前提下，MLFQ如何权衡周转时间和响应时间？\n在预先不清楚任务到底是long-running或short-running的情况下，MLFQ会先假设任务属于shrot-running任务，如果假设正确，任务就会很快完成，周转时间和响应时间都得到优化；即使假设错误，任务的优先级也能逐渐降低，把更多的调度机会让给其他short-running任务。\n2、MLFQ如何从历史调度中学习，以便未来做出更好的决策？\nMLFQ主要根据任务是否有主动让出CPU的行为来判断其是否是交互类任务，如果是，则维持在当前的优先级，保证该任务的调度优先权，提升交互类任务的响应性。\n当然，MLFQ并非完美的调度算法，它也存在着各种问题，其中最让人困扰的就是MLFQ各项参数的设定，比如优先级队列的数量，时间片的长度、Priority Boost的间隔等。这些参数并没有完美的参考值，只能根据不同的工作负载来进行设置。\n 比如，我们可以将低优先级队列上任务的时间片设置长一些，因为低优先级的任务往往是CPU密集型任务，它们不太关心响应时间，较长的时间片长能够减少上下文切换带来的消耗。\n CFS：Linux的完全公平调度 本节我们将介绍一个平时打交道最多的调度算法，Linux系统下的CFS（Completely Fair Scheduler，完全公平调度）。与上一节介绍的MLFQ不同，CFS并非以优化周转时间和响应时间为目标，而是希望将CPU公平地均分给每个任务。\n 当然，CFS也提供了给进程设置优先级的功能，让用户/管理员决定哪些进程需要获得更多的调度时间。\n 基本原理 大部分调度算法都是基于固定时间片来进行调度，而CFS另辟蹊径，采用基于计数的调度方法，该技术被称为virtual runtime。\nCFS给每个任务都维护一个vruntime值，每当任务被调度之后，就累加它的vruntime。比如，当任务A运行了5ms的时间片之后，则更新为vruntime += 5ms。CFS在下次调度时，选择vruntime值最小的任务来调度，比如：\n那CFS应该什么时候进行任务切换呢？切换得频繁些，任务的调度会更加的公平，但是上下文切换带来的消耗也越大。因此，CFS给用户提供了个可配参数sched_latency，让用户来决定切换的时机。CFS将每个任务分到的时间片设置为 time_slice = sched_latency / n（n为当前的任务数） ，以确保在sched_latency周期内，各任务能够均分CPU，保证公平性。\n比如将sched_latency设置为48ms，当前有4个任务A、B、C和D，那么每个任务分到的时间片为12ms；后面C和D结束之后，A和B分到的时间片也更新为24ms：\n从上述原理上看，在sched_latency 不变的情况下，随着系统任务数的增加，每个任务分到的时间片也随之减少，任务切换所带来的消耗也会增大。为了避免过多的任务切换消耗，CFS提供了可配参数min_granularity来设置任务的最小时间片。比如sched_latency设置为48ms，min_granularity设置为 6ms，那么即使当前任务数有12，每个任务数分到的时间片也是6ms，而不是4ms。\n给任务分配权重 有时候，我们希望给系统中某个重要的业务进程多分配些时间片，而其他不重要的进程则少分配些时间片。但按照上一节介绍的基本原理，使用CFS调度时，每个任务都是均分CPU的，有没有办法可以做到这一点呢？\n可以给任务分配权重，让权重高的任务更多的CPU！\n加上权重机制后，任务时间片的计算方式变成了这样： $$ time_slice_{k}=\\frac{weight_k}{\\sum_{i=0}^{n-1}weight_{i}}*sched_latency $$ 比如，sched_latency还是设置为48ms，现有A和B两个任务，A的权重设置为1024，B的权重设置为3072，按照上述的公式，A的时间片是12ms，B的时间片是36ms。\n从上一节可知，CFS每次选取vruntime值最小的任务来调度，而每次调度完成后，vruntime的计算规则为vruntime += runtime，因此仅仅改变时间片的计算规则不会生效，还需将vruntime的计算规则调整为： $$ vruntime_{i}=vruntime_{i}+\\frac{weight_{0}}{weight_{i}}*runtime_{i} $$ 还是前面的例子，假设A和B都没有I/O操作，更新vruntime计算规则后，调度情况如下，任务B比任务A能够分得更多的CPU了。\n使用红黑树提升vruntime查找效率 CFS每次切换任务时，都会选取vruntime值最小的任务来调度，因此需要它有个数据结构来存储各个任务及其vruntime信息。\n最直观的当然就是选取一个有序列表来存储这些信息，列表按照vruntime排序。这样在切换任务时，CFS只需获取列表头的任务即可，时间复杂度为O(1)。比如当前有10个任务，vruntime保存为有序链表[1, 5, 9, 10, 14, 18, 17, 21, 22, 24]，但是每次插入或删除任务时，时间复杂度会是O(N)，而且耗时随着任务数的增多而线性增长！\n为了兼顾查询、插入、删除的效率，CFS使用红黑树来保存任务和vruntime信息，这样，查询、插入、删除操作的复杂度变成了log(N)，并不会随着任务数的增多而线性增长，极大提升了效率。\n另外，为了提升存储效率，CFS在红黑树中只保存了处于Running状态的任务的信息。\n应对I/O与休眠 每次都选取vruntime值最小的任务来调度这种策略，也会存在任务饿死的问题。考虑有A和B两个任务，时间片为1s，起初A和B均分CPU轮流运行，在某次调度后，B进入了休眠，假设休眠了10s。等B醒来后，$vruntime_{B}$就会比$vruntime_{A}$小10s，在接下来的10s中，B将会一直被调度，从而任务A出现了饿死现象。\n为了解决该问题，CFS规定当任务从休眠或I/O中返回时，该任务的vruntime会被设置为当前红黑树中的最小vruntime值。上述例子，B从休眠中醒来后，$vruntime_{B}$会被设置为11，因此也就不会饿死任务A了。\n 这种做法其实也存在瑕疵，如果任务的休眠时间很短，那么它醒来后依旧是优先调度，这对于其他任务来说是不公平的。\n 写在最后 本文花了很长的篇幅讲解了几种常见CPU调度算法的原理，每种算法都有各自的优缺点，并不存在一种完美的调度策略。在应用中，我们需要根据实际的工作负载，选取合适的调度算法，配置合理的调度参数，权衡周转时间和响应时间、任务公平和切换消耗。这些都应验了《Fundamentals of Software Architecture》中的那句名言：Everything in software architecture is a trade-off.\n本文中描述的调度算法都是基于单核处理器进行分析的，而多核处理器上的调度算法要比这复杂很多，比如需要考虑处理器之间共享数据同步、缓存亲和性等，但本质原理依然离不开本文所描述的几种基础调度算法。\n 参考\n Operating Systems: Three Easy Pieces, Remzi H Arpaci-Dusseau / Andrea C Arpaci-Dusseau 计算机系统基础(三)：异常、中断和输入/输出, 袁春风 南京大学  更多文章请关注微信公众号：元闰子的邀请\n ","date":"2021-07-25T00:00:00Z","permalink":"https://www.yrunz.com/p/%E6%8E%A2%E7%B4%A2cpu%E7%9A%84%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86/","title":"探索CPU的调度原理"},{"content":"《认知觉醒》是前些日子在微信读书上无意中点开，然后利用碎片时间读完的一本关于个人成长的书籍。作者周岭结合自己的成长经历，对现代年轻人普遍的成长困扰给出了自己的一些看法，并提出了能够帮助大家正确、高效地成长的一些实用方法。\n以前读过的关于个人成长的书籍还有李笑来的《财富自由之路》，《认知觉醒》的不同之处在于它更加的接地气。书中提到的很多高效成长的方法，在我看来，绝大部分人都可以做到。其中的一些方法，本人也一直在使用，效果确实很明显，这本书值得大家去翻一翻。\n关键是“专注” 在这个信息爆炸的年代，专注一件事情变得越来越困难。古人总说“一心不能二用”，但现在的人似乎总是在追求着“一心二用”。在跑步时听音乐、在吃饭时看视频、在走路时听书、在睡觉时思绪万千\u0026hellip; 我们追求时间利用率的最大化，却也导致了行为与感受的分离。\n”一心二用“这一习惯一旦养成，对个人成长必然会造成巨大的影响。个人的成长主要靠学习，科学的学习模式应该是极度的专注 + 适度的休息，如果我们没法专注，学习的效率急速下降，很多时候甚至是白忙活了。\n所以，要想更加正确、高效地成长，学会“专注”是关键。在跑步时，我们可以试着感受抬腿摆臂和迎面微风；在吃饭时，可以试着感受饭菜的酸甜苦辣；在睡觉时，可以试着感受身体的紧张与松弛\u0026hellip; 试着在生活的每一件小事情上养成“专注”的习惯。\n善于刻意练习与关联学习 人的天性就是避祸就福，我们总是习惯于待在舒适区，对舒适区之外的东西避而不谈。然而，成长就是不断扩大舒适区的过程。并不是说你在舒适区里待得足够够久了，它就会扩大；相反，你需要不断的走出舒适区。就好比你练习了1000遍的C和弦，却也照样学不会大横按。\n走出舒适区的一个关键点是刻意学习，找到我们的知识薄弱点，不断地进行补充，反复地练习。\n 比如，当你发现操作系统的基础知识不够牢固，那么就去找一本经典的操作系统书籍，仔细地阅读，认真地对待书上的每一道习题，以此达到查漏补缺的效果。\n 《认知觉醒》把成长区域分成了舒适区、拉伸区和困难区3部分，长期处于拉伸区才可以更快地进步。我们常犯的一个错误就是，从舒适区直接跳到了困难区，导致很容易受挫。\n 比如你发现操作系统的基础知识不够牢固之后，马上就去阅读起了Linux的内核源码，如此一来，估计要不了几天，就坚持不下去了。\n 除了刻意练习，学会关联学习也很重要，也就是我们常说的“举一反三”。关联学习除了可以加深对当前知识点的印象之外，更重要的是可以找到知识的本质原理。很多知识都是相通的，当你把一个知识的本质原理弄明白之后，就会达到所谓融会贯通的效果了。\n 比如你学习七层网络模型之后，记住了在这个模型中，网络分成了物理层、数据链路层、网络层、传输层、会话层、表示层、应用层等七层，但这也就仅仅记住了而已。\n如果你学会了关联学习，就会开始联想在软件计算机领域还有哪些地方用到了类似的模型。接着，你很快就发现了Web应用中经典的三层架构；领域驱动设计中的领域层、应用层、接口层、基础设施层；还有前台、中台和后台的划分等等，这些其实都运用了同一个架构模式，分层架构。在分层架构中，每一层都只专注于自己的职责，也就是软件设计领域的一个重要原则：单一职责原则。\n如此一来，以前学到的各种知识点，一下子就都融会贯通了起来。\n 学会反思 成长也是一个不断产生BUG，然后修复BUG的过程。现代的软件开发追求小步快跑、敏捷迭代，快速发现问题，然后解决问题。人的成长也一样需要敏捷迭代。我们每天都会犯一些错误（BUG），如果我们放任这些BUG不管，终有一天它们会酿成事故，在最关键的时刻，给你最致命的一击。\n所以，我们要学会每日反思，复盘产生BUG的原因，探讨解决BUG的措施。方法也很简单，找一个可以记录文字的本子或软件，比如OneNote，每天晚上睡前按照如下的模板进行反思：\n 1、描述经历 —— 以便日后回顾时能想起当时的场景。\n2、分析原因 —— 多问几个为什么，直到有深度的启发。\n3、改进措施 —— 尽可能提炼出一个认知点或行动点。\n 只有正视我们自身的问题，不害怕，不逃避，并纠正之，不重犯，我们才能更快速地成长。\n制定每日计划 制定每日计划很重要，它可以避免我们每天都像无头苍蝇一样迷失在茫茫的信息洪流之中。但计划有时候也会有副作用，当因为事情冲突而没完成当天计划时，可能会心生愧疚。久而久之，也就觉得没必要做计划了，因为做了也没法顺利完成。\n其实，我们完全可以把计划当成是一种提示工具，而不是必须完成的任务。计划的作用只是在完成一件事情之后，提示我们还有下一件事要做，而不至于无所事事。至于今天列出的计划，有多少完成了，有多少还未完成，这些都不是很重要。\n每日计划的模板不用很复杂，能够简单记录每天要做的事情即可，比如书中给出的模板就挺好。\n早冥读写跑，人生五件套 早起。早起可以让一天的时间更加的充实。如今，大部分的程序员晚上的时间基本都被工作填满，长期下去，个人成长速度也会放缓。而早起能够改变这一现状。曾国藩曾说过，“少睡多做，一人之生气”，每天早起2小时进行充电，一年下来就多了接近100个小时的时间，足以让一个人得到快速成长。\n冥想。冥想在最近几年变得流行起来，大家都在鼓吹冥想的好处，可以提升脑力，深度休息等等。在我看来，冥想最重要的是可以锻炼自己的专注力，磨练自己的耐心。当你能够沉住气在10分钟内什么也不想时，这份专注和耐心也足够强大了。\n读书。书是人类进步的阶梯，读书就是跟智者的一次面对面交流，它是获得知识的最廉价的方法。但前提是要学会辨别好书，豆瓣读书上的评分是一个很好的参考方式，挑那些经受过时间考验的经典书籍来读，克服英文阅读的障碍。\n写作。只读不写的学习很难把他人的知识转变成自己的知识，要学会使用自己的语言重新组织学到的知识。当你能够教授别人时，这份知识才真正成为你知识体系中的一部分。另外，不要把取悦读者作为写作的目的，要秉着自我提升的目的去写作，不断提升自己的知识总结能力，磨练自己的写作技巧。\n跑步。脑力锻炼的同时也不能忽视体力锻炼，适当的运动除了能够让身体更健康，还能让大脑得到放松，为接下来的工作学习做好准备。\n写在最后 《认知觉醒》这本书中有提到，评判一本书的好坏，关键点在于它有没有对你有所触动。对我来说，这本书做到了，其中的一些观点确实可以引发我的共鸣。书中提出了很多帮助个人成长的方法，但如果你仅仅是知道了这些知识点，而没有去行动落实，最终的结果终究还是“懂得很多大道理，却仍然过不好这一生”。所以，成长没有捷径，还得脚踏实地，一步一个脚印。\n","date":"2021-06-14T00:00:00Z","permalink":"https://www.yrunz.com/p/%E8%AE%A4%E7%9F%A5%E8%A7%89%E9%86%92%E7%9A%84%E8%AF%BB%E5%90%8E%E6%84%9F/","title":"《认知觉醒》的读后感"},{"content":"进行中 《打开：周濂的 100 堂西方哲学课》，70%，了解西方哲学史，学习大师的思考方式，从而认识你自己。\n《威尼斯日记》，30%，今年发现的，有“作家中的作家”之称的，阿城。文字简洁干练，非常值得学习。\n挂起中 《刘擎西方现代思想讲义》，50%，了解伟大的哲学家们的思想。\n已完成 《邓小平时代》，100%，读完本书，一方面被邓小平的坚韧、格局、领导力所屈服，另一方面也看到了我党一路走来也是在不断地犯错-反思-改正-进步。恰逢2021年是我党建党100周年，这一年里也看了很多关于党史的影视节目，对我党历史也有了更深刻的了解。从觉醒年代，到北伐战争，然后长征、抗日、大决战、抗美援朝、文革、改革开放，一路走来，我党在黑暗中不断摸索前行，磕磕碰碰，逐渐找到一条通往光明的道路。\n《吴军阅读与写作讲义》，100%，强调通识教育，特别是大语文的重要性​，教你如何更好地阅读和写作。但大多理论和方法都是点到为止，干货不多，但也有不少触动的地方。\n《认知觉醒》，100%，早冥读写跑，人生五件套；做每一件事情都要专注事情本身；坚持每日反思，每日计划。这些都是我对这本书最深刻的触动，正如作者所说，如果对一本书哪怕只有一点深刻的触动，那这本书就没白读了。\n《写给大家看的设计书》，100%，写给小白看的设计入门书籍，作者提出了设计的4大基本原则：亲密性、对齐、重复、对比，对于写PPT来说非常受用。\n《人生的智慧》，100%，只有健康的体魄，再加上平静的心境，才能让我们幸福的过完这一生。\n《艺术的故事》，100%，从史前时代开始讲起，介绍世界各地的各种艺术和艺术家们的故事。这本书一定要买实体书看，在微信读书上无法体会到艺术带给人的震撼。\n《非暴力沟通》，100%，记住书中介绍几种沟通技巧，观察、感受、需要、请求，并在与他人交流的时候提醒自己使用它们，有利于改善与他人的关系。\n《影响力》，100%，初看书名以为是管理学的书，读了才发现原来是一本社会心理学的书，通过很多实际的例子，讲述如何利用各种影响力来达成目标。\n《万历十五年》，100%，读完印象最深的是，万历皇帝一开始也是想励精图治，随之却被各种事情所打击，最后变成了无为而治。在怒其不争的同时，也深深体会到他身为人皇的不容易。\n《文心：不一样的国文课》，100%，跟着书中的王先生重新上了堂国文课，极大的提升了我对读书和写作的兴趣。\n《语言学的邀请》，100%，来自西方的语言学家的著作，作者知识面很广，在书中融入了大量其他领域的知识来介绍语言学，读完会发现，原来人类的语言竟是如此有趣。\n《朝花夕拾》，100%，读完《文心》，马上又找了鲁迅先生的这本散文集。鲁迅先生用平凡的语言描绘了他的少年往事，很温馨。读到有趣之处，不自觉也露出了笑容。\n《富兰克林自传》，100%，富兰克林是查理·芒格的偶像，从一个普通家庭的小孩，通过自学，逐渐成长为美国的开国元勋，而且还是一个科学家！读完这本书，像是经历了一遍他那传奇的一生。\n《大秦帝国：黑色裂变》，100%，描写了秦孝公和商鞅对秦国进行变法的那段历史，在作者的笔下，春秋战国变成了一个让人无比向往的时代。读完，让人有种想穿越回到那伟大的时代的冲动。\n《如果这是宋史》，100%，整个系列有5册，类似于《明朝那些事儿》的风格，但是文笔略逊一筹，可以当作了解宋朝历史的入门读物。\n《财富自由之路》，100%，刚开始以为是一本讲投资的书，读了之后发现原来是一本讲如何学习、如何提升自己的书。书中的一些观点和《穷查理宝典》中的很类似，获益良多。\n《原则》，对冲基金公司桥水创始人的人生经验之作，分成传记、生活原则、工作原则三部分。其中传记部分最为精彩，对于 “保持极度开放的头脑” 和 “保持极度求真” 这两个观点印象深刻。\n《曾国藩传》，100%，传奇的曾国藩的一生。\n《曾国藩家书》，100%，对我影响很大的一本书，对书中“少睡多做，一人之生气也”印象深刻。\n计划中 《Merriam-Webster\u0026rsquo;s Vocabulary Builder》\n《Word Power Made Easy : The Complete Handbook for Building a Superior Vocabulary》\n《老子道德经注》\n《周易大传今注》\n《心理学与生活》\n《与社会学同游》\n《乌合之众》\n《大问题：简明哲学导论》\n《乡土中国》\n《荷塘月色》\n《美的历程》\n《On Writing Well》\n《棋王》\n","date":"2021-06-05T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BA%BA%E6%96%87%E7%A4%BE%E7%A7%91%E7%B1%BB%E4%B9%A6%E7%B1%8D/","title":"人文社科类书籍"},{"content":"进行中 已完成 《人体简史：你的身体30亿岁了》，100%，了解人类身体的结构，读到最后一章介绍人体死亡后的变化，不免感慨万分。人类真的很渺小，最后终究会是宇宙的一粒尘埃。\n《基因之河》，100%，从基因的角度讲述生命的进化。读完之后，并没有很深刻的印象，还是觉得前些年读的《基因组：人种自传23章》更加好。\n《万物发明指南》，100%，以一种独特的穿越视角来介绍人类文明历史上各种重要的发明，非常的有趣易读。\n《病者生存：疾病如何延续人类寿命》，100%，颠覆常识，刷新认知的一本书，原来人类的很多疾病也帮助人类在特定的时期渡过了一个又一个的难关。\n《消失的微生物》，100%，原来微生物也可以像基因一样在世代中遗传，只是现代人所追求的“无菌”让人体内微生物多样性逐渐缺失，也间接导致了很多现代疾病的盛行。看完这本书最大的感受就是，以后要好好善待我们身体里的这群小朋友了。\n《上帝掷骰子吗？》，100%，读完此书，在了解到神奇的量子世界的同时，也如同亲身经历了那个星光璀璨的伟大时代。科学史上的乌云和暴雨、追逐流星的辉光、重重的迷雾和险滩，感同身受。\n《极简宇宙史》，100%，极大地扩展了我的宇宙观，读完会让你觉得人类太过渺小，这个世界太过美妙，世间万物有太多值得我们去探索、去求真的规律。如果早些年读到，说不定就选择读物理专业了。\n《物种起源》，100%，整本书更像是一篇长长的论文，作者对物种起源的论证实在是太过严谨了，以至于读起来略显枯燥。\n《走进奇妙的元素周期表》，100%，高中时死记硬背的元素周期表，其中的元素性质早已忘光了。但在作者的笔下，元素竟变得如此的有趣，而且充满了规律，再次体会到了这世界的奇妙。\n《随机漫步的傻瓜》，100%，这个世界充满着随机性，就像书中所说 “你的成功不见得是因为比其他人高明，而很可能是运气的结果。”。这本书可以让你认识到身边的事情多多少少都有些随机成分，并需要对“黑天鹅”事件时刻保持警惕。\n《妙趣横生博弈论》，100%，这本书通过现实事例来阐述博弈论，看完虽说对博弈论还是一知半解，但明白了这世上很多现象原来是博弈的结果。\n《系统之美：决策者的系统思考》，100%，这本书读起来很有亲切感，因为几乎整本书都是在讲述“反馈”。对于学控制专业的人而言，这是再熟悉不过的概念了。反馈，真的是无处不在。\n《失控：全人类的最终命运和结局》，《科技想要什么》，《新经济、新规则》，100%，凯文·凯利的三部曲，对未来的预言。\n计划中 《万物简史》\n《星际航行概论》\n《暗淡蓝点：探寻人类的太空家园》\n《改变世界的方程：牛顿、爱因斯坦和相对论》\n《意识探秘：意识的神经生物学研究》\n《演化：跨越40亿年的生命记录》\n《超越时空：通过平行宇宙、时间卷曲和第十维度的科学之旅》\n《天体物理概率论》\n","date":"2021-06-05T00:00:00Z","permalink":"https://www.yrunz.com/p/%E7%A7%91%E6%99%AE%E7%B1%BB%E4%B9%A6%E7%B1%8D/","title":"科普类书籍"},{"content":"进行中 《价值投资实战手册》，60%，唐朝对他的投资体系的回顾与总结。\n已完成 《穷查理宝典》，100%，查理·芒格的个人传记，被他那百科全书般的知识所折服，更深受其终身学习、时刻保持求知欲望的精神所影响。\n《世界上最简单的会计书》，100%，确实可以称得上世界上最简单的会计书，通过案例来解释会计学的种种概念，小白入门会计学的力荐之作。\n《富爸爸 穷爸爸》，100%，收获比想象中要多，有助于学会如何管理自己的财务。\n《手把手教你读财报》，100%，唐朝的力作，从财报中看一家公司的优秀与否。\n《聪明的投资者》，100%，学习投资理财的第一本书籍。\n《股票大作手回忆录》，100%，天才的回忆录。\n计划中 《彼得·林奇的成功投资》\n《巴芒演义》\n《投资最重要的事》\n","date":"2021-06-05T00:00:00Z","permalink":"https://www.yrunz.com/p/%E7%BB%8F%E6%B5%8E%E6%8A%95%E8%B5%84%E7%B1%BB%E4%B9%A6%E7%B1%8D/","title":"经济投资类书籍"},{"content":"进行中 《Database System Concepts(7th Edition)》，10%，数据库必读书籍，相比第 6 版增加了很多新内容，结合 CMU 的公开课，很棒。\n《Spark SQL 内核剖析》，5%，作为阅读 Spark SQL 源码的引导还是不错的。\n挂起中 《Fundamentals of Software Architecture》，80%，架构师的入门指南，书中介绍各种常用的架构模式，教你如何设计一个好的软件系统，而且也会教你如何成为一个优秀的Tech Leader。\n《Designing Data-Intensive Applications》，90%，值得时常温习的一本后端技术大全，每读一章都醍醐灌顶。\n《The Programmer’s Brain》：20%， 从认知科学的角度教你如何更好地阅读代码、理解代码、编写代码，对于程序员新手来说值得一读。书中提到的很多学习程序的方法，感觉就是将有经验的程序员的一些学习方法，结合认知科学的理论更好地呈现了出来。\n《Operating Systems: Three Easy Pieces》，90%，巩固一下操作系统基础，这本书将操作系统的知识点讲得非常清晰易懂。\n《Database Internals：A deep-dive into how distributed data systems work》，5%，复习一下数据库知识。\n已完成 《大数据处理框架 Apache Spark 设计与实现》，100%，将 Spark 的一些核心流程介绍得很易懂，而且有很多图片示范，但是还不够深入，没有结合源码来介绍。\n《Trino - The Definitive Guide》，100%，入门 Presto / Trino 的不错书籍，对架构、核心流程介绍的比官方文档要详细些。但是也不够深入，主要面向的是框架用户，而不是框架内核开发。\n《凤凰架构》，100%，周志明老师的又一力作，从架构的视角介绍了如何构建大型分布式系统，全书的话题涉猎很广，基本把分布式系统所能涉及的知识点都讲解了，比如远程服务调用、事务、安全、一致性等。书中罗列了很多参考阅读材料，可作为进阶架构师的一本导航书，如果把其中提到的知识点都研究透，那么可以就成为专家了。\n《软件架构设计：大型网站技术架构与业务架构融合之道》，100%，可以作为架构设计的入门书籍，知识面很广，但是不够深入。\n《Microservices vs. Service-Oriented Architecture》，100%，比较微服务架构和面向服务架构的异同点。\n《Go: Design Patterns for Real-World Projects》，100%，主要通过TDD的流程来讲解如何使用Go实现经典的23种设计模式，其中也介绍了Go的一些基础知识。书的整体水准一般，但也算是开卷有益。\n《Go语言程序设计语言》，100%，Go语言圣经，学习Go语言的必读之书，也是需要时常温习的一本经典书籍。\n《On Java 8》，100%，《Java编程思想》的Java 8版本，全面而详细地介绍了Java 8的各种基础知识。即使已经使用Java两年了，读这本书的过程中的还是获益匪浅，仔细阅读每一句话，会有意想不到的收获。\n《Java 8 实战》，100%，介绍了Java 8的各种新特性，新的日期API、Stream、Optional等都非常地好用，读完这本书，可以让你写出可读性更好的Java 8风格代码。\n《A Philosophy of Software Design》，100%，介绍降低软件复杂性的一些很实用的方法，比如写好代码注释，做好接口设计等。\n《微服务架构设计模式》，100%，深入浅出地把微服务的架构设计、开发、测试和发布运维都介绍了一遍，而且提供了很多例子，有助于加深理解微服务的各种概念。\n《实践领域驱动设计》，100%，对我影响很深的一本技术类书籍，对提升软件设计能力、写出优雅代码很有帮助。相比于Eric Evans的那本《领域驱动设计》，该书结合了大量的例子，让DDD中的各种概念更容易理解些。\n《领域驱动设计：软件核心复杂性应对之道》，100%，领域驱动设计的开山之作，内容比较偏理论。初读晦涩难懂，只依稀记得几个概念，再读时，对里面的一些概念也就理解清晰了许多。\n《架构整洁之道》，100%，《代码整洁之道》作者的又一力作，涵盖软件研发完整过程及所有核心架构模式。\n《Streaming Systems》，100%，目前流式计算框架五花八门，这本书以Apache Beam框架为例子，介绍了流式系统的一些通用概念。先了解Apache Beam，再来读这本书，里面的概念更容易理解些。\n《企业IT架构转型之道：阿里巴巴中台战略思想与架构实践》，100%，介绍阿里巴巴架构的演变过程，帮助了解时下热门的 “中台“ 概念的由来和含义。\n《聊聊“架构”》，100%，与“架构”相关的概念居多，没有太多的干货。\n《重构：改善既有代码的设计》，100%，深入浅出介绍了重构的各种常见方法，对写好代码很有帮助。\n《HBase不睡觉书》，100%，介绍了HBase的架构原理和用法，适合入门，相对于《HBase权威指南》，这本书确实不容易让人睡觉。\n《Apache Kafka源码剖析》，100%，介绍Kafka的设计思想和实现，对Kafka的使用者而言，很值得一读。\n《构建之法》，100%，介绍软件工程的一些概念，对技术管理很有帮助。\n《Redis设计与实现》，100%，介绍Redis的设计原理和数据结构。\n《MySQL技术内幕：InnoDB存储引擎》，100%，介绍InnoDB的技术原理和工作机制，对理解数据库技术很有帮助。\n《编写可读代码的艺术》，100%，提升代码可读性。\n《程序员的自我修养 : 链接、装载与库》，100%，主要讲C/C++运行库的工作原理。\n《STL源码剖析》，100%，侯捷老师是何等的功力深厚，才能讲STL剖析得如此清楚。\n《Effective C++：改善程序与设计的55个具体做法》，100%，可以将C++水平提升一个档次的书籍。\n《C++ Primer》，100%，值得反复翻看的C++经典书籍。\n计划中 《HBase原理与实践》\n《Apache Kafka实战》\n《Go语言笔记》\n《反应式设计模式》\n《Principles of Computer System Design》\n《敏捷整洁之道：回归本源》\n《Transaction Processing》\n《The Garbage Collection Handbook》\n《Category Theory for Programmers》\n《The Effective Engineer：How to Leverage Your Efforts in Software Engineering to Make a Disproportionate and Meaningful Impact》\n《TCP/IP Illustrated, Volume 1: The Protocols》\n《API Design Patterns》\n《Righting Software》\n《Software Architecture: The Hard Parts》\n","date":"2021-06-05T00:00:00Z","permalink":"https://www.yrunz.com/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E7%B1%BB%E4%B9%A6%E7%B1%8D/","title":"计算机软件类书籍"},{"content":"前言 对于软件工程师来说，编码能力的重要性自不必说，技术写作的能力也相当重要。一篇好的设计文档能够指导需求的开发测试，提升软件质量；一篇好的用户文档能够帮助用户迅速熟悉软件的使用方法；一篇好的技术博文可以让人耳目一新，受益匪浅；一篇好的经验总结可以让新手们少走弯路。\n技术写作的目的是让读者能够顺利地使用一个软件或理解一项技术或弄懂业务流程。它与创作型写作的最大区别在于，技术写作并非为了取悦读者，而是追求以简洁和精确的文字去阐明事实。\n 一篇好的技术文章应该能够让符合条件的读者，在良好的阅读体验下，理解甚至掌握文章所要传达的内容。\n 技术写作是一项学问，很多同学或多或少都有写些技术文章的想法，但因为缺乏一些基本的写作技巧，常常无从下手。本文将给出一些技术写作的建议，力求让软件工程师们能够写好技术文章，爱上技术写作。\n为什么要技术写作 前言有提到，一篇好的技术文章能够给读者带来众多益处，其实，技术写作也同样能让作者本身收益颇丰。\n提升表达能力 如何组织文章，如何将复杂的技术原理通熟易懂地表达出来，这都非常考验人的表达能力。\n加强架构和逻辑思维 文章如同软件，也有架构和逻辑。博士们的架构和逻辑思维之所以普遍强大，一个很重要原因是他们都经过了严格的论文写作磨练。当我们把文章写好时，架构和逻辑思维会得到增强，软件设计和开发能力也能随之提高。\n加深对技术/业务的理解 想要写好技术文章，必须要熟悉写作的内容，自然地要求作者在写作前做足功课，如此一来也就加深了对相关技术/业务的理解。\n展示自我 通过技术文章来分享知识是一个很好的展示自我的途径，让大家知道你当前熟悉的领域，逐渐扩大自己的影响力，对后续的职业发展可以起到很大的帮助。\n心灵愉悦 在公开平台上发表技术文章，收获很多浏览量，被读者评论，得到读者点赞和收藏，这些都能够让人得到心灵上的愉悦。\n如何开始技术写作 所谓万事开头难，对习惯于与代码打交道的软件工程师来说，要开始与文字打交道的技术写作，很难。相信很多同学都遇到过憋了几个小时都没写出几个字，或者一直在纠结写什么内容的窘境。其实，只要找到一些方法，着手技术写作，并没那么难。\n从记录学习/工作内容开始 可以先从记录日常的学习/工作内容开始，慢慢习惯与文字打交道，此过程重在建立起写作的自信。\n文章长短不重要 不要一开始就想着写出惊骇世俗的文章，成为最出色的技术博主。也并非只有长篇大论才算得上好的技术文章，一些问题解决记录、经验总结的短文也能给读者很大的帮助。\n通过学习找到写作灵感 如果你还在为要写什么内容而焦头烂额，那么就去学习一项新的技术或者去阅读一本书吧。最好的写作时机就是刚学到知识的时候，因为这时你很清楚从零到一的过程，这也是你要传递给读者的东西。\n学会做笔记 笔记是很好的写作素材，在日常的工作和学习中多做些笔记，把自己的灵感记录下来，后面写作起来也会轻松许多。\n写作的三部曲 第一步：立下写作目标 写作的第一步是立下目标，明确要写哪一类的文章，并朝着目标去写作。比如，立下了介绍Java中HashMap数据类型的目标，就不要在文章上描述JVM的垃圾回收原理，这是混淆了写作目标。\n第二步：确定受众读者 写作的第二步是确定受众读者，只写这类读者可以接受的知识。比如，要写一篇题目是《从零开始学习Java语言》的文章，这明显是一篇针对Java初学者的文章，那么就不要在文章里剖析JVM内存管理的实现源码，这是混淆了文章受众。\n第三步：组织文章 组织文章就是根据中心旨意，把要表达的知识串联成一篇条理清晰的文章。很多新手都会面临“心中想法万千，却无从下笔”的困境，这就是缺乏文章组织导致的。《文心》一书中有提到：\n 对于文章的组织，也不妨举出一个总方法来，那就是 ‘回问自己’ 四个大字。\n 我们可以通过“回问自己”的方法来组织文章，以《教你写好代码注释》一文为例：\n\u0026ldquo;是为了要说些什么才写这篇文章的？\u0026rdquo;\n—— 为了总结些写好代码注释的方法。这样文章的中心意旨就明确了。\n\u0026ldquo;中心意旨在我们意念中间是怎么来的？\u0026rdquo;\n—— 读到《A Philosophy of Software Design》一书中关于代码注释的章节深有感触，想分享给大家。这样文章依据的材料范围也就确认了。\n“这个材料可以增加中心意旨的力量吗？”\n—— 书中关于high-level注释和low-level注释的例子可以很好地体现“什么是好的代码注释”这个旨意。这样就可以不断筛选出好的素材，文章的主要内容也就确认了。\n“还有更简练通顺的表达吗？”\n—— 这样写好像更通顺一些。这样经过不断的修正，一篇文章也就出来了。\n一些技术写作建议 1 熟悉写作内容 作为文章的作者，你需要比读者更熟悉写作内容。可以不是相关领域的专家，但至少能够将知识清晰表达出来，并且能够回答大部分读者的问题。这就要求在写作之前，花时间去阅读相关文章、书籍，甚至是请教专家。\n2 写作前先列大纲 文章不仅仅是把内容罗列出来，要注重知识的表达，因此需要一个清晰的文章架构。在写作前先列出大纲，能够帮你理清写作思路，确认内容是否符合逻辑，构建清晰的文章架构。多想想，哪个内容需要先阐述？段落的顺序要怎么排？哪些知识需要更多的解释？哪些点到为止即可？\n3 精简文字 技术写作不是剧本小说，不需要反转曲折的剧情，更不需要含沙射影的表达，它追求的是直接、实用、清晰明了的表达风格。没必要使用过于复杂的文字去描述技术原理，这只会让它们更加难以理解。使用简洁的文字，多用短句，能够让文章可读性更好。\n4 多举例子 避免通篇介绍技术原理的写作，这会让文章过于枯燥，内容也晦涩难懂。要多举例子，它不仅能让技术原理更易懂，也能让主题更加深刻。比如在《教你写好代码注释》中，通过举例正反面的代码注释，更能让读者对好的代码注释产生共鸣。\n5 善用图表 有时候，我们会遇到很难用文字，或需要用很多文字才能描述清楚的东西，比如复杂的业务流程和模块依赖。这时可以使用图表来可视化表达，一张恰当的图表能够清晰地阐明技术原理，胜过千言万语。\n 一些画图软件推荐\n 适合新手：MicroSoft Office PowerPoint、MicroSoft Office Visio、Apple Keynote 在线画图：Draw.io、ProcessOn、Excalidraw 代码绘图：PlantUML 手绘风格：Apple Keynote、Excalidraw 高级玩家：Sketch、Lunacy   6 代码分段 在深度剖析一些技术原理或系统框架时，我们往往都会涉及源码分析，切忌直接在文章中贴上上百行的代码，然后在代码前/后用一段文字对其说明。这会导致读者为了将代码和说明对应上，而频繁上下翻页，严重影响阅读感受。\n 反面教材：\n... inline void* oopDesc::field_base(int offset) const { return (void*)\u0026amp;((char*)this)[offset]; } template \u0026lt;class T\u0026gt; inline T* oopDesc::obj_field_addr(int offset) const { return (T*)field_base(offset); } // 剩余上百行的代码 ... 由上述代码片段可知，每个field在oop中都有一个对应的偏移量（offset），xxx。\n 更好的方法是将代码分段讲解，并在在其中穿插关键注释。\n 正面例子：\n// 获取field前需要先判断是否采用了指针压缩技术，先根据offset调用obj_field_addr // 得到field的地址，然后调用load_decode_heap_oop得到实例 inline oop oopDesc::obj_field(int offset) const { return UseCompressedOops ? load_decode_heap_oop(obj_field_addr\u0026lt;narrowOop\u0026gt;(offset)) : load_decode_heap_oop(obj_field_addr\u0026lt;oop\u0026gt;(offset)); } oopDesc::obj_field方法主要用于xxx。\n// 基础类型特有的实现与obj_field_addr类似，只是转型成特有的基础类型指针 inline jbyte* oopDesc::byte_field_addr(int offset) const { return (jbyte*)field_base(offset); } oopDesc::byte_field_addr主要用于xxx，在xxx时会被调用。\n 7 反复修正 好的文章都是经过反复的修正才诞生，不仅仅局限于错别字和用词的修改，要以读者，甚至是审稿人的视角去审视整篇文章。怎么才能让这段内容表达更清晰？哪些知识需要延展？哪些片段可以裁剪掉？\n养成在发布前仔细阅读一遍文章的习惯，杜绝低级错误，这也是对读者最大的尊重。\n8 做好排版 如同代码需要分段讲解，文字也需要分段，一大段的文字容易让人觉得枯燥。对重点语句/词语需要加粗突出；善用标题、有序/无序列表来罗列知识点，让文章看起来更加清晰。\n推荐使用markdown进行技术写作，它排版简洁美观，语法简单，而且绝大多数的平台都支持markdown格式的文章发布。另外，还可以使用markdown-nice等排版工具自定义文章背景、色彩、字体等，提升阅读观感。\n9 读好的文章 养成读好文章的习惯，学习他们的写作方式，不断提升自己的写作技巧。\n总结 《文心》将文章写作归结为三个阶段：习作、应用和创作。\n 习作只是法则与手腕的练习，应用之作只是对付他人和事务的东西，创作才是发挥自己天分的真成绩。\n 技术写作也一样，第一阶段习作，对应读书笔记、经验分享等总结类文章；第二阶段应用，对应工作中的设计文档、用户文档等指南类文档；第三阶段创作，对应类似《对XXX领域未来发展的看法》的这类文章，这往往也要求作者具备深厚的知识储备。\n这三者之中，最基本、最重要的是习作。只有当习作到了相当的程度，才能有应用，也才能谈得上创作。\n上面介绍了很多写好技术文章的方法，但最简单，也是最有效的方法是：不要停止写作。\n 参考\n 文心, 夏丏尊/叶圣陶 技术文章如何写作才能有较好的阅读体验, 伍迷 Technical Writing: Definition and Observations, Richard Nordquist 15 Tips to Improve Your Technical Writing, TBS Staff Advice for Technical Writing, Chris Coyier Developers: The Why and How to Writing Technical Articles, Goodness Kayode   ","date":"2021-05-02T00:00:00Z","permalink":"https://www.yrunz.com/p/%E6%95%99%E4%BD%A0%E5%86%99%E5%A5%BD%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/","title":"教你写好技术文章"},{"content":" 《从分层架构到微服务架构》是一系列介绍《Fundamentals of Software Architecture》中提到的8种架构模式的文章，这里不会事无巨细地介绍所有的细节，而是会挑选其中关键内容，更多详情请阅读原书。\n往期精彩：\n 从分层架构到微服务架构（一） 从分层架构到微服务架构（二）之分层架构 从分层架构到微服务架构（三）之管道架构   前言 微内核架构（Microkernel Architecture），也被称为插件式架构（plug-in architecture），作为一个在几十年前就被创建出来的架构模式，它如今仍然被广泛应用在各个领域中。比如在Web浏览器领域，谷歌的Chrome浏览器之所以被认为功能强大，一个很重要的原因是它有着丰富的插件类型；在开发工具领域，微软的VS Code初始安装后还只是个简单的文本编辑器，但用户可以安装各种插件，从而让它摇身一变成为功能强大的IDE。\nChrome和VS Code都是微内核架构的典型应用例子，它们提供一个具备最基础能力的核心系统，并定义好插件的开发接口。至于需要开发或安装哪种类型的插件，则完全由普通开发者和用户决定，这样的设计让系统具备了极强的可定制化和可扩展能力。\n架构视图 微内核架构由以下两部分组成：核心系统（core system）和插件（plug-in component），将应用系统的业务逻辑拆分成核心系统和插件，能够提供很好的可扩展性和灵活性，极大地方便了后续需求的新增和修改。\n核心系统 核心系统通常只需提供能够支撑整个系统正常运行的基本功能，比如前文所举的VS Code例子，用户初始安装的是VS Code的核心系统，它只是一个提供了打开文件、编辑文件内容和保存文件等基本功能的文本编辑器，其他的扩展功能（如语法检查）都是通过安装插件集成的。将复杂的业务逻辑从核心系统中剥离出来，并通过插件实现，能够提升系统的可扩展性和可维护性。同时，因为复杂的功能都成了互不干扰的插件，系统的可测性也得到了提高。\n考虑现在需要实现一个电子设备回收系统，在回收之前，每种型号的手机设备的回收流程都不一样，那么我们可以这样去实现：\npublic void assessDevice(String deviceID) { if (deviceID.equals(\u0026#34;iPhone6s\u0026#34;)) { assessiPhone6s(); } else if (deviceID.equals(\u0026#34;iPad1\u0026#34;)) assessiPad1(); } else if (deviceID.equals(\u0026#34;Galaxy5\u0026#34;)) assessGalaxy5(); } else ... ... } } 如果我们把assessDevice看成是核心系统，那么后面每次新增一个型号的手机，都需要新增一个if分支，也即对核心系统进行了改动。这样的设计会导致核心系统非常地脆弱，正所谓改的越多，出问题的概率也越大。\n比起这种将所有的可定制业务逻辑放在核心系统上的设计，更好的应该是将它们实现为插件的形式，这样不仅每个设备回收逻辑都解耦了，还提供了强大的可扩展性：添加一个新的回收设备类型，只需新增一种插件即可，核心系统无需变动。\npublic void assessDevice(String deviceID) { String plugin = pluginRegistry.get(deviceID); DevicePlugin devicePlugin = (DevicePlugin)constructor.newInstance(); DevicePlugin.assess(); } 微内核架构在实现时通常都结合了其他架构模式，这主要体现在核心系统的设计上，比如根据具体的业务特点，我们可以将核心系统设计成technically partitioned的分层架构，或者是domain partitioned的模块化架构。\n插件 插件就是一些包含了定制化业务逻辑、扩展功能、附加功能的独立组件，用于扩充核心系统的功能。插件之间是独立的，插件与核心系统之间则一般是“点对点”通信：核心系统通过调用插件提供的接口（比如插件类的方法）使用扩展功能。\n插件可以划分为编译时插件和运行时插件两种类型，前者每次变更都需要重新构建和部署整个系统，但实现较为简单；后者则可以在系统运行时进行插件的新增和删除操作，相对地，实现也较为复杂。\n编译时插件 在编译时插件中，插件通常以package或namespace实现，比如在package中可以以这样的命名规则来区分插件：app.plug-in.\u0026lt;domain\u0026gt;.\u0026lt;context\u0026gt;。\n运行时插件 运行时插件中插件的实现通常是动态库的形式，比如.jar 、.so、.dll文件。在上述的设备回收系统的例子中，每种型号的手机设备回收逻辑包含在一个独立的.jar文件中：\n远端插件 当然，插件和核心系统并非只能通过本地接口调用进行通信，还可以采用REST/消息队列/RPC等方式，这种场景下，插件就变成了一个独立部署的服务。远程插件具备运行时插件的特点，而且能够提供更好的scalability：插件和核心系统甚至都不必使用相同的技术栈实现，只需遵守既定的REST接口即可。\n为了提升系统处理请求的responsiveness，我们还可以将核心系统调用插件的过程实现为异步通信。以前文的电子设备回收系统为例，在异步通信的架构下，系统通过一个线程触发插件启动对某个设备的回收流程。之后，该线程无需一直等待回收结束，它可以去继续回收别的设备。当设备回收结束后，插件会通过异步队列告知核心系统。这样的异步设计可以减少无谓的等待流程，明显改善系统的responsiveness。\n如果涉及到读写数据库，为了能够维持插件的独立性，每个插件最好能够拥有独立的数据库。如果插件间有着无可避免的数据交互，则可以为核心系统配置一个中心数据库，并通过它来进行数据中转。\n插件中心 核心系统在加载插件前，必须得知道当前有哪些可用的插件，以及这些插件在哪里可以获取。这要求系统有一个地方去管理插件，这就是插件中心（plug-in registry）的功能。插件中心类似于服务化架构中服务注册中心的作用，它保存了所有插件的基本信息，包括名称、数据契约、通信协议、加载地址等。\n我们可以简单地将插件中心实现为一个本地的map表，其中key可以是插件名称，value为获取插件的地址：\nMap\u0026lt;String, String\u0026gt; registry = new HashMap\u0026lt;String, String\u0026gt;(); static { //point-to-point access example  registry.put(\u0026#34;iPhone6s\u0026#34;, \u0026#34;Iphone6sPlugin\u0026#34;); //messaging example  registry.put(\u0026#34;iPhone6s\u0026#34;, \u0026#34;iphone6s.queue\u0026#34;); //restful example  registry.put(\u0026#34;iPhone6s\u0026#34;, \u0026#34;https://atlas:443/assess/iphone6s\u0026#34;); } 为了实现一些较为复杂的功能，如插件上下线通知等，我们还可以借助Apache ZooKeeper、ETCD这类的分布式协同系统实现远程插件中心。\n通信契约 通信契约定义了插件与核心系统之间的通信方式、交互行为和数据格式。通信方式可以是本地接口调用、REST、RPC、消息队列等；交互行为则可以理解为插件对核心系统提供的接口，比如本地的函数/方法、REST的URI等；对本地插件而言，数据格式通常是一个类/结构体，对远程插件而言，常用的数据格式有JSON、XML、ProtoBuf等。\n考虑电子设备回收系统的例子，系统有着如下定义的通信契约：\npublic interface AssessmentPlugin { // 回收设备流程 \tpublic AssessmentOutput assess(); // 将该插件注册到插件中心 \tpublic String register(); // 从插件中心去注册 \tpublic String deregister(); } public class AssessmentOutput { // 回收报告，仅仅用于展示结构给用户看，核心系统无需了解该格式 \tpublic String assessmentReport; // 用于标识该设备是否可以在二手市场上重新售卖 \tpublic Boolean resell; // 表示该设备的价值 \tpublic Double value; // 表示推荐的售卖价格 \tpublic Double resellPrice; } 从该契约定义中可以看出，通信方式为本地接口调用（AssessmentPlugin接口）；它有着3个交互行为，assess()为回收设备流程、register()表示将该插件注册到插件中心、deregister表示去注册；数据格式则是AssessmentOutput类，它定义了回收流程的结果。\n架构评分 和之前介绍的分层架构、管道架构一样，微内核架构同样属于单体架构，因此Simplicity和Overall cost是该架构模式主要优势；而Elasticity、Fault tolerance和Scalability是主要劣势。\n另外，微内核架构的Testability、Deployability、Reliability、Modularity之所以能够取得3颗星，得益于不同的功能能够被拆分至独立的插件上，特别地，运行时插件的增删无需重新部署系统。这使得系统能够快速响应需求变更，具备很高的扩展性。比如对于前面的电子设备回收系统，如果需要新增一种新的电子设备回收流程，只需新增一个插件即可；如果某种设备不再需要回收，则去除对应插件即可。\n微内核架构比较特别的一点是，它既可以是technically partitioned，也可以是domain partitioned，这取决于核心系统的实现方式，前文也有介绍。\n总结 Robert C.Martin曾经说过，软件开发技术发展的历史就是一个如何想方设法方便地增加插件，从而构建一个可扩展、可维护的系统架构的故事。在敏捷开发的潮流之下，需求的变更如同家常便饭，系统不应该因为某一部分发生变更从而导致其他不相关的部分出现问题。将系统设计为微内核架构，就等于构建起了一面变更无法逾越的防火墙，插件发生的变更就不会影响系统的核心业务逻辑。\n微内核架构的设计思想，能够极大提升系统的可扩展性和健壮性，在其他的一些软件方法论里，我们也隐约能看到它的影子。比如在领域驱动设计中，领域层就相当于核心系统，它定义了系统的核心业务逻辑；基础设施层则相当于插件，切换不同的基础设施并不会影响系统的业务逻辑，这得益于基础设施层依赖倒置的设计原则。\n当然，作为微内核架构也有着一些缺点，它天然具备了单体架构的一些劣势，比如核心系统作为架构的中心节点并不具备Fault tolerance能力。因此，该架构模式往往被广泛应用于一些着重提供很强的用户定制化功能的小型产品，如VS Code等，它们对系统的Elasticity、Fault tolerance和Scalability并没有很高的要求。\n每种架构模式都有其合适的应用场景，只有熟悉常用的几种架构模式，才能设计出更好的软件系统。下一篇文章，我们将继续介绍面向服务的架构。\n","date":"2021-04-23T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%9B%9B%E4%B9%8B%E5%BE%AE%E5%86%85%E6%A0%B8%E6%9E%B6%E6%9E%84/","title":"从分层架构到微服务架构（四）之微内核架构"},{"content":" 《从分层架构到微服务架构》是一系列介绍《Fundamentals of Software Architecture》中提到的8种架构模式的文章，这里不会事无巨细地介绍所有的细节，而是会挑选其中关键内容，更多详情请阅读原书。\n往期精彩：\n 从分层架构到微服务架构（一） 从分层架构到微服务架构（二）之分层架构   前言 管道架构（Pipeline Architecture），通常也被称为管道-过滤器架构（Pipes and Filter Architecture），是最常用的架构模式之一。大部分软件工程师都是通过Unix终端初次接触到该架构模式，Unix终端的Shell语言，对管道-过滤器有着原生的支持。\n比如，现在需要实现这样的一个功能：读取一个文本文件的内容，找到使用频率最高的5个单词，并按照使用频率的大小顺序打印出单词及其使用频率。\n那么，使用Shell可以这样来实现：\ncat content.txt | # step1: 读取文件内容 tr -cs A-Za-z \u0026#39;\\n\u0026#39; | # step2: 将单词按行输出 tr A-Z a-z | # step3: 将所有单词转换为 sort | # step4: 对单词进行排序 uniq -c | # step5: 计算出单词的频率 sort -rn | # step6: 按照频率对单词进行排序 head -n 5 # step7: 获取排序前5的单词 # 输出结果示例： 4 to 4 and 3 the 3 networks 3 linux 这段Shell代码就是一个简单的管道架构实现，其中|表示管道pipe，每一个step就相当于一个过滤器filter。每个filter都将上一个filter的输出结果作为输入数据，对数据进行处理后再将结果输出到管道中。\n除了Shell语言之外，MapReduce也是基于管道架构搭建，其中的map和reduce可以看成是过滤器，只是它们通信的管道为HDFS。\nShell语言和MapReduce编程模型都可以看成是管道架构的low-level实现，当然，它也能应用于higher-level的系统应用上，下面我们来介绍管道架构模式的架构视图。\n架构视图 管道架构由管道pipe和过滤器filter组成：\npipe作为filter之间的数据传输通道，通常都是单向、点对点通信的，这样的设计不仅实现简单，在性能上也能取得较好的效果。另外，pipe上传输的数据并没有统一的格式，每个系统都可以根据自身的特点选择合适的数据结构。\nfilter作为数据处理的组件，通常是无状态的。每个filter都应当只完成一项工作，满足单一职责原则，复杂的工作流应该由多个filter组合而成。一般地，我们将filter分成以下几种类型：\n Producer: 有时候也称为Source，是整个pipeline的start point，负责从数据源中接收数据，并将数据输出到pipe中。 Transformer: 从pipe中接收输入数据，然后对部分或全部数据进按照一定的规则行转换，并将结果输出到pipe中。在函数式编程里，该步骤通常被称为map。 Tester: 从pipe中接收数据，然后对数据进行一些条件判断，并根据判断结果选择是否将数据传递到下游的pipe中。需要注意的是，tester并未对数据进行任何修改。 Consumer: 是整个pipeline的end point，通常将从pipe中读取到的数据持久化到数据库或呈现到用户界面上。  一个系统中可以有多个producer和consumer，比如我们可以同时通过Kafka和REST接口接收输入数据，经过系统的处理后，将结果数据存储到MySQL中，同时也传递一份到数据仓库上用作数据分析。总之，管道架构模式有着很大的灵活性。\n应用例子 管道架构模式被广泛应用在很多应用上，下面我们以一个ETL系统作为例子来理解该模式的运作方式。\n ETL（Extract, Transform, Load）是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程，目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据。\n 业务应用系统在运行过程中会产生各种各样的数据输出到kafka中，ETL系统会消费相关数据，并在经过处理后将结果存储到数据库上。在上图的ETL系统里，各个过滤器的作用如下所述：\n Service Info Capture: 订阅kafka的topic，从中消费业务系统产生的数据，然后通过pipe传送到下游filter。 Duration Filter: 判断数据是否与计算服务请求的处理时长（duration）指标相关，是则将数据传递给Duration Calculator，否则传递给Uptime Filter。 Duration Calculator: 计算服务请求的处理时长，并将计算结果传递给Database Output。 Uptime Filter: 判断数据是否与计算系统正常运行时长（uptime）指标相关，是则将数据传递给Uptime Calculator，否则认为数据并非本ETL系统所关系，结束数据流程。 Uptime Calculator: 计算系统正常运行时长，并将结果传递给Database Output。 Database Output: 将数据持久化到MongoDB中。  上述的ETL系统由1个producer filter，2个tester filter，2个transform filter和1个consumer filter组成，主要的数据处理逻辑是计算系统的遥测指标。系统在架构上具有很高的可扩展性，比如后续想要新增一个指标计算，我们可以在Uptime Filter之后加上新的tester和transform，系统原有的指标计算无需改动；又比如系统后续打算用HBase替换MongoDB，那么我们可以新开发一个HBase Output替换掉原有的Database Output，系统的其他流程同样无需改动。\n架构评分 管道架构模式通常被实现为单体架构，同分层架构模式一样，因为单体架构本身的劣势，其在Elasticity、Fault tolerance、Scalability方面都具有很低的评分。Simplicity是管道架构模式的主要优点之一，filter和pipe实现简单，可以快速构建起一个基于管道架构风格的系统，因此也具有很高的Overall cost评分。\n另外，相比于分层架构模式，管道架构模式在Modularity、Evolutionary和Testability上都有着较高的评分，这得益于filter之间的松耦合，我们可以很容易扩展系统的filter，以及对单个filter进行测试。\n总结 本文主要介绍了管道架构模式，它由管道pipe和过滤器filter组成。根据具体的数据处理逻辑，它将filter划分为producer、transformer、tester和consumer四种类型，是一种典型的technical partition软件架构风格。管道架构模式因为其可扩展性很高的特点而被广泛应用，其中不乏有Shell语言这种low-level的实现，也有ETL系统这种high-level的实现。\n虽说该模式通常被实现为单体架构，但也有像MapReduce这种基于分布式系统的编程模式实现，总之，如果你需要为一个数据处理型的系统选型，那么可以认真地考虑是否采用管道架构模式。\n每种架构模式都有其合适的应用场景，只有熟悉常用的几种架构模式，才能设计出更好的软件系统。下一篇文章，我们将继续介绍微内核架构。\n","date":"2021-04-05T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B8%89%E4%B9%8B%E7%AE%A1%E9%81%93%E6%9E%B6%E6%9E%84/","title":"从分层架构到微服务架构（三）之管道架构"},{"content":" 《从分层架构到微服务架构》是一系列介绍《Fundamentals of Software Architecture》中提到的8种架构模式的文章，这里不会事无巨细地介绍所有的细节，而是会挑选其中关键内容，更多详情请阅读原书。\n往期精彩：\n 从分层架构到微服务架构（一）   前言 软件刚出现的时候，还是大型计算机的年代，一个软件系统一般都只会运行在一台机器上。随着软硬件技术的革新，计算机体积和成本逐渐变小，此时工程师们发现一个软件系统只运行在单台机器上会存在各种瓶颈。如果将系统按照功能划分成前端和后端，分别部署在两台服务器上，问题得到了缓解，于是便有了Client/Server架构的出现。\n随后，个人电脑的兴起带动了众多富桌面应用（rich desktop application）的出现，它们基于操作系统上的user interface开发，数据则是存储在单独部署的database server上，通过标准的网络协议进行数据通信。这种Desktop + Database Server的架构和C/S架构一样，同属两层架构（two-tier architecture）。\n随着90年代互联网的迅速崛起，Browser + Web Server + Database Server的组合也渐渐风靡。Browser为表现层，提供用户交互界面；Web Server为业务层，处理具体的业务逻辑；Database Server为数据层，存储系统数据。三个层次各司其职，这也是大家最熟悉的三层架构（three-tier architecture）。\n上述的几种架构模式都属于分层架构（layered architecture）的范畴，分层架构并没有限定一定得有多少个层次，层次的数量可以根据应用场景灵活控制，因此也被称为n-tier architecture。它结构简单，基于此架构进行系统开发成本也很低（很多公司在组织结构上划分为前端工程师、后端工程师、DBA，根据康威定律，这天然就具备了分层架构开发的良好条件），因此它在业界备受欢迎。如果你的团队还不确定选择什么样的架构，又或者为了践行敏捷宣言中的“just starts coding“，那么分层架构会是一个不错的选择。\n架构视图 在分层架构中，组件根据功能被划分在不同的层次上，虽然层次的数量和类型并没有被限制，但大多数的分层架构都由以下4层组成：表现层（presentation）、业务层（business）、持久层（persistence）和数据层（database），如下图所示。在一些简单的系统中，持久层的逻辑（如SQL）被嵌入到业务层中，形成了经典的三层架构；而在一些复杂的系统中，也会根据具体的业务划分为五层甚至更多的层次。\n前文所述的表现层等4个层次都是逻辑的划分方法，在实际部署时，一般会有下图所示的几种部署形态。形态1中，表现层、业务层和持久层为一个部署单元，而数据层则单独部署，具体表现为一个独立部署的数据库或文件系统；形态2中，表现层被分离出单独部署，业务层和持久层组成一个部署单元，数据层依旧是单独部署的数据库或文件系统；形态3中，包括数据层在内的4层全都在同一个部署单元内，常见于业务简单的系统，它们往往使用的是嵌入式数据库或内存数据库。\n分层架构中的每一层都扮演着各自的角色，比如表现层负责处理所有的用户请求和浏览器交互，而业务层则负责执行每次请求下的特定业务逻辑；表现层无需担心从哪里获取用户数据，它只需要将数据以特定的格式在浏览器上显示即可。同样地，业务层也无需关心用户数据从何而来以及如何呈现，它只需从持久层中取出数据，执行特定的业务逻辑（比如聚合数据），然后将结果返回给表现层。\n每一层都是特定行为的抽象，这样的职责划分，使得组织能够快速高效地创建出责任模型，围绕各层打造开发团队。\n层间隔离 分层架构中的每一层可以是封闭的或者开放的，封闭意味着当一个请求自顶向下在层间传递时，它不能跳过任意的一层。比如，当表现层接收到请求之后，它必须先后经过业务层和持久层才能到达数据层，如下图所示。\n对于简单的数据获取类请求，如果让表现层能够直接访问数据层获取数据，无疑是最简单高效的。也即是让业务层和持久层变成开放状态，允许请求在层间传递时跳过此层。那么，究竟是封闭好，还是开放好呢？要解答这个问题，就要回到层间隔离的出发点上。\n所谓的层间隔离，旨在降低一个层次上的变化对其他层次的组件的影响，简单来说，就是每个层次对其他层次的功能知道的越少越好。为了达到层间隔离的目的，就需要将每个层次置为封闭的状态。假设表现层能够直接访问持久层，那么持久层的变化将会直接影响到业务层和表现层，这加剧了层间的耦合，导致系统变化的代价高昂。\n层间隔离可以降低层次变化对系统的影响，凡事没有绝对，在某些的场景，将特定的层次置为开放的状态也不失为一件好事。考虑以下例子，业务层中存在着一些共享组件承载着业务层公共的功能（比如日志类、审计类、日期和字符串工具类等）。现在有一项架构决策要求表现层不能直接访问这些共享组件，但矛盾的是，原则上表现层是可以直接访问业务层的，这种需要违反原则的决策将会很难落地。\n一种解决方法是，新增一个服务层，该层包含了业务层的这些共享组件。因为业务层是关闭的状态，故表现层也就不能访问到这些共享组件了。然而，新增的服务层必须置为开放状态，否则业务层将无法直接访问持久层。新增一个服务层并置为开放状态，这样既落地了架构决策，也不会影响到原有的功能，一举两得。\n注意事项 在使用分层架构时，需要注意以下两点：\n1、做好模块的划分\n为分层架构做好模块划分主要是为后续的架构演进做好准备，比如在业务复杂到一定程度后演进为微服务架构时，各个模块可以很自然地演进为微服务。为此，应该避免出现类的继承层次过深的现象，这会导致代码严重的耦合，不利于后续的架构演进。\n2、避免掉进sinkhole反模式的陷阱\n所谓sinkhole反模式指的是请求只是简单地路过各个层次，并没有做一些业务处理。\n比如，表现层接收到一个获取基本用户数据（姓名、地址等）的请求后将它传递到业务层；然而，业务层并没有做任何的业务处理，直接将请求传递到持久层；持久层也仅仅是构造了一个简单的SQL语句，向数据层查询用户数据；最后，数据按照原路返回到表现层，中途没有经过任何的数据汇聚、转换等操作。\nsinkhole反模式会导致很多不必要的对象实例化开销，从而增大了系统的内存消耗，并且影响了性能。\n然而，一个系统多多少少都会存在一些sinkhole反模式场景，要判断一个系统是否已经彻底掉进sinkhole反模式的陷阱，主要还是看这类业务请求所占的百分比。根据20-80法则，当系统中有超过80%的业务请求是sinkhole类请求时，表示系统已经掉进sinkhole反模式的陷阱，这从侧面也说明该系统已经不再适合分层架构，是时候考虑架构演进了。\n架构评分 从综合得分上看，分层架构的Overall cost和Simplicity得分很高，这很大程度上得益于分层架构本身是单体架构，少了很多分布式系统才有的复杂性。但这样导致Deployability得分很低，因为3行代码的改动就足以造成整个系统的重新部署。Testability得分不高也是这个原因，整系统的重新上线通常都需要将测试用例全部执行一遍，多了不少额外的工作量。\nElasticity、Fault tolerance、Scalability这些都是单体架构天然的劣势，自然地，分层架构在这些方面得分都很低。另外，sinkhole反模式的存在也拉低了分层架构在Performance上的得分。\n总结 分层架构简单而高效，业界已经有很多成熟的应用，对那些项目刚刚起步，架构师们还没想好要采用哪种架构模式的系统而言，这是非常适合的。在实现分层架构时，我们需要合理地设置各个层次的封闭或开放状态，做好层间隔离，同时也要避免掉进sinkhole反模式陷阱。随着业务的不断扩张，分层架构在可维护性、可测试性、可扩展性等上的短板也会逐步被放大，此时就需要考虑往其他架构模式演进了。\n每种架构模式都有其合适的应用场景，只有熟悉常用的几种架构模式，才能设计出更好的软件系统。下一篇文章，我们将继续介绍管道架构。\n","date":"2021-01-30T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%BA%8C%E4%B9%8B%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84/","title":"从分层架构到微服务架构（二）之分层架构"},{"content":" 《从分层架构到微服务架构》是一系列介绍《Fundamentals of Software Architecture》中提到的8种架构模式的文章，这里不会事无巨细地介绍所有的细节，而是会挑选其中关键内容，更多详情请阅读原书。\n 前言 谈到软件系统设计的方法论，在代码层面，有我们熟悉的23种设计模式（design pattern），对应到架构层面，则有所谓的架构模式（architecture pattern）。它们分别从微观和宏观的角度指导着我们设计出良好的软件系统，因此，作为一个软件工程师，我们不仅要熟悉设计模式，对常见的架构模式也要熟稔于心。正如看到一个设计模式的名字脑里就能浮现出大致的结构图，当我们看到一个架构模式的名字时，也要马上想到对应的架构图及其基本特点。比如，当谈到分层架构时，我们就应该想起它的架构图是怎样的、有哪些出色的架构特征（architecture characteristics）、系统是如何部署的、数据存储的策略是哪种、等等。\n一般地，架构模式大致可以分成两类，单体架构（monolithic architecture）和分布式架构（distributed architecture）。本系列文章将会介绍以下8种常用的架构模式：\n单体架构\n 分层架构（Layered architecture） 管道架构（Pipeline architecture） 微内核架构（Microkernel architecture）  分布式架构\n 基于服务的架构（Service-based architecture） 事件驱动架构（Event-driven architecture） 基于空间的架构（Space-based architecture） 面向服务的架构（Service-oriented architecture） 微服务架构（Microservices architecture）  软件设计中的谬误 在介绍架构模式前，我们先谈谈软件设计中的谬误（fallacy）。所谓谬误，就是在设计软件系统，特别是分布式系统时，我们先入为主地假设它们是正确，但实际上并非如此的一些观念。这些观念都是我们在设计软件时考虑不周的体现。\n谬误1：网络是可靠的 很多软件工程师常常假设网络是可靠的，但实际并非如此。相比20年前，现在的网络会可靠很多，但是仍然具有很大的不确定性。如上图所述，Serivce B可能完全是正常运行的，但是因为网络的问题，Service A发出的请求无法到达Service B。一种更糟糕的场景是，Service B可以收到Service A的请求，并处理了相关的数据，但是网络问题导致了Service A无法收到Service B的响应，从而造成了数据不一致。网络的不可靠也是为什么系统中常常出现服务通信超时、服务熔断等的原因。\n总而言之，如果假设网络是可靠的，那么我们设计出来的软件系统将会是不可靠的。\n谬误2：时延是0 如上图所示，服务内组件间的函数/方法级别的调用，耗时是微妙，甚至是纳秒级别；但是服务间的远程调用（比如REST、消息队列、RPC），耗时会是微秒级别，甚至在异常场景会达到了秒级！在设计系统，特别是分布式系统时，时延是一个无法被忽视的因素，我们必须清楚系统的平均时延，否则设计出来的方案可能根本不可行。比如，假设系统中服务间通信时延为100ms，如果一个请求的调用链涉及到10个服务，那么该请求的时延将会是1000ms！这么高的平均时延对于一般系统来说是完全无法接受的。\n进行系统设计时，考虑平均时延还不够，更重要的是95th和99th百分点。一个系统的平均时延可能仅仅只有数十毫秒，但是95th百分点的时延却达到了数百毫秒，很多时候，这也恰恰成为了拖垮整系统性能的那块“短板”。\n谬误3：带宽是无限的 在单体架构中，业务流程都在单服务内闭环，消耗的带宽很少甚至为0，因此带宽并不是主要关注点。一旦将系统拆分成分布式架构，一个业务流程可能涉及多个服务间的通信，带宽就成了必须考虑的因素。带宽的不足，会导致网络变慢，从而影响系统的时延（谬误2：时延是0）和可靠性（谬误1：网络是可靠的）。\n如上图所示，假设在一个Web系统中，Service A负责处理前端请求，Service B负责管理用户信息（包括姓名、性别、年龄等45个属性）。Service A每处理一个请求都需要向Service B查询用户姓名（200 bytes），而在一次请求中，Service B却返回了用户的所有信息（500 kb）。如果系统每秒处理2000次请求，每次请求消耗500 kb带宽，那么每秒消耗的总带宽会是1 Gb！如果Service B仅仅返回必须的姓名，那么同等条件下，每秒消耗的总带宽仅仅是400 kb。\n此类问题就是所谓的stamp coupling，解决方法也很多，比如在请求中添加属性选择，使用GraphQL替代REST。相比于这些技术手段，更重要的是确定服务间通信所需的最小数据集，并在进行系统设计时将其作为一个重点关注的因素。\n谬误4：网络是安全的 VPN、防火墙等的广泛使用，使得很多工程师在设计系统时忽略了“网络是不安全的”这一重要原则。特别是从单体架构演进到分布式架构以后，系统被攻击的概率将会大大增加。因此，在分布式系统中，每个服务都必须是安全的endpoint，这样才能确保任何未知或恶意的请求都被拦截掉。当然，安全是有代价的，这也是像微服务架构这类细服务粒度的系统，一次业务请求中调用链过长后性能极速下降的重要原因。\n谬误5：网络拓扑一成不变 这里的网络拓扑指的是系统运行时所涉及到的网络设备，包括所有的路由器、防火墙、集线器、交换机等。很多工程师会假设网络拓扑是固定的，然而并非如此。\n假设如下场景，为架构师的你在周一早上回到公司后，发现组内同事都在为系统中所有的服务间通信都在不断出现响应超时现象而抓狂，但奇怪的是周末并没有做服务变更。经过几个小时的攻关后，你发现周一凌晨2点时有过一次网络升级，而恰恰是这次“次要”的网络升级，推翻之前设计系统时的时延假设，从而触发了本次事故。\n因此，软件工程师也需要与网络管理员时常联系，确保在每次网络升级前都明确网络拓扑的变更点，从而做出相应的调整。\n谬误6：只有一个网络管理员 网络管理员往往不止有一个，特别是在“云”时代，数据中心分散在多个地域，理所当然也存在着多个局域网。运行在“云”上的系统很有可能跨越多个数据中心，因此工程师们应当感知各个数据中心的网络管理员对网络的相关操作，提前做出应对措施，避免出现因网络拓扑变更（谬误5：网络拓扑一成不变）而导致的服务通信超时，甚至触发服务熔断。\n谬误7：通信成本为0 这里的通信成本并非指网络时延，而是指每增加一次服务间调用所导致的钱的花销。很多工程师在设计系统时常常忽视掉通信成本，大家都在鼓吹分布式架构相对了单体架构的优越性，却忘记了它带来的服务器、防火墙、网关等硬件的数量增加，这些都是白花花的银子。\n因此，在进行系统设计时，我们也应该将硬件资源和网络拓扑纳入考虑因素。\n谬误8：网络是同质的 很多工程师都会假设网络是同质的，也就是所有的网络设备都来自同一硬件厂商，这当然也是一个谬误。实际上，一个大的通信网络中，硬件设备往往来自于不同的厂商，这得益于网络协议标准的统一。厂商间设备的协作测试毕竟不会太充分，在一些特殊场景下极有可能存在网络丢包，从而影响了网络的可靠性（谬误1：网络是可靠的）、时延（谬误2：时延是0）以及带宽（谬误3：带宽是无限的）。\n一切从“大泥球”开始 “大泥球”架构是著名的反模式架构，最初在1997年由Brian Foote 和 Joseph Yoder提出。在“大泥球”架构里，系统没有进行内部的模块划分，代码耦合严重，调用关系混乱，就像一个大的泥球。如上图所示，每一个点代表一个类，红线则表示类之间的耦合关系。这样的架构对需求变更极不友好，往往牵一发而动全身，而且在部署、可测试性、性能等方面也存在着很多问题。所有的架构师都在极力避免“大泥球”的出现，但很不幸的是，它仍然在实际项目中很常见，特别是项目伊始，代码质量和结构还没被严格管控起来前。\n有反模式的出现，必然就有解决它的方法，这便是架构模式，从下一篇文章开始，我们将逐个介绍常见的8种架构模式。\n总结 跟设计模式类似，架构模式是软件工程师们多年来在架构设计方面的经验总结。每种架构模式并没有绝对的优劣之分，我们不能说微服务架构就一定比单体分层架构优越，它们都有着各自的应用场景。分布式架构比单体架构有着更好的可扩展性、容错性，但也带来了更高的复杂性，比如分布式事务。因此，我们应该熟知各个架构模式的特点，这样才能在特定的业务场景使用合适的架构模式。\n","date":"2021-01-23T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8E%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B8%80/","title":"从分层架构到微服务架构（一）"},{"content":"前言 上一篇文章《如何高效编写Go单元测试（一）》主要介绍了如何使用第三方断言库来使Go单元测试的代码更加简洁和具备可读性，本文我们来聊聊单元测试中的“打桩”。\n// 判断一个字符串s是否是回文字符串 func IsPalindrome(s string) bool { for i := range s { if s[i] != s[len(s)-1-i] { return false } } return true } go test框架足以应对像上述IsPalindrome这种简单的方法的单元测试，但是对于一些较为复杂的方法和模块，go test多多少少会显得力不从心。比如当你需要对依赖了很多第三方库或者跟平台、环境强相关的模块进行单元测试时，仅仅使用go test往往不能使测试用例正常的执行结束，更别说达到代码验证的目的了。\n// 判断/opt/container/config.properties文件中是否包含str字符串 func isConfigFileContain(str string) bool { file, err := os.Open(\u0026#34;/opt/container/config.properties\u0026#34;) if err != nil { panic(err) } content, err := ioutil.ReadAll(file) if err != nil { panic(err) } return strings.Contains(string(content), str) } 假设想要对上述isConfigFileContain函数进行单元测试，因为函数本身依赖了程序实际运行环境才有的/opt/container/config.properties文件，所以如果对其进行如下的单元测试，运行结果肯定出错。\nfunc TestIsConfigFileContain(t *testing.T) { ast := assert.New(t) ast.True(isConfigFileContain(\u0026#34;test\u0026#34;)) } 运行结果如下：\n=== RUN TestIsConfigFileContain --- FAIL: TestIsConfigFileContain (0.00s) panic: open /opt/container/config.properties: no such file or directory [recovered] panic: open /opt/container/config.properties: no such file or directory 果不其然，由于单元测试的环境并没有/opt/container/config.properties文件，因此用例执行失败。\n解决该问题的思路有两种，（1）在运行单元测试用例之前先把/opt/container/config.properties文件创建好；（2）使用一种技术手段让测试用例在调用os.Open(\u0026quot;/opt/container/config.properties\u0026quot;)时能够按照我们的预想返回相应的结果。\n这两种思路都属于广义上的“打桩”，那么我们常说的单元测试中的“打桩”究竟是什么？它又是用来解决什么问题的呢？\n什么是“打桩” 在单元测试中，通常可以将所涉及的对象分为两种，主要测试对象和次要测试对象。比如在上述例子中，我们测试的主要测试对象就是IsPalindrome函数，而次要测试对象则是os.Open和ioutil.ReadAll函数。一般地，在测试用例中我们只需关注主要测试对象的行为是否正确。对于次要测试对象，我们通常只会关注主要测试对象和次要测试对象之间的交互，比如是否被调用、调用参数、调用的次数、调用的结果等，至于次要测试对象是如何执行的，这些细节过程我们并不关注。\n因此，在进行单元测试中（特别是次要测试对象需要依赖特定的条件时，比如上述例子中依赖于/opt/container/config.properties文件的存在），我们常常选择使用一个模拟对象来替换次要测试对象，以此来模拟真实场景，对主要测试对象进行测试。而“使用一个模拟对象来替换次要测试对象”这个行为，我们通常称之为“打桩”。因此，“打桩”的作用就是在单元测试中让我们从次要测试对象的繁琐依赖中解脱出来，进而能够聚焦于对主要测试对象的测试上。\nstub与mock的区别 stub和mock是两种最常见的打桩手段，它们都能够用来替换次要测试对象，从而实现对一些复杂依赖的隔离，但是它们在实现和关注点上又有所区别。为了解它们之间的区别，考虑以下一段代码：\n// 邮箱消息 type Message struct {} // 邮箱服务 type MailService interface { Start() Send(msg Message) Stop() } // 订单 type Order struct { mailService MailService } // 创建新订单 func NewOrder(service MailService) *Order { return \u0026amp;Order{mailService:service} } // 进行一些业务操作 func (o *Order) DoSomething() { ... } // 关闭订单时，会发送邮件 func (o *Order) Close() { ... o.mailService.Send(Message{}) } 假设有一个订单业务Order ，它依赖了一个邮箱服务MailService。系统在创建订单之后，执行DoSometing方法进行一些业务操作，并在关闭订单时使用邮箱服务发送一个消息通知用户。现在我们要测试在订单关闭时，是否已经发送邮件。由于在单元测试中，一般不会使用真实的邮箱服务进行邮件发送，因此需要采用打桩技术来隔离邮箱服务的真实行为。下面，我们分别使用stub和mock来完成这一次的打桩。\n如果使用stub来对MailService进行打桩，那么就要进行如下的实现：\ntype StubMailService struct { messages []Message } func (s *StubMailService) Start() { // 空实现 } func (s *StubMailService) Send(msg Message) { s.messages = append(s.messages, msg) } func (s *StubMailService) Stop() { // 空实现 } func (s *StubMailService) SendNum() int { return len(s.messages) } func NewStubMailService() *StubMailService { return \u0026amp;StubMailService{messages:make([]Message, 0)} } 对应的测试用例如下：\nfunc TestOrder_Stub(t *testing.T) { stub := NewStubMailService() order := NewOrder(stub) order.DoSomething() order.Close() assert.Equal(t, 1, stub.SendNum()) } 如果使用mock来对MailService进行打桩（这里我们采用的是go mock框架），则对应的测试用例如下：\nfunc TestOrder_Mock(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() mock := NewMockMailService(ctrl) mock.EXPECT().Send(Message{}).Times(1) order := NewOrder(mock) order.DoSomething() order.Close() } 从上述两个测试用例可以看出，在实现上，使用stub进行打桩时，我们需要自己实现MailService接口；而使用mock时，则直接利用框架的能力生成一个实现了MailService接口的mock对象。对比来看，mock更加简单一些，只需关注主要测试方法，也就是所谓的“just enough”；而stub则要实现具体的逻辑，即使是不需要关注的次要测试方法，也需要给出空实现。\nMartin Fowler在《Mocks Aren’t Stubs》一文中将单元测试中的验证（verification）分为state verification和behavior verification两种，stub属于前者，mock则属于后者。正如它们的名称所描述，state verification关注的是测试对象的状态；behavior verification关注的是测试对象的行为。如上述例子，同样是验证Order.DoSomething的逻辑，stub通过记录发送过的消息数量来实现，也即是状态；mock则通过mock.EXPECT().Send(Message{}).Times(1)来验证MailService.Send的调用次数来实现，也即是行为。\nGo单元测试中的“打桩” 为全局变量打桩 全局变量也经常在代码中用到，因为它具有全局性，如果在单元测试用例中对全局变量做了修改，则在用例结束时，需要将其恢复为原来的值，避免对其他用例造成影响，比如：\nfunc TestGlobalVal(t *testing.T) { val1 := global.Val1 // 步骤1：记住原来的值 \tglobal.Val1 = 5 // 步骤2：赋予新的值 \t... // 测试用例代码 \tglobal.Val1 = val1 // 步骤3：恢复原来的值 } 如果测试用例涉及到的全局变量很多，这样就需要对每个全局变量都执行上述3个步骤，显得代码很不简洁：\nfunc TestGlobalVal(t *testing.T) { val1 := global.Val1 val2 := global.Val2 val3 := global.Val3 global.Val1 = 5 global.Val2 = 7 global.Val3 = 6 ... // 测试用例代码 \tglobal.Val1 = val1 global.Val2 = val2 global.Val3 = val3 } 针对全局变量的打桩，gostub为我们提供了一个简洁的实现方式。\n gostub：https://github.com/prashantv/gostub\n 对上述例子，下面使用gostub对其进行优化：\nfunc TestGlobalVal(t *testing.T) { // 对全局变量进行打桩 \tstub := gostub.Stub(\u0026amp;global.Val1, 5). Stub(\u0026amp;global.Val2, 7). Stub(\u0026amp;global.Val3, 6) ... // 测试用例代码，这里使用这3个全局变量时的值分别为5，7，6 \t// 对全局变量进行复原 \tstub.Reset() } 从上述例子来看，使用gostub为全局变量打桩使得代码更加简洁，可读性更好了。\n除了为全局变量打桩，gostub也可以对函数/方法进行打桩，但是其对代码有一定的限制条件，因此易用性并不是十分好。下一节，我们将介绍一个更加好用的函数/方法打桩神器。\n为函数/方法打桩 Go语言中，如果在函数声明时给它加上一个接收者，即将该函数附加到一种类型上，就变成了方法。比如，在前文中func IsPalindrome(s string) bool就是一个典型的函数声明；而func (s *StubMailService) Send(msg Message) 则是一个典型的方法声明。\n在Go单元测试中，用来对函数和方法进行打桩的框架不少，但是就易用性而言，属monkey patch最好。\n monkey patch：https://github.com/bouk/monkey\n 如果直接对前言中的isConfigFileContain函数进行单元测试，因为没有/opt/container/config.properties文件，函数中的os.Open和ioutil.ReadAll都会执行失败。前文有提到，解决方法有两种，一种是创建/opt/container/config.properties文件；另一种，我们可以使用mokey patch实现。只要通过monkey patch对os.Open和ioutil.ReadAll进行打桩即可，测试代码如下：\nfunc TestIsConfigFileContain_MonkeyPatch(t *testing.T) { ast := assert.New(t) // 对os.Open进行打桩，固定返回(\u0026amp;os.File{}, nil) \tmonkey.Patch(os.Open, func(name string) (*os.File, error) { return \u0026amp;os.File{}, nil }) // 对ioutil.ReadAll进行打桩，固定返回([]byte(\u0026#34;test for monkey patch\u0026#34;), nil) \tmonkey.Path(ioutil.ReadAll, func(r io.Reader) ([]byte, error) { return []byte(\u0026#34;test for monkey patch\u0026#34;), nil }) // 测试用例结束时，解除打桩，避免影响其他用例 \tdefer monkey.UnpatchAll() ast.True(isConfigFileContain(\u0026#34;test\u0026#34;)) } monkey patch对函数进行打桩的API很简单，形式如下monkey.Patch(\u0026lt;target function\u0026gt;, \u0026lt;replacement function\u0026gt;)，需要注意的是，在用例结束之后，记得调用monkey.UnpatchAll来解除打桩，避免影响其他用例。\n使用monkey patch对方法的打桩方法与函数的打桩方法稍微有点差异，考虑如下代码：\n// 从远端key-value数据库中获取记录 func GetRecord(key string) (string, error) { cli := db.CreateClient() var val string if err := cli.Get(\u0026#34;key1\u0026#34;, \u0026amp;val); err != nil { return \u0026#34;\u0026#34;, err } return val, nil } 其中db.CreateClient创建一个一个连接远端数据库的客户端db.Client，其定义如下：\npackage db ... // 数据库服务端远程代理，实现db.KvDb接口 type Client struct { // RPC客户端 \tcli *rpc.Client } func (c *Client) Get(key string, reply *string) error { var ret string // 通过RPC调用服务端的接口 \terr := c.cli.Call(\u0026#34;Server.Get\u0026#34;, key, \u0026amp;ret) if err != nil { fmt.Printf(\u0026#34;Call db Server.Get rpc failed, error: %v\u0026#34;, err) *reply = \u0026#34;\u0026#34; return err } *reply = ret return nil } ... // 工厂方法，返回远程代理实例 func CreateClient() *Client { rpcCli, err := rpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;192.168.21.34:8088\u0026#34;) if err != nil { fmt.Printf(\u0026#34;Create rpc client failed, error: %v.\u0026#34;, err) return nil } return \u0026amp;Client{cli: rpcCli} } 现在需要对GetRecord进行单元测试，因为在测试环境中并没有远端数据库实例，因此直接执行如下的测试用例，会运行失败：\nfunc TestGetRecord(t *testing.T) { val, err := GetRecord(\u0026#34;key1\u0026#34;) assert.Nil(t, err) assert.Equal(t, \u0026#34;value1\u0026#34;, val) } // 测试结果: === RUN TestGetRecord Create rpc client failed, error: dial tcp 192.168.21.34:8088: connect: connection refused. --- FAIL: TestGetRecord (0.00s) 现在我们使用monkey patch来解决该问题：\nfunc TestGetRecord_MonkeyPatch(t *testing.T) { var c *db.Client // 因为\u0026#34;Client.Get\u0026#34;方法的接收者是指针类型，所以这里必须声明为指针类型 \tmonkey.PatchInstanceMethod(reflect.TypeOf(c), \u0026#34;Get\u0026#34;, func(_ *db.Client, reply *string) error { *reply = \u0026#34;value1\u0026#34; return nil }) defer monkey.UnpatchAll() val, err := GetRecord(\u0026#34;key1\u0026#34;) assert.Nil(t, err) assert.Equal(t, \u0026#34;value1\u0026#34;, val) } // 测试结果: === RUN TestGetRecord --- PASS: TestGetRecord (0.00s) 如代码所述，使用monkey patch为方法进行打桩的用法为monkey.PatchInstanceMethod(\u0026lt;type\u0026gt;, \u0026lt;name\u0026gt;, \u0026lt;replacement\u0026gt;)，其中type通过reflect.TypeOf获得，值得注意的是，type必须跟方法定义的接收者类型一致，如上述代码中，Client.Get方法的接收者是指针类型，因此type必须声明为*Client类型。\n monkey patch并不支持对包私有（首字母小写）的函数/方法进行打桩。因为设计者认为包私有的函数/方法是不稳定的，因此对它们进行打桩可能会导致测试用例代码的频繁更改，得不偿失。\n 为接口打桩 在单元测试中，我们也经常需要对接口interface进行打桩，比如上文所述的订单业务例子就对接口MailService进行了打桩。在该例子中，我们介绍了两种对接口打桩的方式。一是自己创建一个实现了MailService接口的桩对象stub，但是该方法有一定限制，当接口比较复杂或嵌套很多层时，该方式将会变得异常麻烦，考虑如下ComplexItf接口定义：\ntype Itf1 interface { Func1() Func2() } type Itf2 interface { Func3(itf Itf1) Func4() } type Itf3 interface { Itf1 Func5() } type ComplexItf interface { Itf2 Itf3 Func6() Func7() Func8(itf2 Itf2) Func9() Itf1 ... } 对于这么复杂的ComplexItf接口，光是其自身的方法都已经很多，更别提嵌套的Itf2和Itf3了。更好的是采用第二种打桩方法，也就是mock方式，我们通常使用gomock框架来实现。\n gomock：https://github.com/golang/mock\n 使用gomock进行打桩时，我们完全将实现接口这一繁琐的工作交给了框架，比如使用gomock对MailService接口打桩时，在安装好gomock之后，只需执行如下命令，mock对象就会自动生成：\nmockgen -source=yrunz/mail_service.go -destination=yrunz/mock_mail_service.go -package=yrunz 其中-source表示MailService接口所在文件路径，-destination表示生成的mock对象所做的文件路径，-package表示mock对象的包名。生成的mock对象对应的代码如下：\n// Code generated by MockGen. DO NOT EDIT. // Source: yrunz/mail_service.go  // Package yrunz is a generated GoMock package. package yrunz import ( gomock \u0026#34;github.com/golang/mock/gomock\u0026#34; reflect \u0026#34;reflect\u0026#34; ) // MockMailService is a mock of MailService interface type MockMailService struct { ctrl *gomock.Controller recorder *MockMailServiceMockRecorder } // MockMailServiceMockRecorder is the mock recorder for MockMailService type MockMailServiceMockRecorder struct { mock *MockMailService } // NewMockMailService creates a new mock instance func NewMockMailService(ctrl *gomock.Controller) *MockMailService { mock := \u0026amp;MockMailService{ctrl: ctrl} mock.recorder = \u0026amp;MockMailServiceMockRecorder{mock} return mock } // EXPECT returns an object that allows the caller to indicate expected use func (m *MockMailService) EXPECT() *MockMailServiceMockRecorder { return m.recorder } // Start mocks base method func (m *MockMailService) Start() { m.ctrl.T.Helper() m.ctrl.Call(m, \u0026#34;Start\u0026#34;) } ... 生成之后就可以使用NewMockMailService工厂方法创建一个mock对象进行单元测试了：\nfunc TestOrder_Mock(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() mock := NewMockMailService(ctrl) mock.EXPECT().Send(Message{}).Times(1) order := NewOrder(mock) order.DoSomething() order.Close() } 我们注意到，mockgen工具生成的mock对象都是Mock+接口名的命名形式，并提供了一个New+Mock+接口名命名方式的工厂方法用于创建mock对象，其中工厂方法的入参为*gomock.Controller类型。\n前文有提到，mock属于behavior verification，也就是行为验证方式。实际使用gomock框架时，我们通过调用mock对象的EXPECT设定预期返回值、预期动作以及调用次数验证等。比如上述例子中的mock.EXPECT().Send(Message{}).Times(1)表示mock对象的Send方法在测试用例中应该被调用一次，且入参为Message{}，否则用例验证失败。\ngomock的一些常用的行为验证方法如下：\n .Do()：声明在匹配时要运行的操作。\n.DoAndReturn()：声明在匹配调用时要运行的操作，并模拟返回该函数的返回值。\n.Return()：在匹配调用时模拟返回该函数的返回值。\n.MaxTimes()：设置最大的调用次数\n.MinTimes()：设置最小的调用次数\n.AnyTimes()：运行调用次数为0或更多次。\n.Times()：设置调用次数为n次。\n 如果调用方法的入参不固定，可以使用gomock.Any()进行匹配，比如前面的例子中，可以这样：\nmock.EXPECT().Send(gomock.Any()).Times(1) 常用的参数匹配如下：\n gomock.Any()：匹配任意值\ngomock.Eq()：通过反射匹配到指定的类型\ngomock.Nil()：匹配nil\n 总结 本文主要主要介绍了单元测试中的“打桩”，打桩主要作用是在单元测试中让我们从次要测试对象的繁琐依赖中解脱出来，进而能够聚焦于对主要测试对象的测试上。常见的打桩技术stub和mock也并非完全相同，前者属于state verification，后者属于behavior verification。另外本文还介绍了Go单元测试的几种打桩框架，为全局变量打桩的gostub框架、为函数/方法打桩的monkey patch框架、为接口打桩的go mock框架。熟练地使用这些框架，能够让我们更加高效、优雅地编写Go单元测试。\n","date":"2021-01-10T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E7%BC%96%E5%86%99go%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%BA%8C/","title":"如何高效编写Go单元测试（二）"},{"content":"前言 2020年是艰难的一年，对于中国和世界而言，是新冠疫情的卷席全人类；对于个人而言，是工作上的无比繁忙。\n以前一直会开这么一个玩笑，“在我们公司工作，那是一年工作，三年经验”。在工作的前两年，说出这句话更多的是一种自嘲，但在今年，它却是一个真实的写照。回顾2020年自己所做的事情，初略一想，除了工作，貌似也只剩下工作了。年初时定下的一些计划，大部分都因为工作繁忙的缘故而被搁置。在阅读和写作上，梳理了自己今年读过的书，数量还不及去年的三分之一；而写过的文章，更是寥寥无几。特别是在作为主业的软件技术方面，更是没有实质的进步，感觉还是停留在2019年的水平。在这个技术日新月异的行业，不进则退，貌似，今年是失败的一年？\n一直以来都坚信《钢之炼金术师》中等价交换这一原则，既然花了这么多时间在工作上，那必定会有所收获。仔细一想，今年收获最大的，莫过于对意志的磨练。\n身为一名软件工程师，相信大家对技术都有着执着的追求。特别是初入职场，肯定有过把所有相关的技术框架学个遍的想法，唯恐跟不上时代的潮流。如果在工作的第一年问我，“对于一名软件工程师而言，什么是最重要的？”，我会回答，技术；工作的第二年，在学习了一些软件方法论，特别是领域驱动设计之后，结合工作上的项目经验，这才慢慢认识到，软件技术万变不离其宗，业务才是软件的核心。如果还问我同样的问题，我会回答，业务和技术；工作的第三年，在经历了如此艰难的2020年之后，如果再问题同样的问题，我会回答，意志、业务和技术。\n意志 一直以来大概是没有经历过很考验意志的时刻，高中按部就班地学习，然后考上大学；大学也是平平淡淡地度过六年，然后步入职场。连挑灯夜战都没几次，更别说引锥刺股了。工作的前两年虽说也有过曲折，但对比2020年，那都是不值得一提。因为新项目的巨大挑战，从3月初开始，下班的时间点逐渐延后，并在4月份达到了高峰，甚至在4月的最后一周里连睡觉都成了一件奢侈的事情。在整个4月里，为了解决新项目的难题，拼的已经不再是软件技术，更多的是意志力。\n记得有一天晚上为了解决一个问题，已经通宵工作到凌晨6点，却还是连问题原因都没找出来。心情的低落，身体的疲惫，那一刻已经临近崩溃。这时想起《指环王》里面Sam对Frodo说的一番话：\n Frodo: I can’t do this, Sam.\nSam: I know. It’s all wrong. By rights, we shouldn’t even be here. But we are. It’s like in the great stories, Mr. Frodo. The ones that really mattered.\nFull of darkness and danger they were. And sometimes you didn’t want to know the end. Because how could the end be happy? How could the world go back to the way it was when so much bad had happened?\nBut in the end, it’s only a passing thing, this shadow. Even darkness must pass. A new day will come. And when the sun shines, it will shine out the clearer. Those were the stories that stayed with you that meant something. Even if you were too small to understand why. But I think, Mr. Frodo, I do understand. I know now.\nFold in those stories had lots of chances of turning back, only they didn’t. They kept going because they were holding on to something.\nFrodo: What are we holding on to Sam?\nSam: There is some good in this world, Mr. Frodo. And it’s worth fighting for.\n 困难总会过去，只要心怀希望，没有迈不过去的坎。\n随着4月的结束，这一挑战也成功告一段落。当走在去庆祝的路上时，伴随着倾洒的阳光和迎面的微风，嘴角轻轻扬起，那一刻的舒畅，永远也不会忘掉。没有人愿意再重复一次这样的经历，但它却让我们的内心更加的强大了，而我也在这次的经历中收获了意志。\n读书 2020年读的书相比去年少了很多，而且大多都是在零散的时间里阅读的电子版书籍。软件技术类的书基本都是在O\u0026rsquo;Reilly平台上阅读，上面技术类的书籍很全还很新（通过ACM注册会员很划算，转送门：https://zhuanlan.zhihu.com/p/83928266）；其他人文、科普类的都是在微信读书上完成。不得不说，微信读书可以让人充分利用各种碎片时间，最重要的是还能在睡前起到催眠的作用，实在是失眠多梦必备APP。\n软件类              年初转Go开发之后看的第一本Go相关的技术书籍，江湖人称《Go语言圣经》，从基本语法讲到高级特性，细节很丰富，入门必备书籍。 主要通过TDD的流程来讲解如何使用Go实现经典的23种设计模式，其中也介绍了Go的一些基础知识。书的整体水准一般，但也算是开卷有益。       今年读过的最好的技术类书籍，从实现最简单的数据库讲起，深入浅出地介绍了当前大火的各种分布式系统的实现原理。读完之后有种醍醐灌顶的感觉。 可以说是架构师的入门指南，书中不仅介绍了如何设计一个好的软件系统，而且还教你如何成为一个优秀的Tech Leader，非常值得一读。    人文社科类              写给小白看的设计入门书籍，作者提出了设计的4大基本原则：亲密性、对齐、重复、对比，对于写PPT来说非常受用。 很早就听说这本书了，今年读完之后也深有感触，只有健康的体魄，再加上平静的心境，才能让我们幸福的过完这一生。       一直很好奇美学这一门学科讲的是什么，于是就挑了朱光潜大师的这一本《谈美》。看完之后，内容也没记住多少，倒是再看一棵树时，不再只会从科学和实用的角度去看待它，还会提醒自己尝试从美学的角度欣赏它。 从史前时代开始讲起，介绍世界各地的各种艺术和艺术家们的故事。这本书一定要买实体书看，在微信读书上无法体会到艺术带给人的震撼。       也是很出名的一本书了，记住书中介绍几种沟通技巧，观察、感受、需要、请求，并在与他人交流的时候提醒自己使用它们，有利于改善与他人的关系。 初看书名以为是管理学的书，读了才发现原来是一本社会心理学的书，通过很多实际的例子，讲述如何利用各种影响力来达成目标。       读完印象最深的是，万历皇帝一开始也是想励精图治，随之却被各种事情所打击，最后变成了无为而治。在怒其不争的同时，也深深体会到他身为人皇的不容易。     科普类              去年读的《原则》的作者力荐的书籍，从基因的角度讲述生命的进化。读完之后，并没有很深刻的印象，还是觉得前些年读的《基因组：人种自传23章》更加好。 以一种独特的穿越视角来介绍人类文明历史上各种重要的发明，非常的有趣易读。       颠覆常识，刷新认知的一本书，原来人类的很多疾病也帮助人类在特定的时期渡过了一个又一个的难关。 原来微生物也可以像基因一样在世代中遗传，只是现代人所追求的“无菌”让人体内微生物多样性逐渐缺失，也间接导致了很多现代疾病的盛行。看完这本书最大的感受就是，以后要好好善待我们身体里的这群小朋友了。    总结 2020年过得很艰难，但也遇到了很多美好的人和事；虽说工作繁忙，却也磨练了意志。希望2021年里能够克服惰性，保持阅读和写作，也希望生活能对自己更好些。\n","date":"2020-12-31T00:00:00Z","permalink":"https://www.yrunz.com/p/2020%E5%B9%B4%E7%9A%84%E6%88%90%E9%95%BF%E5%8D%B0%E8%AE%B0/","title":"2020年的成长印记"},{"content":"前言 单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。我们根据它来检验代码的行为是否和预期的一样，如果单元测试不通过，要么代码有bug，要么测试条件输入不正确，总之，需要修复使单元测试能够通过。单元测试一个最大的好处，就是确保一个程序模块的行为符合我们设计的预期，在将来对代码进行修改/重构时，还能最大限度地保证代码的行为仍然正确。\nGo对单元测试的支持已经相当友好了，原生的go test标准库就是专门用来进行单元测试的编写的。使用go test编写单元测试时需要遵循一些约定，比如所有测试代码都需要添加到_test.go结尾的测试文件中，这样在使用go build进行构建时，测试代码才会被排除在外。另外，每个测试函数都必须导入testing包，测试函数的名字必须以Test开头，且跟在Test后面的后缀名必须以大写开头，因此测试函数的声明应该是这样的：\nfunc TestSin(t *testing.T) { /* ... */ } func TestCos(t *testing.T) { /* ... */ } func TestLog(t *testing.T) { /* ... */ } _test.go测试文件通常和需要被测试的文件放在同一个包内，比如有如下的一段待测试的代码（在word包目录下的word.go文件）：\npackage word // 判断一个字符串s是否时回文字符串 func IsPalindrome(s string) bool { for i := range s { if s[i] != s[len(s)-1-i] { return false } } return true } 那么在编写测试时，我们同样在word包目录下，创建一个word_test.go文件，单元测试的代码如下：\npackage word import \u0026#34;testing\u0026#34; func TestPalindrome(t *testing.T) { // \u0026#34;detartrated\u0026#34;是一个回文字符串，因此IsPalindrome(\u0026#34;detartrated\u0026#34;)的返回值应该为true  // 如果返回false，则表示其实现有问题，需要使用t.Error进行错误报告 \tif !IsPalindrome(\u0026#34;detartrated\u0026#34;) { t.Error(`IsPalindrome(\u0026#34;detartrated\u0026#34;) = false`) } if !IsPalindrome(\u0026#34;kayak\u0026#34;) { t.Error(`IsPalindrome(\u0026#34;kayak\u0026#34;) = false`) } } func TestNonPalindrome(t *testing.T) { if IsPalindrome(\u0026#34;palindrome\u0026#34;) { t.Error(`IsPalindrome(\u0026#34;palindrome\u0026#34;) = true`) } } 测试用例成功则打印：\n=== RUN TestPalindrome --- PASS: TestPalindrome (0.00s) PASS 用例执行失败则是：\n=== RUN TestNonPalindrome --- FAIL: TestNonPalindrome (0.00s) nba_test.go:53: IsPalindrome(\u0026quot;kayak\u0026quot;) = true FAIL 没有断言的go test框架 从单元测试的代码中可以看出，在判断IsPalindrome方法是否运行正确时，我们并未使用断言，而是通过if语句进行判断：如果结果错误则通过t.Error方法报告错误。这是因为Go原生就不支持断言，官网也给出了他们这样设计的原因，简单来说就是不想让开发者在错误处理上进行偷懒。\n Go doesn\u0026rsquo;t provide assertions. They are undeniably convenient, but our experience has been that programmers use them as a crutch to avoid thinking about proper error handling and reporting\u0026hellip;(详见https://golang.org/doc/faq#assertions)\n 但对单元测试来说，没有断言真的是很不方便。特别地，对以前做Java开发时习惯了使用Junit进行单元测试的同学而言更是难受。另外，使用if语句来对方法的输出结果进行判断，并进行对应的错误处理，会导致单元测试代码充斥着大量的if分支，影响了代码的可读性。\n那么，有没有更好的解决方法呢？\n针对这个问题，我们可以引入第三方的断言库来解决。\n使用testify进行断言 在第三方断言库的选择上，就活跃度和易用性而言，testify都是最佳的选择。\n testify：https://github.com/stretchr/testify\n 现在，我们使用testify为上述IsPalindrome的单元测试用例进行重构：\npackage word import \u0026#34;testing\u0026#34; import \u0026#34;github.com/stretchr/testify/assert\u0026#34; func TestPalindrome(t *testing.T) { // 断言IsPalindrome方法的返回值为True \tassert.True(t, IsPalindrome(\u0026#34;detartrated\u0026#34;)) assert.True(t, IsPalindrome(\u0026#34;kayak\u0026#34;)) } func TestNonPalindrome(t *testing.T) { // 断言IsPalindrome方法的返回值为False \tassert.False(t, IsPalindrome(\u0026#34;palindrome\u0026#34;)) } 测试用例成功则打印：\n=== RUN TestPalindrome --- PASS: TestPalindrome (0.00s) PASS 用例执行失败则是：\n=== RUN TestNonPalindrome palindrome_test.go:23: Error Trace:\tpalindrome_test.go:23 Error: Should be false Test: TestNonPalindrome --- FAIL: TestNonPalindrome (0.00s) 由此可见，重构后的测试用例更加简洁，可读性也更加好了。而且，在断言出错的情况下，打印出来的错误信息也相对丰富。\ntestify底层实现也是基于go test框架，在上述用法中，每个assert方法都将testing.T作为第一个入参，以此来使用go test框架的错误报告的基础能力。另外，如果你在一个测试方法中需要断言很多次，每次都传参testing.T就显得比较繁琐，那么可以这样实现来简化：\nfunc TestSomething(t *testing.T) { // 创建一个assert实例，只需传参testing.T一次 \tassert := assert.New(t) // 断言两者相等 \tassert.Equal(123, 123) // 断言两者不相等 \tassert.NotEqual(123, 456) // 断言某个实例为nil \tassert.Nil(object) // 断言object实例不为nil \tif assert.NotNil(object) { // 当知道object不为nil之后，就可以安全地对其进行访问了 \t// 进一步断言object的Value属性的值为\u0026#34;Something\u0026#34; \tassert.Equal(\u0026#34;Something\u0026#34;, object.Value) } } testify有着极其丰富的断言方法，除了上述几个assert.True、assert.Nil、assert.Equal常用的断言方法以外，还有用来断言目录是否存在的assert.DirExists；断言某个方法是否抛出panic的assert.Panics；断言字符串是否符合指定正则表达式的assert.Regexp，等等。总之，testify绝对能够满足你在Go单元测试断言方面的所有需要。\n 更多用法请参考testify assert API文档：https://godoc.org/github.com/stretchr/testify/assert\n 总结 本文主要介绍了如何使用testify库来为Go单元测试引入断言的能力，以此来使得测试用例代码更加简洁。assert只是testify库提供能力之一，比如它还有mock包，提供了“打桩”的能力。说起“打桩”，写过Java单元测试的同学一定很熟悉，Java中的Mockito和PowerMock框架就提供了类似的功能。本文之所以没有介绍testify库的mock功能，是因为还有更加好用的mock库。下一篇文章，我们将介绍如何高效、优雅地在Go单元测试中进行打桩。\n","date":"2020-12-22T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E7%BC%96%E5%86%99go%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B8%80/","title":"如何高效编写Go单元测试（一）"},{"content":"家乡博贺是粤西的一个小渔港，三面环海的地理位置，天然的深水港口，让这里有着吃不完的海鲜。每个人的家乡都会或多或少有着独特的风俗习惯，博贺也不例外。小时候最喜欢的节日，除了春节以外，便是中秋节了。不是因为月饼，更不是因为“团圆”寓意，对于小孩子而言，真正能让我们期待的是自家的烧烤。\n小时候以为中秋节烧烤，那得是全国都有的习惯吧。等出来读大学之后才发现，这竟然是博贺独特的风俗。不同于现在满大街的烧烤店，二十年前，也只有春节的时候才能在街上看到大大小小的烧烤摊，更别说自家买食材开炉烧烤了。于是，中秋夜便成了家乡小孩子无比期待的一年一度的“烧烤庆典”。\n博贺的中秋夜有两个流程，先是赏月，然后才是烧烤。所谓赏月其实是对月亮的祭拜，在自家门前摆一个桌子，放上月饼、柚子、糖水等，倒几杯米酒，插上蜡烛和香，然后一家人坐在桌子前，一边赏着月亮，一边吃着月饼，一边扯着家常。对于小孩子而言，这当然是枯燥的，小时候对月饼无感，特别是叉烧伍仁馅，那简直就是黑暗料理之王。于是总追着妈妈问，“妈，几时赏完月啊？”，然而等到的回答永远都是，“等一阵，月公还未食完呢”。\n等赏完月，收拾好桌子，就可以准备开始烧烤了。整一条街，每家门口都摆上了烧烤炉，通街都是明亮的炉火，也别是一番风景。\n小时候的烧烤大多是鸡翅、鸡肾、鸡翅根、鲜牛肉等普通食材，但博贺烧烤的精华在于食材的腌制。食材通常在上午就已经准备好，加上自己调制的酱汁，要腌制个大半天。酱汁主料是生抽，还得配上新鲜的香葱、甜椒、大蒜和生姜，再加些许蚝油等调味，这些普通的调料混在一起，竟成了美味的自制烧烤汁。等到晚上把食材取出来烧烤时，酱汁的香味早已深深潜入到食材内部。\n火炭的高温能够把食材的风味发挥到极致，把腌制好的鸡翅放到炭炉上炙烤十几分钟，等鸡翅表面成了金黄色后，撒上白芝麻，再烤一会就能上口吃了。长时间的腌制使得鸡翅即使经过了高温的炙烤也依旧饱满，一口下去，焦脆的表皮下，是饱满多汁的鸡肉。外焦内嫩的口感，满口的香味，这样的鸡翅谁能不爱。这也使得烧鸡翅在我心中一直占据着烧烤之王的地位。\n长大些后，家庭条件好了些，海鲜也加入到烧烤食材的阵营里。不同于肉类的腌制，海鲜的烧烤则注重原汁原味。先把新鲜大虾的虾线挑出，用竹签串起，放到炭炉上烤至七成熟后，在表面上涂上一层生抽，然后烤至九成熟就可以起炉了。一口下去，鲜甜的虾肉再带上淡淡的酱香味，嗯，满分。\n一直觉得家乡的烧烤跟日料烧肉很像，腌制入味、酱汁饱满，以至于每次在外吃到干巴巴、满口孜然味的烧烤时，都会无比怀念家乡的自家烧烤。如今，小镇上早已开满了大大小小的烧烤店，吃烧烤也不再只属于节日的狂欢。但是家乡中秋夜烧烤的习俗还是很好的保留了下来，也许比起烧烤，大家更享受的是那份团圆的气氛吧。\n","date":"2020-10-02T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%AE%B6%E4%B9%A1%E7%9A%84%E4%B8%AD%E7%A7%8B%E7%83%A7%E7%83%A4%E5%A4%9C/","title":"家乡的中秋烧烤夜"},{"content":"前言 当你点开一个招聘APP，筛选条件选择互联网技术，在列出来的一大堆职位上，往往有那么几个带有“架构师”三个字眼的高薪职位。当你被它的高薪所吸引而点击查看职位详情时，又会被它的高要求所劝退。它们往往要求工作年限在5年以上，需要求职者有过3年以上的系统设计经验，精通各种架构模式和系统框架，反观自己却一个条件都不满足。\n软件架构师就是这么一个让人向往，但又让人望洋兴叹的一个职位。就像建筑设计师总有成为总设计师的梦想，航天工作者总有成为总工程师的壮志，相信每一个软件工程师都有过成为软件架构师的想法。引用维基百科里的定义，软件架构师的职责就是在软件系统研发中，负责依据需求来确定主要的技术选择、设计系统的主体框架结构，并负责搭建实施。然而，架构师所需的技能远远不止于技术选择和系统设计。本文主要介绍软件架构的定义，以及要成为一个软件架构师所需具备的一些技能，让你对软件架构师这一职位有一个更深的了解。\n 文中大部分的观点来自于《Fundamentals of Software Architecture》一书，想了解更多详情推荐阅读原书。\n 软件架构的定义 对于软件架构（Software Architecture），我们通常将它看成是软件系统的蓝图（blueprint），但是如果要给出一个精确的定义，往往很难。维基百科里对软件架构的定义为，有关软件整体结构与组件的抽象描述，用于指导大型软件系统各个方面的设计。但是，这种定义也是片面的，软件架构并不仅仅是系统的整体结构和组件，光有这些还不足以指导设计出好的软件系统。\nMark Richards和Neal Ford在书中，从四个维度上对软件架构进行了描述，分别是Structure、Architecture characteristics、Architecture decisions和Design principles。\nStructure Structure描述的是软件系统所使用的架构风格，比如最常见的分层架构（layered architecture）、事件驱动架构（event-driven architecture）、微核架构（microkernel architecture）、微服务架构（microservices architecture）等等。当你去问架构师一个软件系统使用什么架构时，如果他告诉你，“系统使用的是微服务架构”，那么也他仅仅阐明了系统的架构风格而已。若想了解整个系统的软件架构，对architecture characteristics、architecture decisions和design principles都要有深入的认识。\nArchitecture characteristics Architecture characteristics也就是我们常说的非功能需求，比如有可用性（Availability）、可扩展性（Scalability）、可靠性（Reliability）等。Architecture characteristics往往容易被软件新手所忽略，但是它对于软件系统而言却是非常的重要。如果说功能需求决定了一个软件系统的下限，那么非功能需求则决定了它的上限。\nArchitecture decisions Architecture decisions描述了开发软件系统时所必须遵循的规则，比如图中例子，对于一个分层架构风格的系统而言，开发工程师需要遵循以下规则：只有业务层才能直接访问服务层，表现层不能直接访问服务层。Architecture decisions更多的只是一种约束，违反了这种约束可能并不会对系统的功能造成影响，但是却是系统架构腐化的源头。\nDesign principles Design principles指的是系统设计的原则，用于引导开发团队选择更符合系统特点的技术方案。Design principles只会给出一个方向，而不是具体的实现方案。比如图中例子给出的系统设计原则就是：微服务之间应该尽可能通过异步通信来提升系统的性能。至于开发团队通过REST或者RPC的方式进行异步通信实现，设计原则并未进行限制。\n成为架构师所需的技能 就像软件架构不仅仅是系统的整体结构和组件一样，要成为一个软件架构师，只会技术选型是远远不够的。一个合格的软件架构师应该具备以下的几种技能：\n进行架构决策  An architect is expected to define the architecture decisions and design principles used to guide technology decisions within the team, the department, or across the enterprise.\n 这是一个架构师所需具备的最基本的技能，需要为开发团队给出系统设计的原则和系统开发的约束。架构师在这里的角色更多的是一个引导者，而不是具体技术方案的制定者。比如，开发团队要进行前端框架的选型，作为架构师应该给出的建议是选择Reactive风格的前端框架（引导团队在React.js、Angular、Vue.js或者其他Reactive风格的前端框架之间进行选择），而不是直接建议选择React.js框架。前者属于架构决策，而后者则是技术决策。\n持续对系统架构进行分析  An architect is expected to continually analyze the architecture and current technology environment and then recommend solutions for improvement.\n 就像一个软件系统的生命周期并不止于开发阶段的结束，软件架构也不是一锤子买卖。这就要求架构师能够持续对系统架构进行分析，并提出改进的建议，使得系统在面对业务和技术的双重变化时，仍然能够保持架构良好。\n保持对技术和业界的发展趋势的敏感  An architect is expected to keep current with the latest technology and industry trends\n 作为一个架构师必须时刻保持对技术和业界发展趋势的敏感。在敏捷开发的潮流下，软件的特性会频繁的发生变化，但是软件的基础架构往往是很少改变的。架构师如果不能把握当前技术和业界发展的趋势，从而导致设计出来的软件架构不能够应付未来几年的业务和技术变化，这对于一个软件系统而言将会是灾难性的。\n确保团队按照既定的规则进行开发  An architect is expected to ensure compliance with architecture decisions and design principles.\n 架构师不仅仅需要制定设计原则和开发约束，还需要确保团队能够一直按照这些规则进行软件开发。这就要求架构师对开发人员提交的核心代码进行Code Review，否则系统的架构很容易就腐化掉了。\n扩展知识的广度  An architect is expected to have exposure to multiple and diverse technologies, frameworks, platforms, and environments.\n 对于一个架构师而言，他并不需要精通每一种框架、平台和语言，但至少要尽可能多的了解它们，这样才能更好的支撑架构决策。这就要求架构师能够持续的学习新的知识，不断地跳出自己的舒适区。最好的情况就是精通2～3种语言和框架，并且熟悉业界各种常用的语言和框架，这样的知识深度和广度的结合才能设计出更好的软件架构。\n拥有一定的领域知识  An architect is expected to have a certain level of business domain expertise.\n 所有的技术都是服务于既有的业务，剥离了业务的软件技术毫无价值。架构师无需像领域专家一样精通系统的各种业务，但至少也要有一定的业务积累。软件是用来解决问题的，不懂业务的架构师来做软件架构设计，就相当于还没读懂题目就开始解题，结果往往适得其反。比如一个需要低时延的业务，交给一个不懂业务的架构师来进行系统设计，可能得出来的是一个高吞吐量的架构。\n人际交往的能力  An architect is expected to possess exceptional interpersonal skills, including teamwork, facilitation, and leadership.\n 对于大部分的开发工程师和架构师而言，这可能是最难的一条了要求了。他们很擅长，也很乐意去解决技术上的问题，但是对于与人相关的问题则相当的抵触。但这对于一个合格架构师来说所必须克服的一点，因为架构师不仅仅需要制定技术规则，更重要的是领导团队按照既定规则进行开发，这不可避免地就涉及到领导力和人际交往的能力。\n当一个开发工程师决定在一次需求开发中采用单例模式，可能团队里的其他人并不会有太多的关注。但是当一个架构师决定采用微服务架构来设计系统时，可能就会受到团队内各类人员的挑战，比如版本经理可能觉得微服务架构太复杂，会不会影响交付的节奏；开发人员可能觉得分层架构更好实现。这种情况下就要求架构师能够有很好的人际交往能力，说服各类人员，这样项目才能更好的进行下去。\n总结 软件架构是一个很抽象的东西，目前对它的定义大部分都是一些很宽泛的描述。《Fundamentals of Software Architecture》从四个维度上对软件架构进行了描述，让软件架构有了一个更加清晰的视图。在此基础上，书中也提出了一个合格的软件架构师所需要具备的几种技能。总的来说，就是想要设计出一个好的软件架构很难，要成为一个好的软件架构师更难。\n另外，书中还提出了软件架构的两个准则，很有道理，就是有点抽象。不过没关系，不要试图理解它，要去感受它。\n 1、Everything in software architecture is a trade-off.\n2、Why is more important than how.\n ","date":"2020-09-13T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%9C%A8%E6%88%90%E4%B8%BA%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E5%89%8D%E6%89%80%E9%9C%80%E4%BA%86%E8%A7%A3%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/","title":"在成为架构师之前所需了解的一些知识"},{"content":"前言 上一篇文章《使用Go实现GoF的23种设计模式（二）》中，我们介绍了结构型模式（Structural Pattern）中的组合模式、适配器模式和桥接模式。本文将会介绍完剩下的几种结构型模式，代理模式、装饰模式、外观模式和享元模式。本文将会继续采用消息处理系统作为例子，如果对该例子不清楚，请移步《使用Go实现GoF的23种设计模式（一）》和《使用Go实现GoF的23种设计模式（二）》对其相关的设计和实现进行了解。\n代理模式（Proxy Pattern） 简介 代理模式为一个对象提供一种代理以控制对该对象的访问，它是一个使用率非常高的设计模式，即使在现实生活中，也是很常见，比如演唱会门票黄牛。假设你需要看一场演唱会，但是官网上门票已经售罄，于是就当天到现场通过黄牛高价买了一张。在这个例子中，黄牛就相当于演唱会门票的代理，在正式渠道无法购买门票的情况下，你通过代理完成了该目标。\n从演唱会门票的例子我们也可以看出，使用代理模式的关键在于当Client不方便直接访问一个对象时，提供一个代理对象控制该对象的访问。Client实际上访问的是代理对象，代理对象会将Client的请求转给本体对象去处理。\n在程序设计中，代理模式也分为好几种：\n1、远程代理（remote proxy），远程代理适用于提供服务的对象处在远程的机器上，通过普通的函数调用无法使用服务，需要经过远程代理来完成。因为并不能直接访问本体对象，所有远程代理对象通常不会直接持有本体对象的引用，而是持有远端机器的地址，通过网络协议去访问本体对象。\n2、虚拟代理（virtual proxy），在程序设计中常常会有一些重量级的服务对象，如果一直持有该对象实例会非常消耗系统资源，这时可以通过虚拟代理来对该对象进行延迟初始化。\n3、保护代理（protection proxy），保护代理用于控制对本体对象的访问，常用于需要给Client的访问加上权限验证的场景。\n4、缓存代理（cache proxy），缓存代理主要在Client与本体对象之间加上一层缓存，用于加速本体对象的访问，常见于连接数据库的场景。\n5、智能引用（smart reference），智能引用为本体对象的访问提供了额外的动作，常见的实现为C++中的智能指针，为对象的访问提供了计数功能，当访问对象的计数为0时销毁该对象。\n这几种代理都是一样的实现原理，下面我们将介绍远程代理的Go语言实现。\nGo实现 考虑要将消息处理系统输出到数据存储到一个数据库中，数据库的接口如下：\npackage db ... // Key-Value数据库接口 type KvDb interface { // 存储数据 \t// 其中reply为操作结果，存储成功为true，否则为false \t// 当连接数据库失败时返回error，成功则返回nil \tSave(record Record, reply *bool) error // 根据key获取value，其中value通过函数参数中指针类型返回 \t// 当连接数据库失败时返回error，成功则返回nil \tGet(key string, value *string) error } type Record struct { Key string Value string } 数据库是一个Key-Value数据库，使用map存储数据，下面为数据库的服务端实现，db.Server实现了db.KvDb接口：\npackage db ... // 数据库服务端实现 type Server struct { // 采用map存储key-value数据 \tdata map[string]string } func (s *Server) Save(record Record, reply *bool) error { if s.data == nil{ s.data = make(map[string]string) } s.data[record.Key] = record.Value *reply = true return nil } func (s *Server) Get(key string, reply *string) error { val, ok := s.data[key] if !ok { *reply = \u0026#34;\u0026#34; return errors.New(\u0026#34;Db has no key \u0026#34; + key) } *reply = val return nil } 消息处理系统和数据库并不在同一台机器上，因此消息处理系统不能直接调用db.Server的方法进行数据存储，像这种服务提供者和服务使用者不在同一机器上的场景，使用远程代理再适合不过了。\n远程代理中，最常见的一种实现是远程过程调用（Remote Procedure Call，简称 RPC），它允许客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法。在Go语言领域，除了大名鼎鼎的gRPC，Go标准库net/rpc包里也提供了RPC的实现。下面，我们通过net/rpc对外提供数据库服务端的能力：\npackage db ... // 启动数据库，对外提供RPC接口进行数据库的访问 func Start() { rpcServer := rpc.NewServer() server := \u0026amp;Server{data: make(map[string]string)} // 将数据库接口注册到RPC服务器上 \tif err := rpcServer.Register(server); err != nil { fmt.Printf(\u0026#34;Register Server to rpc failed, error: %v\u0026#34;, err) return } l, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:1234\u0026#34;) if err != nil { fmt.Printf(\u0026#34;Listen tcp failed, error: %v\u0026#34;, err) return } go rpcServer.Accept(l) time.Sleep(1 * time.Second) fmt.Println(\u0026#34;Rpc server start success.\u0026#34;) } 到目前为止，我们已经为数据库提供了对外访问的方式。现在，我们需要一个远程代理来连接数据库服务端，并进行相关的数据库操作。对消息处理系统而言，它不需要，也不应该知道远程代理与数据库服务端交互的底层细节，这样可以减轻系统之间的耦合。因此，远程代理需要实现db.KvDb：\npackage db ... // 数据库服务端远程代理，实现db.KvDb接口 type Client struct { // RPC客户端 \tcli *rpc.Client } func (c *Client) Save(record Record, reply *bool) error { var ret bool // 通过RPC调用服务端的接口 \terr := c.cli.Call(\u0026#34;Server.Save\u0026#34;, record, \u0026amp;ret) if err != nil { fmt.Printf(\u0026#34;Call db Server.Save rpc failed, error: %v\u0026#34;, err) *reply = false return err } *reply = ret return nil } func (c *Client) Get(key string, reply *string) error { var ret string // 通过RPC调用服务端的接口 \terr := c.cli.Call(\u0026#34;Server.Get\u0026#34;, key, \u0026amp;ret) if err != nil { fmt.Printf(\u0026#34;Call db Server.Get rpc failed, error: %v\u0026#34;, err) *reply = \u0026#34;\u0026#34; return err } *reply = ret return nil } // 工厂方法，返回远程代理实例 func CreateClient() *Client { rpcCli, err := rpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:1234\u0026#34;) if err != nil { fmt.Printf(\u0026#34;Create rpc client failed, error: %v.\u0026#34;, err) return nil } return \u0026amp;Client{cli: rpcCli} } 作为远程代理的db.Client并没有直接持有db.Server的引用，而是持有了它的ip:port，通过RPC客户端调用了它的方法。\n接下来，我们需要为消息处理系统实现一个新的Output插件DbOutput，调用db.Client远程代理，将消息存储到数据库上。\n 在《使用Go实现GoF的23种设计模式（二）》中我们为Plugin引入生命周期的三个方法Start、Stop、Status之后，每新增一个新的插件，都需要实现这三个方法。但是大多数插件的这三个方法的逻辑基本一致，因此导致了一定程度的代码冗余。对于重复代码问题，有什么好的解决方法呢？组合模式！\n下面，我们使用组合模式将这个方法提取成一个新的对象LifeCycle，这样新增一个插件时，只需将LifeCycle作为匿名成员（嵌入组合），就能解决冗余代码问题了。\npackage plugin ... type LifeCycle struct { name string status Status } func (l *LifeCycle) Start() { l.status = Started fmt.Printf(\u0026#34;%s plugin started.\\n\u0026#34;, l.name) } func (l *LifeCycle) Stop() { l.status = Stopped fmt.Printf(\u0026#34;%s plugin stopped.\\n\u0026#34;, l.name) } func (l *LifeCycle) Status() Status { return l.status }  DbOutput的实现如下，它持有一个远程代理，通过后者将消息存储到远端的数据库中。\npackage plugin ... type DbOutput struct { LifeCycle // 操作数据库的远程代理 \tproxy db.KvDb } func (d *DbOutput) Send(msg *msg.Message) { if d.status != Started { fmt.Printf(\u0026#34;%s is not running, output nothing.\\n\u0026#34;, d.name) return } record := db.Record{ Key: \u0026#34;db\u0026#34;, Value: msg.Body.Items[0], } reply := false err := d.proxy.Save(record, \u0026amp;reply) if err != nil || !reply { fmt.Println(\u0026#34;Save msg to db server failed.\u0026#34;) } } func (d *DbOutput) Init() { d.proxy = db.CreateClient() d.name = \u0026#34;db output\u0026#34; } 测试代码如下：\npackage test ... func TestDbOutput(t *testing.T) { db.Start() config := pipeline.Config{ Name: \u0026#34;pipeline3\u0026#34;, Input: plugin.Config{ PluginType: plugin.InputType, Name: \u0026#34;hello\u0026#34;, }, Filter: plugin.Config{ PluginType: plugin.FilterType, Name: \u0026#34;upper\u0026#34;, }, Output: plugin.Config{ PluginType: plugin.OutputType, Name: \u0026#34;db\u0026#34;, }, } p := pipeline.Of(config) p.Start() p.Exec() // 验证DbOutput存储的正确性 \tcli := db.CreateClient() var val string err := cli.Get(\u0026#34;db\u0026#34;, \u0026amp;val) if err != nil { t.Errorf(\u0026#34;Get db failed, error: %v\\n.\u0026#34;, err) } if val != \u0026#34;HELLO WORLD\u0026#34; { t.Errorf(\u0026#34;expect HELLO WORLD, but actual %s.\u0026#34;, val) } } // 运行结果 === RUN TestDbOutput Rpc server start success. db output plugin started. upper filter plugin started. hello input plugin started. Pipeline started. --- PASS: TestDbOutput (1.01s) PASS 装饰模式（Decorator Pattern） 简介 在程序设计中，我们常常需要为对象添加新的行为，很多同学的第一个想法就是扩展本体对象，通过继承的方式达到目的。但是使用继承不可避免地有如下两个弊端：（1）继承时静态的，在编译期间就已经确定，无法在运行时改变对象的行为。（2）子类只能有一个父类，当需要添加的新功能太多时，容易导致类的数量剧增。\n对于这种场景，我们通常会使用装饰模式（Decorator Pattern）来解决，它使用组合而非继承的方式，能够动态地为本体对象叠加新的行为。理论上，只要没有限制，它可以一直把功能叠加下去。装饰模式最经典的应用当属Java的I/O流体系，通过装饰模式，使用者可以动态地为原始的输入输出流添加功能，比如按照字符串输入输出，添加缓存等，使得整个I/O流体系具有很高的可扩展性和灵活性。\n从结构上看，装饰模式和代理模式具有很高的相似性，但是两种所强调的点不一样。前者强调的是为本体对象添加新的功能，后者强调的是对本体对象的访问控制。当然，代理模式中的智能引用在笔者看来就跟装饰模式完全一样了。\nGo实现 考虑为消息处理系统增加这样的一个功能，统计每个消息输入源分别产生了多少条消息，也就是分别统计每个Input产生Message的数量。最简单的方法是在每一个Input的Receive方法中进行打点统计，但是这样会导致统计代码与业务代码的耦合。如果统计逻辑发生了变化，就会产生霰弹式修改，随着Input类型的增多，相关代码也会变得越来越难维护。\n更好的方法是将统计逻辑放到一个地方，并在每次调用Input的Receive方法后进行打点统计。而这恰好适合采用装饰模式，为Input（本体对象）提供打点统计功能（新的行为）。我们可以设计一个InputMetricDecorator作为Input的装饰器，在装饰器中完成打点统计的逻辑。\n首先，我们需要设计一个用于统计每个Input产生Message数量的对象，该对象应该是一个全局唯一的，因此采用单例模式进行了实现：\npackage metric ... // 消息输入源统计，设计为单例 type input struct { // 存放统计结果，key为Input类型如hello、kafka \t// value为对应Input的消息统计 \tmetrics map[string]uint64 // 统计打点时加锁 \tmu *sync.Mutex } // 给名称为inputName的Input消息计数加1 func (i *input) Inc(inputName string) { i.mu.Lock() defer i.mu.Unlock() if _, ok := i.metrics[inputName]; !ok { i.metrics[inputName] = 0 } i.metrics[inputName] = i.metrics[inputName] + 1 } // 输出当前所有打点的情况 func (i *input) Show() { fmt.Printf(\u0026#34;Input metric: %v\\n\u0026#34;, i.metrics) } // 单例 var inputInstance = \u0026amp;input{ metrics: make(map[string]uint64), mu: \u0026amp;sync.Mutex{}, } func Input() *input { return inputInstance } 接下来我们开始实现InputMetricDecorator，它实现了Input接口，并持有一个本体对象Input。在InputMetricDecorator在Receive方法中调用本体Input的Receive方法，并完成统计动作。\npackage plugin ... type InputMetricDecorator struct { input Input } func (i *InputMetricDecorator) Receive() *msg.Message { // 调用本体对象的Receive方法 \trecord := i.input.Receive() // 完成统计逻辑 \tif inputName, ok := record.Header.Items[\u0026#34;input\u0026#34;]; ok { metric.Input().Inc(inputName) } return record } func (i *InputMetricDecorator) Start() { i.input.Start() } func (i *InputMetricDecorator) Stop() { i.input.Stop() } func (i *InputMetricDecorator) Status() Status { return i.input.Status() } func (i *InputMetricDecorator) Init() { i.input.Init() } // 工厂方法, 完成装饰器的创建 func CreateInputMetricDecorator(input Input) *InputMetricDecorator { return \u0026amp;InputMetricDecorator{input: input} } 最后，我们在Pipeline的工厂方法上，为本体Input加上InputMetricDecorator代理：\npackage pipeline ... // 根据配置创建一个Pipeline实例 func Of(conf Config) *Pipeline { p := \u0026amp;Pipeline{} p.input = factoryOf(plugin.InputType).Create(conf.Input).(plugin.Input) p.filter = factoryOf(plugin.FilterType).Create(conf.Filter).(plugin.Filter) p.output = factoryOf(plugin.OutputType).Create(conf.Output).(plugin.Output) // 为本体Input加上InputMetricDecorator装饰器 \tp.input = plugin.CreateInputMetricDecorator(p.input) return p } 测试代码如下：\npackage test ... func TestInputMetricDecorator(t *testing.T) { p1 := pipeline.Of(pipeline.HelloConfig()) p2 := pipeline.Of(pipeline.KafkaInputConfig()) p1.Start() p2.Start() p1.Exec() p2.Exec() p1.Exec() metric.Input().Show() } // 运行结果 === RUN TestInputMetricDecorator Console output plugin started. Upper filter plugin started. Hello input plugin started. Pipeline started. Console output plugin started. Upper filter plugin started. Kafka input plugin started. Pipeline started. Output: Header:map[content:text input:hello], Body:[HELLO WORLD] Output: Header:map[content:text input:kafka], Body:[I AM MOCK CONSUMER.] Output: Header:map[content:text input:hello], Body:[HELLO WORLD] Input metric: map[hello:2 kafka:1] --- PASS: TestInputMetricProxy (0.00s) PASS 外观模式（Facade Pattern） 简介 从结构上看，外观模式非常的简单，它主要是为子系统提供了一个更高层次的对外统一接口，使得Client能够更友好地使用子系统的功能。图中，Subsystem Class是子系统中对象的简称，它可能是一个对象，也可能是数十个对象的集合。外观模式降低了Client与Subsystem之间的耦合，只要Facade不变，不管Subsystem怎么变化，对于Client而言都是无感知的。\n外观模式在程序设计中用的非常多，比如我们在商城上点击购买的按钮，对于购买者而言，只看到了购买这一统一的接口，但是对于商城系统而言，其内部则进行了一系列的业务处理，比如库存检查、订单处理、支付、物流等等。外观模式极大地提升了用户体验，将用户从复杂的业务流程中解放了出来。\n外观模式经常运用于分层架构上，通常我们都会为分层架构中的每一个层级提供一个或多个统一对外的访问接口，这样就能让各个层级之间的耦合性更低，使得系统的架构更加合理。\nGo实现 外观模式实现起来也很简单，还是考虑前面的消息处理系统。在Pipeline中，每一条消息会依次经过Input-\u0026gt;Filter-\u0026gt;Output的处理，代码实现起来就是这样：\np := pipeline.Of(config) message := p.input.Receive() message = p.filter.Process(message) p.output.Send(message) 但是，对于Pipeline的使用者而言，他可能并不关心消息具体的处理流程，他只需知道消息已经经过Pipeline处理即可。因此，我们需要设计一个简单的对外接口：\npackage pipeline ... func (p *Pipeline) Exec() { msg := p.input.Receive() msg = p.filter.Process(msg) p.output.Send(msg) } 这样，使用者只需简单地调用Exec方法，就能完成一次消息的处理，测试代码如下：\npackage test ... func TestPipeline(t *testing.T) { p := pipeline.Of(pipeline.HelloConfig()) p.Start() // 调用Exec方法完成一次消息的处理 \tp.Exec() } // 运行结果 === RUN TestPipeline console output plugin started. upper filter plugin started. hello input plugin started. Pipeline started. Output: Header:map[content:text input:hello], Body:[HELLO WORLD] --- PASS: TestPipeline (0.00s) PASS 享元模式（Flyweight Pattern） 简介 在程序设计中，我们常常会碰到一些很重型的对象，它们通常拥有很多的成员属性，当系统中充斥着大量的这些对象时，系统的内存将会承受巨大的压力。此外，频繁的创建这些对象也极大地消耗了系统的CPU。很多时候，这些重型对象里，大部分的成员属性都是固定的，这种场景下， 可以使用享元模式进行优化，将其中固定不变的部分设计成共享对象（享元，flyweight），这样就能节省大量的系统内存和CPU。\n享元模式摒弃了在每个对象中保存所有数据的方式， 通过共享多个对象所共有的相同状态， 让你能在有限的内存容量中载入更多对象。\n当我们决定对一个重型对象采用享元模式进行优化时，首先需要将该重型对象的属性划分为两类，能够共享的和不能共享的。前者我们称为内部状态（intrinsic state），存储在享元中，不随享元所处上下文的变化而变化；后者称为外部状态（extrinsic state），它的值取决于享元所处的上下文，因此不能共享。比如，文章A和文章B都引用了图片A，由于文章A和文章B的文字内容是不一样的，因此文字就是外部状态，不能共享；但是它们所引用的图片A是一样的，属于内部状态，因此可以将图片A设计为一个享元\n工厂模式通常都会和享元模式结对出现，享元工厂提供了唯一获取享元对象的接口，这样Client就感知不到享元是如何共享的，降低了模块的耦合性。享元模式和单例模式有些类似的地方，都是在系统中共享对象，但是单例模式更关心的是对象在系统中仅仅创建一次，而享元模式更关心的是如何在多个对象中共享相同的状态。\nGo实现 假设现在需要设计一个系统，用于记录NBA中的球员信息、球队信息以及比赛结果。\n球队Team的数据结构定义如下：\npackage nba ... type TeamId uint8 const ( Warrior TeamId = iota Laker ) type Team struct { Id TeamId // 球队ID \tName string // 球队名称 \tPlayers []*Player // 球队中的球员 } 球员Player的数据结构定义如下：\npackage nba ... type Player struct { Name string // 球员名字 \tTeam TeamId // 球员所属球队ID } 比赛结果Match的数据结构定义如下：\npackage nba ... type Match struct { Date time.Time // 比赛时间 \tLocalTeam *Team // 主场球队 \tVisitorTeam *Team // 客场球队 \tLocalScore uint8 // 主场球队得分 \tVisitorScore uint8 // 客场球队得分 } func (m *Match) ShowResult() { fmt.Printf(\u0026#34;%s VS %s - %d:%d\\n\u0026#34;, m.LocalTeam.Name, m.VisitorTeam.Name, m.LocalScore, m.VisitorScore) } NBA中的一场比赛由两个球队，主场球队和客场球队，完成比赛，对应着代码就是，一个Match实例会持有2个Team实例。目前，NBA总共由30支球队，按照每个赛季每个球队打82场常规赛算，一个赛季总共会有2460场比赛，对应地，就会有4920个Team实例。但是，NBA的30支球队是固定的，实际上只需30个Team实例就能完整地记录一个赛季的所有比赛信息，剩下的4890个Team实例属于冗余的数据。\n这种场景下就适合采用享元模式来进行优化，我们把Team设计成多个Match实例之间的享元。享元的获取通过享元工厂来完成，享元工厂teamFactory的定义如下，Client统一使用teamFactory.TeamOf方法来获取球队Team实例。其中，每个球队Team实例只会创建一次，然后添加到球队池中，后续获取都是直接从池中获取，这样就达到了共享的目的。\npackage nba ... type teamFactory struct { // 球队池，缓存球队实例 \tteams map[TeamId]*Team } // 根据TeamId获取Team实例，从池中获取，如果池里没有，则创建 func (t *teamFactory) TeamOf(id TeamId) *Team { team, ok := t.teams[id] if !ok { team = createTeam(id) t.teams[id] = team } return team } // 享元工厂的单例 var factory = \u0026amp;teamFactory{ teams: make(map[TeamId]*Team), } func Factory() *teamFactory { return factory } // 根据TeamId创建Team实例，只在TeamOf方法中调用，外部不可见 func createTeam(id TeamId) *Team { switch id { case Warrior: w := \u0026amp;Team{ Id: Warrior, Name: \u0026#34;Golden State Warriors\u0026#34;, } curry := \u0026amp;Player{ Name: \u0026#34;Stephen Curry\u0026#34;, Team: Warrior, } thompson := \u0026amp;Player{ Name: \u0026#34;Klay Thompson\u0026#34;, Team: Warrior, } w.Players = append(w.Players, curry, thompson) return w case Laker: l := \u0026amp;Team{ Id: Laker, Name: \u0026#34;Los Angeles Lakers\u0026#34;, } james := \u0026amp;Player{ Name: \u0026#34;LeBron James\u0026#34;, Team: Laker, } davis := \u0026amp;Player{ Name: \u0026#34;Anthony Davis\u0026#34;, Team: Laker, } l.Players = append(l.Players, james, davis) return l default: fmt.Printf(\u0026#34;Get an invalid team id %v.\\n\u0026#34;, id) return nil } } 测试代码如下：\npackage test ... func TestFlyweight(t *testing.T) { game1 := \u0026amp;nba.Match{ Date: time.Date(2020, 1, 10, 9, 30, 0, 0, time.Local), LocalTeam: nba.Factory().TeamOf(nba.Warrior), VisitorTeam: nba.Factory().TeamOf(nba.Laker), LocalScore: 102, VisitorScore: 99, } game1.ShowResult() game2 := \u0026amp;nba.Match{ Date: time.Date(2020, 1, 12, 9, 30, 0, 0, time.Local), LocalTeam: nba.Factory().TeamOf(nba.Laker), VisitorTeam: nba.Factory().TeamOf(nba.Warrior), LocalScore: 110, VisitorScore: 118, } game2.ShowResult() // 两个Match的同一个球队应该是同一个实例的 \tif game1.LocalTeam != game2.VisitorTeam { t.Errorf(\u0026#34;Warrior team do not use flyweight pattern\u0026#34;) } } // 运行结果 === RUN TestFlyweight Golden State Warriors VS Los Angeles Lakers - 102:99 Los Angeles Lakers VS Golden State Warriors - 110:118 --- PASS: TestFlyweight (0.00s) 总结 本文我们主要介绍了结构型模式中的代理模式、装饰模式、外观模式和享元模式。代理模式为一个对象提供一种代理以控制对该对象的访问，强调的是对本体对象的访问控制；装饰模式能够动态地为本体对象叠加新的行为，强调的是为本体对象添加新的功能；外观模式为子系统提供了一个更高层次的对外统一接口，强调的是分层和解耦；享元模式通过共享对象来降低系统的资源消耗，强调的是如何在多个对象中共享相同的状态。\n到目前为止，7种结构型模式已经全部介绍完，下一篇文章，我们开始将介绍最后一类设计模式——行为型模式（Behavioral Pattern）。\n","date":"2020-09-06T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BD%BF%E7%94%A8go%E5%AE%9E%E7%8E%B0gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%89/","title":"使用Go实现GoF的23种设计模式（三）"},{"content":"前言 上一篇文章《使用Go实现GoF的23种设计模式（一）》介绍了23种设计模式中的创建型模式（Creational Pattern），创建型模式是处理对象创建的一类设计模式，主要思想是向对象的使用者隐藏对象创建的具体细节，从而达到解耦的目的。本文主要聚焦在结构型模式（Structural Pattern）上，其主要思想是将多个对象组装成较大的结构，并同时保持结构的灵活和高效，从程序的结构上解决模块之间的耦合问题。\n组合模式（Composite Pattern） 简述 在面向对象编程中，有两个常见的对象设计方法，组合和继承，两者都可以解决代码复用的问题，但是使用后者时容易出现继承层次过深，对象关系过于复杂的副作用，从而导致代码的可维护性变差。因此，一个经典的面向对象设计原则是：组合优于继承。\n我们都知道，组合所表示的语义为“has-a”，也就是部分和整体的关系，最经典的组合模式描述如下：\n 将对象组合成树形结构以表示“部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。\n Go语言天然就支持了组合模式，而且从它不支持继承关系的特点来看，Go也奉行了组合优于继承的原则，鼓励大家在进行程序设计时多采用组合的方法。Go实现组合模式的方式有两种，分别是直接组合（Direct Composition）和嵌入组合（Embedding Composition），下面我们一起探讨这两种不同的实现方法。\nGo实现 直接组合（Direct Composition）的实现方式类似于Java/C++，就是将一个对象作为另一个对象的成员属性。\n一个典型的实现如《使用Go实现GoF的23种设计模式（一）》中所举的例子，一个Message结构体，由Header和Body所组成。那么Message就是一个整体，而Header和Body则为消息的组成部分。\ntype Message struct { Header *Header Body *Body } 现在，我们来看一个稍微复杂一点的例子，同样考虑上一篇文章中所描述的插件架构风格的消息处理系统。前面我们用抽象工厂模式解决了插件加载的问题，通常，每个插件都会有一个生命周期，常见的就是启动状态和停止状态，现在我们使用组合模式来解决插件的启动和停止问题。\n首先给Plugin接口添加几个生命周期相关的方法：\npackage plugin ... // 插件运行状态 type Status uint8 const ( Stopped Status = iota Started ) type Plugin interface { // 启动插件 \tStart() // 停止插件 \tStop() // 返回插件当前的运行状态 \tStatus() Status } // Input、Filter、Output三类插件接口的定义跟上一篇文章类似 // 这里使用Message结构体替代了原来的string，使得语义更清晰 type Input interface { Plugin Receive() *msg.Message } type Filter interface { Plugin Process(msg *msg.Message) *msg.Message } type Output interface { Plugin Send(msg *msg.Message) } 对于插件化的消息处理系统而言，一切皆是插件，因此我们将Pipeine也设计成一个插件，实现Plugin接口：\npackage pipeline ... // 一个Pipeline由input、filter、output三个Plugin组成 type Pipeline struct { status plugin.Status input plugin.Input filter plugin.Filter output plugin.Output } func (p *Pipeline) Exec() { msg := p.input.Receive() msg = p.filter.Process(msg) p.output.Send(msg) } // 启动的顺序 output -\u0026gt; filter -\u0026gt; input func (p *Pipeline) Start() { p.output.Start() p.filter.Start() p.input.Start() p.status = plugin.Started fmt.Println(\u0026#34;Hello input plugin started.\u0026#34;) } // 停止的顺序 input -\u0026gt; filter -\u0026gt; output func (p *Pipeline) Stop() { p.input.Stop() p.filter.Stop() p.output.Stop() p.status = plugin.Stopped fmt.Println(\u0026#34;Hello input plugin stopped.\u0026#34;) } func (p *Pipeline) Status() plugin.Status { return p.status } 一个Pipeline由Input、Filter、Output三类插件组成，形成了“部分-整体”的关系，而且它们都实现了Plugin接口，这就是一个典型的组合模式的实现。Client无需显式地启动和停止Input、Filter和Output插件，在调用Pipeline对象的Start和Stop方法时，Pipeline就已经帮你按顺序完成对应插件的启动和停止。\n相比于上一篇文章，在本文中实现Input、Filter、Output三类插件时，需要多实现3个生命周期的方法。还是以上一篇文章中的HelloInput、UpperFilter和ConsoleOutput作为例子，具体实现如下：\npackage plugin ... type HelloInput struct { status Status } func (h *HelloInput) Receive() *msg.Message { // 如果插件未启动，则返回nil \tif h.status != Started { fmt.Println(\u0026#34;Hello input plugin is not running, input nothing.\u0026#34;) return nil } return msg.Builder(). WithHeaderItem(\u0026#34;content\u0026#34;, \u0026#34;text\u0026#34;). WithBodyItem(\u0026#34;Hello World\u0026#34;). Build() } func (h *HelloInput) Start() { h.status = Started fmt.Println(\u0026#34;Hello input plugin started.\u0026#34;) } func (h *HelloInput) Stop() { h.status = Stopped fmt.Println(\u0026#34;Hello input plugin stopped.\u0026#34;) } func (h *HelloInput) Status() Status { return h.status } package plugin ... type UpperFilter struct { status Status } func (u *UpperFilter) Process(msg *msg.Message) *msg.Message { if u.status != Started { fmt.Println(\u0026#34;Upper filter plugin is not running, filter nothing.\u0026#34;) return msg } for i, val := range msg.Body.Items { msg.Body.Items[i] = strings.ToUpper(val) } return msg } func (u *UpperFilter) Start() { u.status = Started fmt.Println(\u0026#34;Upper filter plugin started.\u0026#34;) } func (u *UpperFilter) Stop() { u.status = Stopped fmt.Println(\u0026#34;Upper filter plugin stopped.\u0026#34;) } func (u *UpperFilter) Status() Status { return u.status } package plugin ... type ConsoleOutput struct { status Status } func (c *ConsoleOutput) Send(msg *msg.Message) { if c.status != Started { fmt.Println(\u0026#34;Console output is not running, output nothing.\u0026#34;) return } fmt.Printf(\u0026#34;Output:\\n\\tHeader:%+v, Body:%+v\\n\u0026#34;, msg.Header.Items, msg.Body.Items) } func (c *ConsoleOutput) Start() { c.status = Started fmt.Println(\u0026#34;Console output plugin started.\u0026#34;) } func (c *ConsoleOutput) Stop() { c.status = Stopped fmt.Println(\u0026#34;Console output plugin stopped.\u0026#34;) } func (c *ConsoleOutput) Status() Status { return c.status } 测试代码如下：\npackage test ... func TestPipeline(t *testing.T) { p := pipeline.Of(pipeline.DefaultConfig()) p.Start() p.Exec() p.Stop() } // 运行结果 === RUN TestPipeline Console output plugin started. Upper filter plugin started. Hello input plugin started. Pipeline started. Output: Header:map[content:text], Body:[HELLO WORLD] Hello input plugin stopped. Upper filter plugin stopped. Console output plugin stopped. Hello input plugin stopped. --- PASS: TestPipeline (0.00s) PASS 组合模式的另一种实现，嵌入组合（Embedding Composition），其实就是利用了Go语言的匿名成员特性，本质上跟直接组合是一致的。\n还是以Message结构体为例，如果采用嵌入组合，则看起来像是这样：\ntype Message struct { Header Body } // 使用时，Message可以引用Header和Body的成员属性，例如： msg := \u0026amp;Message{} msg.SrcAddr = \u0026#34;192.168.0.1\u0026#34; 适配器模式（Adapter Pattern） 简述 适配器模式是最常用的结构型模式之一，它让原本因为接口不匹配而无法一起工作的两个对象能够一起工作。在现实生活中，适配器模式也是处处可见，比如电源插头转换器，可以让英式的插头工作在中式的插座上。适配器模式所做的就是将一个接口Adaptee，通过适配器Adapter转换成Client所期望的另一个接口Target来使用，实现原理也很简单，就是Adapter通过实现Target接口，并在对应的方法中调用Adaptee的接口实现。\n一个典型的应用场景是，系统中一个老的接口已经过时即将废弃，但因为历史包袱没法立即将老接口全部替换为新接口，这时可以新增一个适配器，将老的接口适配成新的接口来使用。适配器模式很好的践行了面向对象设计原则里的开闭原则（open/closed principle），新增一个接口时也无需修改老接口，只需多加一个适配层即可。\nGo实现 继续考虑上一节的消息处理系统例子，目前为止，系统的输入都源自于HelloInput，现在假设需要给系统新增从Kafka消息队列中接收数据的功能，其中Kafka消费者的接口如下：\npackage kafka ... type Records struct { Items []string } type Consumer interface { Poll() Records } 由于当前Pipeline的设计是通过plugin.Input接口来进行数据接收，因此kafka.Consumer并不能直接集成到系统中。\n怎么办？使用适配器模式！\n为了能让Pipeline能够使用kafka.Consumer接口，我们需要定义一个适配器如下：\npackage plugin ... type KafkaInput struct { status Status consumer kafka.Consumer } func (k *KafkaInput) Receive() *msg.Message { records := k.consumer.Poll() if k.status != Started { fmt.Println(\u0026#34;Kafka input plugin is not running, input nothing.\u0026#34;) return nil } return msg.Builder(). WithHeaderItem(\u0026#34;content\u0026#34;, \u0026#34;text\u0026#34;). WithBodyItems(records.Items). Build() } // 在输入插件映射关系中加入kafka，用于通过反射创建input对象 func init() { inputNames[\u0026#34;hello\u0026#34;] = reflect.TypeOf(HelloInput{}) inputNames[\u0026#34;kafka\u0026#34;] = reflect.TypeOf(KafkaInput{}) } ... 因为Go语言并没有构造函数，如果按照上一篇文章中的抽象工厂模式来创建KafkaInput，那么得到的实例中的consumer成员因为没有被初始化而会是nil。因此，需要给Plugin接口新增一个Init方法，用于定义插件的一些初始化操作，并在工厂返回实例前调用。\npackage plugin ... type Plugin interface { Start() Stop() Status() Status // 新增初始化方法，在插件工厂返回实例前调用 \tInit() } // 修改后的插件工厂实现如下 func (i *InputFactory) Create(conf Config) Plugin { t, _ := inputNames[conf.Name] p := reflect.New(t).Interface().(Plugin) // 返回插件实例前调用Init函数，完成相关初始化方法 \tp.Init() return p } // KakkaInput的Init函数实现 func (k *KafkaInput) Init() { k.consumer = \u0026amp;kafka.MockConsumer{} } 上述代码中的kafka.MockConsumer为我们模式Kafka消费者的一个实现，代码如下：\npackage kafka ... type MockConsumer struct {} func (m *MockConsumer) Poll() *Records { records := \u0026amp;Records{} records.Items = append(records.Items, \u0026#34;i am mock consumer.\u0026#34;) return records } 测试代码如下：\npackage test ... func TestKafkaInputPipeline(t *testing.T) { config := pipeline.Config{ Name: \u0026#34;pipeline2\u0026#34;, Input: plugin.Config{ PluginType: plugin.InputType, Name: \u0026#34;kafka\u0026#34;, }, Filter: plugin.Config{ PluginType: plugin.FilterType, Name: \u0026#34;upper\u0026#34;, }, Output: plugin.Config{ PluginType: plugin.OutputType, Name: \u0026#34;console\u0026#34;, }, } p := pipeline.Of(config) p.Start() p.Exec() p.Stop() } // 运行结果 === RUN TestKafkaInputPipeline Console output plugin started. Upper filter plugin started. Kafka input plugin started. Pipeline started. Output: Header:map[content:kafka], Body:[I AM MOCK CONSUMER.] Kafka input plugin stopped. Upper filter plugin stopped. Console output plugin stopped. Pipeline stopped. --- PASS: TestKafkaInputPipeline (0.00s) PASS 桥接模式（Bridge Pattern） 简述 桥接模式主要用于将抽象部分和实现部分进行解耦，使得它们能够各自往独立的方向变化。它解决了在模块有多种变化方向的情况下，用继承所导致的类爆炸问题。举一个例子，一个产品有形状和颜色两个特征（变化方向），其中形状分为方形和圆形，颜色分为红色和蓝色。如果采用继承的设计方案，那么就需要新增4个产品子类：方形红色、圆形红色、方形蓝色、圆形红色。如果形状总共有m种变化，颜色有n种变化，那么就需要新增m*n个产品子类！现在我们使用桥接模式进行优化，将形状和颜色分别设计为一个抽象接口独立出来，这样需要新增2个形状子类：方形和圆形，以及2个颜色子类：红色和蓝色。同样，如果形状总共有m种变化，颜色有n种变化，总共只需要新增m+n个子类！\n上述例子中，我们通过将形状和颜色抽象为一个接口，使产品不再依赖于具体的形状和颜色细节，从而达到了解耦的目的。桥接模式本质上就是面向接口编程，可以给系统带来很好的灵活性和可扩展性。如果一个对象存在多个变化的方向，而且每个变化方向都需要扩展，那么使用桥接模式进行设计那是再合适不过了。\nGo实现 回到消息处理系统的例子，一个Pipeline对象主要由Input、Filter、Output三类插件组成（3个特征），因为是插件化的系统，不可避免的就要求支持多种Input、Filter、Output的实现，并能够灵活组合（有多个变化的方向）。显然，Pipeline就非常适合使用桥接模式进行设计，实际上我们也这么做了。我们将Input、Filter、Output分别设计成一个抽象的接口，它们按照各自的方向去扩展。Pipeline只依赖的这3个抽象接口，并不感知具体实现的细节。\npackage plugin ... type Input interface { Plugin Receive() *msg.Message } type Filter interface { Plugin Process(msg *msg.Message) *msg.Message } type Output interface { Plugin Send(msg *msg.Message) } package pipeline ... // 一个Pipeline由input、filter、output三个Plugin组成 type Pipeline struct { status plugin.Status input plugin.Input filter plugin.Filter output plugin.Output } // 通过抽象接口来使用，看不到底层的实现细节 func (p *Pipeline) Exec() { msg := p.input.Receive() msg = p.filter.Process(msg) p.output.Send(msg) } 测试代码如下：\npackage test ... func TestPipeline(t *testing.T) { p := pipeline.Of(pipeline.DefaultConfig()) p.Start() p.Exec() p.Stop() } // 运行结果 === RUN TestPipeline Console output plugin started. Upper filter plugin started. Hello input plugin started. Pipeline started. Output: Header:map[content:text], Body:[HELLO WORLD] Hello input plugin stopped. Upper filter plugin stopped. Console output plugin stopped. Pipeline stopped. --- PASS: TestPipeline (0.00s) PASS 总结 本文主要介绍了结构型模式中的组合模式、适配器模式和桥接模式。组合模式主要解决代码复用的问题，相比于继承关系，组合模式可以避免继承层次过深导致的代码复杂问题，因此面向对象设计领域流传着组合优于继承的原则，而Go语言的设计也很好实践了该原则；适配器模式可以看作是两个不兼容接口之间的桥梁，可以将一个接口转换成Client所希望的另外一个接口，解决了模块之间因为接口不兼容而无法一起工作的问题；桥接模式将模块的抽象部分和实现部分进行分离，让它们能够往各自的方向扩展，从而达到解耦的目的。\n下一篇文章，我们将继续聚焦于结构型模式，介绍完剩余的4种结模式：装饰模式、外观模式、享元模式和代理模式。\n","date":"2020-08-23T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BD%BF%E7%94%A8go%E5%AE%9E%E7%8E%B0gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BA%8C/","title":"使用Go实现GoF的23种设计模式（二）"},{"content":"前言 从1995年GoF提出23种设计模式到现在，25年过去了，设计模式依旧是软件领域的热门话题。在当下，如果你不会一点设计模式，都不好意思说自己是一个合格的程序员。设计模式通常被定义为：\n 设计模式（Design Pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人理解并且保证代码可靠性。\n 从定义上看，设计模式其实是一种经验的总结，是针对特定问题的简洁而优雅的解决方案。既然是经验总结，那么学习设计模式最直接的好处就在于可以站在巨人的肩膀上解决软件开发过程中的一些特定问题。然而，学习设计模式的最高境界是习得其中解决问题所用到的思想，当你把它们的本质思想吃透了，也就能做到即使已经忘掉某个设计模式的名称和结构，也能在解决特定问题时信手拈来。\n好的东西有人吹捧，当然也会招黑。设计模式被抨击主要因为以下两点：\n1、设计模式会增加代码量，把程序逻辑变得复杂。这一点是不可避免的，但是我们并不能仅仅只考虑开发阶段的成本。最简单的程序当然是一个函数从头写到尾，但是这样后期的维护成本会变得非常大；而设计模式虽然增加了一点开发成本，但是能让人们写出可复用、可维护性高的程序。引用《软件设计的哲学》里的概念，前者就是战术编程，后者就是战略编程，我们应该对战术编程Say No！（请移步《一步步降低软件复杂性》）\n2、滥用设计模式。这是初学者最容易犯的错误，当学到一个模式时，恨不得在所有的代码都用上，从而在不该使用模式的地方刻意地使用了模式，导致了程序变得异常复杂。其实每个设计模式都有几个关键要素：适用场景、解决方法、优缺点。模式并不是万能药，它只有在特定的问题上才能显现出效果。所以，在使用一个模式前，先问问自己，当前的这个场景适用这个模式吗？\n《设计模式》一书的副标题是“可复用面向对象软件的基础”，但并不意味着只有面向对象语言才能使用设计模式。模式只是一种解决特定问题的思想，跟语言无关。就像Go语言一样，它并非是像C++和Java一样的面向对象语言，但是设计模式同样适用。本系列文章将使用Go语言来实现GoF提出的23种设计模式，按照创建型模式（Creational Pattern）、结构型模式（Structural Pattern）和行为型模式（Behavioral Pattern）三种类别进行组织，文本主要介绍其中的创建型模式。\n单例模式（Singleton Pattern） 简述 单例模式算是23中设计模式里最简单的一个了，它主要用于保证一个类仅有一个实例，并提供一个访问它的全局访问点。\n在程序设计中，有一些对象通常我们只需要一个共享的实例，比如线程池、全局缓存、对象池等，这种场景下就适合使用单例模式。\n但是，并非所有全局唯一的场景都适合使用单例模式。比如，考虑需要统计一个API调用的情况，有两个指标，成功调用次数和失败调用次数。这两个指标都是全局唯一的，所以有人可能会将其建模成两个单例SuccessApiMetric和FailApiMetric。按照这个思路，随着指标数量的增多，你会发现代码里类的定义会越来越多，也越来越臃肿。这也是单例模式最常见的误用场景，更好的方法是将两个指标设计成一个对象ApiMetric下的两个实例ApiMetic success和ApiMetic fail。\n如何判断一个对象是否应该被建模成单例？\n通常，被建模成单例的对象都有“中心点”的含义，比如线程池就是管理所有线程的中心。所以，在判断一个对象是否适合单例模式时，先思考下，这个对象是一个中心点吗？\nGo实现 在对某个对象实现单例模式时，有两个点必须要注意：（1）限制调用者直接实例化该对象；（2）为该对象的单例提供一个全局唯一的访问方法。\n对于C++/Java而言，只需把类的构造函数设计成私有的，并提供一个static方法去访问该类点唯一实例即可。但对于Go语言来说，即没有构造函数的概念，也没有static方法，所以需要另寻出路。\n我们可以利用Go语言package的访问规则来实现，将单例结构体设计成首字母小写，就能限定其访问范围只在当前package下，模拟了C++/Java中的私有构造函数；再在当前package下实现一个首字母大写的访问函数，就相当于static方法的作用了。\n在实际开发中，我们经常会遇到需要频繁创建和销毁的对象。频繁的创建和销毁一则消耗CPU，二则内存的利用率也不高，通常我们都会使用对象池技术来进行优化。考虑我们需要实现一个消息对象池，因为是全局的中心点，管理所有的Message实例，所以将其实现成单例，实现代码如下：\npackage msgpool ... // 消息池 type messagePool struct { pool *sync.Pool } // 消息池单例 var msgPool = \u0026amp;messagePool{ // 如果消息池里没有消息，则新建一个Count值为0的Message实例 \tpool: \u0026amp;sync.Pool{New: func() interface{} { return \u0026amp;Message{Count: 0} }}, } // 访问消息池单例的唯一方法 func Instance() *messagePool { return msgPool } // 往消息池里添加消息 func (m *messagePool) AddMsg(msg *Message) { m.pool.Put(msg) } // 从消息池里获取消息 func (m *messagePool) GetMsg() *Message { return m.pool.Get().(*Message) } ... 测试代码如下：\npackage test ... func TestMessagePool(t *testing.T) { msg0 := msgpool.Instance().GetMsg() if msg0.Count != 0 { t.Errorf(\u0026#34;expect msg count %d, but actual %d.\u0026#34;, 0, msg0.Count) } msg0.Count = 1 msgpool.Instance().AddMsg(msg0) msg1 := msgpool.Instance().GetMsg() if msg1.Count != 1 { t.Errorf(\u0026#34;expect msg count %d, but actual %d.\u0026#34;, 1, msg1.Count) } } // 运行结果 === RUN TestMessagePool --- PASS: TestMessagePool (0.00s) PASS 以上的单例模式就是典型的“饿汉模式”，实例在系统加载的时候就已经完成了初始化。对应地，还有一种“懒汉模式”，只有等到对象被使用的时候，才会去初始化它，从而一定程度上节省了内存。众所周知，“懒汉模式”会带来线程安全问题，可以通过普通加锁，或者更高效的双重检验锁来优化。对于“懒汉模式”，Go语言有一个更优雅的实现方式，那就是利用sync.Once，它有一个Do方法，其入参是一个方法，Go语言会保证仅仅只调用一次该方法。\n// 单例模式的“懒汉模式”实现 package msgpool ... var once = \u0026amp;sync.Once{} // 消息池单例，在首次调用时初始化 var msgPool *messagePool // 全局唯一获取消息池pool到方法 func Instance() *messagePool { // 在匿名函数中实现初始化逻辑，Go语言保证只会调用一次 \tonce.Do(func() { msgPool = \u0026amp;messagePool{ // 如果消息池里没有消息，则新建一个Count值为0的Message实例 \tpool: \u0026amp;sync.Pool{New: func() interface{} { return \u0026amp;Message{Count: 0} }}, } }) return msgPool } ... 建造者模式（Builder Pattern） 简述 在程序设计中，我们会经常遇到一些复杂的对象，其中有很多成员属性，甚至嵌套着多个复杂的对象。这种情况下，创建这个复杂对象就会变得很繁琐。对于C++/Java而言，最常见的表现就是构造函数有着长长的参数列表：\nMyObject obj = new MyObject(param1, param2, param3, param4, param5, param6, ...) 而对于Go语言来说，最常见的表现就是多层的嵌套实例化：\nobj := \u0026amp;MyObject{ Field1: \u0026amp;Field1 { Param1: \u0026amp;Param1 { Val: 0, }, Param2: \u0026amp;Param2 { Val: 1, }, ... }, Field2: \u0026amp;Field2 { Param3: \u0026amp;Param3 { Val: 2, }, ... }, ... } 上述的对象创建方法有两个明显的缺点：（1）对对象使用者不友好，使用者在创建对象时需要知道的细节太多；（2）代码可读性很差。\n针对这种对象成员较多，创建对象逻辑较为繁琐的场景，就适合使用建造者模式来进行优化。\n建造者模式的作用有如下几个：\n1、封装复杂对象的创建过程，使对象使用者不感知复杂的创建逻辑。\n2、可以一步步按照顺序对成员进行赋值，或者创建嵌套对象，并最终完成目标对象的创建。\n3、对多个对象复用同样的对象创建逻辑。\n其中，第1和第2点比较常用，下面对建造者模式的实现也主要是针对这两点进行示例。\nGo实现 考虑如下的一个Message结构体，其主要有Header和Body组成：\npackage msg ... type Message struct { Header *Header Body *Body } type Header struct { SrcAddr string SrcPort uint64 DestAddr string DestPort uint64 Items map[string]string } type Body struct { Items []string } ... 如果按照直接的对象创建方式，创建逻辑应该是这样的：\n// 多层的嵌套实例化 message := msg.Message{ Header: \u0026amp;msg.Header{ SrcAddr: \u0026#34;192.168.0.1\u0026#34;, SrcPort: 1234, DestAddr: \u0026#34;192.168.0.2\u0026#34;, DestPort: 8080, Items: make(map[string]string), }, Body: \u0026amp;msg.Body{ Items: make([]string, 0), }, } // 需要知道对象的实现细节 message.Header.Items[\u0026#34;contents\u0026#34;] = \u0026#34;application/json\u0026#34; message.Body.Items = append(message.Body.Items, \u0026#34;record1\u0026#34;) message.Body.Items = append(message.Body.Items, \u0026#34;record2\u0026#34;) 虽然Message结构体嵌套的层次不多，但是从其创建的代码来看，确实存在对对象使用者不友好和代码可读性差的缺点。下面我们引入建造者模式对代码进行重构：\npackage msg ... // Message对象的Builder对象 type builder struct { once *sync.Once msg *Message } // 返回Builder对象 func Builder() *builder { return \u0026amp;builder{ once: \u0026amp;sync.Once{}, msg: \u0026amp;Message{Header: \u0026amp;Header{}, Body: \u0026amp;Body{}}, } } // 以下是对Message成员对构建方法 func (b *builder) WithSrcAddr(srcAddr string) *builder { b.msg.Header.SrcAddr = srcAddr return b } func (b *builder) WithSrcPort(srcPort uint64) *builder { b.msg.Header.SrcPort = srcPort return b } func (b *builder) WithDestAddr(destAddr string) *builder { b.msg.Header.DestAddr = destAddr return b } func (b *builder) WithDestPort(destPort uint64) *builder { b.msg.Header.DestPort = destPort return b } func (b *builder) WithHeaderItem(key, value string) *builder { // 保证map只初始化一次 \tb.once.Do(func() { b.msg.Header.Items = make(map[string]string) }) b.msg.Header.Items[key] = value return b } func (b *builder) WithBodyItem(record string) *builder { b.msg.Body.Items = append(b.msg.Body.Items, record) return b } // 创建Message对象，在最后一步调用 func (b *builder) Build() *Message { return b.msg } 测试代码如下：\npackage test ... func TestMessageBuilder(t *testing.T) { // 使用消息建造者进行对象创建 \tmessage := msg.Builder(). WithSrcAddr(\u0026#34;192.168.0.1\u0026#34;). WithSrcPort(1234). WithDestAddr(\u0026#34;192.168.0.2\u0026#34;). WithDestPort(8080). WithHeaderItem(\u0026#34;contents\u0026#34;, \u0026#34;application/json\u0026#34;). WithBodyItem(\u0026#34;record1\u0026#34;). WithBodyItem(\u0026#34;record2\u0026#34;). Build() if message.Header.SrcAddr != \u0026#34;192.168.0.1\u0026#34; { t.Errorf(\u0026#34;expect src address 192.168.0.1, but actual %s.\u0026#34;, message.Header.SrcAddr) } if message.Body.Items[0] != \u0026#34;record1\u0026#34; { t.Errorf(\u0026#34;expect body item0 record1, but actual %s.\u0026#34;, message.Body.Items[0]) } } // 运行结果 === RUN TestMessageBuilder --- PASS: TestMessageBuilder (0.00s) PASS 从测试代码可知，使用建造者模式来进行对象创建，使用者不再需要知道对象具体的实现细节，代码可读性也更好。\n工厂方法模式（Factory Method Pattern） 简述 工厂方法模式跟上一节讨论的建造者模式类似，都是将对象创建的逻辑封装起来，为使用者提供一个简单易用的对象创建接口。两者在应用场景上稍有区别，建造者模式更常用于需要传递多个参数来进行实例化的场景。\n使用工厂方法来创建对象主要有两个好处：\n1、代码可读性更好。相比于使用C++/Java中的构造函数，或者Go中的{}来创建对象，工厂方法因为可以通过函数名来表达代码含义，从而具备更好的可读性。比如，使用工厂方法productA := CreateProductA()创建一个ProductA对象，比直接使用productA := ProductA{}的可读性要好。\n2、与使用者代码解耦。很多情况下，对象的创建往往是一个容易变化的点，通过工厂方法来封装对象的创建过程，可以在创建逻辑变更时，避免霰弹式修改。\n工厂方法模式也有两种实现方式：（1）提供一个工厂对象，通过调用工厂对象的工厂方法来创建产品对象；（2）将工厂方法集成到产品对象中（C++/Java中对象的static方法，Go中同一package下的函数）\nGo实现 考虑有一个事件对象Event，分别有两种有效的时间类型Start和End：\npackage event ... type Type uint8 // 事件类型定义 const ( Start Type = iota End ) // 事件抽象接口 type Event interface { EventType() Type Content() string } // 开始事件，实现了Event接口 type StartEvent struct{ content string } ... // 结束事件，实现了Event接口 type EndEvent struct{ content string } ... 1、按照第一种实现方式，为Event提供一个工厂对象，具体代码如下：\npackage event ... // 事件工厂对象 type Factory struct{} // 更具事件类型创建具体事件 func (e *Factory) Create(etype Type) Event { switch etype { case Start: return \u0026amp;StartEvent{ content: \u0026#34;this is start event\u0026#34;, } case End: return \u0026amp;EndEvent{ content: \u0026#34;this is end event\u0026#34;, } default: return nil } } 测试代码如下：\npackage test ... func TestEventFactory(t *testing.T) { factory := event.Factory{} e := factory.Create(event.Start) if e.EventType() != event.Start { t.Errorf(\u0026#34;expect event.Start, but actual %v.\u0026#34;, e.EventType()) } e = factory.Create(event.End) if e.EventType() != event.End { t.Errorf(\u0026#34;expect event.End, but actual %v.\u0026#34;, e.EventType()) } } // 运行结果 === RUN TestEventFactory --- PASS: TestEventFactory (0.00s) PASS 2、按照第二种实现方式，分别给Start和End类型的Event单独提供一个工厂方法，代码如下：\npackage event ... // Start类型Event的工厂方法 func OfStart() Event { return \u0026amp;StartEvent{ content: \u0026#34;this is start event\u0026#34;, } } // End类型Event的工厂方法 func OfEnd() Event { return \u0026amp;EndEvent{ content: \u0026#34;this is end event\u0026#34;, } } 测试代码如下：\npackage event ... func TestEvent(t *testing.T) { e := event.OfStart() if e.EventType() != event.Start { t.Errorf(\u0026#34;expect event.Start, but actual %v.\u0026#34;, e.EventType()) } e = event.OfEnd() if e.EventType() != event.End { t.Errorf(\u0026#34;expect event.End, but actual %v.\u0026#34;, e.EventType()) } } // 运行结果 === RUN TestEvent --- PASS: TestEvent (0.00s) PASS 抽象工厂模式（Abstract Factory Pattern） 简述 在工厂方法模式中，我们通过一个工厂对象来创建一个产品族，具体创建哪个产品，则通过swtich-case的方式去判断。这也意味着该产品组上，每新增一类产品对象，都必须修改原来工厂对象的代码；而且随着产品的不断增多，工厂对象的职责也越来越重，违反了单一职责原则。\n抽象工厂模式通过给工厂类新增一个抽象层解决了该问题，如上图所示，FactoryA和FactoryB都实现·抽象工厂接口，分别用于创建ProductA和ProductB。如果后续新增了ProductC，只需新增一个FactoryC即可，无需修改原有的代码；因为每个工厂只负责创建一个产品，因此也遵循了单一职责原则。\nGo实现 考虑需要如下一个插件架构风格的消息处理系统，pipeline是消息处理的管道，其中包含了input、filter和output三个插件。我们需要实现根据配置来创建pipeline ，加载插件过程的实现非常适合使用工厂模式，其中input、filter和output三类插件的创建使用抽象工厂模式，而pipeline的创建则使用工厂方法模式。\n各类插件和pipeline的接口定义如下：\npackage plugin ... // 插件抽象接口定义 type Plugin interface {} // 输入插件，用于接收消息 type Input interface { Plugin Receive() string } // 过滤插件，用于处理消息 type Filter interface { Plugin Process(msg string) string } // 输出插件，用于发送消息 type Output interface { Plugin Send(msg string) } package pipeline ... // 消息管道的定义 type Pipeline struct { input plugin.Input filter plugin.Filter output plugin.Output } // 一个消息的处理流程为 input -\u0026gt; filter -\u0026gt; output func (p *Pipeline) Exec() { msg := p.input.Receive() msg = p.filter.Process(msg) p.output.Send(msg) } 接着，我们定义input、filter、output三类插件接口的具体实现：\npackage plugin ... // input插件名称与类型的映射关系，主要用于通过反射创建input对象 var inputNames = make(map[string]reflect.Type) // Hello input插件，接收“Hello World”消息 type HelloInput struct {} func (h *HelloInput) Receive() string { return \u0026#34;Hello World\u0026#34; } // 初始化input插件映射关系表 func init() { inputNames[\u0026#34;hello\u0026#34;] = reflect.TypeOf(HelloInput{}) } package plugin ... // filter插件名称与类型的映射关系，主要用于通过反射创建filter对象 var filterNames = make(map[string]reflect.Type) // Upper filter插件，将消息全部字母转成大写 type UpperFilter struct {} func (u *UpperFilter) Process(msg string) string { return strings.ToUpper(msg) } // 初始化filter插件映射关系表 func init() { filterNames[\u0026#34;upper\u0026#34;] = reflect.TypeOf(UpperFilter{}) } package plugin ... // output插件名称与类型的映射关系，主要用于通过反射创建output对象 var outputNames = make(map[string]reflect.Type) // Console output插件，将消息输出到控制台上 type ConsoleOutput struct {} func (c *ConsoleOutput) Send(msg string) { fmt.Println(msg) } // 初始化output插件映射关系表 func init() { outputNames[\u0026#34;console\u0026#34;] = reflect.TypeOf(ConsoleOutput{}) } 然后，我们定义插件抽象工厂接口，以及对应插件的工厂实现：\npackage plugin ... // 插件抽象工厂接口 type Factory interface { Create(conf Config) Plugin } // input插件工厂对象，实现Factory接口 type InputFactory struct{} // 读取配置，通过反射机制进行对象实例化 func (i *InputFactory) Create(conf Config) Plugin { t, _ := inputNames[conf.Name] return reflect.New(t).Interface().(Plugin) } // filter和output插件工厂实现类似 type FilterFactory struct{} func (f *FilterFactory) Create(conf Config) Plugin { t, _ := filterNames[conf.Name] return reflect.New(t).Interface().(Plugin) } type OutputFactory struct{} func (o *OutputFactory) Create(conf Config) Plugin { t, _ := outputNames[conf.Name] return reflect.New(t).Interface().(Plugin) } 最后定义pipeline的工厂方法，调用plugin.Factory抽象工厂完成pipelien对象的实例化：\npackage pipeline ... // 保存用于创建Plugin的工厂实例，其中map的key为插件类型，value为抽象工厂接口 var pluginFactories = make(map[plugin.Type]plugin.Factory) // 根据plugin.Type返回对应Plugin类型的工厂实例 func factoryOf(t plugin.Type) plugin.Factory { factory, _ := pluginFactories[t] return factory } // pipeline工厂方法，根据配置创建一个Pipeline实例 func Of(conf Config) *Pipeline { p := \u0026amp;Pipeline{} p.input = factoryOf(plugin.InputType).Create(conf.Input).(plugin.Input) p.filter = factoryOf(plugin.FilterType).Create(conf.Filter).(plugin.Filter) p.output = factoryOf(plugin.OutputType).Create(conf.Output).(plugin.Output) return p } // 初始化插件工厂对象 func init() { pluginFactories[plugin.InputType] = \u0026amp;plugin.InputFactory{} pluginFactories[plugin.FilterType] = \u0026amp;plugin.FilterFactory{} pluginFactories[plugin.OutputType] = \u0026amp;plugin.OutputFactory{} } 测试代码如下：\npackage test ... func TestPipeline(t *testing.T) { // 其中pipeline.DefaultConfig()的配置内容见【抽象工厂模式示例图】  // 消息处理流程为 HelloInput -\u0026gt; UpperFilter -\u0026gt; ConsoleOutput \tp := pipeline.Of(pipeline.DefaultConfig()) p.Exec() } // 运行结果 === RUN TestPipeline HELLO WORLD --- PASS: TestPipeline (0.00s) PASS 原型模式（Prototype Pattern） 简述 原型模式主要解决对象复制的问题，它的核心就是clone()方法，返回Prototype对象的复制品。在程序设计过程中，往往会遇到有一些场景需要大量相同的对象，如果不使用原型模式，那么我们可能会这样进行对象的创建：新创建一个相同对象的实例，然后遍历原始对象的所有成员变量， 并将成员变量值复制到新对象中。这种方法的缺点很明显，那就是使用者必须知道对象的实现细节，导致代码之间的耦合。另外，对象很有可能存在除了对象本身以外不可见的变量，这种情况下该方法就行不通了。\n对于这种情况，更好的方法就是使用原型模式，将复制逻辑委托给对象本身，这样，上述两个问题也都迎刃而解了。\nGo实现 还是以建造者模式一节中的Message作为例子，现在设计一个Prototype抽象接口：\npackage prototype ... // 原型复制抽象接口 type Prototype interface { clone() Prototype } type Message struct { Header *Header Body *Body } func (m *Message) clone() Prototype { msg := *m return \u0026amp;msg } 测试代码如下：\npackage test ... func TestPrototype(t *testing.T) { message := msg.Builder(). WithSrcAddr(\u0026#34;192.168.0.1\u0026#34;). WithSrcPort(1234). WithDestAddr(\u0026#34;192.168.0.2\u0026#34;). WithDestPort(8080). WithHeaderItem(\u0026#34;contents\u0026#34;, \u0026#34;application/json\u0026#34;). WithBodyItem(\u0026#34;record1\u0026#34;). WithBodyItem(\u0026#34;record2\u0026#34;). Build() // 复制一份消息 \tnewMessage := message.Clone().(*msg.Message) if newMessage.Header.SrcAddr != message.Header.SrcAddr { t.Errorf(\u0026#34;Clone Message failed.\u0026#34;) } if newMessage.Body.Items[0] != message.Body.Items[0] { t.Errorf(\u0026#34;Clone Message failed.\u0026#34;) } } // 运行结果 === RUN TestPrototype --- PASS: TestPrototype (0.00s) PASS 总结 本文主要介绍了GoF的23种设计模式中的5种创建型模式，创建型模式的目的都是提供一个简单的接口，让对象的创建过程与使用者解耦。其中，单例模式主要用于保证一个类仅有一个实例，并提供一个访问它的全局访问点；建造者模式主要解决需要创建对象时需要传入多个参数，或者对初始化顺序有要求的场景；工厂方法模式通过提供一个工厂对象或者工厂方法，为使用者隐藏了对象创建的细节；抽象工厂模式是对工厂方法模式的优化，通过为工厂对象新增一个抽象层，让工厂对象遵循单一职责原则，也避免了霰弹式修改；原型模式则让对象复制更加简单。\n下一篇文章，将介绍23种设计模式中的7种结构型模式（Structural Pattern），及其Go语言的实现。\n","date":"2020-08-10T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BD%BF%E7%94%A8go%E5%AE%9E%E7%8E%B0gof%E7%9A%8423%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%80/","title":"使用Go实现GoF的23种设计模式（一）"},{"content":"前言 在上一篇文章《从Hash索引到LSM树（一）》中，我们通过append-only log的数据结构，实现了一个具备高写入性能的key-value数据库。append-only log之所以有很高的写入性能，主要得益于磁盘的顺序写入。这可能违反了我们对磁盘的认知，因为在我们的印象中，写磁盘总是很慢。其实不然，准确地说应该是随机写磁盘很慢，因为在写之前可能会进行多次寻址。如果只是顺序写磁盘，性能是非常的高，如下的一个ACM报告中显示，顺序写磁盘甚至比随机写内存的性能还要高！\n 举个例子，Kafka是一个高性能的消息队列，它的厉害之处就在于极致地利用磁盘的顺序写入性能，如果生产者和消费者的速率相当，消息甚至可以在操作系统的Page Cache层面就完成了传递。所以，以后别再认为写磁盘很慢了！\n append-only log大幅提升了数据写入性能，但是随之而来的是，非常低的数据读取性能。针对这一点，我们采用Hash索引进行了优化，优化的效果也非常的显著。然而，Hash索引有两个明显的限制：（1）当key的数量很多时，维护Hash索引会给内存带来很大的压力；（2）区间查询很低效。如何对这两个限制进行优化呢？这就轮到本文介绍的主角，LSM树，出场了。\nLSM树（Log-Structured Merge Tree）并不是一种数据结构，准确来说是一种存储模型，由MemTable、Immutable MemTable、SSTable等部分组成。它也是利用了append-only log的优势，大幅提升了写入性能。同时，因为key的存储有序性，所以具备了不错的读取性能，也克服了上文所述Hash索引的两个限制。下面，本文将一步步分析LSM树是如何做到这一点的。\nSSTable 在最简单的数据库例子中，因为数据是无序存储的，所以在读取某个key的值时，就需要遍历整个数据文件，算法复杂度是O(n)。为了提升读性能，我们不得不在内存中维护所有key的Hash索引。\n假如存储数据时，对记录按照key进行排序的会怎样？\n对于key有序存储这种情况，即使不用Hash索引，也能得到很好的查询效率，因为我们可以使用二分查找法（Binary Search）来快速找到key所在的位置，算法复杂度是O(logn)。LSM树正是采用key有序这种方式来组织数据存储的，并称之为SSTable。\nSSTable（Sorted String Table）是LSM树最基础的一个存储结构，存储在磁盘中，并且数据按照key进行排序的。数据保持key有序的好处是可以在O(logn)的时间下，快速找到一个key值，相比于纯粹的append-only log有了很大的提升。但是，如果所有的数据都存储在一个SSTable上，数据量一大，查询效率也会下降。因此，LSM树通常会将数据分散存储在多个SSTable中，并且记录每个SSTable的最大key和最小key，这样就能快速定位到一个key存储在哪个SSTable上了。\n// SSTable，数据保存到SSTable后只读不写 public class SSTable { ... // 数据存储路径  private final LogFile logFile; // 该SStable中存储的最小Key  private String minKey; // 该SStable中存储的最大Key  private String maxKey; // 使用二分查找法获取key值  public String get(String key) { // step1：先判断是否在SSTable的范围内  if (key.compareTo(minKey) \u0026lt; 0 || key.compareTo(maxKey) \u0026gt; 0) { return \u0026#34;\u0026#34;; } // step2：二分查找  long start = 0; long end = logFile.size(); while (start \u0026lt; end) { long mid = start + (end - start) / 2; // 先找到一条record到起始offset  long startOffset = logFile.startOffsetOf(mid); String record = logFile.read(startOffset); String midKey = Util.keyOf(record); if (key.compareTo(midKey) == 0) { return Util.valueOf(record); } else if (key.compareTo(midKey) \u0026lt; 0) { end = mid; } else { // 找到一条record到起始offset时可能会有mid == start的情况  if (mid == start) { break; } start = mid; } } return \u0026#34;\u0026#34;; } ... }  这里只是介绍了一种比较简单的SSTable实现方式，实际上，各种LSM树存储引擎对SSTable的实现都有所差异，比如LevelDB就将SSTable划分成两大块，数据存储区存储key:value数据，数据管理区存储索引等数据。\n 那么怎样才能保证SSTable的有序性呢？\n类似的在磁盘中维护数据有序的存储结构最常见的当属B/B+树了，如果对SSTable也采用类似的存储结构，那么带来的第一个问题就是每次写入都会伴随着磁盘的随机写，从而影响了数据的写入性能，这明显就违反了LSM树的初衷。为了同时兼顾SSTable的有序性以及写入性能，LSM树采用了MemTable这一组件。\nMemTable 相比于磁盘上维护一个有序的数据结构，在内存上实现数据有序要简单得多，而且具备较高的读写性能，常见的有序数据结构有红黑树、AVL树、跳表等，不管你插入的顺序如何，读出来的数据总是有序的。MemTable正是LSM维护在内存中的一个有序的数据结构，接下来我们看下LSM是如何利用Memtable做到同时兼顾SSTable的有序行和写入性能的：\n1、当写入请求过来时，先将record写入到Memtable中，这样就能保证record在内存中有序了，而且具备较高的写入性能。\n2、当Memtable的大小达到一定的阈值后（通常是几个Mb的大小），将MemTable转成Immutable MemTable（一个只读不写的MemTable），并创建新的MemTable接收写请求。\n 和《从Hash索引到LSM树（一）》中的segment file机制类似，一个时刻只有current segment file接收写请求，其他的只读不写。\n 3、通过后台任务，定时将Immutable MemTable的数据刷到SSTable中，因为Immutable MemTable本身的有序性，所以就能保证SSTable中的数据是有序的，而且数据写入SSTable文件时完全是顺序写入，做到了有序性和写入性能的兼顾。\n4、当读请求过来时，查找的顺序是MemTable-\u0026gt;Immutable MemTable-\u0026gt;SSTable，找到则返回，否则一步步执行下去。\nMemtable底层通常采用跳表来实现（LevelDB、HBase都采用了这一实现方法），相比较AVL和红黑树，跳表在插入数据的时候可以避免频繁的树节点调整操作，所以写入效率很高，而且实现起来也更简单些。\n// LSM维护在内存中的有序数据结构，数据写入时先写MemTable public class MemTable { // 基于跳表实现的key-value结构  private final ConcurrentSkipListMap\u0026lt;String, String\u0026gt; cache; // 当前存储数据的大小  private AtomicInteger size; ... // 查找key  public String get(String key) { if (!cache.containsKey(key)) { return \u0026#34;\u0026#34;; } return cache.get(key); } // 添加key:value，并更新当前Memtable的大小  public void add(String key, String value) { cache.put(key, value); size.addAndGet(key.length() + value.length()); } // 返回当前Memtable的大小（字节为单位）  // 用于判断达到阈值之后，转成Immutable MemTable  public int size() { return this.size.get(); } // 达到阈值之后转储到SSTable  public void compact2Sst(SSTable sst) { cache.forEach(sst::add); } ... } LsmKvDb 使用LSM树作为存储引擎的数据库，通常对SSTable进行分层管理，方便查询以及后续的Compact操作。本文也将采用对SSTable进行分层的架构实现LsmKvDb。\n首先对Level进行抽象，每个Level都由多个SSTable组成：\n// 对LSM的层的抽象，由SSTable组成 public class Level { private final List\u0026lt;SSTable\u0026gt; ssts; ... public void add(SSTable sst) { ssts.add(sst); } // 在当前level中查找key对应的value, 从老到新遍历所有SSTable  public String find(String key) { for (int i = ssts.size() - 1; i \u0026gt;= 0; i--) { String value = ssts.get(i).get(key); if (!value.equals(\u0026#34;\u0026#34;)) { return value; } } return \u0026#34;\u0026#34;; } // sst与当前level进行compact操作  public void compactWith(SSTable sst) {...} // 对给定sst集合与当前level进行compact操作  public void compactWith(List\u0026lt;SSTable\u0026gt; ssts) {...} } LsmKvDb的实现代码如下，写数据时写入MemTable，当达到阈值后转Immutable MemTable。Immutable MemTable与MemTable具有相同的数据结构，唯一不同的是前者只读不写，后者既读也写。\n/** * 基于LSM树的key-value数据库, 采用分层架构 * MemTable -\u0026gt; Immutable MemTable -\u0026gt; Level0 -\u0026gt; Level1 -\u0026gt; Level2 */ public class LsmKvDb implements KvDb { ... // 存储SSTable的目录  private final String sstDir; // 当前写入的MemTable  private MemTable memTable; // MemTable到达阈值大小后转储到immutableMts  private final List\u0026lt;MemTable\u0026gt; immutableMts; // 后台定时将immutableMts中的MemTable刷到Level0，各SSTable之间可能由Key重叠  private final Level level0; // 后台定时将Level0中的SSTable与Level1中的进行合并  private final Level level1; // 当Level1中的SSTable的数量到达一定阈值后，选择最老的SSTable与Level2中的进行合并  private final Level level2; ... @Override public String get(String key) { // step1: 从MemTable中读取  String value = memTable.get(key); if (!value.equals(\u0026#34;\u0026#34;)) { return value; } // step2: 从Immutable MemTable中读取，从新到老  for (int i = immutableMts.size() - 1; i \u0026gt;= 0; i--) { value = immutableMts.get(i).get(key); if (!value.equals(\u0026#34;\u0026#34;)) { return value; } } // step3: 从Level0中读取  value = level0.find(key); if (!value.equals(\u0026#34;\u0026#34;)) { return value; } // step4: 从Level1中读取  ... // step5: 从Level2中读取  ... return \u0026#34;\u0026#34;; } @Override public void set(String key, String value) { memTable.add(key, value); // 当MemTable大小到达阈值后转成Immutable MemTable  if (memTable.size() \u0026gt; MEMTABLE_MAX_SIZE) { synchronized (this) { immutableMts.add(memTable); memTable = MemTable.create(); } } } ... } Compaction 上一篇文章《从Hash索引到LSM树（一）》已经对Compaction机制已经有了讲解，其目的是清除掉已经被覆写或删除了的记录，避免数据存储文件无休止的增长下去。对于LSM树而言，该机制同样适用，随着数据的不断添加、更新和删除，一些SSTable之间必然存在着重叠的key或被删除的key。通过Compaction，可以将多个SSTable合并成一个，从而节省了磁盘空间。\n 在上篇文章中，对segment file的compact操作主要依赖于Hash索引。因为是索引覆盖全部的key，所以可以很容易通过新的segment file的Hash索引来判断该key是否已经被处理过。但对于SSTable而言，并没有覆盖全部key的Hash索引，那么如何进行compact才高效呢？\n得益于SSTable的有序性，我们可以应用归并排序算法来进行compact操作！\n LSM树的Compaction通常有三种类型，分别是minor compact、major compact和full compact。\nMinor Compact minor compact指的是将Immutable MemTable中的数据直接转存到Level0中的SSTable。\n因为是直接将各个Immutable MemTable的数据转储成SSTable，并没有做合并的操作，因此在Level0中，各个SSTable之间的key可能存在重叠的现象。\nMajor Compact major compact指的是将Level n中的SSTable合并到Level n+1中。\nLevel0 -\u0026gt; Level1的合并步骤如下：\n1、选中Level0中的最老的SSTable sst0，然后在Level0中找到与sst0 的key存在重叠的所有SSTable sst0...n。\n2、在Level1中，选取所有与 sst0...n存在key重叠的SSTable sst'0...m。\n3、对sst0...n和sst'0...m采用多路归并排序算法进行合并，得到新的sst‘’0...k，并存储在Level1中。\n4、删除sst0...n和sst'0...m。\n不同于Level0，Level1和Level2中各个SSTable之间并不存在key重叠的现象，因此Level1 -\u0026gt; Level2的合并会稍微简单些。\nLevel1 -\u0026gt; Level2的合并步骤如下：\n1、选中Level1中的最老的SSTable sst0。\n2、在Level2中，选取所有与 sst0存在key重叠的SSTable sst'0...m。\n3、对sst0和sst'0...m采用多路归并排序算法进行合并，得到新的sst‘’0...k，并存储在Level2中。\n4、删除sst0和sst'0...m。\nFull Compact full compact指的是对Level0、Level1、Level2中所有的SSTable进行compact操作，同样也是采用多路归并排序算法。\n通常full compact耗时较多，所以一般都会选择在流量较少的时刻进行。\n优化LSM树 为SSTable引入block 到目前为止，对于在一个SSTable中查找一个key，我们首先会根据min key和max key判断该key是否属于该SSTable所属的范围，如果属于，则对SSTable采用二分查找法进行搜索。二分查找之所以在LsmKvDb中行得通，是因为这是一个简单的SSTable实现 —— 数据按string存储和\\n分隔。在实际的运用中，为了尽可能地利用磁盘空间，SSTable中数据通常都是以字节码的形式存储，也不会以\\n分隔每条record，这种情况下采用二分查找的实现就比较复杂了，而且效率也会太高。\n一个常见的优化方法是，在SSTable中对record按照一定的size组织成多个block，并以block为单位进行压缩。为了能够快速找到某个key所属的block，需要在内存中维护每个block的起始key对应在SSTable中的offset（一个稀疏的Hash索引）。\n在查找key的步骤如下：\n1、根据索引定位到key所属的block。\n2、将该block加载到内存中，并解压。\n3、对内存中的数据采用二分查找。\n 在设计block的大小时，应该利用磁盘的空间局部性原理，使得系统能够只花费一次磁盘I/O就能将整个block加载到内存中。\n 为SSTable引入Bloom Filter 其实当目标key属于某个SSTable的key范围时，该key也不一定会存在于该SSTable中。但是到目前为止，只要目标key在某个SSTable的范围内，LsmKvDb都会进行查找操作。随着系统中的SSTable数目的增多，查询效率必然会随之下降。\n一个常见的优化方法时，为SSTable引入布隆过滤器Bloom Filter。\nBloom Filter是保存在内存中的一种数据结构，可以用来告诉你 “某样东西一定不存在或者可能存在”。它由一个超长的二进制位数组和一系列的Hash函数组成。二进制位数组初始全部为0，当有元素加入集合时，这个元素会被一系列Hash函数计算映射出一系列的值，所有的值在位数组的偏移量处置为1。如果需要判断某个元素是否存在于集合当中，只需判断该元素被Hash后的值在数组中的值，如果存在为0的，则该元素一定不存在；如果全为1，则可能存在，这种情况可能有误判。\n通过Bloom Filter，我们可以很快就能判断目标key是否不存在于SSTable中，从而提升了读性能。\n Google的Guava库就提供了一个BloomFilter的实现，并且可以按需来设置误判率。\n 总结 本文承接上《从Hash索引到LSM树（一）》，主要介绍了LSM树的基本原理，并且在原来append-only log的基础上实现了一个简单的基于LSM树的key-value数据库LsmKvDb。LSM树主要由MemTable、Immutable MemTable、SSTable组成，其中MemTable和Immutable MemTable在内存中维护，而SSTable则存储在磁盘中。SSTable的有序性使得LSM树在无需Hash索引的情况下具有不错的读取性能，而且支持区间查询；而Memable则使得LSM树具备很高的写入性能。\n本系列文章，我们从一个最简单的key-value数据库起步，一步步通过Hash索引、LSM树、布隆过滤器等技术手段对其进行了优化，从中也深入分析了各个技术点的实现原理。但数据库的索引技术远不止这些，比如最常用到的B/B+树，也是非常值得深入学习的，以后有机会再对其进行深入分析.\n","date":"2020-07-28T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8Ehash%E7%B4%A2%E5%BC%95%E5%88%B0lsm%E6%A0%91%E4%BA%8C/","title":"从Hash索引到LSM树（二）"},{"content":"前言 数据库算是软件应用系统中最常用的一类组件了，不管是一个庞大而复杂的电商系统，还是一个简单的个人博客，多多少少都会用到数据库，或是存储海量的数据，或是存储简单的状态信息。一般地，我们都喜欢将数据库划分为关系型数据库和非关系型数据库（又称NoSQL数据库），前者的典型代表是MySQL数据库，后者的典型代表是HBase数据库。不管是关系型，还是非关系型，数据库都离不开两个最基本的功能：（1）数据存储；（2）数据查询。简单来说就是，当你把数据丢给数据库时，它能够保持下来，并在稍后你想获取的时候，把数据返回给你。\n围绕着这两个基本功能，各类数据库都运用了很多技术手段对其进行了优化，其中最广为人知的当属数据库索引技术。索引是一种数据结构，它在牺牲少量数据存储（写）性能的情况下，可以大幅提升数据查询（读）性能。索引也有很多种类型，Hash索引算是最简单高效的一种了，但是由于它自身的限制，在数据库系统中并不被广泛使用。当今最常用的索引技术是B/B+树索引，被广泛地应用在关系型数据库中，主要应用于读多写少的场景。随着NoSQL数据库的兴起，LSM（Log-Structured Merged-Tree）树也逐渐流行，并被Google的BigTable论文所发扬光大。严格来说，LSM树并不算一种传统意义上的索引，它更像是一种设计思想，主要应用于写多读少的场景。\n本系列文章，将从实现最简单的Key-Value数据库讲起，然后针对实现过程中遇到的一些瓶颈，采用上述的索引技术，对数据库进行优化，以此达到对数据库的索引技术有一个较为深刻的理解。\n最简单的数据库 Martin Kleppmann在《Designing Data-Intensive Applications》一书中给出了一个最简单数据库的实现：\n#!/bin/bash db_set() { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get() { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 } 这不到10行的shell代码实现了一个简单的Key-Value数据库。它一共有两个函数，db_set和db_get，前者对应数据存储功能，后者对应数据查询功能。该数据库采用简单的文本格式（database文件）进行数据存储，每条记录包含了一个键值对，key和value之间通过逗号（,）进行分隔。\n数据库的使用方法也很简单，通过调用db_set key value可以将key及其对应的value存储到数据库中；通过db_get key可以得到该key对应的value：\n$ db_set 123456 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;London\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Big Ben\u0026#34;,\u0026#34;London Eye\u0026#34;]}\u0026#39; $ db_set 42 \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]}\u0026#39; $ db_get 42 {\u0026#34;name\u0026#34;:\u0026#34;San Francisco\u0026#34;,\u0026#34;attractions\u0026#34;:[\u0026#34;Golden Gate Bridge\u0026#34;]} 透过db_set的实现我们发现，该数据库每次写都是直接往database文件中追加记录，鉴于文件系统顺序写的高效，因此该数据库的数据写入具有较高的性能。但是追加写也意味着，对同一个key进行更新时，其对应的旧的value并不会被覆盖，这也使得每次调用db_get获取某个key的value时，总是需要遍历所有记录，找到所有符合条件的value，并取其中最新的一个。因此，该数据库的读性能是非常低的。\n下面我们采用Java对这个最简单的数据库进行重写：\n/** * SimpleKvDb.java * 追加写 * 全文件扫描读 */ public class SimpleKvDb implements KvDb { ... @Override public String get(String key) { try (Stream\u0026lt;String\u0026gt; lines = logFile.lines()) { // step1: 筛选出该key对应的的所有value（对应grep \u0026#34;^$1,\u0026#34; database）  List\u0026lt;String\u0026gt; values = lines .filter(line -\u0026gt; Util.matchKey(key, line)) .collect(Collectors.toList()); // step2: 选取最新值（对应 sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1）  String record = values.get(values.size() - 1); return Util.valueOf(record); } catch (IOException e) { e.printStackTrace(); return null; } } @Override public void set(String key, String value) { // step1: 追加写（对应 echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database）  String record = Util.composeRecord(key, value); logFile.append(record); } ... } 使用JHM进行压测结果如下：\nBenchmark Mode Cnt Score Error Units SimpleKvDbReadBenchmark.simpleKvDb_get_10000_test avgt 8 0.631 ± 0.033 ms/op // 读耗时，1w条记录 SimpleKvDbReadBenchmark.simpleKvDb_get_100000_test avgt 8 7.020 ± 0.842 ms/op // 读耗时，10w条记录 SimpleKvDbReadBenchmark.simpleKvDb_get_1000000_test avgt 8 62.562 ± 5.466 ms/op // 读耗时，100w条记录 SimpleKvDbWriteBenchmark.simpleKvDb_set_test avgt 8 0.036 ± 0.005 ms/op // 写耗时 从结果可以看出，该数据库的实现具有较高的写性能，但是读性能很低，而且读耗时会随着数据量的增加而线性增长。\n那么如何优化SimpleKvDb的读性能？引入索引技术！\n索引（index）是从数据库中的数据衍生出来的一种数据结构，它并不会对数据造成影响，只会影响数据库的读写性能。对于读操作，它能快速定位到目的数据，从而极大地提升读性能；对于写操作，由于需要增加额外的更新索引操作，因此会略微降低写性能。\n 如前言所述，索引也有很多类型，每种索引的特点都各有差别。因此到底要不要采用索引，具体采用哪种索引，需要根据实际的应用场景来决定。\n 下面，我们将首先采用最简单高效的Hash索引对SimpleKvDb进行优化。\n给数据库加上Hash索引 考虑到Key-Value数据库本身就类似于Hash表的这个特点，我们很容易想到如下的索引策略：在内存中维护一个Hash表，记录每个key对应的记录在数据文件（如前文所说的database文件）中的字节位移（byte offset）。\n对于写操作，在往数据文件追加记录后，还需要更新Hash表；对于读操作，首先通过Hash表确定该key对应记录在数据文件中的位移，然后通过字节位移快速找到value在数据文件中的位置并读取，从而避免了全文遍历这样的低效行为。\n给SimpleKvDb加上Hash索引，对应的代码实现为：\n/** * HashIdxKvDb.java * 追加写 * 使用Hash索引提升读性能 */ public class HashIdxKvDb implements KvDb { // 数据存储文件  private final LogFile curLog; // 索引，value为该key对应的数据在文件中的offset  private final Map\u0026lt;String, Long\u0026gt; idx; ... @Override public String get(String key) { if (!idx.containsKey(key)) { return \u0026#34;\u0026#34;; } // step1: 读取索引  long offset = idx.get(key); // step2: 根据索引读取value  String record = curLog.read(offset); return Util.valueOf(record); } @Override public void set(String key, String value) { String record = Util.composeRecord(key, value); long curSize = curLog.size(); // step1: 追加写数据  if (curLog.append(record) != 0) { // step2: 更新索引  idx.put(key, curSize); } } ... } 在实现HashIdxKvDb之前，我们将数据存储文件抽象成了LogFile对象，它的两个基本方法是append（追加写记录）和read（根据offset读记录），其中，read函数通过RandomAccessFile的seek方法快速定位到记录所处的位置，具体实现如下：\n// 追加写的日志文件，存储数据库数据 class LogFile { // 文件所在路径  private Path path; ... // 向日志文件中写入一行记录，自动添加换行符  // 返回成功写入的字节大小  long append(String record) { try { record += System.lineSeparator(); Files.write(path, record.getBytes(), StandardOpenOption.APPEND); return record.getBytes().length; } catch (IOException e) { e.printStackTrace(); } return 0; } // 读取offset为起始位置的一行  String read(long offset) { try (RandomAccessFile file = new RandomAccessFile(path.toFile(), \u0026#34;r\u0026#34;)) { file.seek(offset); return file.readLine(); } catch (IOException e) { e.printStackTrace(); } return \u0026#34;\u0026#34;; } ... } 使用JHM进行压测结果如下：\nBenchmark Mode Cnt Score Error Units HashIdxKvDbReadBenchmark.hashIdxKvDb_get_10000_test avgt 8 0.021 ± 0.001 ms/op // 读耗时，1w条记录 HashIdxKvDbReadBenchmark.hashIdxKvDb_get_100000_test avgt 8 0.021 ± 0.001 ms/op // 读耗时，10w条记录 HashIdxKvDbReadBenchmark.hashIdxKvDb_get_1000000_test avgt 8 0.021 ± 0.001 ms/op // 读耗时，100w条记录 HashIdxKvDbWriteBenchmark.hashIdxKvDb_set_test avgt 8 0.038 ± 0.005 ms/op // 写耗时 从压测结果可以看出，相比SimpleKvDb，HashIdxKvDb的读性能有了大幅的提升，而且读耗时不再随着数据量的增加而成线性增长；而且写性能并没有明显的下降。\n虽然Hash索引实现很简单，却是极其的高效，它只需要1次磁盘寻址（seek操作），加上1次磁盘I/O（readLine操作），就能将数据加载出来。如果数据之前已经加载到文件系统缓存里，甚至都不用磁盘I/O。\n数据合并——compact 到目前为止，不管是SimpleKvDb，还是HashIdxKvDb，写操作都是不断在一个文件中追加数据，这种存储方式，通常我们称之为append-only log。\n那么，如何才能避免append-only log无休止的一直扩张下去，直到磁盘空间不足呢？\nappend-only log的一个显著特点是旧的记录不会被覆盖删除，但是这些数据往往是无用的，因为读取某个key的value时，数据库都是取其最新的值。因此，解决该问题的一个思路是把这些无用的记录清除掉：\n（1）当往append-only log追加数据到达一定大小后，另外创建一个新的append-only log进行追加。在这种机制下，数据分散到多个append-only log文件中存储，我们称这些log文件为segment file。\n（2）保证只有当前的current segment file是可读可写，old segment file只读不写。\n（3）对old segment file进行compact操作——只保留每个key对应的最新记录，把的老记录删除。\ncompact操作往往是在后台线程中执行，数据库会将合并的结果写到一个新的compacted segment file中，这样在执行compact操作时，就不会影响从old segment file中读数据的逻辑。等到compact操作完成之后，再把old segment file删除，后续的读操作迁移到compacted segment file上。\n现在，单个compacted segment file中的key都是唯一的，但是多个compacted segment file之间还是有可能存在重复的key，我们还能够更近一步，对多个compacted segment file再一次进行compact操作，这样数据量会再次减少。\n 类似的compact操作可以一层层执行下去，比如，可以对level2 compacted segment file进行compact，生成level3 compacted segment file。但是并不是compact的层次越多越好,具体的compact策略需要结合实际的应用场景进行设计。\n 给HashIdxKvDb加上compact机制 下面，我们试着给HashIdxKvDb加上compact机制。由于在compact机制下，数据会分散在多个segment file中存储，因此之前的Hash索引机制不再适用，我们需要给每个segment file都单独维护一份Hash索引。当然，这样也比较容易实现，只需要维护一个Hash表，key为segment file，value为该segment file对应的Hash索引。\n对应的代码实现如下：\n// 多文件哈希索引实现 class MultiHashIdx { ... private Map\u0026lt;LogFile, Map\u0026lt;String, Long\u0026gt;\u0026gt; idxs; // 获得指定LogFile中，Key的索引  long idxOf(LogFile file, String key) { if (!idxs.containsKey(file) || !idxs.get(file).containsKey(key)) { return -1; } return idxs.get(file).get(key); } // 添加指定LogFile中Key的索引  void addIdx(LogFile file, String key, long offset) { idxs.putIfAbsent(file, new ConcurrentHashMap\u0026lt;\u0026gt;()); idxs.get(file).put(key, offset); } ... } 另外，我们还需要在CompactionHashIdxKvDb里分别维护一份old segment file、level1 compacted segment file和level2 compacted segment file集合，并通过ScheduledExecutorService定时对这些集合进行compact操作。\n/** * 追加写，当当前segemnt file到达一定大小后，追加到新到segment file上。并定时对旧的segment file进行compact。 * 为每个segment file维持一个哈希索引，提升读性能 * 支持单线程写，多线程读 */ public class CompactionHashIdxKvDb implements KvDb { ... // 当前追加写的segment file路径  private LogFile curLog; // 写old segment file集合，会定时对这些文件进行level1 compact合并  private final Deque\u0026lt;LogFile\u0026gt; toCompact; // level1 compacted segment file集合，会定时对这些文件进行level2 compact合并  private final Deque\u0026lt;LogFile\u0026gt; compactedLevel1; // level2 compacted segment file集合  private final Deque\u0026lt;LogFile\u0026gt; compactedLevel2; // 多segment file哈希索引  private final MultiHashIdx idx; // 进行compact的定时调度  private final ScheduledExecutorService compactExecutor; ... } 相比于HashIdxKvDb， CompactionHashIdxKvDb 在写入新的数据之前，需要判断当前文件大小是否写满，如果写满了，则需要创建新的LogFile进行追加，并将写满后的LogFile归档到toCompact队列中。\n@Override public void set(String key, String value) { try { // 如果当前LogFile写满了，则放到toCompact队列中，并创建新的LogFile  if (curLog.size() \u0026gt;= MAX_LOG_SIZE_BYTE) { String curPath = curLog.path(); Map\u0026lt;String, Long\u0026gt; oldIdx = idx.allIdxOf(curLog); curLog.renameTo(curPath + \u0026#34;_\u0026#34; + toCompactNum.getAndIncrement()); toCompact.addLast(curLog); // 创建新的文件后，索引也要更新  idx.addAllIdx(curLog, oldIdx); curLog = LogFile.create(curPath); idx.cleanIdx(curLog); } String record = Util.composeRecord(key, value); long curSize = curLog.size(); // 写成功则更新索引  if (curLog.append(record) != 0) { idx.addIdx(curLog, key, curSize); } } catch (IOException e) { e.printStackTrace(); } } CompactionHashIdxKvDb 的读操作相对麻烦，因为数据被分散在多个segment file上，所以需要按照如下顺序完成数据查找，直到查询到为止：当前追加的LogFile-\u0026gt;toCompact队列-\u0026gt;compactedLevel1队列-\u0026gt;compactedLevel2队列。因此，CompactionHashIdxKvDb 的读操作在极端情况下（所查询的数据存储在comactedLevel2队列上时）也会较为低效。\n@Override public String get(String key) { // 第一步：从当前的LogFile查找  if (idx.idxOf(curLog, key) != -1) { long offset = idx.idxOf(curLog, key); String record = curLog.read(offset); return Util.valueOf(record); } // 第二步：从toCompact中查找  String record = find(key, toCompact); if (!record.isEmpty()) { return record; } // 第三步：从 compactedLevel1 中查找  record = find(key, compactedLevel1); if (!record.isEmpty()) { return record; } // 第四步：从 compactedLevel2 中查找  record = find(key, compactedLevel2); if (!record.isEmpty()) { return record; } return \u0026#34;\u0026#34;; } 对toCompact队列里的old segment file进行单文件level1 compact操作时，可以利用Hash索引。因为Hash索引上所对应的记录总是最新的，因此只需遍历Hash索引，将每个key对应的最新记录查询出来，写到新的level1 compacted segment file中即可。\n// 进行level1 compact，对单个old segment file合并 void compactLevel1() { while (!toCompact.isEmpty()) { // 创建新的level1 compacted segment file  LogFile newLogFile = LogFile.create(curLog.path() + \u0026#34;_level1_\u0026#34; + level1Num.getAndIncrement()); LogFile logFile = toCompact.getFirst(); // 只保留每个key对应的最新的value  idx.allIdxOf(logFile).forEach((key, offset) -\u0026gt; { String record = logFile.read(offset); long curSize = newLogFile.size(); if (newLogFile.append(record) != 0) { idx.addIdx(newLogFile, key, curSize); } }); // 写完后存储到compactedLevel1队列中，并删除toCompact中对应的文件  compactedLevel1.addLast(newLogFile); toCompact.pollFirst(); logFile.delete(); } } 对compactedLevel1队列进行多文件level2 compact的策略是：将当前队列里所有的level1 compacted segment file合并成一个level2 compacted segment file。具体步骤如下：\n1、生成一份compactedLevel1队列的snapshot。目的是为了避免在level2 compact过程中，有新的level1 compacted segment file加入到队列造成影响。\n2、对snapshot进行compact操作，按照从新到旧的顺序，将level1 compacted segment file中的记录写入新的level2 compacted segment file中，如果发现level2 compacted segment file已经存在该key，则跳过。\n3、等完成任务后，再从compactedLevel1队列里删除已经合并过的level1 compacted segment file。\n// 进行level2 compact，针对compactedLevel1队列中所有的文件进行合并 void compactLevel2() { ... // 生成一份快照  Deque\u0026lt;LogFile\u0026gt; snapshot = new LinkedList\u0026lt;\u0026gt;(compactedLevel1); if (snapshot.isEmpty()) { return; } int compactSize = snapshot.size(); // level2的文件命名规则为：filename_level2_num  LogFile newLogFile = LogFile.create(curLog.path() + \u0026#34;_level2_\u0026#34; + level2Num.getAndIncrement()); while (!snapshot.isEmpty()) { // 从最新的level1 compacted segment file开始处理  LogFile logFile = snapshot.pollLast(); logFile.lines().forEach(record -\u0026gt; { String key = Util.keyOf(record); // 只有当前level2 compacted segment file中不存在的key才写入  if (idx.idxOf(newLogFile, key) == -1) { // 写入成功后，更新索引  long offset = newLogFile.size(); if (newLogFile.append(record) != 0) { idx.addIdx(newLogFile, key, offset); } } }); } compactedLevel2.addLast(newLogFile); // 写入完成后，删除compactedLevel1队列中相应的文件  while (compactSize \u0026gt; 0) { LogFile logFile = compactedLevel1.pollFirst(); logFile.delete(); compactSize--; } ... } 总结 本文首先介绍了Martin Kleppmann给出的最简单的数据库，并使用Java语言对它进行了重新的实现，接着采用Hash索引和compact机制对其进行了一系列的优化。\nSimpleKvDb采用append-only log的方式存储数据，append-only log最主要的优点是具备很高的写入性能（文件系统的顺序写比随机写要快很多）。追加写也意味着同一个key对应的旧记录不会被覆盖删除，因此在查询数据时，需要遍历整个文件，找到该key的所有记录，并选取最新的一个。因为涉及到全文遍历，因此SimpleKvDb的读性能非常低。\n为了优化SimpleKvDb的读性能，我们实现了具有Hash索引的HashIdxKvDb。Hash索引是一个在内存中维护的Hash表，保存每个key对应的记录在文件中的offset。因此每次数据查询只需要1次磁盘寻址，加上1次磁盘I/O，非常高效。\n为了解决append-only log一直扩张导致磁盘空间不足的问题，我们给HashIdxKvDb引入了compact机制，实现了CompactionHashIdxKvDb。compact机制能够有效清理数据库中的无效的旧数据，从而减缓了磁盘空间的压力。\nHash索引虽然简单高效，但是有如下两个限制：\n1、必须在内存中维护Hash索引。如果选择在磁盘上实现Hash索引，那么将会带来大量的磁盘随机读写，导致性能的急剧下降。另外，随着compact机制的引入，数据被分散在多个segment file中存储，我们不得不为每个segment file维护一份Hash索引，这就导致Hash索引的内存占用量不断增加，给系统带来了很大的内存压力。\n2、区间查询非常低效。比如，当需要查询数据库中范围在[key0000, key9999]之间的所有key时，必须遍历索引中所有的元素，然后找到符合要求的key。\n针对Hash索引的这两个限制，要怎样进行优化呢？本系列的下一篇文章，我们将介绍另一种不存在这两个限制的索引——LSM树。\n","date":"2020-06-26T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%BB%8Ehash%E7%B4%A2%E5%BC%95%E5%88%B0lsm%E6%A0%91%E4%B8%80/","title":"从Hash索引到LSM树（一）"},{"content":"最近几年，领域驱动设计（Domain-Driven Design，DDD）这个术语越来越多地出现在软件工程师的视野里。对DDD不熟悉的人可能会觉得它是软件领域里的一个新的概念，但是实际上，Eric Evans在十几年前就已经提出了这个概念。这个“古老”的概念在之所以能够重焕新生，很大程度上是因为遇上了“微服务”这个浪潮。如果把DDD里面的理念拿去和微服务架构做对比，你会发现它们有着高度的相似性——DDD里的限界上下文不正是微服务架构中的微服务吗？于是，各大公司纷纷运用DDD的方法论来构建自己的产品架构。有些团队成功地将DDD结合到了产品架构中，产生了许多优秀的实践；也有些团队反映DDD太过复杂，很难落地。那么DDD究竟是个什么样的理念？为什么大家都争先恐后地使用它，彷佛不加点DDD都不好意思说自己是微服务架构？然而又为什么那么多团队说DDD难以落地？本文将会结合简单的代码实现来谈谈笔者对DDD的理解。\n什么是领域驱动设计？ 软件的核心是其为用户解决领域相关的问题的能力。\n软件就是为了解决某一领域相关问题而存在的，比如一个普通的计算器软件，就是为了满足我们进行简单的加减乘除运算而存在。对于计算器这种小而简单的软件，一个普通的软件工程师可能花上几天就能过设计开发出来，而且基本不会出现Bug。但是对于一些大型而且复杂的系统，一个团队都得花上很长的时间去设计整个架构，然后经过n轮迭代才能开发出可用的版本，而且后面还有各种Bug要去处理。比如证券交易系统，里面就包括了用户系统、账户系统、订单系统、撮合系统等一系列的子系统，而且其中的调用关系和业务都非常复杂。像这样一个庞大的系统，怎样才能把它设计好呢？这正是DDD要回答的问题。\n领域驱动设计（DDD）是一种软件开发的方法论，旨在帮助我们设计出高质量的软件模型。\n在软件领域，解决复杂问题的方法不外乎是“分治”和“抽象”，DDD也是基于这两个理念建立起一套方法论。其中将一个系统划分成多个限界上下文，限界上下文中划分出多个子域，这是分治；然后在分别对各个子域进行领域建模，这是抽象。当你在设计一个业务复杂的系统却无从下手时，尝试一下DDD，说不定困难就会迎刃而解了。DDD中最核心的理念就是领域建模，可以说它提供的各种方法都是为了帮助我们设计出更能准确传达业务规则的领域模型。一个好的领域模型可以让一个系统更加健壮，可以让一个框架易用性更加好，可以让一段代码更加好维护。那么，什么样的模型才是好的领域模型？下面，我们通过一个例子来简单说明下。\n 什么是领域模型？\n领域模型是关于某个特定业务领域的软件模型。通常，领域模型通过对象模型来实现，这些对象同时包含了数据和行为，并且表达了准确的业务含义。\n 日期和时间领域模型 如何设计一个日期和时间API？\n首先需要对日期和时间的概念进行建模，从直觉上，我们可以将日期和时间抽象成一个对象Date。另外，时间和日期经常都需要进行格式化输出，因此我们还需要一个用于表示时间格式的对象DateFormat。为了更好地表示年月周日等概念，再抽象出一个表示日历的Calendar对象，以及表示时区的TimeZone对象。\n相信到这里大家都已经知道，这正是JDK 1.1版本的日期时间API，下面我们先回顾一下它的用法：\npublic class TestOldDate { public static void main(String[] args) { // 获取表示当前时刻的Date对象  Date date1 = new Date(); // 通过Calendar等到指定日期时间的Date对象，采用当前的系统时区  Calendar calendar = Calendar.getInstance(TimeZone.getDefault()); calendar.set(2020, 2, 10, 0, 0, 0); Date date2 = calendar.getTime(); // 进行时间比较  System.out.println(\u0026#34;date1 is after date2: \u0026#34; + date1.after(date2)); // 进行时间的加减法，如获得昨天的这个时刻：  calendar.setTime(date1); calendar.set(Calendar.DAY_OF_MONTH, calendar.get(Calendar.DAY_OF_MONTH) - 1); Date date3 = calendar.getTime(); // 对日期格式化输出  DateFormat df = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); System.out.println(\u0026#34;date3: \u0026#34; + df.format(date3)); } } /* Output: date1 is after date2: false date3: 2020-02-07 23:55:39 */ 如果你用习惯了JDK 1.1版本的日期时间API，可能会觉得上述例子中的用法也没有多大的问题。但是，仔细思考一下就会发现这其中的逻辑跟我们人类对时间的处理逻辑不太像，比如要对时间做加法，首先要将需要操作的Date对象设置到Calendar，然后对Calendar做加法，最后调用Calendar的接口得到结果。时间的加法难道不应该直接对Date对象加上一个时间段就行了吗？\n相信很多小伙伴都会遇到这种情况，自己写出来的代码可读性不够好。这其中原因可能是对领域的理解不够深，设计出来的领域模型没能准确的表达业务逻辑（如JDK 1.1的日期时间模型），或者开发前根本就没有进行领域建模。这样容易导致采用了一种“机器思维”去进行开发，而不是按照我们平常思考问题的思维去开发。\nJDK 1.8引入了全新的日期和时间API来解决老版本的API所存在的种种问题，下面，我们来看一下比之前更准确地表达日期和时间的领域模型：\nJDK 1.8的日期和时间领域模型中的领域知识明显比老版本的领域模型要丰富很多，而且模型更加符合人类思考日期和时间的思维。下面，我们看下新的日期和时间API的用法：\npublic class TestNewDate { public static void main(String[] args) { // 获取表示当前时刻的LocalDateTime对象  LocalDateTime date1 = LocalDateTime.now(ZoneId.systemDefault()); // 获取指定时间的LocalDateTime对象  LocalDateTime date2 = LocalDateTime.of( LocalDate.of(2020, 2, 10), LocalTime.of(0, 0, 0)); // 进行是时间比较  System.out.println(\u0026#34;date1 is after date2: \u0026#34; + date1.isAfter(date2)); // 进行时间的加减法，如获得昨天的这个时刻：  LocalDateTime date3 = date1.minus(Period.ofDays(1)); // 对时间进行格式化输出  DateTimeFormatter df = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); System.out.println(\u0026#34;date3: \u0026#34; + df.format(date3)); } } /* Output: date1 is after date2: false date3: 2020-02-07 23:56:51 */ 实现同样的功能，JDK 1.8版本的日期和时间API明显更加简洁，而且代码的逻辑更加符合人的思维，可读性更好（比如使用.now()函数创建当前时刻的LocalDateTime对象，代码阅读起来就跟人类的自然语言一样）。由此可见，设计出一个高质量的领域模型对于软件系统是多么的重要。\n在这个例子中，JDK并没有显式地使用DDD提供的战术建模手段对日期和时间API进行设计，但是从JDK 1.1到JDK 1.8版本中的变化，其中就蕴含着DDD最核心的内容：设计出更符合业务规则和人类思维的领域模型。从这个例子中我们也能看出，DDD并没有传说中的那么神秘，也未必一定要运用在复杂的系统，即使是一个简单的日期和时间API，其中也可以看到它的身影。\n如果让你对JDK 1.1的日期和时间API进行优化，相信很多人都设计不出像JDK 1.8版本的这样优秀的API，不管在经验，还是在方法上我们都欠点火候。简单的API如此，更别说设计复杂的大型系统了。这时，我们需要一些具体的建模方法来指导设计。\nDDD的建模方法 DDD主要提出了两种建模方法来帮助我们设计出高质量的领域模型：战略建模和战术建模。\n战略建模根据领域知识对系统进行限界上下文和子域的划分，战术建模具体为每个限界上下文设计出领域模型。而这两者中又内涵很多知识点，光看下面的这张DDD的概念图，你可能会觉得DDD太过复杂了。\n确实，DDD的学习曲线比较陡，特别是第一次看Eric Evans所著的《领域驱动设计——软件核心复杂性应对之道》时，会有种不知所云的感觉。再看Vaughn Vernon所著的《实现领域驱动设计》可能会好点了，但是里面提到的各种概念还是没能很清晰地理解。所谓“实践出真知”，只有通过不断地实践，才能学习到DDD的精髓，体会到它的魔力。下一篇文章，我们将开始通过实践一个简单的业务功能着手介绍DDD的各种理论知识。\n","date":"2020-03-08T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%AE%9E%E8%B7%B5%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E4%B8%80/","title":"实践领域驱动设计（一）"},{"content":"前言 在《Java对象表示——Oop-Klass模型（一）》一文的最后讲到，为了实现Java方法调用的动态绑定，HotSpot使用了与C++虚函数类似的机制，同时为了避免每个对象都维护一个虚函数表，于是就设计了Klass类。\n如下为HotSpot源码中对Klass的功能介绍：\n A Klass provides:\n​ 1: language level class object (method dictionary etc.)\n​ 2: provide vm dispatch behavior for the object\nBoth functions are combined into one C++ class.\n 可见，Klass主要提供了两个功能：\n（1）用于表示Java类。Klass中保存了一个Java对象的类型信息，包括类名、限定符、常量池、方法字典等。一个class文件被JVM加载之后，就会被解析成一个Klass对象存储在内存中。\n（2）实现对象的虚分派（virtual dispatch）。所谓的虚分派，是JVM用来实现多态的一种机制。\nclass A { void callMe() { System.out.println(\u0026#34;This is A.\u0026#34;); } } class B extends A { @Override public void callMe() { System.out.println(\u0026#34;This is B.\u0026#34;); } } class C extends A { @Override public void callMe() { System.out.println(\u0026#34;This is C.\u0026#34;); } } public class VmDispatch { public static void main(String[] args) { A b = new B(); A c = new C(); // b和c的静态类型为A，那么JVM是如何将它们动态绑定到正确的实现上的呢？  b.callMe(); c.callMe(); } } /* Output： This is B. This is C. */ 考虑上述例子，基类A有两个子类，分别为B和C。在main函数中，b和c的静态类型都是A，但是在调用callMe()方法时，JVM会将它们绑定到正确的实现上。这其中奥秘就是JVM的虚分派机制，而该机制的实现用到了Klass中的虚函数表。\nKlass的继承体系 跟Oop一样，Klass也有一个继承体系，如下图所示：\n// hotspot/src/share/vm/oops/oopsHierarchy.hpp ... class Klass; // Klass继承体系的最高父类 class InstanceKlass; // 表示一个Java普通类，包含了一个类运行时的所有信息 class InstanceMirrorKlass; // 表示java.lang.Class class InstanceClassLoaderKlass; // 主要用于遍历ClassLoader继承体系 class InstanceRefKlass; // 表示java.lang.ref.Reference及其子类 class ArrayKlass; // 表示一个Java数组类 class ObjArrayKlass; // 普通对象的数组类 class TypeArrayKlass; // 基础类型的数组类 ... 不同于Oop，Klass在InstanceKlass下又设计了3个子类，其中InstanceMirrorKlass用于表示java.lang.Class类型，该类型对应的oop特别之处在于其包含了static field，因此计算oop大小时需要把static field也考虑进来；InstanceClassLoaderKlass主要提供了遍历当前ClassLoader的继承体系；InstanceRefKlass用于表示java.lang.ref.Reference及其子类。\n对象的类型信息 Klass的主要用途之一就是保存一个Java对象的类型信息，如下选出其中一些比较重要的field：\n// hotspot/src/share/vm/oops/klass.hpp class Klass : public Metadata { ... // 类名，其中普通类名和数组类名略有不同  // 普通类名如：java/lang/String，数组类名如：[Ljava/lang/String;  Symbol* _name; // 最后一个secondary supertype  Klass* _secondary_super_cache; // 保存所有secondary supertypes  Array\u0026lt;Klass*\u0026gt;* _secondary_supers; // 保存所有primary supertypes的有序列表  Klass* _primary_supers[_primary_super_limit]; // 当前类所属的java/lang/Class对象对应的oop  oop _java_mirror; // 当前类的直接父类  Klass* _super; // 第一个子类 (NULL if none); _subklass-\u0026gt;next_sibling() 为下一个  Klass* _subklass; // 串联起当前类所有的子类  Klass* _next_sibling; // 串联起被同一个ClassLoader加载的所有类（包括当前类）  Klass* _next_link; // 对应用于加载当前类的java.lang.ClassLoader对象  ClassLoaderData* _class_loader_data; // 提供访问当前类的限定符途径, 主要用于Class.getModifiers()方法.  jint _modifier_flags; // 访问限定符  AccessFlags _access_flags; ... } 如上述代码片段所示，Klass继承了Metadata，后者为《深入解析Java的运行时数据区》一文中提到的“元空间”（Metaspace）的实现，这也意味着Java对象的类型信息存储在方法区，而不是在堆中。\nprimary supertype和secondary supertype主要用于快速类型检查（比如在调用instanceOf时能够快速得到结果），其中primary type和secondary type的定义出现在《Fast subtype checking in the HotSpot JVM》一文中：\n A klass T is a primary type iff T is a proper class, or an array of a primary type, or an array of primitive values. Interfaces and arrays of interfaces are excluded.\nA klass T is a secondary type iff T is a interface or an array of a secondary type. Every type is either a primary type or a secondary type but not both.\n 接着，我们继续看下表示普通对象类型的InstanceKlass所包含的信息，它继承自Klass，在父类的基础上增加了不少信息，如下列出较为重要的一些：\n// hotspot/src/share/vm/oops/instanceKlass.hpp class InstanceKlass: public Klass { ... // 当前类的状态  enum ClassState { allocated, // 已分配  loaded, // 已加载，并添加到类的继承体系中  linked, // 链接/验证完成  being_initialized, // 正在初始化  fully_initialized, // 初始化完成  initialization_error // 初始化失败  }; // 当前类的注解  Annotations* _annotations; // 当前类数组中持有的类型  Klass* _array_klasses; // 当前类的常量池  ConstantPool* _constants; // 当前类的内部类信息  Array\u0026lt;jushort\u0026gt;* _inner_classes; // 保存当前类的所有方法.  Array\u0026lt;Method*\u0026gt;* _methods; // 如果当前类实现了接口，则保存该接口的default方法  Array\u0026lt;Method*\u0026gt;* _default_methods; // 保存当前类所有方法的位置信息  Array\u0026lt;int\u0026gt;* _method_ordering; // 保存当前类所有default方法在虚函数表中的位置信息  Array\u0026lt;int\u0026gt;* _default_vtable_indices; // 保存当前类的field信息（包括static field），数组结构为：  // f1: [access, name index, sig index, initial value index, low_offset, high_offset]  // f2: [access, name index, sig index, initial value index, low_offset, high_offset]  // ...  // fn: [access, name index, sig index, initial value index, low_offset, high_offset]  // [generic signature index]  // [generic signature index]  // ...  Array\u0026lt;u2\u0026gt;* _fields; ... } 注意到，_fields中的每个元素都包含了当前field都偏移量信息，如前文《Java对象表示——Oop-Klass模型（一）》所提到，这些偏移量用于在oop中找到对应field的地址。\n虚函数表（vtable） 虚函数表（vtable）主要是为了实现Java中的虚分派功能而存在。HotSpot把Java中的方法都抽象成了Method对象，InstanceKlass中的成员属性_methods就保存了当前类所有方法对应的Method实例。HotSpot并没有显式地把虚函数表设计为Klass的field，而是提供了一个虚函数表视图，并在类初始化时创建出来。\n// hotspot/src/share/vm/oops/instanceKlass.hpp class InstanceKlass: public Klass { ... // 返回一个新的vtable，在类初始化时创建  klassVtable* vtable() const; inline Method* method_at_vtable(int index); .. } // 以下为方法对应实现 // hotspot/src/share/vm/oops/instanceKlass.cpp ... // vtable()的实现 klassVtable* InstanceKlass::vtable() const { return new klassVtable(this, start_of_vtable(), vtable_length() / vtableEntry::size()); } // method_at_vtable()的实现 inline Method* InstanceKlass::method_at_vtable(int index) { ... // 校验逻辑  vtableEntry* ve = (vtableEntry*)start_of_vtable(); return ve[index].method(); } 一个klassVtable可看成是由多个vtableEntry组成的数组，其中每个元素vtableEntry里面都包含了一个方法的地址。在进行虚分派时，JVM会根据方法在klassVtable中的索引，找到对应的vtableEntry，进而得到方法的实际地址，最后根据该地址找到方法的字节码并执行。\n总结 这两篇文章我们探讨了HotSpot的Oop-Klass对象模型，其中Oop表示对象的实例，存储在堆中；Klass表示对象的类型，存储在方法区中。但这也只是讲述了Oop-Klass对象模型中最基础的部分，该模型所包含的内容还远不止这些，如果想要更加全面而深入地了解Oop-Klass对象模型，最好的方法是阅读HotSpot的源码。\n最后，我们通过一张图来总结这两篇文章所讲述的内容：\n","date":"2020-02-02T00:00:00Z","permalink":"https://www.yrunz.com/p/java%E7%9A%84%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8Boop-klass%E6%A8%A1%E5%9E%8B%E4%BA%8C/","title":"Java的对象模型——Oop-Klass模型（二）"},{"content":"前言 谈起Java对象，笔者的第一反应是在：Java中的每一个对象（不包括基础类型）都继承于Object对象。相信这也是大多数程序员对Java对象的初次印象，Object可以表示所有的Java对象。但是，这种理解仅仅是停留在语言层面，至于更深的JVM层面，对象还是用Object来表示吗？显然不是。JVM通常使用非Java语言实现，是用来解析并运行Java程序的，它有自己的模型来表示Java语言的各种特性，包括Object。下面我们以HotSpot为例，一起来探讨Java对象在JVM层面的Java对象模型。\n HotSpot采用C++语言实现，下文中的JVM如无特殊说明，指的都是HotSpot。\n Java程序通过new操作符来创建一个对象，在深入探讨HotSpot的Java对象模型前，我们先看下new操作符的具体实现。\n// hotspot/src/share/vm/interpreter/interpreterRuntime.cpp ... // HotSpot中new操作符的实现函数 IRT_ENTRY(void, InterpreterRuntime::_new(JavaThread* thread, ConstantPool* pool, int index)) Klass* k_oop = pool-\u0026gt;klass_at(index, CHECK); instanceKlassHandle klass (THREAD, k_oop); // Make sure we are not instantiating an abstract klass  klass-\u0026gt;check_valid_for_instantiation(true, CHECK); // Make sure klass is initialized  klass-\u0026gt;initialize(CHECK); // At this point the class may not be fully initialized  // ...  oop obj = klass-\u0026gt;allocate_instance(CHECK); thread-\u0026gt;set_vm_result(obj); IRT_END ... 上述代码片段来自HotSpot源码中new操作符的实现函数，先不深入分析每一行的具体含义，这段代码给我们最直观的功能就是：先对klass对象进行初始化工作，然后再用它来创建出oop对象。到这里我们大致就能猜出，oop表示的就是一个Java对象。而这里的klass和Java中的Class之间似乎有着紧密的联系，一是两者的名字非常类似，另外也可通过第16行代码得到进一步的肯定。对Java的反射机制稍微有所了解的人，看着第16行代码一定很熟悉，因为它与使用Class.newInstance()方法来创建Object对象很类似。\n实际正如上述所猜测，HotSpot使用Oop-Klass模型来表示Java的对象。\nOop的继承体系 这里的Oop并非是Object-oriented programming，而是Ordinary object pointer（普通对象指针），是HotSpot用来表示Java对象的实例信息的一个体系。其中oop是Oop体系中的最高父类，整个继承体系如下所示：\n// hotspot/src/share/vm/oops/oopsHierarchy.hpp ... // Oop的继承体系 typedef class oopDesc* oop; typedef class instanceOopDesc* instanceOop; typedef class arrayOopDesc* arraysOop; typedef class objArrayOopDesc* objArrayOop; typedef class typeArrayOopDesc* typeArrayOop; ... 每个Java对象都有它独有的生命周期，我们使用new操作符将它创建出来，然后对它执行各式各样的操作（如获取成员属性、调用成员函数、加锁等），最后被GC回收掉。那么Java对象的这一系列经历，JVM又是怎么实现的呢？JVM使用Oop来表示一个Java对象，自然地，这些经历都会跟oop有关。\noop的子类有两个，分别是instanceOop和arrayOop。前者表示Java中普通的对象，后者则表示数组对象。arrayOop也有两个子类，objArrayOop表示普通对象类型的数组，而typeArrayOopDesc则表示基础类型的数组。如下图所示，oop的存储结构主要由对象头和对象体组成。\noop对象头 oop主要有两个成员属性：\n// hotspot/src/share/vm/oops/oop.hpp class oopDesc { ... private: // 用于存储对象的运行时记录信息，如哈希值、GC分代年龄、锁状态等  volatile markOop _mark; // Klass指针的联合体，指向当前对象所属的Klass对象  union _metadata { // 未采用指针压缩技术时使用  Klass* _klass; // 采用指针压缩技术时使用  narrowKlass _compressed_klass; } _metadata; ... } _mark和_metadata被称为对象头，其中前者存储对象的运行时记录信息；后者是一个指针，指向当前对象所属的Klass对象。\n 因为某些历史原因，HotSpot把markOop放到Oop体系里，但是它并继承oop，因此前文所描述的Oop体系并没有包含它。\n markOop的存储结构在32位和64位系统中有所差异，但是具体存储的信息是一样的，本节只介绍它在32位系统中的存储结构。在32位系统中，markOop一共占32位，存储结构如图下所示：\n从图中可知，诸如对象hash值、线程ID、分代年龄等信息都是存储在markOop中，而且在不同的状态下，其结构也是略有不同。无锁指一个对象没有被加锁时的状态；偏向锁，顾名思义会偏向于第一个访问锁的线程，当同步锁只有一个线程访问时，JVM会将其优化为偏向锁，此时就相当于没有同步语义；当发生多线程竞争时，偏向锁就会膨胀为轻量级锁，后者采用CAS（Compare And Swap）实现，避免了用户态和内核态之间的切换；如果某个线程获取轻量级锁失败，该锁就会继续膨胀为重量级锁，此时JVM会向操作系统申请互斥量，因此性能消耗也是最高的。\noop提供4个方法来判断当前对象处于何种状态下：\n// hotspot/src/share/vm/oops/oop.hpp class oopDesc { ... bool is_locked() const; bool is_unlocked() const; bool has_bias_pattern() const; ... bool is_gc_marked() const; } // hotspot/src/share/vm/oops/oop.inline.hpp ... inline bool oopDesc::is_gc_marked() const { return mark()-\u0026gt;is_marked(); } inline bool oopDesc::is_locked() const { return mark()-\u0026gt;is_locked(); } inline bool oopDesc::is_unlocked() const { return mark()-\u0026gt;is_unlocked(); } inline bool oopDesc::has_bias_pattern() const { return mark()-\u0026gt;has_bias_pattern(); } ... 从上述代码可知，oop调用markOop的方法来判断当前对象是否已经加锁、是否是偏向锁，markOop则通过判断其存储结构中的标志位来实现，如下列代码所示：\n// hotspot/src/share/vm/oops/markOop.hpp ... class markOopDesc: public oopDesc { ... // unlocked_value = 1  // lock_mask_in_place = right_n_bits(2)，is_locked()利用存储结构的最右边两位  // 来判断当前对象是否是加锁状态。值得注意的是，偏向锁并不属于加锁状态。  bool is_locked() const { return (mask_bits(value(), lock_mask_in_place) != unlocked_value); } // lock_mask_in_place = right_n_bits(3)，is_unlocked()并不是简单地对is_locked()  // 的结果取反，而是使用存储结构的最右边三位来判断。值得注意的是，偏向锁也并不属于无锁状态。  bool is_unlocked() const { return (mask_bits(value(), biased_lock_mask_in_place) == unlocked_value); } // marked_value = 3  // lock_mask_in_place = right_n_bits(2)，当锁标志位的值为3（二进制为11）时返回true。  bool is_marked() const { return (mask_bits(value(), lock_mask_in_place) == marked_value); } // biased_lock_pattern = 5  // biased_lock_mask_in_place = right_n_bits(3)，当存储结构的最后三位的值为5（二进制  // 为101）时返回true  bool has_bias_pattern() const { return (mask_bits(value(), biased_lock_mask_in_place) == biased_lock_pattern); } ... } oop对象体 JVM将Java对象的field存储在oop的对象体中，oop提供了一系列的方法来获取和设置field，并且针对每种基础类型都提供了特有的实现。\n// hotspot/src/share/vm/oops/oop.hpp class oopDesc { ... // 返回成员属性的地址  void* field_base(int offset) const; // 如果成员是基础类型，则用特有的方法  jbyte* byte_field_addr(int offset) const; jchar* char_field_addr(int offset) const; jboolean* bool_field_addr(int offset) const; jint* int_field_addr(int offset) const; jshort* short_field_addr(int offset) const; jlong* long_field_addr(int offset) const; jfloat* float_field_addr(int offset) const; jdouble* double_field_addr(int offset) const; Metadata** metadata_field_addr(int offset) const; // 同样是成员的地址获取方法，在GC时使用  template \u0026lt;class T\u0026gt; T* obj_field_addr(int offset) const; ... // instanceOop获取和设置其成员属性的方法  oop obj_field(int offset) const; volatile oop obj_field_volatile(int offset) const; void obj_field_put(int offset, oop value); void obj_field_put_raw(int offset, oop value); void obj_field_put_volatile(int offset, oop value); // 如果成员时基础类型，则使用其特有的方法，这里只列出针对byte类型的方法  jbyte byte_field(int offset) const; void byte_field_put(int offset, jbyte contents); ... } 具体实现如下列代码所示：\n// hotspot/src/share/vm/oops/oop.inline.hpp ... // 获取对象中field的地址 inline void* oopDesc::field_base(int offset) const { return (void*)\u0026amp;((char*)this)[offset]; } // 获取普通对象field的地址，对调用field_base的结果进行转型得到 template \u0026lt;class T\u0026gt; inline T* oopDesc::obj_field_addr(int offset) const { return (T*)field_base(offset); } // 基础类型特有的实现与obj_field_addr类似，只是转型成特有的基础类型指针 inline jbyte* oopDesc::byte_field_addr(int offset) const { return (jbyte*) field_base(offset); } ... // 获取field前需要先判断是否采用了指针压缩技术，先根据offset调用obj_field_addr // 得到field的地址，然后调用load_decode_heap_oop得到实例 inline oop oopDesc::obj_field(int offset) const { return UseCompressedOops ? load_decode_heap_oop(obj_field_addr\u0026lt;narrowOop\u0026gt;(offset)) : load_decode_heap_oop(obj_field_addr\u0026lt;oop\u0026gt;(offset)); } // 直接对指针解引用得到field inline oop oopDesc::load_decode_heap_oop(oop* p) { return *p; } ... // 设置field前需要先判断是否采用了指针压缩技术，同样也是先根据offset得到地址， // 然后在设置field的值 inline void oopDesc::obj_field_put(int offset, oop value) { UseCompressedOops ? oop_store(obj_field_addr\u0026lt;narrowOop\u0026gt;(offset), value) : oop_store(obj_field_addr\u0026lt;oop\u0026gt;(offset), value); } // 设置field前先更新barrier template \u0026lt;class T\u0026gt; inline void oop_store(T* p, oop v) { if (always_do_update_barrier) { oop_store((volatile T*)p, v); } else { update_barrier_set_pre(p, v); oopDesc::encode_store_heap_oop(p, v); update_barrier_set((void*)p, v); } } // 设置field时直接更新指针指向的值 inline void oopDesc::encode_store_heap_oop(oop* p, oop v) { *p = v; } 由上述代码片段可知，每个field在oop中都有一个对应的偏移量（offset），oop通过该偏移量得到该field的地址，再根据地址得到具体数据。因此，Java对象中的field存储的并不是对象本身，而是对象的地址。\n总结 HotSpot采用Oop-Klass模型来表示Java对象，其中Klass对应着Java对象的类型（Class），而Oop则对应着Java对象的实例（Instance）。Oop是一个继承体系，其中oop是体系中的最高父类，它的存储结构可以分成对象头和对象体。对象头存储的是对象的一些元数据，对象体存储的是具体的成员属性。值得注意的是，如果成员属性属于普通对象类型，则oop只存储它的地址。\n我们都知道Java中的普通方法（没有static和final修饰）是动态绑定的，在C++中，动态绑定通过虚函数来实现，代价是每个C++对象都必须维护一张虚函数表。Java的特点就是一切皆是对象，如果每个对象都维护一张虚函数表，内存开销将会非常大。JVM对此做了优化，虚函数表不再由每个对象维护，改成由Class类型维护，所有属于该类型的对象共用一张虚函数表。因此我们并没有在oop上找到方法调用的相关逻辑，这部分的代码被放在了klass里面。\nKlass相关的内容将会在下一篇文章《Java的对象模型——Oop-Klass（二）》中介绍。\n","date":"2020-01-31T00:00:00Z","permalink":"https://www.yrunz.com/p/java%E7%9A%84%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8Boop-klass%E6%A8%A1%E5%9E%8B%E4%B8%80/","title":"Java的对象模型——Oop-Klass模型（一）"},{"content":"前言 2019年最大的收获莫过于，静下心来，找到了读书和写作的乐趣。\n说起读书的习惯，那要追溯到研究生即将毕业的那一年，在一个盗版的kindle上读完了《曾国藩家书》。书中有一句话让我铭记至今，也让我震撼至今：“少睡多做，一人之生气”。于是便有了早起读书的习惯。研究生在读时，每天都有着充裕的时间，对早起的定义是8点之前，这倒也不算难事；工作之后，9点便要开始上班，对早起的定义也跟着提到7点以前。刚工作的几个月，早起着实是一件极其痛苦的事情，总有着延绵不断的困意，很多时候读着读着便又睡着了，有时甚至把困意带去了公司。多亏了那段时间的磨练，早上的困意逐渐消失，养成了如今早起的习惯。虽说是习惯，但更多的是逼着自己早起，也因此有几段时间以各种借口（最常用的便是工作太累）为由没能坚持这一习惯。很幸运的是，在2019年又重新拾得这一习惯。\n到目前为止，在读书习惯上的经历大致可以分成3个阶段。初读《曾国藩家书》时，便下决心要养成早起读书的习惯，这阶段读书的类别大多局限于史类、经济类和软件类；今年7月份读到《穷查理宝典》后，意识到多学科交叉的重要性，便开始刻意读一些各个领域的入门书籍。依旧记得读《穷查理宝典》时激动的心情，醍醐灌顶，读书的乐趣大概源至于此；当前所处的阶段，始于今年11月份读到《文心》。从前为了增加知识的广度（更多的是过于浮躁），喜欢快速把一本书读完，收得其中大概意思。读完《文心》，像是上了一堂不一样的国文课，“读书的目的，重在收得其内容意趣，否则只是文字的游戏而已。”，于是便学会了静下心来读完一本书。\n 今年有幸在公司听了侯捷老师（《STL源码剖析》的作者）的讲座，他对知识追根究底的精神，深深地影响了我。每次阅读技术书籍读到晦涩难懂之处，想要跳过之时，便会想起侯捷老师的做法，于是就乖乖地重新回去把知识彻底弄懂。\n 至于写作，对于我这么一个以写代码为业的工科生而言，那是很难想象的事情。从没想过写800字作文都得憋出内伤的我，会在2019年找到写作的乐趣。虽说工作以来，偶尔也会在公司平台写一些总结性的博客，但那都是记流水账似的，谈不上写作。搭建个人博客网站来写文章，那是很久之前的想法了，但一直都没有去落实。一是觉得搭建网站太浪费时间了；另外则认为写作更是浪费时间，还不如多读些书。\n今年双十一的时候，趁着优惠在腾讯云买了个云服务器，花上一天时间，搭建了个人博客网站。本着\u0026quot;一份时间出售多次\u0026ldquo;的原则，顺着把微信订阅号也注册了。尽管如此，对写作的热情还是没有明显地上升，依旧不情愿花超过一小时的时间去完成一篇文章。真正让我找到写作乐趣的，是《文心》。如今，写作不再是一件痛苦的事情，每个周末都舍得花上一天的时间去写完一篇文章。\n2019年读了不少书，有匆匆浏览的，也有仔细读完的。基本上做到了读完每本书都有所“触发”，不枉开卷。或是深刻地记住了其中的某句话，又或是学会了其中的一套方法。大体上，今年读过的书可以分成三类：软件类、人文社科类和科普类。\n软件类 道              今年对我影响最深的一本技术类书籍，对提升软件设计能力、写出优雅代码很有帮助。相比于Eric Evans的那本《领域驱动设计》，该书结合了大量的例子，让DDD中的各种概念更容易理解些。 领域驱动设计（DDD）的开山之作，内容比较偏理论。去年在学校图书馆偶然遇见，初读晦涩难懂，只依稀记得几个概念。今年读完《实现领域驱动设计》后，再回来重温这本书，里面的一些概念也就清晰多了。       主要介绍软件的复杂性以及降低复杂性的方法，书里用 “深” 和 “浅” 来表示一个模块的复杂性形容得非常形象。 《代码整洁之道》作者的又一力作，涵盖软件研发完整过程及所有核心架构模式。       目前流式计算框架五花八门，这本书以Apache Beam框架为例子，介绍了流式系统的一些通用概念。先了解Apache Beam，再来读这本书，里面的概念更容易理解些。 深入浅出地把微服务的架构设计、开发、测试和发布运维都介绍了一遍，而且提供了很多例子，有助于加深理解微服务的各种概念。       介绍阿里巴巴架构的演变过程，帮助了解时下热门的 “中台“ 概念的由来和含义。 与“架构”相关的概念居多，没有太多的干货，可以当成是睡前书来读。    术              《Java编程思想》的Java 8版本，全面而详细地介绍了Java 8的各种基础知识。即使已经使用Java两年了，读这本书的过程中的还是获益匪浅。 介绍了Java 8的各种新特性，新的日期API、Stream、Optional等都非常地好用，读完这本书，可以让你写出可读性更好的Java 8风格代码。       函数式编程范式逐渐成为各种语言的必备特性，这本书从理论出发，介绍了如何使用Java进行函数式编程。虽然Java不是函数式的语言，但是加点函数式的东西进去会很酷。 深入介绍了Docker的原理，去年初读时也是晦涩难懂。等到今年有了Docker实践之后，再回来读，对里面的概念和原理更有体会了。       今年公司提倡 重构 和 Clean Code，于是重新拿出来读了一遍。书中通过详细的例子介绍了一些常用的重构手法，真正做到了深入浅出。 介绍了HBase的架构原理和用法，适合入门，相对于《HBase权威指南》，这本书确实不容易让人睡觉。       《Effective C++》作者的又一力作，介绍改善C++ 11和C++ 14代码的一些方法和经验，对于写出现代C++风格代码很有帮助。 侯捷老师翻译的一本大作，详细介绍了C++标准库。虽然只是快速浏览了一遍，但是对里面STL的一些用法印象很是深刻。熟练使用STL可以帮助你写出更优雅的C++代码。       介绍使用C++进行API设计时的一些方法和技巧，对提升C++程序员的模块设计水平很有帮助。     人文社科类              今年读过的最好的人文社科类书籍，跟着书中的王先生重新上了堂国文课，极大的提升了我对读书和写作的兴趣。 来自西方的语言学家的著作，作者知识面很广，在书中融入了大量其他领域的知识来介绍语言学，读完会发现，原来人类的语言竟是如此有趣。       读完《文心》，马上又找了鲁迅先生的这本散文集。鲁迅先生用平凡的语言描绘了他的少年往事，很温馨。读到有趣之处，不自觉也露出了笑容。 同样也和语言有关，内容略显枯燥，读完最深刻的就是，对任何的言和事都要保持批判性的思考。       查理·芒格的个人传记，被他那百科全书般的知识所折服，更深受其终身学习、时刻保持求知欲望的精神所影响。 富兰克林是查理·芒格的偶像，从一个普通家庭的小孩，通过自学，逐渐成长为美国的开国元勋，而且还是一个科学家！读完这本书，像是经历了一遍他那传奇的一生。       描写了秦孝公和商鞅对秦国进行变法的那段历史，在作者的笔下，春秋战国变成了一个让人无比向往的时代。读完，让人有种想穿越回到那伟大的时代的冲动。 整个系列有5册，类似于《明朝那些事儿》的风格，但是文笔略逊一筹，可以当作了解宋朝历史的入门读物。       刚开始以为是一本讲投资的书，读了之后发现原来是一本讲如何学习、如何提升自己的书。书中的一些观点和《穷查理宝典》中的很类似，获益良多。 对冲基金公司桥水创始人的人生经验之作，分成传记、生活原则、工作原则三部分。其中传记部分最为精彩，对于 “保持极度开放的头脑” 和 “保持极度求真” 这两个观点印象深刻。       确实可以称得上世界上最简单的会计书，通过案例来解释会计学的种种概念，小白入门会计学的力荐之作。 很早以前就听过这本书了，直到今年才在微信读书上读完，收获比想象中要多，有助于学会如何管理自己的财务。    科普类              读完此书，在了解到神奇的量子世界的同时，也如同亲身经历了那个星光璀璨的伟大时代。科学史上的乌云和暴雨、追逐流星的辉光、重重的迷雾和险滩，感同身受。 这本书极大地扩展了我的宇宙观，读完会让你觉得人类太过渺小，这个世界太过美妙，世间万物有太多值得我们去探索、去求真的规律。如果早些年读到，说不定就选择读物理专业了。       整本书更像是一篇长长的论文，作者对物种起源的论证实在是太过严谨了，以至于读起来略显枯燥。 高中时死记硬背的元素周期表，其中的元素性质早已忘光了。但在作者的笔下，元素竟变得如此的有趣，而且充满了规律，再次体会到了这世界的奇妙。       这个世界充满着随机性，就像书中所说 “你的成功不见得是因为比其他人高明，而很可能是运气的结果。”。这本书可以让你认识到身边的事情多多少少都有些随机成分，并需要对“黑天鹅”事件时刻保持警惕。 这本书通过现实事例来阐述博弈论，看完虽说对博弈论还是一知半解，但明白了这世上很多现象原来是博弈的结果。       这本书读起来很有亲切感，因为几乎整本书都是在讲述“反馈”。对于学控制专业的人而言，这是再熟悉不过的概念了。反馈，真的是无处不在。     总结 王国维曾经说过，读书有三重境界。第一境界 “昨夜西风凋碧树，独上高楼，望尽天涯路“ 说的是博览群书，厚积薄发；第二境界 “衣带渐宽终不悔，为伊消得人憔悴” 说的是坚定不移，追根究底；第三境界 “众里寻她千百度，蓦然回首，那人却在，灯火阑珊处” 说的是融会贯通，知行合一。2019年末之际，有幸拾得读书乐趣，也算是踏进了读书的第一境界。\n","date":"2019-12-31T00:00:00Z","permalink":"https://www.yrunz.com/p/2019%E5%B9%B4%E7%9A%84%E8%AF%BB%E4%B9%A6%E5%8D%B0%E8%AE%B0/","title":"2019年的读书印记"},{"content":"前言 对于移位操作符，很多人既感到熟悉，又感到陌生。熟悉是因为移位操作符是最基本的操作符之一，几乎每种编程语言都包含这一操作符；陌生是因为除非是追求极致性能等罕见场景，否则也很难用得上它。打开JDK源码，你会发现移位操作符的身影极为常见，弄清楚它的用法，对阅读源码很有帮助。\n移位操作是把数据看作是二进制数，然后将其向左或向右移动若干位的运算。在Java编程语言中，移位操作符包含三种，分别是 \u0026lt;\u0026lt;（左移）、 \u0026gt;\u0026gt;（带符号右移）和 \u0026gt;\u0026gt;\u0026gt;（无符号右移），这三种操作符都只能作用于long、int、short、byte、char这四种基本的整型类型上。\n左移操作符 \u0026laquo; 左移操作符 \u0026lt;\u0026lt; 是将数据转换成二进制数后，向左移若干位，高位丢弃，低位补零。看如下例子：\npublic static void main(String[] args) { int i = -1; System.out.println(\u0026#34;Before \u0026lt;\u0026lt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); i \u0026lt;\u0026lt;= 10; System.out.println(\u0026#34;After \u0026lt;\u0026lt; , i\u0026#39;s value is \u0026#34; + i); System.out.println(\u0026#34;i\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i)); } Java的int占32位，因此对i = -1转换成二进制数，然后左移10位，其结果是左边高10位丢弃，右边低10位补0，再转换为十进制，得到i = -1024的结果。\n因此，上述例子的输出结果为：\nBefore \u0026lt;\u0026lt; , i's value is -1 i's binary string is 11111111111111111111111111111111 After \u0026lt;\u0026lt; , i's value is -1024 i's binary string is 11111111111111111111110000000000 带符号右移操作符 \u0026raquo; 众所周知，Java中整型表示负数时，最高位为符号位，正数为0，负数为1。\u0026gt;\u0026gt; 是带符号的右移操作符，将数据转换成二进制数后，向右移若干位，高位补符号位，低位丢弃。对于正数作右移操作时，具体体现为高位补0；负数则补1。看如下例子：\npublic static void main(String[] args) { // 对正数进行右移操作  int i1 = 4992; System.out.println(\u0026#34;Before \u0026gt;\u0026gt; , i1\u0026#39;s value is \u0026#34; + i1); System.out.println(\u0026#34;i1\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i1)); i1 \u0026gt;\u0026gt;= 10; System.out.println(\u0026#34;After \u0026gt;\u0026gt; , i1\u0026#39;s value is \u0026#34; + i1); System.out.println(\u0026#34;i1\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i1)); // 对负数进行右移操作  int i2 = -4992; System.out.println(\u0026#34;Before \u0026gt;\u0026gt; , i2\u0026#39;s value is \u0026#34; + i2); System.out.println(\u0026#34;i2\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i2)); i2 \u0026gt;\u0026gt;= 10; System.out.println(\u0026#34;After \u0026gt;\u0026gt; , i2\u0026#39;s value is \u0026#34; + i2); System.out.println(\u0026#34;i2\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i2)); } 例子中，i1 = 4992转换成二进制数，右移10位，其结果是左边高10位补0，右边低10位丢弃，再转换为十进制，得到i1 = 4的结果。同理，i2 = -4992，右移10位，左边高10位补1，右边低10位丢弃，得到i2 = -5的结果。\n因此，上述例子的输出结果为：\nBefore \u0026gt;\u0026gt; , i1's value is 4992 i1's binary string is 1001110000000 After \u0026gt;\u0026gt; , i1's value is 4 i1's binary string is 100 Before \u0026gt;\u0026gt; , i2's value is -4992 i2's binary string is 11111111111111111110110010000000 After \u0026gt;\u0026gt; , i2's value is -5 i2's binary string is 11111111111111111111111111111011 无符号右移操作符 \u0026raquo;\u0026gt; 无符号右移操作符 \u0026gt;\u0026gt;\u0026gt;与\u0026gt;\u0026gt;类似，都是将数据转换为二进制数后右移若干位，不同之处在于，不论负数与否，结果都是高位补零，低位丢弃。看如下例子：\npublic static void main(String[] args) { int i3 = -4992; System.out.println(\u0026#34;Before \u0026gt;\u0026gt;\u0026gt; , i3\u0026#39;s value is \u0026#34; + i3); System.out.println(\u0026#34;i3\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i3)); i3 \u0026gt;\u0026gt;\u0026gt;= 10; System.out.println(\u0026#34;After \u0026gt;\u0026gt;\u0026gt; , i3\u0026#39;s value is \u0026#34; + i3); System.out.println(\u0026#34;i3\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i3)); } 同样对i3 = -4992进行操作，转换成二进制数后，右移10位，其结果为左边高10位补0，右边低10位丢弃，再转换成十进制，得到i3 = 4194299的结果。\n因此，上述例子的输出结果为：\nBefore \u0026gt;\u0026gt;\u0026gt; , i3's value is -4992 i3's binary string is 11111111111111111110110010000000 After \u0026gt;\u0026gt;\u0026gt; , i3's value is 4194299 i3's binary string is 1111111111111111111011 真的懂了吗？ 对 short、byte、char 的移位操作 再看如下例子：\npublic static void main(String[] args) { byte b = -1; System.out.println(\u0026#34;Before \u0026gt;\u0026gt; , b\u0026#39;s value is \u0026#34; + b); System.out.println(\u0026#34;b\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(b)); b \u0026gt;\u0026gt;\u0026gt;= 6; System.out.println(\u0026#34;After \u0026gt;\u0026gt; , b\u0026#39;s value is \u0026#34; + b); System.out.println(\u0026#34;b\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(b)); } Java的byte占8位，按照前面讲述的原理，对b = -1转换为二进制数后，右移6位，左边高6位补0，右边低位丢弃，其结果应该是b = 3。\n真的这样吗？我们看一下例子运行的结果：\nBefore \u0026gt;\u0026gt; , b's value is -1 b's binary string is 11111111111111111111111111111111 After \u0026gt;\u0026gt; , b's value is -1 b's binary string is 11111111111111111111111111111111 运行结果与我们预期的结果不对！\n原来，Java在处理byte、short、char的移位操作前，会先将其转型成int类型，然后在进行操作！特别地，当对这三者使用\u0026lt;\u0026lt;=、\u0026gt;\u0026gt;=和\u0026gt;\u0026gt;\u0026gt;=时，其实是得到对移位后的int进行低位截断后的结果！对例子改动一下进行验证：\npublic static void main(String[] args) { byte b = -1; System.out.println(\u0026#34;Before \u0026gt;\u0026gt; , b\u0026#39;s value is \u0026#34; + b); System.out.println(\u0026#34;b\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(b)); System.out.println(\u0026#34;After \u0026gt;\u0026gt; , b\u0026#39;s value is \u0026#34; + (b \u0026gt;\u0026gt;\u0026gt; 6)); System.out.println(\u0026#34;b\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(b \u0026gt;\u0026gt;\u0026gt; 6)); } 在该例子中，没有使用 \u0026gt;\u0026gt;\u0026gt;= 对 b 进行再赋值，而是直接将 b \u0026gt;\u0026gt;\u0026gt; 6 进行输出（需要注意的是，b \u0026gt;\u0026gt;\u0026gt; 6 的结果为 int 类型），其输出如下：\nBefore \u0026gt;\u0026gt; , b's value is -1 b's binary string is 11111111111111111111111111111111 After \u0026gt;\u0026gt; , b's value is 67108863 b's binary string is 11111111111111111111111111 因此，第一个例子中实际的运算过程应该是这样：\n对于short和char的移位操作原理也一样，读者可以自行进行实验验证。\n如果移位的位数超过数值所占有的位数会怎样？ 到目前为止的所有的例子中，移位的位数都在数值所占有的位数之内，比如对int类型的移位都没有超过32。那么如果对int类型移位超过32位会怎样？且看如下例子：\npublic static void main(String[] args) { int i4 = -1; System.out.println(\u0026#34;Before \u0026gt;\u0026gt;\u0026gt; , i4\u0026#39;s value is \u0026#34; + i4); System.out.println(\u0026#34;i4\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i4)); System.out.println(\u0026#34;After \u0026gt;\u0026gt;\u0026gt; 31 , i4\u0026#39;s value is \u0026#34; + (i4 \u0026gt;\u0026gt;\u0026gt; 31)); System.out.println(\u0026#34;i4\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i4 \u0026gt;\u0026gt;\u0026gt; 31)); System.out.println(\u0026#34;After \u0026gt;\u0026gt;\u0026gt; 32 , i4\u0026#39;s value is \u0026#34; + (i4 \u0026gt;\u0026gt;\u0026gt; 32)); System.out.println(\u0026#34;i4\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i4 \u0026gt;\u0026gt;\u0026gt; 32)); System.out.println(\u0026#34;After \u0026gt;\u0026gt;\u0026gt; 33 , i4\u0026#39;s value is \u0026#34; + (i4 \u0026gt;\u0026gt;\u0026gt; 33)); System.out.println(\u0026#34;i4\u0026#39;s binary string is \u0026#34; + Integer.toBinaryString(i4 \u0026gt;\u0026gt;\u0026gt; 33)); } 根据前面讲述的原理，对于i4 \u0026gt;\u0026gt;\u0026gt; 31我们很容易得出结果为1。\n那么，i4 \u0026gt;\u0026gt;\u0026gt; 32的结果会是0吗？\nNO！Java对移位操作符的右操作数rhs有特别的处理，对于int类型，只取其低5位，也就是取rhs % 32的结果；对于long类型，只取其低6位，也即是取rhs % 64的结果。因此，对于i4 \u0026gt;\u0026gt;\u0026gt; 32，实际上是i4 \u0026gt;\u0026gt;\u0026gt; (32 % 32) ，也即i4 \u0026gt;\u0026gt;\u0026gt; 0 ，结果仍然是-1。\n同理，对于i4 \u0026gt;\u0026gt;\u0026gt; 33等同于i4 \u0026gt;\u0026gt;\u0026gt; 1，其结果为2147483647。\n因此，上述例子的输出结果如下：\nBefore \u0026gt;\u0026gt;\u0026gt; , i4's value is -1 i4's binary string is 11111111111111111111111111111111 After \u0026gt;\u0026gt;\u0026gt; 31 , i4's value is 1 i4's binary string is 1 After \u0026gt;\u0026gt;\u0026gt; 32 , i4's value is -1 i4's binary string is 11111111111111111111111111111111 After \u0026gt;\u0026gt;\u0026gt; 33 , i4's value is 2147483647 i4's binary string is 1111111111111111111111111111111 对于long类型也是同样的道理，读者可以自行进行实验验证。\n总结 移位操作符虽说是Java中最基本的操作符之一，但是若不彻底弄清楚其中细节，稍有不慎，便容易犯错。移位操作符实际上支持的类型只有int和long，编译器在对short、byte、char类型进行移位前，都会将其转换为int类型再操作。移位操作符在JDK源码中，最常见的用法便是将其当成是乘 * 或者除 / 操作符使用 ：对一个整型左移一位，相当于乘以2；右移一位，相当于除以2。其中原因就是，相比于使用 * 和 / ，在Java代码里使用 \u0026lt;\u0026lt; 和 \u0026gt;\u0026gt; 转换成的指令码运行起来会更高效些。\n","date":"2019-12-22T00:00:00Z","permalink":"https://www.yrunz.com/p/%E5%BD%BB%E5%BA%95%E5%BC%84%E6%87%82java%E7%9A%84%E7%A7%BB%E4%BD%8D%E6%93%8D%E4%BD%9C%E7%AC%A6/","title":"彻底弄懂Java的移位操作符"},{"content":"起 读完《文心》，就像是重新上了一堂国文课一样，跟之前不太一样的国文课。\n国文课是民国时期的叫法，现在都改称为语文课了。从小学、初中、至高中，语文作为一门基础课程 —— 从平时喊“语文、数学、英语”就可得知 —— 在我们学生心里，一直都是最重要的科目。对我而言，语文更是到了让人敬畏的程度。“敬”是语文作为高考必考的科目，不得不认真对待；“畏”是对语文所考察的知识点感到无力，完成一道题，你很难确认自己是否做对了。\n 不像数学有着固定的公式解法，语文的很多题目感觉就像是随机作答一般。就拿阅读理解中体会作者情感一题来说，就算这次猜对了，下一次给出另外一篇文章，难道就会解了吗？\n 以至于高考完以后，心里莫名的愉快，因为从此再无语文课。直到最近读完叶圣陶和夏丐尊两位大师所著的《文心》，对 国文 算是有了重新的认识。书中以故事的形式介绍了国文的种种，阅读的过程，就像是跟着书中王先生重新上了堂国文课。\n国文的种类很广，散文、叙事文、诗、词、小说、戏剧等等都属于这一范畴。而国文课所教授的，概括起来，莫过于是 读 的功夫与 写 的功夫。\n读 “作者把经验或想象所得的具体的事物翻译成白纸上的黑字，我们读者却要倒翻过去，把白纸上的黑字再依旧翻译为具体的事物。”\n从前读描写景物的文章最多只是脑海里浮现出文中情景，读讲述故事的文章最多也只是弄清楚文中情节，至于作者的感情，那是读再多遍也无法体会出来。所以，读大师的文章却丝毫鉴赏不出大师的风采，不看作者，还以为只不过是个普通的作家写出的文章罢了。\n这其中原因，除了不善于挖掘作者在文章中所表达的事物之外，另一个很重要的就是不了解文章的背景。每篇文章都有一个背景，作者便是在此背景下，把当时经验、感情编织到文章里面。\n 辛弃疾的那首起句“郁孤台下清江水”的《菩萨蛮》词，题目只作《题江西造口壁》，如果我们不知道宋室南渡的变乱及造口的位置，读去会有什么趣味呢？\n 在读一篇文章之前，尝试着先去把背景弄清楚，这样也许就可以感受到当时作者的情感，读起来也会更有趣味些。\n“读书的目的，重在收得其内容意趣，否则只是文字的游戏而已。”\n从前为了增加知识的广度（更多的是过于浮躁），喜欢快速把一本书读完，收得其中大概意思。至于书中的一些细节知识点却不会去记住，甚至很多时候根本都没有留意到，想着用到时再回去查阅。这样下来，虽说看起来懂得挺多知识，但其中大部分都是些皮毛，被深入地一问，便回答不上了。\n 最近公司需要进行软件认证，平时没少进行Java编码，之前《Java编程思想》也看过，而其中一些关于Java的基础知识很多却还是都不懂。直到最近静下心来细读《On Java 8》，才发现很多基础知识在书上都有介绍，只是以前没有关注罢了。\n 如果很难集中注意对一本书进行细读，可以通过写读书笔记或博客来驱动。读书笔记不是读到好的文段便摘录下来的几句，而是读到这些文段时的感想。“读书要精细，才能写出读书笔记，反过来，试写读书笔记，也就是使读书不苟且的一种方法。”。另外，写博客也是一种好的驱动方法，在阅读时不断去想着如何去给别人讲述这些知识点，这样对知识的理解也会更深刻些。\n“读书贵有新得，作文贵有新味，最重要的是触发的功夫。”\n所谓触发，就是由一件事感悟到其他的事。比如，读《文心》读到作文追求简炼，便想到也有代码简洁一说，这就是一种触发。我们常常听别人说要多学科交叉，触发就是一种可以把各科知识点关联起来的好方法。在阅读的过程中，多联想些之前学得的知识，便通过触发来逐步构建自己的知识体系。\n写 “文字是心的表现，也可有三种分别，就是知的文、情的文与意的文。”\n我们心的作用，普通心理学家分为知、情、意三种，文字是心的表现，因此也可分为这三类。知是知识，情是感情，意是意欲。知的文最典型的就是科普文章，作者通过文字给大众传授一些普遍的科学规律；情的文最典型的就是抒情散文，作者借景物或事物来寄托当时的情感；意的文最典型的就是广告，作者通过文字来煽动大家对商品的购买欲望。\n写作的第一步就是要认清目标，确定要写哪一类的文章。比如写一篇技术文章，却往文章里添加了些个人感情的文字，这是混淆了写作的目标；第二步就是要认清读者，只写这类读者可以接受的知识。比如要给Java新手写一篇入门的技术文章，而文章里写的却是JDK的源码剖析，这是混淆了文章受众；第三步就是要组织文章，根据中心旨意把要表达的知识组织成一篇条理清晰的文章。\n“对于文章的组织，也不妨举出一个总方法来，那就是 ‘回问自己’ 四个大字。”\n在写作的三个步骤里，文章的组织是最难的一步，这是关于怎么写好文章的学问。对于写作新手，难免会遇到“心中想法万千，却无从下笔”的窘境。这时候，可以尝试通过回问自己来着手一篇文章写作，以上一篇文章《一步步降低软件复杂性》为例：\n\u0026ldquo;是为了要说些什么才写这篇文章的?\u0026rdquo; —— 为了总结些降低软件复杂性的方法。这样文章的中心意旨就明确了。\n\u0026ldquo;中心意旨在我们意念中间是怎么来的？\u0026rdquo; —— 读完《A Philosophy of Software Design》一书深有感触，想分享给大家。这样文章依据的材料范围也就确认了。\n“这个材料可以增加中心意旨的力量吗？” —— 书中关于深浅模块例子可以很好地比喻软件的复杂性。这样就可以不断筛选出好的素材，文章的主要内容也就确认了。\n“还有更简练通顺的表达吗？” —— 这样写好像更通顺一些。这样经过不断的修正，一篇文章也就出来了。\n“习作只是法则与手腕的练习，应用之作只是对付他人和事务的东西，创作才是发挥自己天分的真成绩。”\n文章写作活动可以分为三类，习作、应用和创作。这三者之中，最基本最重要的是习作。只有当习作到了相当的程度，才能谈得到应用，才能谈得到创作。最基本的往往坚持下来最困难。想起初中时的语文老师蔡先生让我们每天都写一篇随笔，但总是不愿花超过半个小时的时间去完成。有时实在憋不出东西来，就把一段话拆成多行，撑满一页纸后便当作一首新体诗交差了上去。想起来也是可笑至极。如果当时能认真对待些，写作水平也不至于到现在这么差了。\n结 《文心》算是今年读过的社科类书中最好的一本了，读完不敢说文章鉴赏和写作能力有多大的提升，但至少兴趣是上来了，舍得花上一天的时间去完成一篇文章了。\n所有的习惯和知识都可以通过锻炼习得，文章的读和写也一样，而且它们是可以相互促进的。多读，学习优秀文章的写法，写作水平也就提升了；多写，知道写作在哪方面有缺陷，就会主动去阅读同类优秀文章来学习了。\n说到底，最重要的还是坚持，每天坚持让自己进步一点，一年下来，就会发现自己成长了许多。\n","date":"2019-12-15T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%B8%8D%E4%B8%80%E6%A0%B7%E7%9A%84%E5%9B%BD%E6%96%87%E8%AF%BE/","title":"不一样的国文课"},{"content":"前言 在进行软件开发时，我们常常会追求软件的高可维护性，高可维护性意味着当有新需求来时，系统易扩展；当出现bug时，开发人员易定位。而当我们说一个系统的可维护性太差时，往往指的是该系统太过复杂，导致给系统增加新功能时容易出现bug，而出现bug之后又难以定位。\n那么，软件的复杂性又是如何定义的呢？\nJohn Ousterhout给出的定义如下：\n Complexity is anything related to the structure of a software system that makes it hard to understand and modify the system.\n 可见，软件的复杂性是一个很泛的概念，任何使软件难以理解和难以修改的东西，都属于软件的复杂性。为此，John Ousterhout提出了一个公式来度量一个系统的复杂性： $$ C = \\sum_{p}c_{p}t_{p} $$\n 式中，$p$表示系统中的模块，$c_{p}$表示该模块的认知负担（Cognitive Load，即一个模块难以理解的程度），$t_{p}$表示在日常开发中在该模块花费的开发时间。\n 从公式上看，一个软件的复杂性由它的各个模块的复杂性累加而成，而 模块复杂性 = 模块认知负担 * 模块开发时间，也就是模块的复杂性即和模块本身有关，也跟在该模块上花费的开发时间有关。需要注意的是，如果一个模块非常难以理解，但是后续开发过程中几乎没有涉及到它，那么它的复杂性也是很低的。\n导致软件复杂的原因 导致软件复杂的原因可以细分出很多种来，而概括起来莫过于两种：依赖（dependencies） 和 隐晦（obscurity）。前者会让修改起来很费劲而且容易出现bug，比如当修改模块1时，往往也涉及到模块2、模块3、... 的改动；后者会让软件难以理解，定位一个bug，甚至是仅仅读懂一段代码都需要花费大量的时间。\n软件的复杂性往往伴随着如下几种症状：\n霰弹式修改（Change amplification）。当只需要修改一个功能，但又不得不对许多模块作出改动时，我们称之为霰弹式修改。这通常是因为模块之间耦合过重，相互依赖太多导致的。 比如，有一组Web页面，每个页面都是一个HTML文件，每个HTML都有一个背景属性。由于各个HTML的背景属性都是分开定义的，因此如果需要把背景颜色从橙色修改为蓝色时，就需要改动所有的HTML文件。\n认知负担（Cognitive load）。当我们说一个模块隐晦、难以理解时，它就有过重的认知负担，这种情况下往往需要读者花费大量时间才能明白该模块的功能。比如，提供一个不带任何注释的calculate接口，它有2个int类型的入参和一个int类型的返回值。从该函数的签名上看，调用者根本无法得知函数的功能是什么，他只能通过花时间去阅读源码来确定函数功能后才敢去调用该函数。\nint calculate(int val1, int val2); 不确定性（Unknown unknowns）。相比于前两种症状，不确定性的破坏性更大，它通常指一些在开发需求时，你必须注意的，但是又无从得知的点。它常常是因为一些隐晦的依赖导致的，会让你在开发完一个需求之后感觉心里很没谱，隐约觉得自己的代码哪里有问题，但又不清楚问题在哪，只能祈祷在测试阶段能够暴露而不要漏洞商用阶段。\n如何降低软件的复杂性 对 “战术编程” Say No！ 很多程序员在进行特性开发或bug修复时，关注点往往是如何简单快速让程序跑起来，这就是典型的战术编程（Tactical programming）方法，它追求的是短期的效益——节省开发时间。战术编程最普遍的体现就是在编码之前没有进行模块设计，想到哪里就写到哪里。战术编程在系统前期可能会比较方便，一旦系统庞大起来、模块之间的耦合变重之后，添加或修改功能、修复bug都会变得寸步难行。随着系统变得越来越复杂，最后不得不对系统进行重构甚至重写。\n与战术编程相对的就是战略编程（Strategic programming），它追求的是长期的效益——增加系统可维护性。仅仅是让程序跑起来还不足以满足，还需要考虑程序的可维护性，让后续在添加或修改功能、修复bug时都能够快速响应。因为考虑的点比较多，也就注定战略编程需要花费一定的时间去进行模块设计，但相比于战术编程后期导致的问题，这一点时间也是完全值得的。\n让模块更“深”一点！ 一个模块由接口（interface）和实现（implementation）两部分组成，如果把一个模块比喻成一个矩形，那么接口就是矩形顶部的边，而实现就是矩形的面积（也可以把实现看成是模块提供的功能）。当一个模块提供的功能一定时，深模块（Deep module）的特点就是矩形顶部的边比较短，整体形状高瘦，也即接口比较简单；浅模块（Shallow module）的特点就是矩形顶部的边比较长，整体形状矮胖，也即接口比较复杂。\n模块的使用者往往只看到接口，模块越深，模块暴露给调用者的信息就越少，调用者与该模块的耦合性也就越低。因此，把模块设计得更“深”一点，有助于降低系统的复杂性。\n那么，怎样才能设计出一个深模块呢？\n  更简单的接口 简单的接口比简单的实现更重要，更简单的接口意味着模块的易用性更好，调用者使用起来更方便。而简单的实现 + 复杂的接口这种形式，一方面影响了接口的易用性，另一方面则加深了调用者与模块的耦合。因此，在进行模块设计时，最好遵守“把简单留给别人，把复杂留给自己”的原则。\n 异常也属于接口的一部分，在编码过程中，应该杜绝没经过处理，就随意将异常往上抛的现象，这样只会增加系统的复杂性。\n   更通用的接口 在设计接口时，你往往有两种选择：（1）设计成专用的接口；（2）设计成通用的接口。前者实现起来更方便，而且完全可以满足当前的需求，但可扩展性低，属于战术编程；后者则需要花时间对系统进行抽象，但可扩展性高，属于战略编程。通用的接口意味着该接口适用的场景不止一个，典型的就是“ 一个接口，多个实现 ”的形式。\n有些程序员可能会反驳，在无法预知未来变化的情况下，通用就意味着过度设计。过度通用确实属于过度设计，但对接口进行适度的抽象并不是，相反它可以使系统更有层次感，可维护性也更高。\n  隐藏细节 在进行模块设计时，还要学会区分对于调用者而言，哪些信息是重要的，哪些信息是不重要的。隐藏细节指的就是只给调用者暴露重要的信息，把不重要的细节隐藏起来。隐藏细节一则使模块接口更简单，二则使系统更易维护。\n 如何判断细节对于调用者是否重要？以下有几个例子：\n1、对于Java的Map接口，重要的细节：Map中每一个元素都是由\u0026lt;Key, Value\u0026gt;组成的；不重要的细节：Map底层是如何存储这些元素、如何实现线程安全等。\n2、对于文件系统中的read函数，重要的细节：每次读操作从哪个文件读、读多少字节；不重要的细节：如何切换到内核态、如何从硬盘里读数据等。\n3、对于多线程应用程序，重要的细节：如何创建一个线程；不重要的细节：多核CPU如何调度该线程。\n   进行分层设计！ 设计良好的软件架构都有一个特点，就是层次清晰，每一层都提供了不同的抽象，各个层次之间的依赖明确。不管是经典的Web三层架构、DDD所提倡的四层架构以及六边形架构，抑或是所谓的Clean Architecture，都有着鲜明的层次感。\n              在进行分层设计时，需要注意的是，每一层都应该提供不同的抽象，并要尽量避免在一个模块中出现大量的Pass-Through Mehod。比如在DDD的四层架构中，领域层提供了对领域业务逻辑的抽象，应用层提供了对系统用例的抽象，接口层提供了对系统访问接口的抽象，基础设施层则提供对如数据库访问这类的基础服务的抽象。\n所谓的Pass-Through Mehod是指那些“在函数体内直接调用其他函数，而本身只做了极少的事情”的函数，通常其函数签名与被其调用的函数签名很类似。Pass-Through Mehod所在的模块通常都是浅模块，让系统增加了无谓的层次和函数调用，会使系统更加复杂。\n学会写代码注释！ 注释是软件开发过程中的性价比极高的一种手法，它只需要花费20%的时间，即可获取80%的价值。它可以提高晦涩难懂的代码的可读性；可以起到隐藏代码复杂细节的作用，比如接口注释可以帮助开发者在没有阅读代码的情况下快速了解该接口的功能和用法；如果写的好，它还可以改善系统的设计。\n 具体如何写好代码注释，参考《教你写好代码注释》一文。\n 总结 软件的复杂性是我们程序员在日常开发中所必须面对的东西，学会如何 “弄清楚什么是软件复杂性，找到导致软件复杂的原因，并利用各种手法去战胜软件的复杂性” 是一门必备的能力。有句话说得很好，“代码质量决定生活质量”，当你把软件的复杂性降低了，bug减少了，系统可维护性更高了，自然也就带来了更好的生活质量。\n模块设计是降低软件复杂度最有效的手段，学会使用“战略编程”的方法，并坚持下去。我们常常提倡“一次把事情做对”，但这对于模块设计而言并不适用，几乎没有人可以第一次就把一个模块设计成完美的模样。二次设计是一个非常有效的手法，与其在系统腐化之后再花大量时间进行重构或重写，还不如在第一次完成模块设计后，再花点时间进行二次设计，多问问自己：是否有更简单的接口？是否有更通用的设计？是否有更简洁高效的实现？\n\u0026ldquo;罗马不是一天建成的\u0026rdquo;，降低软件的复杂性也一样，贵在坚持。\n","date":"2019-12-08T00:00:00Z","permalink":"https://www.yrunz.com/p/%E4%B8%80%E6%AD%A5%E6%AD%A5%E9%99%8D%E4%BD%8E%E8%BD%AF%E4%BB%B6%E5%A4%8D%E6%9D%82%E5%BA%A6/","title":"一步步降低软件复杂度"},{"content":"前言 相信大家都会遇到这种情况：一周前自己写的代码，现在再拿出来看，发现读不懂了，“ 这代码是我写的？？？”。这时候，代码注释就可以发挥它的作用了——提高晦涩难懂的代码的可读性；注释可以起到隐藏代码复杂细节的作用，比如接口注释可以帮助开发者在没有阅读代码的情况下快速了解该接口的功能和用法；如果写的好，注释还可以改善系统的设计。\n既然注释这么多好处，为什么我们程序员还是不愿意写注释？\n“代码都写不完了，哪有时间写注释，以后再补吧“\n时间不够论。这是最常见的原因，在交付速度飞快的今天，“代码写不完”是一个再常见不过的情况了，但写注释真的会导致需求延迟吗？绝不！相对于写一个接口的实现，写接口注释的时间可能只需要花费前者的5%。但不写注释，后面使用接口的人必须要多花费**50%**的时间去读懂代码！而且对于大部分程序员而言，“以后再补“大概要到2910年才能落实。\n“好的代码就是最好的注释，我的代码可读性很好，没必要写注释”\n好代码胜过注释论。不少程序员认为，好的代码就是最好的注释，只要代码可读性好，注释就可以省去。然而一个软件系统很多信息是无法通过代码呈现出来的，比如系统的设计思路、函数执行的预置条件等等。此外，代码可读性也不是绝对的，对于一个没有使用过Java 8 的 Lambda表达式的开发者而言，通篇的箭头“-\u0026gt;“简直就是一场噩梦。\n”过期的注释容易误导人“\n过期注释论。不可否认，过期的注释很容易误导读者，但是这并不能成为否认注释的借口。除非是重大的重构或重写，对注释进行大改动的情况很少出现。通常，在更改代码之后，只需花费极少的时间去更新注释，就可以避免过期注释这种情况了。\n注释的分类 注释大致可以分成四类：接口注释、数据成员注释、实现注释和模块依赖注释。\n接口注释 平时我们所说的接口，通常指的是一个类（包括interface、class、enum）和方法。对类而言，接口注释主要描述该类提供的功能；对方法而言，除了描述方法功能之外，方法的入参和返回值都要进行说明。当然，使用类/方法的一些预置条件和副作用等信息都需要在接口注释中提到。\n/** * Returns the length of this string. * The length is equal to the number of \u0026lt;a href=\u0026#34;Character.html#unicode\u0026#34;\u0026gt;Unicode * code units\u0026lt;/a\u0026gt; in the string. * * @return the length of the sequence of characters represented by this * object. */ public int length() { return value.length; }  典型的接口注释（选自JDK 1.8中的String类）\n 数据成员注释 数据成员注释和接口注释在大多数情况下都是必须的，这对于让读者快速读懂代码有很大的帮助。数据成员包括类的普通成员变量和静态成员变量，数据成员注释除了描述数据成员的本身用途之外，成员的默认值、副作用等信息都需要提及。\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0  /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = -6849794470754667710L; /** * Class String is special cased within the Serialization Stream Protocol. * * A String instance is written into an ObjectOutputStream according to * \u0026lt;a href=\u0026#34;{@docRoot}/../platform/serialization/spec/output.html\u0026#34;\u0026gt; * Object Serialization Specification, Section 6.2, \u0026#34;Stream Elements\u0026#34;\u0026lt;/a\u0026gt; */ private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; .... }  典型的数据成员注释（选自JDK 1.8中的String类）\n 实现注释 对于一段代码，如果无法一眼就看出其含义而需要深入分析其实现才能读懂，就需要添加实现注释对这段代码的含义进行说明。代码的实现注释通常不是必须的，如果一段代码每一行都需要注释，那就要重新审视一下这段代码的设计是否有合理了。此外，实现注释描述还需要描述一些代码无法体现，但是对于读者了解这段代码很有帮助的信息，比如代码的设计思路等。\npublic final class String { ... public char[] toCharArray() { // Cannot use Arrays.copyOf because of class initialization order issues  char result[] = new char[value.length]; System.arraycopy(value, 0, result, 0, value.length); return result; } ... }  典型的实现注释（选自JDK 1.8中的String类）\n 模块依赖注释 模块依赖注释相对少见一些，主要描述两个相互依赖的模块的一些依赖信息，因为它并不属于单独某个模块，所以在哪里写这个注释需要认真衡量一下。实在找不到好的位置时，可以写一个类似README的文件，专门用于描述模块之间的依赖关系。\ntypedef enum Status { STATUS_OK = 0, STATUS_UNKNOWN_TABLET = 1, STATUS_WRONG_VERSION = 2, ... STATUS_INDEX_DOESNT_EXIST = 29, STATUS_INVALID_PARAMETER = 30, STATUS_MAX_VALUE = 30, // Note: if you add a new status value you must make the following  // additional updates:  // (1) Modify STATUS_MAX_VALUE to have a value equal to the  // largest defined status value, and make sure its definition  // is the last one in the list. STATUS_MAX_VALUE is used  // primarily for testing.  // (2) Add new entries in the tables \u0026#34;messages\u0026#34; and \u0026#34;symbols\u0026#34; in  // Status.cc.  // (3) Add a new exception class to ClientException.h  // (4) Add a new \u0026#34;case\u0026#34; to ClientException::throwException to map  // from the status value to a status-specific ClientException  // subclass.  // (5) In the Java bindings, add a static class for the exception  // to ClientException.java  // (6) Add a case for the status of the exception to throw the  // exception in ClientException.java  // (7) Add the exception to the Status enum in Status.java, making  // sure the status is in the correct position corresponding to  // its status code. }  典型的模块依赖注释（选自《A Philosophy of Software Design》中的例子）\n 如何写好代码注释 利用好注释模板 注释模板为注释写作提供了极大的便利，我们常用的开发工具如IDEA、VS Code都对注释模板有很好的支持。在配置好注释模板之后（一般情况下默认模板即可），只需简单的操作，就能生成模板，我们只需往模板里填上内容即可。对于方法的接口注释，注释模板尤为方便，方法的入参和返回值标识注释模板都已经提供好。\n/** * * @param user * @param password * @return */ private boolean login(String user, String password) { ... }  IntelliJ IDEA默认的注释模板\n 不要重复代码 注释与代码重复是开发者最容易犯的一个错误，这也是很多开发者认为注释是冗余的原因。确实，对于那些通过读代码可以很容易就推断出来的信息，注释就是多余的，更甚者，出现过期注释还容易误导读者。\n// Add a horizontal scroll bar hScrollBar = new JScrollBar(JScrollBar.HORIZONTAL); add(hScrollBar, BorderLayout.SOUTH); // Add a vertical scroll bar vScrollBar = new JScrollBar(JScrollBar.VERTICAL); add(vScrollBar, BorderLayout.EAST); // Initialize the caret-position related values caretX = 0; caretY = 0; caretMemX = null;  典型的重复代码的注释（选自《A Philosophy of Software Design》中的例子）\n 某些程序员喜欢在注释中使用代码中的变量名或其中的单词，这种情况也是注释重复代码的一种体现。像下面的这个例子，注释完全就是冗余的，可以猜测开发者纯粹是为了注释而注释。\n/** * 用户登录 * @param user User对象 * @param password Password对象 * @return */ private boolean login(User user, Password password) { ... }  使用代码变量名的注释\n 注释也要分层 在进行系统设计时，我们常常会采用分层架构，每一层负责不同功能。系统的顶层往往会更抽象一点，为功能调用者隐藏了很多细节（high-level）；底层往往会更细节一点，实现系统的具体功能（low-level）。在进行注释写作时，我们也要学会对注释进行分层。high-level的注释要提供比代码更抽象的信息，比如代码的设计思路；low-level的注释要提供比代码更细节的信息，比如表示一个范围的两个参数是左闭右开还是左闭右闭；我们需要避免写出与代码同一level的注释，因为这往往就是上一节所提到的注释重复代码。\nlow-level注释写作指南 对于需要通过阅读这一段代码才能获取的信息，就适合以low-level注释写在这段代码前面，一些常见的例子有：\n 变量的单位是什么？ 表示范围的一组参数是左闭右开还是左闭右闭？ 某个变量为null时代表什么含义？ 某个资源应该由谁来负责释放，接口调用者还是接口提供者？  low-level注释不能太过抽象，否则就失去了其应有的作用：\n// Current offset in resp Buffer uint32_t offset; // Contains all line-widths inside the document and // number of appearances. private TreeMap\u0026lt;Integer, Integer\u0026gt; lineWidths;  太过抽象的low-level注释（选自《A Philosophy of Software Design》中的例子）\n 好的low-level注释应当详细介绍代码的意图及其需要注意的点：\n// Position in this buffer of the first object that hasn\u0026#39;t // been returned to the client. uint32_t offset; // Holds statistics about line lengths of the form \u0026lt;length, count\u0026gt; // where length is the number of characters in a line (including // the newline), and count is the number of lines with // exactly that many characters. If there are no lines with // a particular length, then there is no entry for that length. private TreeMap\u0026lt;Integer, Integer\u0026gt; numLinesWithLength;  典型的low-level注释（选自《A Philosophy of Software Design》中的例子）\n high-level注释写作指南 high-level注释的作用是隐藏具体实现细节，快速让读者对整一段代码有一个全局的了解。high-level注释除了描述对代码进行抽象的概括（What）之外，还经常描述代码的设计思路（Why），这有助于帮助读者更容易、深入地了解整个系统。high-level注释不应该描述具体代码实现的信息，更不能犯注释重复代码的错误。在写high-level注释之前，先问一下自己：\n 这段代码要做什么事情？ 这段代码最核心的功能是什么？ 怎样才能以最简单的描述表达这段代码的核心功能？  太过细节的high-level注释其实就是在重复代码，另一方面该注释既不能解释此代码的总体目的，也不能解释其如何适合包含此代码的方法，导致其失去了其应有作用：\n// If there is a LOADING readRpc using the same session // as PKHash pointed to by assignPos, and the last PKHash // in that readRPC is smaller than current assigning // PKHash, then we put assigning PKHash into that readRPC. int readActiveRpcId = RPC_ID_NOT_ASSIGNED; for (int i = 0; i \u0026lt; NUM_READ_RPC; i++) { if (session == readRpc[i].session \u0026amp;\u0026amp; readRpc[i].status == LOADING \u0026amp;\u0026amp; readRpc[i].maxPos \u0026lt; assignPos \u0026amp;\u0026amp; readRpc[i].numHashes \u0026lt; MAX_PKHASHES_PERRPC) { readActiveRpcId = i; break; } }  太过细节的high-level注释（选自《A Philosophy of Software Design》中的例子）\n 更好的high-level注释应该在更高级别上描述代码的整体功能：\n// Try to append the current key hash onto an existing // RPC to the desired server that hasn\u0026#39;t been sent yet. int readActiveRpcId = RPC_ID_NOT_ASSIGNED; for (int i = 0; i \u0026lt; NUM_READ_RPC; i++) { if (session == readRpc[i].session \u0026amp;\u0026amp; readRpc[i].status == LOADING \u0026amp;\u0026amp; readRpc[i].maxPos \u0026lt; assignPos \u0026amp;\u0026amp; readRpc[i].numHashes \u0026lt; MAX_PKHASHES_PERRPC) { readActiveRpcId = i; break; } }  典型的high-level注释（选自《A Philosophy of Software Design》中的例子）\n 规范接口注释 接口注释是用的最多的一种注释，它可以让读者快速了解整个模块的功能并知道如何使用该接口，而不必花费大量时间去阅读源码。\n对于一个类的接口注释，其通常是high-level的注释，主要描述这个类提供的一些功能；\n对于一个方法的接口注释，则同时需要包括high-level和low-level的注释，常见的有以下几点：\n 整个方法提供的主要功能 方法的所有参数和返回值含义 调用该方法的副作用（比如改变了系统的某个状态） 该方法可能抛出的所有异常 调用该方法的预置条件（比如调用该方法前，系统必须处于某个状态）  实现注释描述what、why，而不是how 写实现注释时需要记住的最重要的一点就是，描述代码是做什么的（what）和为什么这么做（why），而不是描述怎么做（how）。因为实现代码本身就是how，如果还添加描述how的注释，那就犯了“注释重复代码”的错误了。\n前文中的这个注释就是典型的描述how的注释，该注释除了用文字重复一遍代码的逻辑，并没有其他更好的用处：\n// If there is a LOADING readRpc using the same session // as PKHash pointed to by assignPos, and the last PKHash // in that readRPC is smaller than current assigning // PKHash, then we put assigning PKHash into that readRPC.   典型的描写how的实现注释（选自《A Philosophy of Software Design》中的例子）\n 更好的方法是描述what的注释，通过文字表达该段代码的用途，置于该用途是如何实现的，那就交给代码去解释吧！\n// Try to append the current key hash onto an existing // RPC to the desired server that hasn\u0026#39;t been sent yet.  典型的描写what的实现注释（选自《A Philosophy of Software Design》中的例子）\n 需要注意的是，实现注释通常不是必须的，对于一些简短的、功能单一的函数，一个好的函数命名即可替代实现注释。\n总结 注释是软件开发过程中的性价比极高的一个工具，它只需要花费20%的时间，即可获取80%的价值。代码注释最重要的作用就是让读者可以在不读源码的情况下，快速了解一段代码的主要功能。注释的作用还远远不止这些，John Ousterhout在《A Philosophy of Software Design》一书中提到，写注释最好的时机是在写代码之前。这样，注释就相当于一种设计工具：在编码前通过注释描述这段代码的功能，然后在通过编码实现这个功能，如果这个过程有偏差，则再调整注释。写注释时要切记两点，不要重复代码！更新代码后也要更新注释！前者可以减少冗余的注释，后者则可以避免因为过期的注释而误导读者。\n当然，注释也不是越多越好，如果一个系统写的注释太多，很有可能就是该系统设计得过于复杂，只能通过注释来帮助读者理解整个系统。\n总而言之，学会怎么写好代码注释，是一个程序员的必备技能，这即是为了开发团队的其他成员，也是为了未来的自己。\n","date":"2019-12-04T00:00:00Z","permalink":"https://www.yrunz.com/p/%E6%95%99%E4%BD%A0%E5%86%99%E5%A5%BD%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/","title":"教你写好代码注释"}]